{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"# banknote classification config\n\n# 超参配置\n# yaml\nclass Hyperparameter:\n    # ################################################################\n    #                             Data\n    # ################################################################\n    device = 'cuda'\n    data_root = '../input/celeba-dataset/img_align_celeba'\n\n    image_size = 64\n    seed = 1234  # random seed\n\n    # ################################################################\n    #                             Model Structure\n    # ################################################################\n    z_dim = 100\n    data_channels = 3\n\n    # ################################################################\n    #                             Experiment\n    # ################################################################\n    batch_size = 64\n    n_workers = 4\n    beta = 0.5\n    init_lr = 0.0002\n    epochs = 30\n    verbose_step = 250\n    save_step = 1000\n\n\nHP = Hyperparameter()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:35:00.7135Z","iopub.execute_input":"2022-04-27T01:35:00.714054Z","iopub.status.idle":"2022-04-27T01:35:00.739098Z","shell.execute_reply.started":"2022-04-27T01:35:00.713955Z","shell.execute_reply":"2022-04-27T01:35:00.738422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 生成必要的目录","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\nrandom.seed(HP.seed)\n\nfor foldername in ['data', 'log', 'model_save', 'model_save/Generator', 'model_save/Discriminator']:\n    if not os.path.exists(foldername):\n        os.mkdir(foldername)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:35:00.740297Z","iopub.execute_input":"2022-04-27T01:35:00.740653Z","iopub.status.idle":"2022-04-27T01:35:00.744914Z","shell.execute_reply.started":"2022-04-27T01:35:00.740624Z","shell.execute_reply":"2022-04-27T01:35:00.744407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset_face","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms as T\nimport torchvision.datasets as TD\nfrom torch.utils.data import DataLoader\nimport os\n\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n\ndata_face = TD.ImageFolder(\n    root=HP.data_root,\n    transform=T.Compose([\n        T.Resize(HP.image_size),\n        T.CenterCrop(HP.image_size),\n        T.ToTensor(),\n        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n)\n\nface_loader = DataLoader(data_face, batch_size=HP.batch_size, shuffle=True, num_workers=HP.n_workers)\n\ninvTrans = T.Compose([\n    T.Normalize((0., 0., 0.), (2, 2, 2)),\n    T.Normalize((-0.5, -0.5, -0.5), (1., 1., 1.))\n])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:35:00.74612Z","iopub.execute_input":"2022-04-27T01:35:00.746543Z","iopub.status.idle":"2022-04-27T01:37:49.338027Z","shell.execute_reply.started":"2022-04-27T01:35:00.746503Z","shell.execute_reply":"2022-04-27T01:37:49.337151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## generator","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\n\nclass Generator(nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.projection_layer = nn.Linear(HP.z_dim, 4 * 4 * 1024)\n\n        self.generator = nn.Sequential(\n\n            nn.ConvTranspose2d(\n                in_channels=1024,\n                out_channels=512,\n                kernel_size=(4, 4),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n\n            nn.ConvTranspose2d(\n                in_channels=512,\n                out_channels=256,\n                kernel_size=(4, 4),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n\n            nn.ConvTranspose2d(\n                in_channels=256,\n                out_channels=128,\n                kernel_size=(4, 4),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n\n            nn.ConvTranspose2d(\n                in_channels=128,\n                out_channels=HP.data_channels,\n                kernel_size=(4, 4),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.Tanh()\n        )\n\n    def forward(self, latent_z):\n        z = self.projection_layer(latent_z)\n        z_projected = z.view(-1, 1024, 4, 4)\n        return self.generator(z_projected)\n\n    @staticmethod\n    def weights_init(layer):\n        layer_class_name = layer.__class__.__name__\n        if 'Conv' in layer_class_name:\n            nn.init.normal_(layer.weight.data, 0.0, 0.02)\n        elif 'BatchNorm' in layer_class_name:\n            nn.init.normal_(layer.weight.data, 1.0, 0.02)\n            nn.init.normal_(layer.bias.data, 0.0)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:44:28.803706Z","iopub.execute_input":"2022-04-27T01:44:28.804027Z","iopub.status.idle":"2022-04-27T01:44:28.815574Z","shell.execute_reply.started":"2022-04-27T01:44:28.803983Z","shell.execute_reply":"2022-04-27T01:44:28.814782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## discriminator","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\n\nclass Discriminator(nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.discriminator = nn.Sequential(\n\n            nn.Conv2d(\n                in_channels=HP.data_channels,\n                out_channels=16,\n                kernel_size=(3, 3),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=(3, 3),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=(3, 3),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=(3, 3),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n\n            nn.Conv2d(\n                in_channels=128,\n                out_channels=256,\n                kernel_size=(3, 3),\n                stride=(2, 2),\n                padding=(1, 1),\n                bias=False\n            ),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2)\n        )\n\n        self.linear_layer = nn.Linear(256 * 2 * 2, 1)\n        self.out_ac = nn.Sigmoid()\n\n    def forward(self, image):\n        out_d = self.discriminator(image)\n        out_d = out_d.view(-1, 256 * 2 * 2)\n        return self.out_ac(self.linear_layer(out_d))\n\n    @staticmethod\n    def weights_init(layer):\n        layer_class_name = layer.__class__.__name__\n        if 'Conv' in layer_class_name:\n            nn.init.normal_(layer.weight.data, 0.0, 0.02)\n        elif 'BatchNorm' in layer_class_name:\n            nn.init.normal_(layer.weight.data, 1.0, 0.02)\n            nn.init.normal_(layer.bias.data, 0.0)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:45:01.024472Z","iopub.execute_input":"2022-04-27T01:45:01.024926Z","iopub.status.idle":"2022-04-27T01:45:01.036517Z","shell.execute_reply.started":"2022-04-27T01:45:01.024877Z","shell.execute_reply":"2022-04-27T01:45:01.035657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## trainer","metadata":{}},{"cell_type":"code","source":"import os\nfrom torch import optim\nimport torch\nimport random\nimport numpy as np\nfrom torch import nn\nfrom tensorboardX import SummaryWriter\nimport torchvision.utils as vutils\n\nlogger = SummaryWriter('./log')\n\n# seed init: 保证模型的可复现性\ntorch.manual_seed(HP.seed)\ntorch.random.manual_seed(HP.seed)\nrandom.seed(HP.seed)\nnp.random.seed(HP.seed)\ntorch.cuda.manual_seed(HP.seed)\n\n\ndef save_checkpoint(model, epoch, opt, save_path):\n    save_dict = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': opt.state_dict()\n    }\n    torch.save(save_dict, save_path)\n\n\ndef train():\n\n    # 实例化Generator和Discriminator，并进行参数的初始化\n    G = Generator()\n    G.apply(G.weights_init)\n    D = Discriminator()\n    D.apply(D.weights_init)\n    G.to(HP.device)\n    D.to(HP.device)\n\n    # loss criterion\n    criterion = nn.BCELoss()\n\n    # optimizer\n    optimizer_g = optim.Adam(G.parameters(), lr=HP.init_lr, betas=(HP.beta, 0.999))\n    optimizer_d = optim.Adam(D.parameters(), lr=HP.init_lr, betas=(HP.beta, 0.999))\n\n    start_epoch, step = 0, 0\n\n    G.train()\n    D.train()\n\n    fixed_latent_z = torch.randn(size=(64, 100), device=HP.device)\n\n    for epoch in range(start_epoch, HP.epochs):\n        print('Start Epoch: %d, Step: %d' % (epoch, len(face_loader)))\n        for batch, _ in face_loader:\n            b_size = batch.size(0)\n\n            # 训练Discriminator\n            optimizer_d.zero_grad()\n\n            labels_gt = torch.full(size=(b_size,), fill_value=0.9, dtype=torch.float32, device=HP.device)\n            predict_labels_gt = D(batch.to(HP.device)).squeeze()\n            loss_d_of_gt = criterion(predict_labels_gt, labels_gt)\n\n            labels_fake = torch.full(size=(b_size,), fill_value=0.1, dtype=torch.float32, device=HP.device)\n            latent_z = torch.randn(size=(b_size, HP.z_dim), device=HP.device)\n            predict_labels_fake = D(G(latent_z)).squeeze()\n            loss_d_of_fake = criterion(predict_labels_fake, labels_fake)\n\n            loss_D = loss_d_of_gt + loss_d_of_fake\n            loss_D.backward()\n            optimizer_d.step()\n            logger.add_scalar('Loss/Discriminator', loss_D.mean().item(), step)\n\n            # 训练Generator\n            optimizer_g.zero_grad()\n\n            latent_z = torch.randn(size=(b_size, HP.z_dim), device=HP.device)\n            labels_for_g = torch.full(size=(b_size,), fill_value=0.9, dtype=torch.float32, device=HP.device)\n            predict_labels_from_g = D(G(latent_z)).squeeze()\n\n            loss_G = criterion(predict_labels_from_g, labels_for_g)\n            loss_G.backward()\n            optimizer_g.step()\n            logger.add_scalar('Loss/Generator', loss_G.mean().item(), step)\n\n            if not step % HP.verbose_step:\n                with torch.no_grad():\n                    fake_image_dev = G(fixed_latent_z)\n                    logger.add_image('Generator Face', invTrans(vutils.make_grid(fake_image_dev.detach().cpu(), nrow=8)), step)\n\n            if not step % HP.save_step:\n                model_path_g = 'model_g_%d_%d.pth' % (epoch, step)\n                save_checkpoint(G, epoch, optimizer_g, os.path.join('model_save','Generator', model_path_g))\n                model_path_d = 'model_d_%d_%d.pth' % (epoch, step)\n                save_checkpoint(D, epoch, optimizer_d, os.path.join('model_save','Discriminator', model_path_d))\n\n            step += 1\n            logger.flush()\n            print('Epoch:[%d/%d], step:%d, Discriminator Loss:%.5f, Generator Loss:%.5f' % (\n                epoch, HP.epochs, step, loss_D.mean().item(), loss_G.mean().item()))\n\n    logger.close()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:47:35.451878Z","iopub.execute_input":"2022-04-27T01:47:35.452752Z","iopub.status.idle":"2022-04-27T01:47:35.473882Z","shell.execute_reply.started":"2022-04-27T01:47:35.452705Z","shell.execute_reply":"2022-04-27T01:47:35.472958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 训练","metadata":{}},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T01:47:37.876265Z","iopub.execute_input":"2022-04-27T01:47:37.876554Z","iopub.status.idle":"2022-04-27T01:56:07.169087Z","shell.execute_reply.started":"2022-04-27T01:47:37.876523Z","shell.execute_reply":"2022-04-27T01:56:07.168244Z"},"trusted":true},"execution_count":null,"outputs":[]}]}