{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"# banknote classification config\n\n# 超参配置\n# yaml\nclass Hyperparameter:\n    # ################################################################\n    #                             Data\n    # ################################################################\n    device = 'cuda'\n    data_root = './data/'\n    cls_mapper_path = './data/cls_mapper.json'\n    train_data_root = '../input/sabastien-marcel/shp_marcel_train/Marcel-Train'\n    test_data_root = '../input/sabastien-marcel/shp_marcel_test/Marcel-Test'\n\n    metadata_train_path = './data/train_hand_gesture.txt'\n    metadata_eval_path = './data/eval_hand_gesture.txt'\n    metadata_test_path = './data/test_hand_gesture.txt'\n\n    class_num = 6\n    seed = 1234  # random seed\n\n    # ################################################################\n    #                             Model Structure\n    # ################################################################\n    data_channels = 3\n    conv_kernel_size = 3\n    fc_drop_prob = 0.3\n\n    # ################################################################\n    #                             Experiment\n    # ################################################################\n    batch_size = 16\n    init_lr = 5e-4\n    epochs = 100\n    verbose_step = 250\n    save_step = 1500\n\n\nHP = Hyperparameter()","metadata":{"_uuid":"65394a79-318f-4608-91c7-ecd79c1be0a3","_cell_guid":"8294ca81-28cf-4514-9b6f-15ae769774b0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## utils","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\n\n# 获取某个文件夹下面所有后缀为suffix的文件，返回path的list\ndef recursive_fetching(root, suffix=['jpg', 'png']):\n    all_file_path = []\n\n    def get_all_files(path):\n        all_file_list = os.listdir(path)\n        # 遍历该文件夹下的所有目录或者文件\n        for file in all_file_list:\n            filepath = os.path.join(path, file)\n            # 如果是文件夹，递归调用函数\n            if os.path.isdir(filepath):\n                get_all_files(filepath)\n            # 如果不是文件夹，保存文件路径及文件名\n            elif os.path.isfile(filepath):\n                all_file_path.append(filepath)\n\n    get_all_files(root)\n\n    file_paths = [it for it in all_file_path if os.path.split(it)[-1].split('.')[-1].lower() in suffix]\n\n    return file_paths\n\n\ndef load_meta(meta_path):\n    with open(meta_path, 'r') as fr:\n        return [line.strip().split('|') for line in fr.readlines()]\n\n\ndef load_image(image_path):\n    return Image.open(image_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport json\n\nfor foldername in ['data', 'log', 'model_save']:\n    if not os.path.exists(foldername):\n        os.mkdir(foldername)\n\nnp.random.seed(HP.seed)\n\n# 构建类别到id的映射\ncls_mapper = {\n    'cls2id': {'A': 0, 'B': 1, 'C': 2, 'Five': 3, 'Point': 4, 'V': 5},\n    'id2cls': {0: 'A', 1: 'B', 2: 'C', 3: 'Five', 4: 'Point', 5: 'V'}\n}\njson.dump(cls_mapper, open(HP.cls_mapper_path, 'w'))\n\n# 获取训练集和测试集，并将它们合并\ntrain_items = recursive_fetching(HP.train_data_root, ['ppm'])\ntest_items = recursive_fetching(HP.test_data_root, ['ppm'])\ndataset = train_items + test_items\ndataset_num = len(dataset)\nrandom.shuffle(dataset)\n\ndataset_dict = {}\nfor it in dataset:\n    fn_start = os.path.split(it)[-1].split('-')[0]\n    cls_id = cls_mapper['cls2id'][fn_start]\n    if cls_id not in dataset_dict:\n        dataset_dict[cls_id] = [it]\n    else:\n        dataset_dict[cls_id].append(it)\n\n# 自己划分训练集、评价集和测试集\ntrain_ratio, eval_ratio, test_ratio = 0.8, 0.1, 0.1\ntrain_set, eval_set, test_set = [], [], [],\nfor _, set_list in dataset_dict.items():\n    length = len(set_list)\n    train_num, eval_num = int(length * train_ratio), int(length * eval_ratio)\n    test_num = length - train_num - eval_num\n    random.shuffle(set_list)\n    train_set.extend(set_list[:train_num])\n    eval_set.extend(set_list[train_num:train_num + eval_num])\n    test_set.extend(set_list[train_num + eval_num:])\n\nrandom.shuffle(train_set)\nrandom.shuffle(eval_set)\nrandom.shuffle(test_set)\n\nprint('num of trainset : %d' % (len(train_set)))\nprint('num of evalset : %d' % (len(eval_set)))\nprint('num of testset : %d' % (len(test_set)))\n\nwith open(HP.metadata_train_path, 'w') as fw:\n    for path in train_set:\n        fn_start = os.path.split(path)[-1].split('-')[0]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))\n\nwith open(HP.metadata_eval_path, 'w') as fw:\n    for path in eval_set:\n        fn_start = os.path.split(path)[-1].split('-')[0]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))\n\nwith open(HP.metadata_test_path, 'w') as fw:\n    for path in test_set:\n        fn_start = os.path.split(path)[-1].split('-')[0]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))\n\n\nmode_set, size_set = [], [],\nfor _, path in load_meta(HP.metadata_test_path):\n    img = load_image(path)\n    mode_set.append(img.mode)\n    size_set.append(img.size)\n\nprint(set(mode_set), set(size_set))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset_hg","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\nhg_transform = T.Compose([\n    T.Resize((112, 112)),\n    T.RandomRotation(degrees=45),\n    T.GaussianBlur(kernel_size=(3, 3)),\n    T.RandomHorizontalFlip(),\n    T.ToTensor(),\n    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\nclass HandGestureDataset(torch.utils.data.Dataset):\n\n    def __init__(self, metadata_path):\n        self.dataset = load_meta(metadata_path)\n\n    def __getitem__(self, index):\n        item = self.dataset[index]\n        cls_id, path = int(item[0]), item[1]\n        image = load_image(path)\n        return hg_transform(image).to(HP.device), cls_id\n    \n    def __len__(self):\n        return len(self.dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn.functional import mish\n\n\nclass DSConv2d(torch.nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(DSConv2d, self).__init__()\n        assert kernel_size % 2 == 1, 'kernel_size must be odd!'\n        self.depth_conv = torch.nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=in_channels,\n            kernel_size=(kernel_size, kernel_size),\n            padding=(kernel_size // 2, kernel_size // 2),\n            groups=in_channels\n        )\n        self.pointwise_conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 1))\n\n    def forward(self, x):\n        out = self.depth_conv(x)\n        out_final = self.pointwise_conv(out)\n        return out_final\n\n\nclass TrialBlock(torch.nn.Module):\n\n    def __init__(self, in_channels):\n        super(TrialBlock, self).__init__()\n        self.left_flow = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=(1, 1)),\n            torch.nn.BatchNorm2d(in_channels),\n            torch.nn.Mish(),\n            DSConv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3),\n            torch.nn.BatchNorm2d(in_channels),\n            torch.nn.Mish(),\n            torch.nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=in_channels, kernel_size=(7, 7),\n                padding=(7 // 2, 7 // 2)\n            )\n        )\n        self.right_flow = torch.nn.Sequential(\n            torch.nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=in_channels, kernel_size=(7, 7),\n                padding=(7 // 2, 7 // 2)\n            ),\n            torch.nn.BatchNorm2d(in_channels),\n            torch.nn.Mish(),\n            DSConv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3),\n            torch.nn.BatchNorm2d(in_channels),\n            torch.nn.Mish(),\n            torch.nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=(1, 1))\n        )\n\n    def forward(self, x):\n        out = self.left_flow(x) + self.right_flow(x) + x\n        out_final = mish(out)\n        return out_final\n\n\nclass TrialNet(torch.nn.Module):\n\n    def __init__(self):\n        super(TrialNet, self).__init__()\n\n        self.tn_conv = torch.nn.Sequential(\n\n            torch.nn.Conv2d(\n                in_channels=HP.data_channels,\n                out_channels=64,\n                kernel_size=(3, 3),\n                padding=(3 // 2, 3 // 2)\n            ),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.Mish(),\n            TrialBlock(in_channels=64),\n            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n\n            torch.nn.Conv2d(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=(3, 3),\n                padding=(3 // 2, 3 // 2)\n            ),\n            torch.nn.BatchNorm2d(128),\n            torch.nn.Mish(),\n            TrialBlock(in_channels=128),\n            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n\n            torch.nn.Conv2d(\n                in_channels=128,\n                out_channels=256,\n                kernel_size=(3, 3),\n                padding=(3 // 2, 3 // 2)\n            ),\n            torch.nn.BatchNorm2d(256),\n            torch.nn.Mish(),\n            TrialBlock(in_channels=256),\n            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n\n            TrialBlock(in_channels=256),\n            TrialBlock(in_channels=256),\n            TrialBlock(in_channels=256),\n            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        )\n\n        self.tn_fc = torch.nn.Sequential(\n\n            torch.nn.Linear(in_features=256 * 7 * 7, out_features=2048),\n            torch.nn.Mish(),\n            torch.nn.Dropout(HP.fc_drop_prob),\n\n            torch.nn.Linear(in_features=2048, out_features=1024),\n            torch.nn.Mish(),\n            torch.nn.Dropout(HP.fc_drop_prob),\n\n            torch.nn.Linear(in_features=1024, out_features=HP.class_num)\n        )\n\n    def forward(self, x):\n        out = self.tn_conv(x)\n        out_final = self.tn_fc(out.view(x.size(0), -1))\n        return out_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## trainer","metadata":{}},{"cell_type":"code","source":"import os.path\nimport random\nimport torch\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\n\nlogger = SummaryWriter('./log')\n\n# seed init: 保证模型的可复现性\ntorch.manual_seed(HP.seed)\nrandom.seed(HP.seed)\nnp.random.seed(HP.seed)\ntorch.cuda.manual_seed(HP.seed)\n\n\ndef evaluate(model, devloader, crit):\n    model.eval()\n    sum_loss = 0.\n    with torch.no_grad():\n        for batch in devloader:\n            x, y = batch\n            pred = model(x)\n            loss = crit(pred, y.to(HP.device))\n            sum_loss += loss.item()\n\n    model.train()\n    return sum_loss / len(devloader)\n\n\ndef save_checkpoint(model, epoch, opt, save_path):\n    save_dict = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': opt.state_dict()\n    }\n    torch.save(save_dict, save_path)\n\n\ndef train():\n\n    model = TrialNet().to(HP.device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    opt = optim.Adam(model.parameters(), lr=HP.init_lr)\n\n    trainset = HandGestureDataset(HP.metadata_train_path)\n    train_loader = DataLoader(trainset, batch_size=HP.batch_size, shuffle=True, drop_last=True)\n\n    devset = HandGestureDataset(HP.metadata_eval_path)\n    dev_loader = DataLoader(devset, batch_size=HP.batch_size, shuffle=True, drop_last=False)\n\n    start_epoch, step = 0, 0\n\n    model.train()\n\n    for epoch in range(start_epoch, HP.epochs):\n        print('Start Epoch: %d, Steps: %d' % (epoch, len(train_loader) / HP.batch_size))\n        for batch in train_loader:\n            x, y = batch  # 加载数据\n            opt.zero_grad()  # 梯度归零\n            pred = model(x)\n            loss = criterion(pred, y.to(HP.device))\n            \n            loss.backward()\n            opt.step()\n\n            logger.add_scalar('Loss/Train', loss, step)\n\n            if not step % HP.verbose_step:\n                eval_loss = evaluate(model, dev_loader, criterion)\n                logger.add_scalar('Loss/Dev', eval_loss, step)\n\n            if not step % HP.save_step:\n                model_path = 'model_%d_%d.model' % (epoch, step)\n                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n            \n            if step == 7000:\n                model_path = 'model_%d_%d.model' % (epoch, step)\n                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n\n            step += 1\n            logger.flush()\n            print('Epoch:[%d/%d], step:%d, Train Loss:%.5f, Dev Loss:%.5f' % (epoch, HP.epochs, step, loss.item(), eval_loss))\n\n    torch.save(model, \"hgmodel.dm\")\n    logger.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}