{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70252cd9",
   "metadata": {
    "papermill": {
     "duration": 0.01086,
     "end_time": "2022-04-22T09:29:57.224277",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.213417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15612ab3",
   "metadata": {
    "_cell_guid": "8294ca81-28cf-4514-9b6f-15ae769774b0",
    "_uuid": "65394a79-318f-4608-91c7-ecd79c1be0a3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-22T09:29:57.257687Z",
     "iopub.status.busy": "2022-04-22T09:29:57.256434Z",
     "iopub.status.idle": "2022-04-22T09:29:57.260384Z",
     "shell.execute_reply": "2022-04-22T09:29:57.259906Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025054,
     "end_time": "2022-04-22T09:29:57.260512",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.235458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# banknote classification config\n",
    "\n",
    "# 超参配置\n",
    "# yaml\n",
    "class Hyperparameter:\n",
    "    # ################################################################\n",
    "    #                             Data\n",
    "    # ################################################################\n",
    "    device = 'cuda'\n",
    "    data_root = './data/'\n",
    "    cls_mapper_path = './data/cls_mapper.json'\n",
    "    train_data_root = '../input/sabastien-marcel/shp_marcel_train/Marcel-Train'\n",
    "    test_data_root = '../input/sabastien-marcel/shp_marcel_test/Marcel-Test'\n",
    "\n",
    "    metadata_train_path = './data/train_hand_gesture.txt'\n",
    "    metadata_eval_path = './data/eval_hand_gesture.txt'\n",
    "    metadata_test_path = './data/test_hand_gesture.txt'\n",
    "\n",
    "    class_num = 6\n",
    "    seed = 1234  # random seed\n",
    "\n",
    "    # ################################################################\n",
    "    #                             Model Structure\n",
    "    # ################################################################\n",
    "    data_channels = 3\n",
    "    conv_kernel_size = 3\n",
    "    fc_drop_prob = 0.3\n",
    "\n",
    "    # ################################################################\n",
    "    #                             Experiment\n",
    "    # ################################################################\n",
    "    batch_size = 16\n",
    "    init_lr = 5e-4\n",
    "    epochs = 100\n",
    "    verbose_step = 250\n",
    "    save_step = 1500\n",
    "\n",
    "\n",
    "HP = Hyperparameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb024a",
   "metadata": {
    "papermill": {
     "duration": 0.009222,
     "end_time": "2022-04-22T09:29:57.279305",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.270083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e52439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:29:57.306953Z",
     "iopub.status.busy": "2022-04-22T09:29:57.306142Z",
     "iopub.status.idle": "2022-04-22T09:29:57.307838Z",
     "shell.execute_reply": "2022-04-22T09:29:57.308272Z"
    },
    "papermill": {
     "duration": 0.019775,
     "end_time": "2022-04-22T09:29:57.308396",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.288621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 获取某个文件夹下面所有后缀为suffix的文件，返回path的list\n",
    "def recursive_fetching(root, suffix=['jpg', 'png']):\n",
    "    all_file_path = []\n",
    "\n",
    "    def get_all_files(path):\n",
    "        all_file_list = os.listdir(path)\n",
    "        # 遍历该文件夹下的所有目录或者文件\n",
    "        for file in all_file_list:\n",
    "            filepath = os.path.join(path, file)\n",
    "            # 如果是文件夹，递归调用函数\n",
    "            if os.path.isdir(filepath):\n",
    "                get_all_files(filepath)\n",
    "            # 如果不是文件夹，保存文件路径及文件名\n",
    "            elif os.path.isfile(filepath):\n",
    "                all_file_path.append(filepath)\n",
    "\n",
    "    get_all_files(root)\n",
    "\n",
    "    file_paths = [it for it in all_file_path if os.path.split(it)[-1].split('.')[-1].lower() in suffix]\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def load_meta(meta_path):\n",
    "    with open(meta_path, 'r') as fr:\n",
    "        return [line.strip().split('|') for line in fr.readlines()]\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    return Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4aca1",
   "metadata": {
    "papermill": {
     "duration": 0.009905,
     "end_time": "2022-04-22T09:29:57.327717",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.317812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9f57ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:29:57.364071Z",
     "iopub.status.busy": "2022-04-22T09:29:57.363456Z",
     "iopub.status.idle": "2022-04-22T09:30:01.139440Z",
     "shell.execute_reply": "2022-04-22T09:30:01.139001Z"
    },
    "papermill": {
     "duration": 3.802402,
     "end_time": "2022-04-22T09:30:01.139589",
     "exception": false,
     "start_time": "2022-04-22T09:29:57.337187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of trainset : 4423\n",
      "num of evalset : 550\n",
      "num of testset : 558\n",
      "{'RGB'} {(90, 78), (140, 140), (80, 66), (78, 90), (120, 120), (66, 76), (64, 74), (84, 72), (76, 66), (384, 288), (76, 88), (72, 84), (56, 66), (50, 50), (70, 82), (80, 68), (68, 80), (82, 70), (66, 78), (155, 155), (100, 100), (240, 320), (88, 76)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "for foldername in ['data', 'log', 'model_save']:\n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "\n",
    "np.random.seed(HP.seed)\n",
    "\n",
    "# 构建类别到id的映射\n",
    "cls_mapper = {\n",
    "    'cls2id': {'A': 0, 'B': 1, 'C': 2, 'Five': 3, 'Point': 4, 'V': 5},\n",
    "    'id2cls': {0: 'A', 1: 'B', 2: 'C', 3: 'Five', 4: 'Point', 5: 'V'}\n",
    "}\n",
    "json.dump(cls_mapper, open(HP.cls_mapper_path, 'w'))\n",
    "\n",
    "# 获取训练集和测试集，并将它们合并\n",
    "train_items = recursive_fetching(HP.train_data_root, ['ppm'])\n",
    "test_items = recursive_fetching(HP.test_data_root, ['ppm'])\n",
    "dataset = train_items + test_items\n",
    "dataset_num = len(dataset)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "dataset_dict = {}\n",
    "for it in dataset:\n",
    "    fn_start = os.path.split(it)[-1].split('-')[0]\n",
    "    cls_id = cls_mapper['cls2id'][fn_start]\n",
    "    if cls_id not in dataset_dict:\n",
    "        dataset_dict[cls_id] = [it]\n",
    "    else:\n",
    "        dataset_dict[cls_id].append(it)\n",
    "\n",
    "# 自己划分训练集、评价集和测试集\n",
    "train_ratio, eval_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "train_set, eval_set, test_set = [], [], [],\n",
    "for _, set_list in dataset_dict.items():\n",
    "    length = len(set_list)\n",
    "    train_num, eval_num = int(length * train_ratio), int(length * eval_ratio)\n",
    "    test_num = length - train_num - eval_num\n",
    "    random.shuffle(set_list)\n",
    "    train_set.extend(set_list[:train_num])\n",
    "    eval_set.extend(set_list[train_num:train_num + eval_num])\n",
    "    test_set.extend(set_list[train_num + eval_num:])\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(eval_set)\n",
    "random.shuffle(test_set)\n",
    "\n",
    "print('num of trainset : %d' % (len(train_set)))\n",
    "print('num of evalset : %d' % (len(eval_set)))\n",
    "print('num of testset : %d' % (len(test_set)))\n",
    "\n",
    "with open(HP.metadata_train_path, 'w') as fw:\n",
    "    for path in train_set:\n",
    "        fn_start = os.path.split(path)[-1].split('-')[0]\n",
    "        cls_id = cls_mapper['cls2id'][fn_start]\n",
    "        fw.write('%d|%s\\n' % (cls_id, path))\n",
    "\n",
    "with open(HP.metadata_eval_path, 'w') as fw:\n",
    "    for path in eval_set:\n",
    "        fn_start = os.path.split(path)[-1].split('-')[0]\n",
    "        cls_id = cls_mapper['cls2id'][fn_start]\n",
    "        fw.write('%d|%s\\n' % (cls_id, path))\n",
    "\n",
    "with open(HP.metadata_test_path, 'w') as fw:\n",
    "    for path in test_set:\n",
    "        fn_start = os.path.split(path)[-1].split('-')[0]\n",
    "        cls_id = cls_mapper['cls2id'][fn_start]\n",
    "        fw.write('%d|%s\\n' % (cls_id, path))\n",
    "\n",
    "\n",
    "mode_set, size_set = [], [],\n",
    "for _, path in load_meta(HP.metadata_test_path):\n",
    "    img = load_image(path)\n",
    "    mode_set.append(img.mode)\n",
    "    size_set.append(img.size)\n",
    "\n",
    "print(set(mode_set), set(size_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784f3ad",
   "metadata": {
    "papermill": {
     "duration": 0.010119,
     "end_time": "2022-04-22T09:30:01.160610",
     "exception": false,
     "start_time": "2022-04-22T09:30:01.150491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## dataset_hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b125951b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:30:01.189928Z",
     "iopub.status.busy": "2022-04-22T09:30:01.189240Z",
     "iopub.status.idle": "2022-04-22T09:30:02.715180Z",
     "shell.execute_reply": "2022-04-22T09:30:02.714698Z"
    },
    "papermill": {
     "duration": 1.544531,
     "end_time": "2022-04-22T09:30:02.715317",
     "exception": false,
     "start_time": "2022-04-22T09:30:01.170786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "hg_transform = T.Compose([\n",
    "    T.Resize((112, 112)),\n",
    "    T.RandomRotation(degrees=45),\n",
    "    T.GaussianBlur(kernel_size=(3, 3)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "class HandGestureDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, metadata_path):\n",
    "        self.dataset = load_meta(metadata_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataset[index]\n",
    "        cls_id, path = int(item[0]), item[1]\n",
    "        image = load_image(path)\n",
    "        return hg_transform(image).to(HP.device), cls_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f8ebe",
   "metadata": {
    "papermill": {
     "duration": 0.01032,
     "end_time": "2022-04-22T09:30:02.736368",
     "exception": false,
     "start_time": "2022-04-22T09:30:02.726048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16569c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:30:02.781808Z",
     "iopub.status.busy": "2022-04-22T09:30:02.776452Z",
     "iopub.status.idle": "2022-04-22T09:30:02.783631Z",
     "shell.execute_reply": "2022-04-22T09:30:02.784047Z"
    },
    "papermill": {
     "duration": 0.037363,
     "end_time": "2022-04-22T09:30:02.784182",
     "exception": false,
     "start_time": "2022-04-22T09:30:02.746819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import mish\n",
    "\n",
    "\n",
    "class DSConv2d(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(DSConv2d, self).__init__()\n",
    "        assert kernel_size % 2 == 1, 'kernel_size must be odd!'\n",
    "        self.depth_conv = torch.nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=(kernel_size, kernel_size),\n",
    "            padding=(kernel_size // 2, kernel_size // 2),\n",
    "            groups=in_channels\n",
    "        )\n",
    "        self.pointwise_conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depth_conv(x)\n",
    "        out_final = self.pointwise_conv(out)\n",
    "        return out_final\n",
    "\n",
    "\n",
    "class TrialBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(TrialBlock, self).__init__()\n",
    "        self.left_flow = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=(1, 1)),\n",
    "            torch.nn.BatchNorm2d(in_channels),\n",
    "            torch.nn.Mish(),\n",
    "            DSConv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(in_channels),\n",
    "            torch.nn.Mish(),\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=in_channels, kernel_size=(7, 7),\n",
    "                padding=(7 // 2, 7 // 2)\n",
    "            )\n",
    "        )\n",
    "        self.right_flow = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=in_channels, kernel_size=(7, 7),\n",
    "                padding=(7 // 2, 7 // 2)\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(in_channels),\n",
    "            torch.nn.Mish(),\n",
    "            DSConv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(in_channels),\n",
    "            torch.nn.Mish(),\n",
    "            torch.nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=(1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left_flow(x) + self.right_flow(x) + x\n",
    "        out_final = mish(out)\n",
    "        return out_final\n",
    "\n",
    "\n",
    "class TrialNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TrialNet, self).__init__()\n",
    "\n",
    "        self.tn_conv = torch.nn.Sequential(\n",
    "\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=HP.data_channels,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(3 // 2, 3 // 2)\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Mish(),\n",
    "            TrialBlock(in_channels=64),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(3 // 2, 3 // 2)\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Mish(),\n",
    "            TrialBlock(in_channels=128),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(3 // 2, 3 // 2)\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.Mish(),\n",
    "            TrialBlock(in_channels=256),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            TrialBlock(in_channels=256),\n",
    "            TrialBlock(in_channels=256),\n",
    "            TrialBlock(in_channels=256),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.tn_fc = torch.nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(in_features=256 * 7 * 7, out_features=2048),\n",
    "            torch.nn.Mish(),\n",
    "            torch.nn.Dropout(HP.fc_drop_prob),\n",
    "\n",
    "            torch.nn.Linear(in_features=2048, out_features=1024),\n",
    "            torch.nn.Mish(),\n",
    "            torch.nn.Dropout(HP.fc_drop_prob),\n",
    "\n",
    "            torch.nn.Linear(in_features=1024, out_features=HP.class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.tn_conv(x)\n",
    "        out_final = self.tn_fc(out.view(x.size(0), -1))\n",
    "        return out_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad0d3e",
   "metadata": {
    "papermill": {
     "duration": 0.010551,
     "end_time": "2022-04-22T09:30:02.805355",
     "exception": false,
     "start_time": "2022-04-22T09:30:02.794804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7841fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:30:02.842557Z",
     "iopub.status.busy": "2022-04-22T09:30:02.841858Z",
     "iopub.status.idle": "2022-04-22T09:30:02.931722Z",
     "shell.execute_reply": "2022-04-22T09:30:02.931256Z"
    },
    "papermill": {
     "duration": 0.115985,
     "end_time": "2022-04-22T09:30:02.931851",
     "exception": false,
     "start_time": "2022-04-22T09:30:02.815866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logger = SummaryWriter('./log')\n",
    "\n",
    "# seed init: 保证模型的可复现性\n",
    "torch.manual_seed(HP.seed)\n",
    "random.seed(HP.seed)\n",
    "np.random.seed(HP.seed)\n",
    "torch.cuda.manual_seed(HP.seed)\n",
    "\n",
    "\n",
    "def evaluate(model, devloader, crit):\n",
    "    model.eval()\n",
    "    sum_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch in devloader:\n",
    "            x, y = batch\n",
    "            pred = model(x)\n",
    "            loss = crit(pred, y.to(HP.device))\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "    model.train()\n",
    "    return sum_loss / len(devloader)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, epoch, opt, save_path):\n",
    "    save_dict = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict()\n",
    "    }\n",
    "    torch.save(save_dict, save_path)\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    model = TrialNet().to(HP.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=HP.init_lr)\n",
    "\n",
    "    trainset = HandGestureDataset(HP.metadata_train_path)\n",
    "    train_loader = DataLoader(trainset, batch_size=HP.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    devset = HandGestureDataset(HP.metadata_eval_path)\n",
    "    dev_loader = DataLoader(devset, batch_size=HP.batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    start_epoch, step = 0, 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(start_epoch, HP.epochs):\n",
    "        print('Start Epoch: %d, Steps: %d' % (epoch, len(train_loader) / HP.batch_size))\n",
    "        for batch in train_loader:\n",
    "            x, y = batch  # 加载数据\n",
    "            opt.zero_grad()  # 梯度归零\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y.to(HP.device))\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            logger.add_scalar('Loss/Train', loss, step)\n",
    "\n",
    "            if not step % HP.verbose_step:\n",
    "                eval_loss = evaluate(model, dev_loader, criterion)\n",
    "                logger.add_scalar('Loss/Dev', eval_loss, step)\n",
    "\n",
    "            if not step % HP.save_step:\n",
    "                model_path = 'model_%d_%d.model' % (epoch, step)\n",
    "                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n",
    "            \n",
    "            if step == 7000:\n",
    "                model_path = 'model_%d_%d.model' % (epoch, step)\n",
    "                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n",
    "\n",
    "            step += 1\n",
    "            logger.flush()\n",
    "            print('Epoch:[%d/%d], step:%d, Train Loss:%.5f, Dev Loss:%.5f' % (epoch, HP.epochs, step, loss.item(), eval_loss))\n",
    "\n",
    "    torch.save(model, \"hgmodel.dm\")\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b756e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-22T09:30:02.958985Z",
     "iopub.status.busy": "2022-04-22T09:30:02.955793Z",
     "iopub.status.idle": "2022-04-22T12:19:06.020107Z",
     "shell.execute_reply": "2022-04-22T12:19:06.019313Z"
    },
    "papermill": {
     "duration": 10143.07762,
     "end_time": "2022-04-22T12:19:06.020384",
     "exception": false,
     "start_time": "2022-04-22T09:30:02.942764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Epoch: 0, Steps: 17\n",
      "Epoch:[0/100], step:1, Train Loss:1.74033, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:2, Train Loss:2.17671, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:3, Train Loss:9.08771, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:4, Train Loss:2.88641, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:5, Train Loss:1.85194, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:6, Train Loss:5.25086, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:7, Train Loss:1.75496, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:8, Train Loss:1.89078, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:9, Train Loss:2.21997, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:10, Train Loss:1.96299, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:11, Train Loss:2.20927, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:12, Train Loss:1.81548, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:13, Train Loss:1.66081, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:14, Train Loss:2.41352, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:15, Train Loss:1.84703, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:16, Train Loss:1.86500, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:17, Train Loss:2.12504, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:18, Train Loss:1.74286, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:19, Train Loss:1.71590, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:20, Train Loss:1.86809, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:21, Train Loss:1.82680, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:22, Train Loss:1.67369, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:23, Train Loss:1.71999, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:24, Train Loss:1.72269, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:25, Train Loss:1.41877, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:26, Train Loss:1.24923, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:27, Train Loss:1.44055, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:28, Train Loss:1.36496, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:29, Train Loss:1.35177, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:30, Train Loss:2.38427, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:31, Train Loss:1.73835, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:32, Train Loss:1.68637, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:33, Train Loss:1.46670, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:34, Train Loss:1.45733, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:35, Train Loss:1.45824, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:36, Train Loss:1.58285, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:37, Train Loss:1.33931, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:38, Train Loss:1.54954, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:39, Train Loss:2.26869, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:40, Train Loss:1.32545, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:41, Train Loss:1.28379, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:42, Train Loss:1.45756, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:43, Train Loss:1.10766, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:44, Train Loss:3.82301, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:45, Train Loss:1.38231, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:46, Train Loss:1.35458, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:47, Train Loss:1.22669, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:48, Train Loss:1.43062, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:49, Train Loss:1.27744, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:50, Train Loss:2.16718, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:51, Train Loss:1.49323, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:52, Train Loss:2.00353, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:53, Train Loss:1.79650, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:54, Train Loss:1.32011, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:55, Train Loss:1.61031, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:56, Train Loss:1.60305, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:57, Train Loss:1.37537, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:58, Train Loss:1.79066, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:59, Train Loss:1.88135, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:60, Train Loss:1.59471, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:61, Train Loss:1.57497, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:62, Train Loss:1.76409, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:63, Train Loss:2.03833, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:64, Train Loss:1.51874, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:65, Train Loss:1.67236, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:66, Train Loss:1.61254, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:67, Train Loss:2.00817, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:68, Train Loss:1.45239, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:69, Train Loss:1.74442, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:70, Train Loss:1.87999, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:71, Train Loss:1.34886, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:72, Train Loss:1.48213, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:73, Train Loss:1.37760, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:74, Train Loss:1.36094, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:75, Train Loss:1.29870, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:76, Train Loss:1.51351, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:77, Train Loss:2.21211, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:78, Train Loss:1.86738, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:79, Train Loss:1.62449, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:80, Train Loss:1.38422, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:81, Train Loss:1.42975, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:82, Train Loss:1.63842, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:83, Train Loss:1.29122, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:84, Train Loss:1.33692, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:85, Train Loss:1.90455, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:86, Train Loss:1.52110, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:87, Train Loss:1.34740, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:88, Train Loss:1.06695, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:89, Train Loss:1.23153, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:90, Train Loss:1.40146, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:91, Train Loss:1.56520, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:92, Train Loss:1.58820, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:93, Train Loss:1.05918, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:94, Train Loss:1.26411, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:95, Train Loss:1.18971, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:96, Train Loss:1.32583, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:97, Train Loss:1.27279, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:98, Train Loss:1.56011, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:99, Train Loss:1.11279, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:100, Train Loss:1.34139, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:101, Train Loss:1.74350, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:102, Train Loss:1.82703, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:103, Train Loss:3.03214, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:104, Train Loss:1.88582, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:105, Train Loss:1.29959, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:106, Train Loss:1.56312, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:107, Train Loss:1.78381, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:108, Train Loss:1.20905, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:109, Train Loss:1.46687, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:110, Train Loss:1.28457, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:111, Train Loss:1.76287, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:112, Train Loss:1.17502, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:113, Train Loss:1.74579, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:114, Train Loss:1.22499, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:115, Train Loss:1.14540, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:116, Train Loss:1.34292, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:117, Train Loss:1.46397, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:118, Train Loss:1.47190, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:119, Train Loss:1.22290, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:120, Train Loss:1.80771, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:121, Train Loss:2.13511, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:122, Train Loss:1.26857, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:123, Train Loss:1.69382, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:124, Train Loss:1.55367, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:125, Train Loss:1.52869, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:126, Train Loss:1.44346, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:127, Train Loss:1.80690, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:128, Train Loss:1.20544, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:129, Train Loss:1.26429, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:130, Train Loss:1.72730, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:131, Train Loss:1.39588, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:132, Train Loss:1.71214, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:133, Train Loss:1.20887, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:134, Train Loss:1.32708, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:135, Train Loss:1.48185, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:136, Train Loss:1.35671, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:137, Train Loss:1.16246, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:138, Train Loss:1.86668, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:139, Train Loss:0.84629, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:140, Train Loss:1.08118, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:141, Train Loss:1.34742, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:142, Train Loss:1.63517, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:143, Train Loss:1.33141, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:144, Train Loss:1.16795, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:145, Train Loss:1.38149, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:146, Train Loss:1.59568, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:147, Train Loss:1.13122, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:148, Train Loss:1.70301, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:149, Train Loss:1.84244, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:150, Train Loss:2.30253, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:151, Train Loss:1.58667, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:152, Train Loss:1.23969, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:153, Train Loss:1.42175, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:154, Train Loss:1.27804, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:155, Train Loss:1.26387, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:156, Train Loss:1.54102, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:157, Train Loss:1.33349, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:158, Train Loss:1.14963, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:159, Train Loss:1.66535, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:160, Train Loss:1.32447, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:161, Train Loss:1.26084, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:162, Train Loss:1.45618, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:163, Train Loss:1.38119, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:164, Train Loss:1.25739, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:165, Train Loss:1.32310, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:166, Train Loss:1.11053, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:167, Train Loss:1.39495, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:168, Train Loss:1.44040, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:169, Train Loss:1.60804, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:170, Train Loss:1.78580, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:171, Train Loss:1.47345, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:172, Train Loss:1.27907, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:173, Train Loss:1.38700, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:174, Train Loss:1.25830, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:175, Train Loss:1.35389, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:176, Train Loss:1.63417, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:177, Train Loss:1.35962, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:178, Train Loss:1.29340, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:179, Train Loss:1.48909, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:180, Train Loss:1.50625, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:181, Train Loss:1.29604, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:182, Train Loss:1.72312, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:183, Train Loss:1.58052, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:184, Train Loss:1.65852, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:185, Train Loss:1.58707, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:186, Train Loss:1.42035, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:187, Train Loss:1.32408, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:188, Train Loss:1.33254, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:189, Train Loss:1.70276, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:190, Train Loss:1.72707, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:191, Train Loss:1.70360, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:192, Train Loss:1.77798, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:193, Train Loss:1.57858, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:194, Train Loss:1.42025, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:195, Train Loss:1.38895, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:196, Train Loss:1.76749, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:197, Train Loss:1.50886, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:198, Train Loss:1.47759, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:199, Train Loss:1.14958, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:200, Train Loss:1.48277, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:201, Train Loss:2.56691, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:202, Train Loss:1.36278, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:203, Train Loss:1.38124, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:204, Train Loss:1.50503, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:205, Train Loss:1.32647, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:206, Train Loss:1.79725, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:207, Train Loss:1.53659, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:208, Train Loss:1.43778, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:209, Train Loss:1.66069, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:210, Train Loss:1.32357, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:211, Train Loss:1.28428, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:212, Train Loss:1.71565, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:213, Train Loss:1.75951, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:214, Train Loss:1.43684, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:215, Train Loss:1.36988, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:216, Train Loss:1.17937, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:217, Train Loss:1.37463, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:218, Train Loss:1.21384, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:219, Train Loss:1.29277, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:220, Train Loss:1.36512, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:221, Train Loss:1.65059, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:222, Train Loss:1.67983, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:223, Train Loss:1.15974, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:224, Train Loss:1.42830, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:225, Train Loss:1.34146, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:226, Train Loss:1.38328, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:227, Train Loss:2.26918, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:228, Train Loss:1.56964, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:229, Train Loss:1.78820, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:230, Train Loss:1.22192, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:231, Train Loss:1.51986, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:232, Train Loss:1.46041, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:233, Train Loss:1.59885, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:234, Train Loss:1.62400, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:235, Train Loss:1.31416, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:236, Train Loss:1.22946, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:237, Train Loss:1.57789, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:238, Train Loss:1.15619, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:239, Train Loss:1.32871, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:240, Train Loss:1.21090, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:241, Train Loss:1.69451, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:242, Train Loss:1.17082, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:243, Train Loss:1.09192, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:244, Train Loss:1.12088, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:245, Train Loss:1.77765, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:246, Train Loss:1.17089, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:247, Train Loss:1.61429, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:248, Train Loss:1.60216, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:249, Train Loss:0.98488, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:250, Train Loss:1.12718, Dev Loss:1.78053\n",
      "Epoch:[0/100], step:251, Train Loss:1.38089, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:252, Train Loss:1.06841, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:253, Train Loss:1.49282, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:254, Train Loss:1.62461, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:255, Train Loss:1.13561, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:256, Train Loss:1.43664, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:257, Train Loss:2.00514, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:258, Train Loss:1.64859, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:259, Train Loss:1.44576, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:260, Train Loss:1.19823, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:261, Train Loss:1.54054, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:262, Train Loss:1.25812, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:263, Train Loss:1.48580, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:264, Train Loss:1.16959, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:265, Train Loss:1.38023, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:266, Train Loss:1.30743, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:267, Train Loss:1.43016, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:268, Train Loss:1.31952, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:269, Train Loss:1.91293, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:270, Train Loss:1.18436, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:271, Train Loss:1.13379, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:272, Train Loss:1.26004, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:273, Train Loss:1.45481, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:274, Train Loss:1.26387, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:275, Train Loss:1.15791, Dev Loss:1.43479\n",
      "Epoch:[0/100], step:276, Train Loss:2.02511, Dev Loss:1.43479\n",
      "Start Epoch: 1, Steps: 17\n",
      "Epoch:[1/100], step:277, Train Loss:1.23720, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:278, Train Loss:1.04107, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:279, Train Loss:1.37933, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:280, Train Loss:0.88180, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:281, Train Loss:1.09937, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:282, Train Loss:1.35461, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:283, Train Loss:1.40471, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:284, Train Loss:1.44884, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:285, Train Loss:2.19922, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:286, Train Loss:1.17697, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:287, Train Loss:1.60357, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:288, Train Loss:1.35551, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:289, Train Loss:1.33345, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:290, Train Loss:0.93612, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:291, Train Loss:1.46293, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:292, Train Loss:1.08384, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:293, Train Loss:1.29410, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:294, Train Loss:1.15443, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:295, Train Loss:0.82043, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:296, Train Loss:0.94099, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:297, Train Loss:1.38796, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:298, Train Loss:1.14858, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:299, Train Loss:1.26183, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:300, Train Loss:1.43889, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:301, Train Loss:1.03923, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:302, Train Loss:0.85895, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:303, Train Loss:1.39858, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:304, Train Loss:1.34448, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:305, Train Loss:1.03786, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:306, Train Loss:1.33327, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:307, Train Loss:1.02413, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:308, Train Loss:1.38927, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:309, Train Loss:1.16431, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:310, Train Loss:1.25447, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:311, Train Loss:0.95922, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:312, Train Loss:1.38018, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:313, Train Loss:1.01362, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:314, Train Loss:0.67061, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:315, Train Loss:1.35622, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:316, Train Loss:1.39558, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:317, Train Loss:0.76612, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:318, Train Loss:0.74935, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:319, Train Loss:1.22227, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:320, Train Loss:1.12770, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:321, Train Loss:1.39771, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:322, Train Loss:1.14983, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:323, Train Loss:1.04222, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:324, Train Loss:1.93720, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:325, Train Loss:1.03085, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:326, Train Loss:1.18636, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:327, Train Loss:1.26411, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:328, Train Loss:1.57033, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:329, Train Loss:1.01776, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:330, Train Loss:1.47613, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:331, Train Loss:1.16142, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:332, Train Loss:1.12055, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:333, Train Loss:1.40889, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:334, Train Loss:0.84265, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:335, Train Loss:1.25915, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:336, Train Loss:0.94743, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:337, Train Loss:1.05393, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:338, Train Loss:1.00687, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:339, Train Loss:1.31346, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:340, Train Loss:1.70303, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:341, Train Loss:1.19002, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:342, Train Loss:1.39168, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:343, Train Loss:1.01564, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:344, Train Loss:1.03575, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:345, Train Loss:1.26574, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:346, Train Loss:1.56998, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:347, Train Loss:1.64894, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:348, Train Loss:1.27520, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:349, Train Loss:1.08267, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:350, Train Loss:1.17452, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:351, Train Loss:0.83874, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:352, Train Loss:1.09336, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:353, Train Loss:0.85802, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:354, Train Loss:0.87098, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:355, Train Loss:0.63174, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:356, Train Loss:0.65476, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:357, Train Loss:0.86932, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:358, Train Loss:1.43576, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:359, Train Loss:0.70561, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:360, Train Loss:1.40669, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:361, Train Loss:0.95740, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:362, Train Loss:1.01322, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:363, Train Loss:1.16436, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:364, Train Loss:0.61178, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:365, Train Loss:1.08008, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:366, Train Loss:1.18503, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:367, Train Loss:0.87299, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:368, Train Loss:1.03963, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:369, Train Loss:0.93034, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:370, Train Loss:1.10237, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:371, Train Loss:1.17330, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:372, Train Loss:0.68083, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:373, Train Loss:0.86088, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:374, Train Loss:1.06779, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:375, Train Loss:0.74705, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:376, Train Loss:1.28635, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:377, Train Loss:1.14965, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:378, Train Loss:1.07070, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:379, Train Loss:1.15810, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:380, Train Loss:0.79974, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:381, Train Loss:0.66101, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:382, Train Loss:1.08525, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:383, Train Loss:0.84932, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:384, Train Loss:1.23767, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:385, Train Loss:0.83504, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:386, Train Loss:0.88573, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:387, Train Loss:0.81393, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:388, Train Loss:1.34342, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:389, Train Loss:1.01132, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:390, Train Loss:0.84120, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:391, Train Loss:0.96597, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:392, Train Loss:1.10915, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:393, Train Loss:0.60591, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:394, Train Loss:1.07687, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:395, Train Loss:0.84150, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:396, Train Loss:1.02380, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:397, Train Loss:0.88966, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:398, Train Loss:0.93482, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:399, Train Loss:0.73147, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:400, Train Loss:1.01956, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:401, Train Loss:1.29595, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:402, Train Loss:0.95815, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:403, Train Loss:1.03340, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:404, Train Loss:0.63339, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:405, Train Loss:1.15282, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:406, Train Loss:0.85180, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:407, Train Loss:1.62039, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:408, Train Loss:0.92911, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:409, Train Loss:0.73680, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:410, Train Loss:0.75380, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:411, Train Loss:2.08829, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:412, Train Loss:1.12903, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:413, Train Loss:0.64405, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:414, Train Loss:0.91714, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:415, Train Loss:1.35195, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:416, Train Loss:0.72390, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:417, Train Loss:0.81927, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:418, Train Loss:1.04153, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:419, Train Loss:0.92962, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:420, Train Loss:0.56145, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:421, Train Loss:0.80204, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:422, Train Loss:1.21020, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:423, Train Loss:0.83663, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:424, Train Loss:0.62014, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:425, Train Loss:0.82495, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:426, Train Loss:0.77566, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:427, Train Loss:1.20224, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:428, Train Loss:1.11432, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:429, Train Loss:1.07307, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:430, Train Loss:1.16231, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:431, Train Loss:0.52968, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:432, Train Loss:0.73936, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:433, Train Loss:1.00785, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:434, Train Loss:1.43481, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:435, Train Loss:0.96517, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:436, Train Loss:0.90525, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:437, Train Loss:1.00895, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:438, Train Loss:1.05152, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:439, Train Loss:1.11377, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:440, Train Loss:1.29363, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:441, Train Loss:0.94255, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:442, Train Loss:1.21887, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:443, Train Loss:1.55790, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:444, Train Loss:0.68212, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:445, Train Loss:0.87225, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:446, Train Loss:1.07165, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:447, Train Loss:1.04931, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:448, Train Loss:0.85142, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:449, Train Loss:0.76455, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:450, Train Loss:0.81751, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:451, Train Loss:0.96848, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:452, Train Loss:0.55721, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:453, Train Loss:0.89497, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:454, Train Loss:1.01427, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:455, Train Loss:0.72772, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:456, Train Loss:1.05942, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:457, Train Loss:1.24911, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:458, Train Loss:1.09124, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:459, Train Loss:1.46123, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:460, Train Loss:1.25321, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:461, Train Loss:1.14140, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:462, Train Loss:1.08688, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:463, Train Loss:0.45517, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:464, Train Loss:0.97954, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:465, Train Loss:1.09945, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:466, Train Loss:0.83464, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:467, Train Loss:0.89329, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:468, Train Loss:0.77735, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:469, Train Loss:0.70714, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:470, Train Loss:0.86203, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:471, Train Loss:0.77947, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:472, Train Loss:0.87386, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:473, Train Loss:1.08987, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:474, Train Loss:0.94106, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:475, Train Loss:0.75890, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:476, Train Loss:0.66571, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:477, Train Loss:0.77110, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:478, Train Loss:0.72160, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:479, Train Loss:0.52191, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:480, Train Loss:1.29118, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:481, Train Loss:0.82751, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:482, Train Loss:1.27161, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:483, Train Loss:0.45854, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:484, Train Loss:0.52520, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:485, Train Loss:0.42795, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:486, Train Loss:0.67416, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:487, Train Loss:1.12666, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:488, Train Loss:1.11853, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:489, Train Loss:0.55077, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:490, Train Loss:1.36302, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:491, Train Loss:0.68410, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:492, Train Loss:1.04249, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:493, Train Loss:0.94751, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:494, Train Loss:1.27037, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:495, Train Loss:0.50548, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:496, Train Loss:0.85960, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:497, Train Loss:0.86680, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:498, Train Loss:0.78554, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:499, Train Loss:0.58016, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:500, Train Loss:0.99588, Dev Loss:1.43479\n",
      "Epoch:[1/100], step:501, Train Loss:1.12490, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:502, Train Loss:0.89225, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:503, Train Loss:0.54642, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:504, Train Loss:0.66229, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:505, Train Loss:0.80291, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:506, Train Loss:0.43033, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:507, Train Loss:2.50735, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:508, Train Loss:0.46215, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:509, Train Loss:0.78152, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:510, Train Loss:1.19899, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:511, Train Loss:0.83370, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:512, Train Loss:1.01206, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:513, Train Loss:0.60608, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:514, Train Loss:1.23658, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:515, Train Loss:0.52379, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:516, Train Loss:0.76163, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:517, Train Loss:0.82487, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:518, Train Loss:0.71660, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:519, Train Loss:0.65925, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:520, Train Loss:1.03019, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:521, Train Loss:0.39175, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:522, Train Loss:0.96401, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:523, Train Loss:0.49699, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:524, Train Loss:1.14268, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:525, Train Loss:0.98144, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:526, Train Loss:0.74132, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:527, Train Loss:1.39427, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:528, Train Loss:0.60787, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:529, Train Loss:0.63916, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:530, Train Loss:0.92223, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:531, Train Loss:1.04307, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:532, Train Loss:1.01533, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:533, Train Loss:1.05735, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:534, Train Loss:0.67750, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:535, Train Loss:0.58343, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:536, Train Loss:0.78017, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:537, Train Loss:0.65356, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:538, Train Loss:0.43715, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:539, Train Loss:1.00177, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:540, Train Loss:0.60596, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:541, Train Loss:0.81671, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:542, Train Loss:0.90824, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:543, Train Loss:0.91614, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:544, Train Loss:0.71864, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:545, Train Loss:1.24624, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:546, Train Loss:1.97480, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:547, Train Loss:1.00575, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:548, Train Loss:0.70163, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:549, Train Loss:1.04062, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:550, Train Loss:0.95902, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:551, Train Loss:1.12376, Dev Loss:0.76611\n",
      "Epoch:[1/100], step:552, Train Loss:0.67142, Dev Loss:0.76611\n",
      "Start Epoch: 2, Steps: 17\n",
      "Epoch:[2/100], step:553, Train Loss:0.90150, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:554, Train Loss:0.60056, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:555, Train Loss:0.88231, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:556, Train Loss:0.73497, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:557, Train Loss:0.88833, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:558, Train Loss:0.80691, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:559, Train Loss:1.02316, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:560, Train Loss:0.74085, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:561, Train Loss:0.53600, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:562, Train Loss:0.34505, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:563, Train Loss:0.85428, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:564, Train Loss:1.10792, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:565, Train Loss:1.25818, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:566, Train Loss:0.49558, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:567, Train Loss:1.17676, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:568, Train Loss:0.84163, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:569, Train Loss:0.72529, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:570, Train Loss:0.37134, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:571, Train Loss:1.16342, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:572, Train Loss:0.22707, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:573, Train Loss:0.56954, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:574, Train Loss:0.67566, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:575, Train Loss:0.99826, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:576, Train Loss:1.13136, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:577, Train Loss:1.42352, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:578, Train Loss:0.92724, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:579, Train Loss:0.68452, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:580, Train Loss:1.02428, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:581, Train Loss:0.67634, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:582, Train Loss:0.77438, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:583, Train Loss:1.36570, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:584, Train Loss:0.87569, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:585, Train Loss:0.66395, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:586, Train Loss:1.18049, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:587, Train Loss:0.83494, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:588, Train Loss:1.10814, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:589, Train Loss:0.74319, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:590, Train Loss:0.48587, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:591, Train Loss:0.91328, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:592, Train Loss:0.91086, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:593, Train Loss:0.62354, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:594, Train Loss:0.70527, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:595, Train Loss:1.18657, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:596, Train Loss:0.78763, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:597, Train Loss:0.39234, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:598, Train Loss:0.86985, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:599, Train Loss:0.81027, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:600, Train Loss:1.01982, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:601, Train Loss:1.02939, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:602, Train Loss:0.57773, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:603, Train Loss:0.37787, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:604, Train Loss:0.45009, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:605, Train Loss:0.72135, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:606, Train Loss:0.39395, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:607, Train Loss:0.60623, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:608, Train Loss:0.88677, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:609, Train Loss:0.39430, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:610, Train Loss:0.62716, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:611, Train Loss:0.37981, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:612, Train Loss:0.40532, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:613, Train Loss:0.57273, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:614, Train Loss:0.50835, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:615, Train Loss:0.31013, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:616, Train Loss:0.65993, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:617, Train Loss:0.35658, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:618, Train Loss:0.56377, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:619, Train Loss:1.07596, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:620, Train Loss:0.96880, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:621, Train Loss:1.67202, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:622, Train Loss:0.89074, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:623, Train Loss:1.04345, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:624, Train Loss:1.13552, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:625, Train Loss:0.62384, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:626, Train Loss:1.28328, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:627, Train Loss:1.29623, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:628, Train Loss:1.14820, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:629, Train Loss:0.62284, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:630, Train Loss:0.75005, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:631, Train Loss:0.74852, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:632, Train Loss:1.46824, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:633, Train Loss:0.57025, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:634, Train Loss:0.99071, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:635, Train Loss:0.62608, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:636, Train Loss:0.41383, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:637, Train Loss:0.45038, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:638, Train Loss:0.79619, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:639, Train Loss:0.54708, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:640, Train Loss:0.81000, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:641, Train Loss:0.85846, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:642, Train Loss:0.80424, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:643, Train Loss:0.86354, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:644, Train Loss:0.56363, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:645, Train Loss:1.14753, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:646, Train Loss:0.47706, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:647, Train Loss:1.19634, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:648, Train Loss:1.04851, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:649, Train Loss:0.94680, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:650, Train Loss:1.05606, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:651, Train Loss:0.49690, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:652, Train Loss:0.78968, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:653, Train Loss:0.61066, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:654, Train Loss:0.49409, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:655, Train Loss:0.59477, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:656, Train Loss:0.55702, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:657, Train Loss:0.61840, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:658, Train Loss:0.41536, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:659, Train Loss:0.60120, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:660, Train Loss:0.52272, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:661, Train Loss:0.50669, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:662, Train Loss:0.61870, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:663, Train Loss:1.31889, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:664, Train Loss:0.86621, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:665, Train Loss:0.61383, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:666, Train Loss:0.41933, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:667, Train Loss:0.65668, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:668, Train Loss:1.05124, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:669, Train Loss:0.64952, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:670, Train Loss:0.89863, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:671, Train Loss:1.31579, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:672, Train Loss:0.87984, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:673, Train Loss:0.27506, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:674, Train Loss:0.85899, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:675, Train Loss:1.14958, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:676, Train Loss:0.51057, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:677, Train Loss:0.78983, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:678, Train Loss:0.55673, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:679, Train Loss:1.16201, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:680, Train Loss:0.44179, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:681, Train Loss:0.60817, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:682, Train Loss:0.34461, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:683, Train Loss:0.61640, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:684, Train Loss:0.85828, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:685, Train Loss:0.71073, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:686, Train Loss:0.69905, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:687, Train Loss:0.50419, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:688, Train Loss:0.55976, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:689, Train Loss:0.82927, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:690, Train Loss:0.30347, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:691, Train Loss:0.24515, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:692, Train Loss:1.21536, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:693, Train Loss:0.31966, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:694, Train Loss:0.47501, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:695, Train Loss:0.82359, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:696, Train Loss:0.64408, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:697, Train Loss:0.64485, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:698, Train Loss:0.34852, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:699, Train Loss:0.56822, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:700, Train Loss:0.47456, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:701, Train Loss:1.04087, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:702, Train Loss:0.89600, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:703, Train Loss:1.17678, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:704, Train Loss:0.76927, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:705, Train Loss:0.94109, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:706, Train Loss:0.65783, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:707, Train Loss:0.38594, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:708, Train Loss:0.71994, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:709, Train Loss:0.73682, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:710, Train Loss:0.58095, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:711, Train Loss:0.69834, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:712, Train Loss:0.46993, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:713, Train Loss:0.64256, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:714, Train Loss:0.86413, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:715, Train Loss:0.72470, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:716, Train Loss:1.28514, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:717, Train Loss:0.60108, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:718, Train Loss:0.41402, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:719, Train Loss:0.75208, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:720, Train Loss:0.62805, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:721, Train Loss:0.35583, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:722, Train Loss:0.85235, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:723, Train Loss:0.67820, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:724, Train Loss:0.55414, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:725, Train Loss:0.41045, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:726, Train Loss:0.87955, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:727, Train Loss:0.68412, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:728, Train Loss:0.61989, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:729, Train Loss:0.42592, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:730, Train Loss:0.53190, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:731, Train Loss:0.85562, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:732, Train Loss:0.73031, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:733, Train Loss:0.66712, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:734, Train Loss:0.87239, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:735, Train Loss:0.40962, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:736, Train Loss:0.54709, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:737, Train Loss:0.33733, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:738, Train Loss:0.45997, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:739, Train Loss:0.60277, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:740, Train Loss:0.41984, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:741, Train Loss:0.87628, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:742, Train Loss:0.55321, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:743, Train Loss:0.72954, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:744, Train Loss:0.49386, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:745, Train Loss:0.67431, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:746, Train Loss:0.65442, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:747, Train Loss:0.62961, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:748, Train Loss:0.29664, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:749, Train Loss:0.55867, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:750, Train Loss:0.26229, Dev Loss:0.76611\n",
      "Epoch:[2/100], step:751, Train Loss:0.15252, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:752, Train Loss:0.78332, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:753, Train Loss:0.57241, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:754, Train Loss:0.98228, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:755, Train Loss:0.36874, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:756, Train Loss:0.28827, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:757, Train Loss:0.51548, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:758, Train Loss:0.35411, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:759, Train Loss:1.26538, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:760, Train Loss:0.89961, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:761, Train Loss:0.52832, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:762, Train Loss:1.08089, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:763, Train Loss:0.42113, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:764, Train Loss:0.52741, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:765, Train Loss:0.48482, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:766, Train Loss:0.36101, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:767, Train Loss:0.48675, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:768, Train Loss:0.55761, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:769, Train Loss:0.47828, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:770, Train Loss:0.59086, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:771, Train Loss:0.73924, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:772, Train Loss:0.30769, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:773, Train Loss:0.40102, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:774, Train Loss:0.46696, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:775, Train Loss:0.62033, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:776, Train Loss:0.55129, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:777, Train Loss:0.63155, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:778, Train Loss:0.60310, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:779, Train Loss:0.34511, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:780, Train Loss:1.00576, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:781, Train Loss:0.48220, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:782, Train Loss:0.20961, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:783, Train Loss:1.15779, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:784, Train Loss:0.54047, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:785, Train Loss:0.72847, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:786, Train Loss:0.45125, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:787, Train Loss:0.59417, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:788, Train Loss:0.42919, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:789, Train Loss:0.54069, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:790, Train Loss:0.58558, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:791, Train Loss:0.20571, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:792, Train Loss:0.49648, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:793, Train Loss:0.74542, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:794, Train Loss:0.60729, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:795, Train Loss:0.88501, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:796, Train Loss:0.38080, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:797, Train Loss:0.44497, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:798, Train Loss:0.65370, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:799, Train Loss:0.43675, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:800, Train Loss:0.44284, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:801, Train Loss:1.06536, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:802, Train Loss:0.56554, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:803, Train Loss:0.62729, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:804, Train Loss:0.50080, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:805, Train Loss:0.58956, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:806, Train Loss:0.43620, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:807, Train Loss:0.87270, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:808, Train Loss:0.30071, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:809, Train Loss:0.72111, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:810, Train Loss:0.67810, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:811, Train Loss:0.47010, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:812, Train Loss:0.86133, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:813, Train Loss:0.50265, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:814, Train Loss:0.69457, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:815, Train Loss:0.36644, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:816, Train Loss:1.23892, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:817, Train Loss:0.55186, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:818, Train Loss:0.44220, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:819, Train Loss:0.87078, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:820, Train Loss:0.66161, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:821, Train Loss:0.31347, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:822, Train Loss:0.50366, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:823, Train Loss:0.70460, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:824, Train Loss:0.44985, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:825, Train Loss:0.41938, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:826, Train Loss:0.41240, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:827, Train Loss:0.27863, Dev Loss:0.51113\n",
      "Epoch:[2/100], step:828, Train Loss:0.54530, Dev Loss:0.51113\n",
      "Start Epoch: 3, Steps: 17\n",
      "Epoch:[3/100], step:829, Train Loss:0.53499, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:830, Train Loss:0.69959, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:831, Train Loss:0.41158, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:832, Train Loss:0.53279, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:833, Train Loss:1.06510, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:834, Train Loss:1.01243, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:835, Train Loss:0.62389, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:836, Train Loss:0.79474, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:837, Train Loss:0.80694, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:838, Train Loss:0.50778, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:839, Train Loss:0.59240, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:840, Train Loss:0.29949, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:841, Train Loss:0.69933, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:842, Train Loss:0.85504, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:843, Train Loss:0.54796, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:844, Train Loss:0.72492, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:845, Train Loss:0.96657, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:846, Train Loss:0.38710, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:847, Train Loss:0.96407, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:848, Train Loss:0.43416, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:849, Train Loss:0.68216, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:850, Train Loss:0.79029, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:851, Train Loss:0.59046, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:852, Train Loss:0.61202, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:853, Train Loss:0.66116, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:854, Train Loss:0.16205, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:855, Train Loss:0.41702, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:856, Train Loss:0.44686, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:857, Train Loss:0.41249, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:858, Train Loss:0.89792, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:859, Train Loss:0.34554, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:860, Train Loss:0.29979, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:861, Train Loss:0.69672, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:862, Train Loss:0.47891, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:863, Train Loss:0.86447, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:864, Train Loss:0.92405, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:865, Train Loss:0.59280, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:866, Train Loss:0.39256, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:867, Train Loss:0.80026, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:868, Train Loss:0.56570, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:869, Train Loss:0.43743, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:870, Train Loss:0.58454, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:871, Train Loss:0.51579, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:872, Train Loss:0.75134, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:873, Train Loss:0.55708, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:874, Train Loss:0.28040, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:875, Train Loss:0.37376, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:876, Train Loss:0.88138, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:877, Train Loss:0.92707, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:878, Train Loss:1.49490, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:879, Train Loss:0.34931, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:880, Train Loss:0.28213, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:881, Train Loss:1.03202, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:882, Train Loss:0.43884, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:883, Train Loss:1.29617, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:884, Train Loss:0.85750, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:885, Train Loss:1.05370, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:886, Train Loss:0.60572, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:887, Train Loss:0.70014, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:888, Train Loss:0.57874, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:889, Train Loss:0.57461, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:890, Train Loss:0.47900, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:891, Train Loss:0.39627, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:892, Train Loss:0.43134, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:893, Train Loss:0.18902, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:894, Train Loss:0.94947, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:895, Train Loss:0.42811, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:896, Train Loss:0.50320, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:897, Train Loss:0.28414, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:898, Train Loss:0.61089, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:899, Train Loss:0.25536, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:900, Train Loss:0.64162, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:901, Train Loss:0.60925, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:902, Train Loss:0.45978, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:903, Train Loss:0.65382, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:904, Train Loss:0.63980, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:905, Train Loss:0.26866, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:906, Train Loss:0.38571, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:907, Train Loss:0.36575, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:908, Train Loss:0.33658, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:909, Train Loss:0.26911, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:910, Train Loss:0.21844, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:911, Train Loss:0.46937, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:912, Train Loss:0.45857, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:913, Train Loss:0.76635, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:914, Train Loss:1.04498, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:915, Train Loss:0.58600, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:916, Train Loss:0.21528, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:917, Train Loss:0.79918, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:918, Train Loss:0.54936, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:919, Train Loss:0.24965, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:920, Train Loss:0.59650, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:921, Train Loss:0.76515, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:922, Train Loss:0.62456, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:923, Train Loss:0.38447, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:924, Train Loss:0.51448, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:925, Train Loss:0.63896, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:926, Train Loss:0.55862, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:927, Train Loss:0.30590, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:928, Train Loss:0.40526, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:929, Train Loss:0.71196, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:930, Train Loss:0.42646, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:931, Train Loss:0.19264, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:932, Train Loss:0.48621, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:933, Train Loss:0.87518, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:934, Train Loss:0.70303, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:935, Train Loss:0.69236, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:936, Train Loss:0.42110, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:937, Train Loss:0.26682, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:938, Train Loss:0.68386, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:939, Train Loss:1.07691, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:940, Train Loss:0.51584, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:941, Train Loss:0.70299, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:942, Train Loss:0.25835, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:943, Train Loss:0.21010, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:944, Train Loss:0.46870, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:945, Train Loss:0.49262, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:946, Train Loss:0.92484, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:947, Train Loss:0.57122, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:948, Train Loss:0.40823, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:949, Train Loss:0.74907, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:950, Train Loss:0.43140, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:951, Train Loss:0.68872, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:952, Train Loss:0.34618, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:953, Train Loss:1.58871, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:954, Train Loss:0.71046, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:955, Train Loss:0.57957, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:956, Train Loss:0.22763, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:957, Train Loss:0.82436, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:958, Train Loss:0.38289, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:959, Train Loss:0.84641, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:960, Train Loss:0.52104, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:961, Train Loss:0.77807, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:962, Train Loss:0.50636, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:963, Train Loss:0.39386, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:964, Train Loss:0.53695, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:965, Train Loss:0.45395, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:966, Train Loss:0.48032, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:967, Train Loss:0.71781, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:968, Train Loss:0.73554, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:969, Train Loss:0.37152, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:970, Train Loss:0.39279, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:971, Train Loss:0.47608, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:972, Train Loss:0.23640, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:973, Train Loss:0.44676, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:974, Train Loss:0.70063, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:975, Train Loss:0.44344, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:976, Train Loss:0.49752, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:977, Train Loss:0.45529, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:978, Train Loss:0.38330, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:979, Train Loss:0.96576, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:980, Train Loss:0.53672, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:981, Train Loss:0.45868, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:982, Train Loss:0.83263, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:983, Train Loss:0.34949, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:984, Train Loss:0.20068, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:985, Train Loss:0.26373, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:986, Train Loss:0.85394, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:987, Train Loss:0.39992, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:988, Train Loss:0.29076, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:989, Train Loss:0.53641, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:990, Train Loss:0.30395, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:991, Train Loss:1.22860, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:992, Train Loss:0.38458, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:993, Train Loss:0.66234, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:994, Train Loss:0.21742, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:995, Train Loss:0.53530, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:996, Train Loss:0.67579, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:997, Train Loss:0.39308, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:998, Train Loss:0.39745, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:999, Train Loss:0.34602, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:1000, Train Loss:0.59601, Dev Loss:0.51113\n",
      "Epoch:[3/100], step:1001, Train Loss:0.80477, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1002, Train Loss:1.21118, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1003, Train Loss:0.77707, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1004, Train Loss:0.58399, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1005, Train Loss:0.55909, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1006, Train Loss:0.59832, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1007, Train Loss:0.56192, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1008, Train Loss:0.17670, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1009, Train Loss:0.59675, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1010, Train Loss:0.79210, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1011, Train Loss:0.34619, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1012, Train Loss:0.42009, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1013, Train Loss:0.40745, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1014, Train Loss:0.52551, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1015, Train Loss:0.70486, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1016, Train Loss:0.64520, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1017, Train Loss:0.31172, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1018, Train Loss:0.31755, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1019, Train Loss:0.30348, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1020, Train Loss:0.37909, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1021, Train Loss:0.86568, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1022, Train Loss:0.23108, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1023, Train Loss:0.87991, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1024, Train Loss:0.63230, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1025, Train Loss:0.37272, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1026, Train Loss:0.37014, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1027, Train Loss:0.55420, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1028, Train Loss:0.54962, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1029, Train Loss:0.56934, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1030, Train Loss:0.27782, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1031, Train Loss:0.23807, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1032, Train Loss:0.23756, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1033, Train Loss:0.55289, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1034, Train Loss:0.48075, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1035, Train Loss:0.40698, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1036, Train Loss:0.39570, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1037, Train Loss:0.40601, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1038, Train Loss:0.53647, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1039, Train Loss:0.34127, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1040, Train Loss:0.09252, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1041, Train Loss:0.75652, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1042, Train Loss:0.21266, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1043, Train Loss:0.23457, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1044, Train Loss:0.16620, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1045, Train Loss:0.37780, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1046, Train Loss:0.52937, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1047, Train Loss:0.38666, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1048, Train Loss:0.38429, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1049, Train Loss:0.58292, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1050, Train Loss:1.32897, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1051, Train Loss:0.58203, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1052, Train Loss:0.57218, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1053, Train Loss:0.12298, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1054, Train Loss:0.69109, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1055, Train Loss:0.73324, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1056, Train Loss:0.50943, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1057, Train Loss:0.15846, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1058, Train Loss:0.28565, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1059, Train Loss:0.30590, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1060, Train Loss:0.71565, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1061, Train Loss:0.48728, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1062, Train Loss:0.28538, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1063, Train Loss:0.59699, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1064, Train Loss:0.59525, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1065, Train Loss:0.18052, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1066, Train Loss:0.12636, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1067, Train Loss:0.27659, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1068, Train Loss:0.59097, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1069, Train Loss:0.31076, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1070, Train Loss:0.66229, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1071, Train Loss:0.66802, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1072, Train Loss:0.91792, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1073, Train Loss:0.43332, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1074, Train Loss:0.29135, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1075, Train Loss:0.26477, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1076, Train Loss:0.11815, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1077, Train Loss:0.70188, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1078, Train Loss:0.85389, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1079, Train Loss:0.94044, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1080, Train Loss:0.24985, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1081, Train Loss:0.36053, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1082, Train Loss:0.36863, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1083, Train Loss:0.49926, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1084, Train Loss:0.71621, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1085, Train Loss:0.20308, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1086, Train Loss:0.10895, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1087, Train Loss:0.64777, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1088, Train Loss:0.44941, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1089, Train Loss:0.24359, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1090, Train Loss:0.67137, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1091, Train Loss:0.16099, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1092, Train Loss:0.26443, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1093, Train Loss:0.38339, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1094, Train Loss:0.36490, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1095, Train Loss:0.16353, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1096, Train Loss:0.05769, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1097, Train Loss:0.38724, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1098, Train Loss:0.85608, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1099, Train Loss:0.17415, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1100, Train Loss:0.24019, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1101, Train Loss:0.41904, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1102, Train Loss:0.08183, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1103, Train Loss:0.14583, Dev Loss:0.36410\n",
      "Epoch:[3/100], step:1104, Train Loss:0.72956, Dev Loss:0.36410\n",
      "Start Epoch: 4, Steps: 17\n",
      "Epoch:[4/100], step:1105, Train Loss:0.38779, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1106, Train Loss:0.18595, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1107, Train Loss:0.28371, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1108, Train Loss:0.48275, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1109, Train Loss:0.58516, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1110, Train Loss:0.12222, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1111, Train Loss:0.43462, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1112, Train Loss:0.21710, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1113, Train Loss:0.62582, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1114, Train Loss:0.01626, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1115, Train Loss:0.13736, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1116, Train Loss:0.46945, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1117, Train Loss:0.26354, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1118, Train Loss:0.93478, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1119, Train Loss:0.61022, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1120, Train Loss:0.51854, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1121, Train Loss:0.17843, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1122, Train Loss:0.41149, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1123, Train Loss:0.33023, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1124, Train Loss:0.44369, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1125, Train Loss:0.27239, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1126, Train Loss:0.17201, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1127, Train Loss:0.15353, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1128, Train Loss:0.59298, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1129, Train Loss:0.41457, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1130, Train Loss:0.76368, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1131, Train Loss:0.36624, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1132, Train Loss:0.58876, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1133, Train Loss:0.31371, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1134, Train Loss:0.56739, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1135, Train Loss:0.35682, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1136, Train Loss:0.63757, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1137, Train Loss:0.43262, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1138, Train Loss:0.98014, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1139, Train Loss:0.24618, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1140, Train Loss:0.44031, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1141, Train Loss:0.32808, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1142, Train Loss:0.65491, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1143, Train Loss:0.58324, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1144, Train Loss:0.28251, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1145, Train Loss:0.45372, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1146, Train Loss:0.45983, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1147, Train Loss:0.27491, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1148, Train Loss:0.60123, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1149, Train Loss:0.36474, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1150, Train Loss:0.22882, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1151, Train Loss:0.19044, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1152, Train Loss:0.36166, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1153, Train Loss:0.48886, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1154, Train Loss:0.24539, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1155, Train Loss:0.49557, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1156, Train Loss:0.34998, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1157, Train Loss:0.72910, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1158, Train Loss:0.76377, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1159, Train Loss:0.40731, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1160, Train Loss:0.20711, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1161, Train Loss:0.07263, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1162, Train Loss:1.25457, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1163, Train Loss:0.52730, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1164, Train Loss:0.82724, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1165, Train Loss:0.33224, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1166, Train Loss:0.69725, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1167, Train Loss:0.43977, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1168, Train Loss:0.18577, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1169, Train Loss:0.34170, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1170, Train Loss:0.39902, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1171, Train Loss:0.54832, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1172, Train Loss:0.55960, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1173, Train Loss:0.47574, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1174, Train Loss:0.31846, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1175, Train Loss:0.29540, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1176, Train Loss:0.66984, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1177, Train Loss:0.78793, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1178, Train Loss:0.48299, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1179, Train Loss:0.66472, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1180, Train Loss:0.27592, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1181, Train Loss:0.45150, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1182, Train Loss:0.56931, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1183, Train Loss:0.38419, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1184, Train Loss:0.36035, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1185, Train Loss:0.32671, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1186, Train Loss:0.62458, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1187, Train Loss:0.51351, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1188, Train Loss:0.69141, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1189, Train Loss:0.66135, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1190, Train Loss:0.53413, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1191, Train Loss:0.41912, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1192, Train Loss:0.69865, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1193, Train Loss:0.30716, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1194, Train Loss:0.39016, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1195, Train Loss:0.29154, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1196, Train Loss:0.62465, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1197, Train Loss:0.82987, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1198, Train Loss:0.28662, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1199, Train Loss:0.53777, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1200, Train Loss:0.28306, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1201, Train Loss:0.30688, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1202, Train Loss:1.03660, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1203, Train Loss:0.32251, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1204, Train Loss:0.28290, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1205, Train Loss:0.45428, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1206, Train Loss:0.49185, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1207, Train Loss:0.51183, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1208, Train Loss:0.26063, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1209, Train Loss:0.55114, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1210, Train Loss:0.20766, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1211, Train Loss:0.49314, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1212, Train Loss:0.51071, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1213, Train Loss:0.27605, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1214, Train Loss:0.58351, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1215, Train Loss:0.18389, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1216, Train Loss:0.17140, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1217, Train Loss:0.29083, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1218, Train Loss:0.24473, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1219, Train Loss:0.28551, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1220, Train Loss:0.27414, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1221, Train Loss:0.27221, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1222, Train Loss:0.26349, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1223, Train Loss:0.29878, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1224, Train Loss:0.51436, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1225, Train Loss:0.65786, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1226, Train Loss:0.27369, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1227, Train Loss:0.36331, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1228, Train Loss:0.45173, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1229, Train Loss:0.42508, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1230, Train Loss:0.30017, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1231, Train Loss:0.57291, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1232, Train Loss:0.31494, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1233, Train Loss:0.10463, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1234, Train Loss:0.47578, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1235, Train Loss:0.33621, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1236, Train Loss:0.42012, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1237, Train Loss:0.28637, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1238, Train Loss:0.82800, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1239, Train Loss:0.99671, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1240, Train Loss:0.39769, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1241, Train Loss:0.44898, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1242, Train Loss:0.26346, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1243, Train Loss:0.25987, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1244, Train Loss:0.65365, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1245, Train Loss:0.33628, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1246, Train Loss:0.30382, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1247, Train Loss:0.84487, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1248, Train Loss:0.23119, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1249, Train Loss:0.04125, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1250, Train Loss:0.27947, Dev Loss:0.36410\n",
      "Epoch:[4/100], step:1251, Train Loss:0.30244, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1252, Train Loss:0.49446, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1253, Train Loss:0.32614, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1254, Train Loss:0.68130, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1255, Train Loss:0.88844, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1256, Train Loss:0.28460, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1257, Train Loss:0.22824, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1258, Train Loss:0.58548, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1259, Train Loss:0.20552, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1260, Train Loss:0.74134, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1261, Train Loss:1.01166, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1262, Train Loss:0.84760, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1263, Train Loss:0.14081, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1264, Train Loss:0.29489, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1265, Train Loss:0.46663, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1266, Train Loss:1.04041, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1267, Train Loss:1.05263, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1268, Train Loss:0.97240, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1269, Train Loss:0.42208, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1270, Train Loss:0.52475, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1271, Train Loss:0.91408, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1272, Train Loss:0.21966, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1273, Train Loss:0.56203, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1274, Train Loss:0.54056, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1275, Train Loss:0.32988, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1276, Train Loss:0.48445, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1277, Train Loss:0.42866, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1278, Train Loss:0.33585, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1279, Train Loss:0.39704, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1280, Train Loss:0.26045, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1281, Train Loss:0.43704, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1282, Train Loss:0.23941, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1283, Train Loss:0.36457, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1284, Train Loss:0.78464, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1285, Train Loss:0.47633, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1286, Train Loss:0.56007, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1287, Train Loss:0.68444, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1288, Train Loss:0.29745, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1289, Train Loss:0.29473, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1290, Train Loss:0.51617, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1291, Train Loss:1.00937, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1292, Train Loss:0.35498, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1293, Train Loss:1.11636, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1294, Train Loss:0.36328, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1295, Train Loss:0.42889, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1296, Train Loss:0.67064, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1297, Train Loss:0.29188, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1298, Train Loss:0.23913, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1299, Train Loss:0.32628, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1300, Train Loss:0.34847, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1301, Train Loss:0.31995, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1302, Train Loss:0.43729, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1303, Train Loss:0.52789, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1304, Train Loss:0.25592, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1305, Train Loss:0.15995, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1306, Train Loss:0.70996, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1307, Train Loss:0.18788, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1308, Train Loss:0.05461, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1309, Train Loss:0.31376, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1310, Train Loss:0.66098, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1311, Train Loss:0.16174, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1312, Train Loss:0.16665, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1313, Train Loss:0.04035, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1314, Train Loss:0.23296, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1315, Train Loss:0.57532, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1316, Train Loss:0.54043, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1317, Train Loss:0.23653, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1318, Train Loss:0.77966, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1319, Train Loss:0.67712, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1320, Train Loss:0.31286, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1321, Train Loss:0.03629, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1322, Train Loss:0.47210, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1323, Train Loss:0.38495, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1324, Train Loss:0.24290, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1325, Train Loss:0.21249, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1326, Train Loss:0.54587, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1327, Train Loss:0.35726, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1328, Train Loss:0.06370, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1329, Train Loss:0.76837, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1330, Train Loss:0.36956, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1331, Train Loss:0.21128, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1332, Train Loss:0.20571, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1333, Train Loss:0.37993, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1334, Train Loss:0.11457, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1335, Train Loss:0.47346, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1336, Train Loss:0.24267, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1337, Train Loss:0.45985, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1338, Train Loss:0.15453, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1339, Train Loss:0.03715, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1340, Train Loss:0.50413, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1341, Train Loss:0.03296, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1342, Train Loss:0.74665, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1343, Train Loss:0.18210, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1344, Train Loss:0.45533, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1345, Train Loss:0.06491, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1346, Train Loss:0.12900, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1347, Train Loss:0.13715, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1348, Train Loss:0.72185, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1349, Train Loss:0.16305, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1350, Train Loss:0.89532, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1351, Train Loss:0.26690, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1352, Train Loss:0.18671, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1353, Train Loss:0.24257, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1354, Train Loss:0.32616, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1355, Train Loss:0.05948, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1356, Train Loss:0.24878, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1357, Train Loss:0.05944, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1358, Train Loss:0.40898, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1359, Train Loss:0.38029, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1360, Train Loss:0.20174, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1361, Train Loss:0.60059, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1362, Train Loss:0.25126, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1363, Train Loss:0.03154, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1364, Train Loss:0.36995, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1365, Train Loss:0.03828, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1366, Train Loss:0.41878, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1367, Train Loss:0.47164, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1368, Train Loss:0.05305, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1369, Train Loss:0.26735, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1370, Train Loss:0.09276, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1371, Train Loss:0.15237, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1372, Train Loss:0.61813, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1373, Train Loss:0.09380, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1374, Train Loss:0.10368, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1375, Train Loss:0.12948, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1376, Train Loss:0.60555, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1377, Train Loss:0.27689, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1378, Train Loss:0.41347, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1379, Train Loss:0.48163, Dev Loss:0.37796\n",
      "Epoch:[4/100], step:1380, Train Loss:0.00916, Dev Loss:0.37796\n",
      "Start Epoch: 5, Steps: 17\n",
      "Epoch:[5/100], step:1381, Train Loss:0.07020, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1382, Train Loss:0.73995, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1383, Train Loss:0.76443, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1384, Train Loss:0.13973, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1385, Train Loss:0.15634, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1386, Train Loss:0.46755, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1387, Train Loss:0.14736, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1388, Train Loss:0.27225, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1389, Train Loss:0.40386, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1390, Train Loss:0.53494, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1391, Train Loss:0.57325, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1392, Train Loss:0.12319, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1393, Train Loss:0.27052, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1394, Train Loss:0.18838, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1395, Train Loss:0.24741, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1396, Train Loss:0.27079, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1397, Train Loss:0.13451, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1398, Train Loss:0.35924, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1399, Train Loss:0.27297, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1400, Train Loss:0.22172, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1401, Train Loss:0.18282, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1402, Train Loss:0.25362, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1403, Train Loss:0.68953, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1404, Train Loss:0.11264, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1405, Train Loss:0.40934, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1406, Train Loss:0.37331, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1407, Train Loss:0.23484, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1408, Train Loss:0.27374, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1409, Train Loss:0.25018, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1410, Train Loss:0.74028, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1411, Train Loss:0.24040, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1412, Train Loss:0.30494, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1413, Train Loss:0.42350, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1414, Train Loss:0.21200, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1415, Train Loss:0.11578, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1416, Train Loss:0.12355, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1417, Train Loss:0.14968, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1418, Train Loss:0.23821, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1419, Train Loss:0.28996, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1420, Train Loss:0.35064, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1421, Train Loss:0.31595, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1422, Train Loss:0.68839, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1423, Train Loss:0.24165, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1424, Train Loss:0.10802, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1425, Train Loss:0.41260, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1426, Train Loss:0.15346, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1427, Train Loss:0.44556, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1428, Train Loss:0.51231, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1429, Train Loss:0.27397, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1430, Train Loss:0.52715, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1431, Train Loss:0.49773, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1432, Train Loss:0.49137, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1433, Train Loss:0.20462, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1434, Train Loss:0.42900, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1435, Train Loss:0.39741, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1436, Train Loss:0.12320, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1437, Train Loss:0.25319, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1438, Train Loss:0.29536, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1439, Train Loss:1.74903, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1440, Train Loss:0.32230, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1441, Train Loss:0.44645, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1442, Train Loss:0.05259, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1443, Train Loss:0.39334, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1444, Train Loss:0.63822, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1445, Train Loss:0.20508, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1446, Train Loss:0.54026, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1447, Train Loss:0.19034, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1448, Train Loss:0.68300, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1449, Train Loss:0.31135, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1450, Train Loss:0.57416, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1451, Train Loss:0.64947, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1452, Train Loss:0.52559, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1453, Train Loss:0.80067, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1454, Train Loss:0.38062, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1455, Train Loss:0.07439, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1456, Train Loss:0.75297, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1457, Train Loss:0.24584, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1458, Train Loss:0.47883, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1459, Train Loss:0.33425, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1460, Train Loss:0.17475, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1461, Train Loss:0.43168, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1462, Train Loss:0.41530, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1463, Train Loss:0.70559, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1464, Train Loss:0.06382, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1465, Train Loss:0.05530, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1466, Train Loss:0.34164, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1467, Train Loss:0.36153, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1468, Train Loss:0.22862, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1469, Train Loss:0.14136, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1470, Train Loss:0.09804, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1471, Train Loss:0.27062, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1472, Train Loss:0.25193, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1473, Train Loss:0.15961, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1474, Train Loss:0.19095, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1475, Train Loss:0.28114, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1476, Train Loss:0.40838, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1477, Train Loss:0.32313, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1478, Train Loss:0.53371, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1479, Train Loss:0.49145, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1480, Train Loss:0.44258, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1481, Train Loss:0.31834, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1482, Train Loss:0.67843, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1483, Train Loss:0.66572, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1484, Train Loss:0.13315, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1485, Train Loss:0.47703, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1486, Train Loss:0.33247, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1487, Train Loss:0.29733, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1488, Train Loss:0.54930, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1489, Train Loss:0.28076, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1490, Train Loss:0.10597, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1491, Train Loss:0.24556, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1492, Train Loss:0.51239, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1493, Train Loss:0.52256, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1494, Train Loss:0.03342, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1495, Train Loss:0.72986, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1496, Train Loss:0.72380, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1497, Train Loss:0.29890, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1498, Train Loss:0.24903, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1499, Train Loss:0.48152, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1500, Train Loss:0.38662, Dev Loss:0.37796\n",
      "Epoch:[5/100], step:1501, Train Loss:0.16679, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1502, Train Loss:0.71796, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1503, Train Loss:0.41814, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1504, Train Loss:0.67726, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1505, Train Loss:0.11188, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1506, Train Loss:0.30810, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1507, Train Loss:0.41269, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1508, Train Loss:0.14285, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1509, Train Loss:0.52888, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1510, Train Loss:0.37649, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1511, Train Loss:0.15879, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1512, Train Loss:0.36642, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1513, Train Loss:0.24239, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1514, Train Loss:0.18978, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1515, Train Loss:0.30286, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1516, Train Loss:0.52173, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1517, Train Loss:0.28552, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1518, Train Loss:0.14319, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1519, Train Loss:0.40835, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1520, Train Loss:0.25123, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1521, Train Loss:0.15253, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1522, Train Loss:0.20417, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1523, Train Loss:0.14623, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1524, Train Loss:0.23780, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1525, Train Loss:0.29216, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1526, Train Loss:0.38746, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1527, Train Loss:0.66521, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1528, Train Loss:0.20654, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1529, Train Loss:0.04801, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1530, Train Loss:0.57801, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1531, Train Loss:0.24801, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1532, Train Loss:0.71299, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1533, Train Loss:0.40424, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1534, Train Loss:0.11864, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1535, Train Loss:0.35622, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1536, Train Loss:0.60020, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1537, Train Loss:1.44382, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1538, Train Loss:0.43073, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1539, Train Loss:0.27334, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1540, Train Loss:0.12726, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1541, Train Loss:0.31875, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1542, Train Loss:0.51384, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1543, Train Loss:0.05809, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1544, Train Loss:0.08633, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1545, Train Loss:0.37711, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1546, Train Loss:0.64982, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1547, Train Loss:0.18725, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1548, Train Loss:0.24501, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1549, Train Loss:0.06590, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1550, Train Loss:0.24981, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1551, Train Loss:0.43163, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1552, Train Loss:1.06056, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1553, Train Loss:0.28171, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1554, Train Loss:0.45767, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1555, Train Loss:0.42669, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1556, Train Loss:0.20848, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1557, Train Loss:0.33710, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1558, Train Loss:0.35624, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1559, Train Loss:0.34448, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1560, Train Loss:0.39958, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1561, Train Loss:0.60947, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1562, Train Loss:0.11289, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1563, Train Loss:0.26615, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1564, Train Loss:0.29198, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1565, Train Loss:0.37052, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1566, Train Loss:0.33719, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1567, Train Loss:0.30889, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1568, Train Loss:0.05958, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1569, Train Loss:0.44322, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1570, Train Loss:0.13415, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1571, Train Loss:0.29083, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1572, Train Loss:0.30120, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1573, Train Loss:0.43399, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1574, Train Loss:0.11196, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1575, Train Loss:0.07495, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1576, Train Loss:0.25433, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1577, Train Loss:0.55431, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1578, Train Loss:0.55081, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1579, Train Loss:0.32145, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1580, Train Loss:0.37346, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1581, Train Loss:0.23837, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1582, Train Loss:0.30579, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1583, Train Loss:0.09984, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1584, Train Loss:0.29679, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1585, Train Loss:0.13401, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1586, Train Loss:0.22033, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1587, Train Loss:0.85100, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1588, Train Loss:0.13426, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1589, Train Loss:0.26022, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1590, Train Loss:0.08190, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1591, Train Loss:0.13741, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1592, Train Loss:0.17683, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1593, Train Loss:0.09344, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1594, Train Loss:0.88400, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1595, Train Loss:0.39579, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1596, Train Loss:0.61907, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1597, Train Loss:0.21444, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1598, Train Loss:0.32174, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1599, Train Loss:0.56343, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1600, Train Loss:0.47523, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1601, Train Loss:0.41636, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1602, Train Loss:0.04695, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1603, Train Loss:0.32483, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1604, Train Loss:0.11178, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1605, Train Loss:0.58402, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1606, Train Loss:0.49867, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1607, Train Loss:0.09102, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1608, Train Loss:0.15585, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1609, Train Loss:0.84957, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1610, Train Loss:0.11407, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1611, Train Loss:0.15910, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1612, Train Loss:0.20713, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1613, Train Loss:0.75002, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1614, Train Loss:0.08506, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1615, Train Loss:0.50979, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1616, Train Loss:0.52311, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1617, Train Loss:0.39668, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1618, Train Loss:0.53643, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1619, Train Loss:0.05355, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1620, Train Loss:0.18374, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1621, Train Loss:0.06262, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1622, Train Loss:0.68313, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1623, Train Loss:0.21442, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1624, Train Loss:0.11824, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1625, Train Loss:0.17688, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1626, Train Loss:0.04062, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1627, Train Loss:0.24017, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1628, Train Loss:0.39196, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1629, Train Loss:0.12050, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1630, Train Loss:0.18972, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1631, Train Loss:0.08522, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1632, Train Loss:0.71474, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1633, Train Loss:0.49127, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1634, Train Loss:0.26801, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1635, Train Loss:0.20208, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1636, Train Loss:0.02819, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1637, Train Loss:0.08019, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1638, Train Loss:0.13727, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1639, Train Loss:0.38081, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1640, Train Loss:0.32997, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1641, Train Loss:0.18561, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1642, Train Loss:0.06930, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1643, Train Loss:0.02181, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1644, Train Loss:0.43868, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1645, Train Loss:0.39762, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1646, Train Loss:0.18782, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1647, Train Loss:0.15272, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1648, Train Loss:0.33347, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1649, Train Loss:0.26969, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1650, Train Loss:0.45893, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1651, Train Loss:0.08169, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1652, Train Loss:0.78213, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1653, Train Loss:0.05211, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1654, Train Loss:0.15326, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1655, Train Loss:0.01671, Dev Loss:0.40415\n",
      "Epoch:[5/100], step:1656, Train Loss:0.35235, Dev Loss:0.40415\n",
      "Start Epoch: 6, Steps: 17\n",
      "Epoch:[6/100], step:1657, Train Loss:0.77256, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1658, Train Loss:0.23807, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1659, Train Loss:0.09075, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1660, Train Loss:0.03370, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1661, Train Loss:0.39582, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1662, Train Loss:0.22598, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1663, Train Loss:0.27814, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1664, Train Loss:0.20583, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1665, Train Loss:0.06571, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1666, Train Loss:0.11958, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1667, Train Loss:0.08184, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1668, Train Loss:0.47264, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1669, Train Loss:0.66224, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1670, Train Loss:0.28630, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1671, Train Loss:0.30600, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1672, Train Loss:0.34196, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1673, Train Loss:0.14593, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1674, Train Loss:0.23863, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1675, Train Loss:0.36863, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1676, Train Loss:0.09899, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1677, Train Loss:0.35746, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1678, Train Loss:0.28151, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1679, Train Loss:0.24840, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1680, Train Loss:0.35785, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1681, Train Loss:0.28773, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1682, Train Loss:0.54721, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1683, Train Loss:0.17593, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1684, Train Loss:0.29796, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1685, Train Loss:0.28119, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1686, Train Loss:0.43187, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1687, Train Loss:0.14213, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1688, Train Loss:1.25537, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1689, Train Loss:0.21648, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1690, Train Loss:0.50432, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1691, Train Loss:0.80039, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1692, Train Loss:0.05111, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1693, Train Loss:0.61064, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1694, Train Loss:0.40876, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1695, Train Loss:0.44685, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1696, Train Loss:0.85164, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1697, Train Loss:0.22535, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1698, Train Loss:0.34877, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1699, Train Loss:0.69197, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1700, Train Loss:0.14149, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1701, Train Loss:0.40937, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1702, Train Loss:0.26065, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1703, Train Loss:0.06330, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1704, Train Loss:0.23319, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1705, Train Loss:0.35387, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1706, Train Loss:0.41931, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1707, Train Loss:0.82671, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1708, Train Loss:0.82512, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1709, Train Loss:0.42252, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1710, Train Loss:0.40178, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1711, Train Loss:0.11778, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1712, Train Loss:0.39073, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1713, Train Loss:0.43333, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1714, Train Loss:0.24841, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1715, Train Loss:0.18265, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1716, Train Loss:0.12343, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1717, Train Loss:0.16143, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1718, Train Loss:0.45251, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1719, Train Loss:0.59804, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1720, Train Loss:0.34262, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1721, Train Loss:0.56606, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1722, Train Loss:0.41573, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1723, Train Loss:1.02322, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1724, Train Loss:0.29847, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1725, Train Loss:0.15524, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1726, Train Loss:0.23990, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1727, Train Loss:0.10487, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1728, Train Loss:0.32045, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1729, Train Loss:0.11080, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1730, Train Loss:1.02818, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1731, Train Loss:0.50529, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1732, Train Loss:0.48864, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1733, Train Loss:0.14394, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1734, Train Loss:0.08649, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1735, Train Loss:0.68451, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1736, Train Loss:0.21166, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1737, Train Loss:0.13063, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1738, Train Loss:0.18123, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1739, Train Loss:0.23586, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1740, Train Loss:0.24631, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1741, Train Loss:0.03003, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1742, Train Loss:0.20484, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1743, Train Loss:0.09697, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1744, Train Loss:0.31858, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1745, Train Loss:0.27091, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1746, Train Loss:0.19297, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1747, Train Loss:1.01287, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1748, Train Loss:0.19545, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1749, Train Loss:0.17844, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1750, Train Loss:0.56987, Dev Loss:0.40415\n",
      "Epoch:[6/100], step:1751, Train Loss:0.14720, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1752, Train Loss:0.10574, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1753, Train Loss:0.07940, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1754, Train Loss:0.28232, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1755, Train Loss:0.07937, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1756, Train Loss:0.28705, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1757, Train Loss:0.36902, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1758, Train Loss:0.43681, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1759, Train Loss:0.45638, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1760, Train Loss:0.25852, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1761, Train Loss:0.12363, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1762, Train Loss:0.11289, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1763, Train Loss:0.11119, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1764, Train Loss:0.27400, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1765, Train Loss:0.05168, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1766, Train Loss:0.47348, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1767, Train Loss:0.45447, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1768, Train Loss:0.18247, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1769, Train Loss:0.07895, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1770, Train Loss:0.02307, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1771, Train Loss:0.11364, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1772, Train Loss:0.20186, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1773, Train Loss:0.33106, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1774, Train Loss:0.02104, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1775, Train Loss:0.50324, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1776, Train Loss:0.24670, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1777, Train Loss:0.43911, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1778, Train Loss:0.08813, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1779, Train Loss:0.17537, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1780, Train Loss:0.19101, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1781, Train Loss:0.79839, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1782, Train Loss:0.89428, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1783, Train Loss:0.45931, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1784, Train Loss:0.22770, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1785, Train Loss:0.05785, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1786, Train Loss:0.47326, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1787, Train Loss:0.16965, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1788, Train Loss:0.43066, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1789, Train Loss:0.16552, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1790, Train Loss:0.14436, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1791, Train Loss:0.50342, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1792, Train Loss:0.19455, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1793, Train Loss:0.28061, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1794, Train Loss:0.60034, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1795, Train Loss:0.73624, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1796, Train Loss:0.35511, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1797, Train Loss:0.22148, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1798, Train Loss:0.29208, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1799, Train Loss:0.37591, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1800, Train Loss:0.33451, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1801, Train Loss:0.32311, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1802, Train Loss:0.18964, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1803, Train Loss:0.28065, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1804, Train Loss:1.60393, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1805, Train Loss:0.07809, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1806, Train Loss:0.55308, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1807, Train Loss:0.46213, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1808, Train Loss:0.23588, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1809, Train Loss:0.29778, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1810, Train Loss:0.36673, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1811, Train Loss:0.17564, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1812, Train Loss:0.10988, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1813, Train Loss:1.01318, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1814, Train Loss:0.14153, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1815, Train Loss:0.04575, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1816, Train Loss:0.34004, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1817, Train Loss:0.43737, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1818, Train Loss:0.43508, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1819, Train Loss:0.36445, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1820, Train Loss:0.09801, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1821, Train Loss:0.00739, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1822, Train Loss:0.16871, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1823, Train Loss:0.40279, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1824, Train Loss:0.12053, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1825, Train Loss:0.09608, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1826, Train Loss:0.30642, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1827, Train Loss:0.07852, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1828, Train Loss:0.10721, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1829, Train Loss:0.10225, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1830, Train Loss:0.04734, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1831, Train Loss:0.25553, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1832, Train Loss:0.51489, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1833, Train Loss:0.33946, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1834, Train Loss:0.03192, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1835, Train Loss:0.22284, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1836, Train Loss:0.23271, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1837, Train Loss:0.06552, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1838, Train Loss:0.11697, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1839, Train Loss:0.07052, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1840, Train Loss:0.42406, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1841, Train Loss:0.03625, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1842, Train Loss:0.46054, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1843, Train Loss:0.30075, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1844, Train Loss:0.40770, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1845, Train Loss:0.18651, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1846, Train Loss:0.11557, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1847, Train Loss:0.00639, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1848, Train Loss:0.20609, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1849, Train Loss:0.29568, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1850, Train Loss:0.32757, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1851, Train Loss:0.20885, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1852, Train Loss:0.01923, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1853, Train Loss:0.50026, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1854, Train Loss:0.04403, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1855, Train Loss:0.14265, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1856, Train Loss:0.09653, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1857, Train Loss:0.06253, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1858, Train Loss:0.13980, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1859, Train Loss:0.14130, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1860, Train Loss:0.29855, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1861, Train Loss:0.29429, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1862, Train Loss:0.12619, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1863, Train Loss:0.05660, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1864, Train Loss:0.13539, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1865, Train Loss:0.29999, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1866, Train Loss:0.35369, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1867, Train Loss:0.35449, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1868, Train Loss:0.31086, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1869, Train Loss:0.33220, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1870, Train Loss:0.04400, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1871, Train Loss:0.09496, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1872, Train Loss:0.17229, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1873, Train Loss:0.46008, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1874, Train Loss:0.30505, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1875, Train Loss:0.10022, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1876, Train Loss:0.50657, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1877, Train Loss:0.10761, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1878, Train Loss:0.00752, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1879, Train Loss:0.19813, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1880, Train Loss:0.17196, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1881, Train Loss:0.19861, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1882, Train Loss:0.14868, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1883, Train Loss:0.18538, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1884, Train Loss:0.35287, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1885, Train Loss:0.18469, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1886, Train Loss:0.59780, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1887, Train Loss:0.49696, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1888, Train Loss:0.02997, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1889, Train Loss:0.65713, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1890, Train Loss:0.65136, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1891, Train Loss:0.31640, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1892, Train Loss:0.38062, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1893, Train Loss:0.24862, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1894, Train Loss:0.18750, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1895, Train Loss:0.95735, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1896, Train Loss:0.30051, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1897, Train Loss:0.52948, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1898, Train Loss:0.20617, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1899, Train Loss:0.23618, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1900, Train Loss:0.74078, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1901, Train Loss:0.28839, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1902, Train Loss:0.18487, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1903, Train Loss:0.18281, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1904, Train Loss:0.14163, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1905, Train Loss:0.10378, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1906, Train Loss:0.06241, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1907, Train Loss:0.53856, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1908, Train Loss:0.42912, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1909, Train Loss:0.16271, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1910, Train Loss:0.53526, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1911, Train Loss:0.51753, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1912, Train Loss:0.16227, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1913, Train Loss:0.51635, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1914, Train Loss:0.28240, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1915, Train Loss:0.51737, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1916, Train Loss:0.36348, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1917, Train Loss:0.32614, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1918, Train Loss:0.21301, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1919, Train Loss:0.27577, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1920, Train Loss:0.62110, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1921, Train Loss:0.36953, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1922, Train Loss:0.19766, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1923, Train Loss:1.43414, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1924, Train Loss:0.28967, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1925, Train Loss:0.13614, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1926, Train Loss:0.19115, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1927, Train Loss:0.52007, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1928, Train Loss:0.04232, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1929, Train Loss:0.86080, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1930, Train Loss:0.44248, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1931, Train Loss:0.33474, Dev Loss:0.30988\n",
      "Epoch:[6/100], step:1932, Train Loss:0.59837, Dev Loss:0.30988\n",
      "Start Epoch: 7, Steps: 17\n",
      "Epoch:[7/100], step:1933, Train Loss:0.25557, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1934, Train Loss:0.40340, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1935, Train Loss:0.16861, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1936, Train Loss:0.23635, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1937, Train Loss:0.39746, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1938, Train Loss:0.23584, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1939, Train Loss:0.16163, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1940, Train Loss:0.38868, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1941, Train Loss:0.26390, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1942, Train Loss:0.23317, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1943, Train Loss:0.08889, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1944, Train Loss:0.13409, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1945, Train Loss:0.41554, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1946, Train Loss:0.25670, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1947, Train Loss:0.73672, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1948, Train Loss:0.29297, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1949, Train Loss:0.73274, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1950, Train Loss:0.04794, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1951, Train Loss:0.23118, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1952, Train Loss:0.51309, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1953, Train Loss:0.08625, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1954, Train Loss:0.62969, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1955, Train Loss:0.18008, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1956, Train Loss:0.43373, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1957, Train Loss:0.58603, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1958, Train Loss:0.16915, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1959, Train Loss:0.29735, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1960, Train Loss:0.57105, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1961, Train Loss:0.62348, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1962, Train Loss:0.54319, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1963, Train Loss:0.57694, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1964, Train Loss:0.19005, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1965, Train Loss:0.40204, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1966, Train Loss:0.03215, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1967, Train Loss:0.27697, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1968, Train Loss:0.08663, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1969, Train Loss:0.08522, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1970, Train Loss:0.47890, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1971, Train Loss:0.86600, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1972, Train Loss:0.31435, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1973, Train Loss:0.20726, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1974, Train Loss:0.51303, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1975, Train Loss:0.11785, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1976, Train Loss:0.19877, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1977, Train Loss:0.16045, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1978, Train Loss:0.16101, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1979, Train Loss:0.20577, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1980, Train Loss:0.44385, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1981, Train Loss:0.05071, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1982, Train Loss:0.47811, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1983, Train Loss:0.92175, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1984, Train Loss:0.27620, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1985, Train Loss:0.11400, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1986, Train Loss:0.23777, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1987, Train Loss:0.20072, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1988, Train Loss:0.00921, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1989, Train Loss:0.08033, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1990, Train Loss:0.03761, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1991, Train Loss:0.05330, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1992, Train Loss:0.06568, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1993, Train Loss:0.15108, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1994, Train Loss:0.09211, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1995, Train Loss:0.17277, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1996, Train Loss:0.03581, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1997, Train Loss:0.21441, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1998, Train Loss:1.23477, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:1999, Train Loss:0.02460, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:2000, Train Loss:0.28340, Dev Loss:0.30988\n",
      "Epoch:[7/100], step:2001, Train Loss:0.26824, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2002, Train Loss:0.01950, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2003, Train Loss:0.85595, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2004, Train Loss:0.12913, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2005, Train Loss:0.14530, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2006, Train Loss:0.54406, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2007, Train Loss:0.17045, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2008, Train Loss:0.03700, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2009, Train Loss:0.11364, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2010, Train Loss:0.30410, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2011, Train Loss:0.25109, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2012, Train Loss:0.06332, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2013, Train Loss:0.04767, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2014, Train Loss:0.27320, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2015, Train Loss:0.44210, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2016, Train Loss:0.66966, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2017, Train Loss:0.41681, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2018, Train Loss:0.28266, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2019, Train Loss:0.47100, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2020, Train Loss:0.34517, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2021, Train Loss:0.18391, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2022, Train Loss:0.26300, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2023, Train Loss:0.21555, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2024, Train Loss:0.07617, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2025, Train Loss:0.10268, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2026, Train Loss:0.58300, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2027, Train Loss:0.06965, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2028, Train Loss:0.05384, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2029, Train Loss:0.48375, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2030, Train Loss:0.11317, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2031, Train Loss:0.24474, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2032, Train Loss:0.46485, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2033, Train Loss:0.06354, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2034, Train Loss:0.13884, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2035, Train Loss:0.09652, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2036, Train Loss:0.14630, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2037, Train Loss:0.21720, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2038, Train Loss:0.28151, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2039, Train Loss:0.33649, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2040, Train Loss:0.23033, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2041, Train Loss:0.36354, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2042, Train Loss:0.51882, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2043, Train Loss:0.61080, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2044, Train Loss:0.25729, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2045, Train Loss:0.61584, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2046, Train Loss:0.25858, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2047, Train Loss:0.45105, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2048, Train Loss:0.42134, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2049, Train Loss:0.08122, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2050, Train Loss:0.01622, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2051, Train Loss:0.19571, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2052, Train Loss:0.35697, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2053, Train Loss:0.41013, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2054, Train Loss:0.21487, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2055, Train Loss:0.56363, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2056, Train Loss:0.02825, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2057, Train Loss:0.26566, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2058, Train Loss:0.46840, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2059, Train Loss:0.25900, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2060, Train Loss:0.29562, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2061, Train Loss:0.04249, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2062, Train Loss:0.18949, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2063, Train Loss:0.10435, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2064, Train Loss:0.65507, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2065, Train Loss:0.09957, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2066, Train Loss:0.22154, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2067, Train Loss:0.14225, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2068, Train Loss:0.15545, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2069, Train Loss:0.39695, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2070, Train Loss:0.47596, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2071, Train Loss:0.04530, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2072, Train Loss:0.30933, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2073, Train Loss:0.26443, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2074, Train Loss:0.01299, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2075, Train Loss:0.16530, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2076, Train Loss:0.02169, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2077, Train Loss:0.15957, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2078, Train Loss:0.00649, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2079, Train Loss:0.46315, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2080, Train Loss:0.16741, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2081, Train Loss:0.33727, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2082, Train Loss:0.26060, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2083, Train Loss:0.34131, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2084, Train Loss:0.04098, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2085, Train Loss:0.12016, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2086, Train Loss:0.82760, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2087, Train Loss:0.40426, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2088, Train Loss:0.01800, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2089, Train Loss:0.37664, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2090, Train Loss:0.22731, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2091, Train Loss:0.06567, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2092, Train Loss:0.51023, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2093, Train Loss:0.48528, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2094, Train Loss:0.24951, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2095, Train Loss:0.36138, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2096, Train Loss:0.38714, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2097, Train Loss:0.10826, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2098, Train Loss:0.12629, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2099, Train Loss:0.06572, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2100, Train Loss:0.12742, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2101, Train Loss:0.25847, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2102, Train Loss:0.12532, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2103, Train Loss:0.85246, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2104, Train Loss:0.05149, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2105, Train Loss:0.11000, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2106, Train Loss:0.14311, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2107, Train Loss:0.47935, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2108, Train Loss:0.09672, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2109, Train Loss:0.27905, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2110, Train Loss:0.04822, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2111, Train Loss:0.21237, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2112, Train Loss:0.03780, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2113, Train Loss:0.09801, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2114, Train Loss:0.21576, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2115, Train Loss:0.36884, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2116, Train Loss:0.09968, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2117, Train Loss:0.28401, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2118, Train Loss:0.27701, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2119, Train Loss:0.17561, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2120, Train Loss:0.06707, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2121, Train Loss:0.42760, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2122, Train Loss:0.00297, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2123, Train Loss:0.17895, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2124, Train Loss:0.23129, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2125, Train Loss:0.30022, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2126, Train Loss:0.07439, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2127, Train Loss:0.48677, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2128, Train Loss:0.43132, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2129, Train Loss:0.08449, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2130, Train Loss:0.32891, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2131, Train Loss:0.01237, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2132, Train Loss:0.09811, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2133, Train Loss:0.17306, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2134, Train Loss:0.67356, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2135, Train Loss:0.25569, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2136, Train Loss:0.13992, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2137, Train Loss:0.49108, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2138, Train Loss:0.14884, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2139, Train Loss:0.45880, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2140, Train Loss:0.12991, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2141, Train Loss:0.16922, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2142, Train Loss:0.10101, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2143, Train Loss:0.01767, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2144, Train Loss:0.46554, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2145, Train Loss:0.04668, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2146, Train Loss:0.49618, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2147, Train Loss:0.44788, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2148, Train Loss:0.19685, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2149, Train Loss:0.41687, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2150, Train Loss:0.11063, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2151, Train Loss:0.92245, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2152, Train Loss:0.16241, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2153, Train Loss:0.06294, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2154, Train Loss:0.30164, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2155, Train Loss:0.58339, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2156, Train Loss:0.34937, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2157, Train Loss:0.22956, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2158, Train Loss:0.11474, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2159, Train Loss:0.35872, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2160, Train Loss:0.29183, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2161, Train Loss:0.01791, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2162, Train Loss:0.08064, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2163, Train Loss:0.08440, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2164, Train Loss:0.17935, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2165, Train Loss:0.15763, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2166, Train Loss:0.15367, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2167, Train Loss:0.08067, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2168, Train Loss:0.12005, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2169, Train Loss:0.05395, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2170, Train Loss:0.07304, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2171, Train Loss:0.32122, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2172, Train Loss:0.14504, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2173, Train Loss:0.02658, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2174, Train Loss:0.72194, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2175, Train Loss:0.37057, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2176, Train Loss:0.49930, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2177, Train Loss:0.27049, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2178, Train Loss:0.38175, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2179, Train Loss:0.07183, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2180, Train Loss:0.48427, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2181, Train Loss:0.15728, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2182, Train Loss:0.00782, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2183, Train Loss:0.28318, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2184, Train Loss:0.08862, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2185, Train Loss:0.32646, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2186, Train Loss:0.00447, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2187, Train Loss:0.21946, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2188, Train Loss:0.25396, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2189, Train Loss:0.94437, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2190, Train Loss:0.35376, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2191, Train Loss:0.30890, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2192, Train Loss:0.33308, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2193, Train Loss:1.12432, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2194, Train Loss:0.38451, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2195, Train Loss:0.25591, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2196, Train Loss:0.18463, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2197, Train Loss:0.35904, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2198, Train Loss:0.60629, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2199, Train Loss:0.50427, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2200, Train Loss:0.11727, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2201, Train Loss:0.10379, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2202, Train Loss:0.33087, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2203, Train Loss:0.03387, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2204, Train Loss:0.16658, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2205, Train Loss:0.06401, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2206, Train Loss:0.41742, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2207, Train Loss:0.01516, Dev Loss:0.20090\n",
      "Epoch:[7/100], step:2208, Train Loss:0.17343, Dev Loss:0.20090\n",
      "Start Epoch: 8, Steps: 17\n",
      "Epoch:[8/100], step:2209, Train Loss:0.13114, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2210, Train Loss:0.04905, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2211, Train Loss:0.25210, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2212, Train Loss:0.22272, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2213, Train Loss:0.55599, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2214, Train Loss:0.27508, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2215, Train Loss:0.23133, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2216, Train Loss:0.09597, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2217, Train Loss:0.22559, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2218, Train Loss:0.43198, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2219, Train Loss:0.01068, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2220, Train Loss:0.24467, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2221, Train Loss:0.12083, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2222, Train Loss:0.19408, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2223, Train Loss:0.21687, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2224, Train Loss:0.43115, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2225, Train Loss:0.39390, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2226, Train Loss:0.17028, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2227, Train Loss:0.05853, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2228, Train Loss:0.26293, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2229, Train Loss:0.20225, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2230, Train Loss:0.01154, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2231, Train Loss:0.05466, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2232, Train Loss:0.15509, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2233, Train Loss:0.09620, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2234, Train Loss:0.23858, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2235, Train Loss:0.29794, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2236, Train Loss:0.17280, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2237, Train Loss:0.18584, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2238, Train Loss:0.24532, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2239, Train Loss:0.09129, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2240, Train Loss:0.21469, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2241, Train Loss:0.26527, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2242, Train Loss:0.12507, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2243, Train Loss:0.41377, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2244, Train Loss:0.05769, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2245, Train Loss:0.11553, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2246, Train Loss:0.34722, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2247, Train Loss:0.00432, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2248, Train Loss:0.10901, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2249, Train Loss:0.13239, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2250, Train Loss:0.62159, Dev Loss:0.20090\n",
      "Epoch:[8/100], step:2251, Train Loss:0.04195, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2252, Train Loss:0.03236, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2253, Train Loss:0.23564, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2254, Train Loss:0.20788, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2255, Train Loss:0.10094, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2256, Train Loss:0.69107, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2257, Train Loss:0.18181, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2258, Train Loss:0.06016, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2259, Train Loss:0.11000, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2260, Train Loss:0.41358, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2261, Train Loss:0.26730, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2262, Train Loss:0.20927, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2263, Train Loss:0.72330, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2264, Train Loss:0.23658, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2265, Train Loss:0.28005, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2266, Train Loss:0.09157, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2267, Train Loss:1.35904, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2268, Train Loss:0.19386, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2269, Train Loss:0.31476, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2270, Train Loss:0.18024, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2271, Train Loss:0.14305, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2272, Train Loss:0.56438, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2273, Train Loss:0.11095, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2274, Train Loss:0.36003, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2275, Train Loss:0.23472, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2276, Train Loss:0.55959, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2277, Train Loss:0.08602, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2278, Train Loss:0.24065, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2279, Train Loss:0.47354, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2280, Train Loss:0.15216, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2281, Train Loss:0.03940, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2282, Train Loss:0.02146, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2283, Train Loss:0.43665, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2284, Train Loss:0.11756, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2285, Train Loss:0.02932, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2286, Train Loss:0.16217, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2287, Train Loss:0.21057, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2288, Train Loss:0.14685, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2289, Train Loss:0.05253, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2290, Train Loss:1.28203, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2291, Train Loss:0.25859, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2292, Train Loss:0.16825, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2293, Train Loss:0.30106, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2294, Train Loss:0.10898, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2295, Train Loss:0.08899, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2296, Train Loss:0.44111, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2297, Train Loss:0.16845, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2298, Train Loss:0.16566, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2299, Train Loss:0.21198, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2300, Train Loss:0.02423, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2301, Train Loss:0.34389, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2302, Train Loss:0.17229, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2303, Train Loss:0.61391, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2304, Train Loss:0.07183, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2305, Train Loss:0.41637, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2306, Train Loss:0.30843, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2307, Train Loss:0.14197, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2308, Train Loss:0.01028, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2309, Train Loss:0.28817, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2310, Train Loss:0.03223, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2311, Train Loss:0.27609, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2312, Train Loss:0.06984, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2313, Train Loss:0.21338, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2314, Train Loss:0.18704, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2315, Train Loss:0.03497, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2316, Train Loss:0.70785, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2317, Train Loss:0.26882, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2318, Train Loss:0.17064, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2319, Train Loss:0.24408, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2320, Train Loss:0.25265, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2321, Train Loss:0.10785, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2322, Train Loss:0.01932, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2323, Train Loss:0.20854, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2324, Train Loss:0.11800, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2325, Train Loss:0.98500, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2326, Train Loss:0.06070, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2327, Train Loss:0.22220, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2328, Train Loss:0.02563, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2329, Train Loss:0.30080, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2330, Train Loss:0.07891, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2331, Train Loss:0.38859, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2332, Train Loss:0.07538, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2333, Train Loss:0.26762, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2334, Train Loss:0.49753, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2335, Train Loss:0.76984, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2336, Train Loss:0.52461, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2337, Train Loss:0.10360, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2338, Train Loss:0.02535, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2339, Train Loss:0.02013, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2340, Train Loss:0.26007, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2341, Train Loss:0.41936, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2342, Train Loss:0.00241, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2343, Train Loss:0.44288, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2344, Train Loss:0.02581, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2345, Train Loss:0.17779, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2346, Train Loss:0.19567, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2347, Train Loss:0.21820, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2348, Train Loss:0.33050, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2349, Train Loss:0.21074, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2350, Train Loss:0.06576, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2351, Train Loss:0.45575, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2352, Train Loss:0.14842, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2353, Train Loss:0.35611, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2354, Train Loss:0.26039, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2355, Train Loss:0.07024, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2356, Train Loss:0.03022, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2357, Train Loss:0.04575, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2358, Train Loss:0.14373, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2359, Train Loss:0.13344, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2360, Train Loss:0.07080, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2361, Train Loss:0.34857, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2362, Train Loss:0.25411, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2363, Train Loss:0.23703, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2364, Train Loss:0.22850, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2365, Train Loss:0.29913, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2366, Train Loss:0.14690, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2367, Train Loss:0.39098, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2368, Train Loss:0.05894, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2369, Train Loss:0.20765, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2370, Train Loss:0.46505, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2371, Train Loss:0.03592, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2372, Train Loss:1.38750, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2373, Train Loss:0.55629, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2374, Train Loss:0.23861, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2375, Train Loss:0.55967, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2376, Train Loss:0.23739, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2377, Train Loss:0.31127, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2378, Train Loss:0.23431, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2379, Train Loss:0.02377, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2380, Train Loss:0.01933, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2381, Train Loss:0.10044, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2382, Train Loss:0.40467, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2383, Train Loss:0.62670, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2384, Train Loss:0.39631, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2385, Train Loss:0.72216, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2386, Train Loss:0.13910, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2387, Train Loss:0.12996, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2388, Train Loss:0.00809, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2389, Train Loss:0.10721, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2390, Train Loss:0.24024, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2391, Train Loss:0.67974, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2392, Train Loss:0.02008, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2393, Train Loss:0.01741, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2394, Train Loss:0.22814, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2395, Train Loss:0.44121, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2396, Train Loss:0.17196, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2397, Train Loss:0.20043, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2398, Train Loss:0.10426, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2399, Train Loss:0.41698, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2400, Train Loss:0.25072, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2401, Train Loss:0.19577, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2402, Train Loss:0.26817, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2403, Train Loss:0.39749, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2404, Train Loss:0.13194, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2405, Train Loss:0.79495, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2406, Train Loss:0.53693, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2407, Train Loss:0.08889, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2408, Train Loss:0.36293, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2409, Train Loss:0.05664, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2410, Train Loss:0.20921, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2411, Train Loss:0.09478, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2412, Train Loss:0.19670, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2413, Train Loss:0.21616, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2414, Train Loss:0.24422, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2415, Train Loss:0.27162, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2416, Train Loss:0.23179, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2417, Train Loss:0.25670, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2418, Train Loss:0.18139, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2419, Train Loss:0.11276, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2420, Train Loss:0.21724, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2421, Train Loss:0.90648, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2422, Train Loss:0.46158, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2423, Train Loss:0.36914, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2424, Train Loss:0.21561, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2425, Train Loss:0.06276, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2426, Train Loss:0.43396, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2427, Train Loss:0.06889, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2428, Train Loss:0.09330, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2429, Train Loss:0.22615, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2430, Train Loss:0.10351, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2431, Train Loss:0.35548, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2432, Train Loss:0.06369, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2433, Train Loss:0.12596, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2434, Train Loss:0.33891, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2435, Train Loss:0.28893, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2436, Train Loss:0.07992, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2437, Train Loss:0.01340, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2438, Train Loss:0.37769, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2439, Train Loss:0.16447, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2440, Train Loss:0.13206, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2441, Train Loss:0.13094, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2442, Train Loss:0.13569, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2443, Train Loss:0.45287, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2444, Train Loss:0.13986, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2445, Train Loss:0.18678, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2446, Train Loss:0.24970, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2447, Train Loss:0.33528, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2448, Train Loss:0.36480, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2449, Train Loss:0.32174, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2450, Train Loss:0.12446, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2451, Train Loss:0.36977, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2452, Train Loss:0.36943, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2453, Train Loss:0.15053, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2454, Train Loss:0.53105, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2455, Train Loss:0.44914, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2456, Train Loss:0.34915, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2457, Train Loss:0.36105, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2458, Train Loss:0.28568, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2459, Train Loss:0.19849, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2460, Train Loss:0.14771, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2461, Train Loss:0.43261, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2462, Train Loss:0.26657, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2463, Train Loss:0.40700, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2464, Train Loss:0.28798, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2465, Train Loss:0.27774, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2466, Train Loss:0.18994, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2467, Train Loss:0.18709, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2468, Train Loss:0.02102, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2469, Train Loss:0.09948, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2470, Train Loss:0.19579, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2471, Train Loss:0.20265, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2472, Train Loss:0.07294, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2473, Train Loss:0.03316, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2474, Train Loss:0.00746, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2475, Train Loss:0.21305, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2476, Train Loss:0.52900, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2477, Train Loss:0.45335, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2478, Train Loss:0.34748, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2479, Train Loss:0.34988, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2480, Train Loss:0.01795, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2481, Train Loss:1.09932, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2482, Train Loss:0.03027, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2483, Train Loss:0.04298, Dev Loss:0.24382\n",
      "Epoch:[8/100], step:2484, Train Loss:0.49711, Dev Loss:0.24382\n",
      "Start Epoch: 9, Steps: 17\n",
      "Epoch:[9/100], step:2485, Train Loss:0.38770, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2486, Train Loss:0.42386, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2487, Train Loss:0.00068, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2488, Train Loss:0.00182, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2489, Train Loss:0.12269, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2490, Train Loss:0.00261, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2491, Train Loss:0.39755, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2492, Train Loss:0.25324, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2493, Train Loss:0.25426, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2494, Train Loss:0.17917, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2495, Train Loss:0.22197, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2496, Train Loss:0.41294, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2497, Train Loss:0.32665, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2498, Train Loss:0.09827, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2499, Train Loss:0.16279, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2500, Train Loss:0.29689, Dev Loss:0.24382\n",
      "Epoch:[9/100], step:2501, Train Loss:0.00581, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2502, Train Loss:0.04052, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2503, Train Loss:0.10754, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2504, Train Loss:0.05496, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2505, Train Loss:0.50179, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2506, Train Loss:0.19405, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2507, Train Loss:0.02809, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2508, Train Loss:0.32286, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2509, Train Loss:0.28997, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2510, Train Loss:0.16983, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2511, Train Loss:0.08149, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2512, Train Loss:0.01211, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2513, Train Loss:0.06522, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2514, Train Loss:0.21373, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2515, Train Loss:0.17160, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2516, Train Loss:0.28294, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2517, Train Loss:0.22948, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2518, Train Loss:0.00440, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2519, Train Loss:0.48304, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2520, Train Loss:0.02698, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2521, Train Loss:0.00517, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2522, Train Loss:0.11644, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2523, Train Loss:0.27708, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2524, Train Loss:0.01695, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2525, Train Loss:0.18127, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2526, Train Loss:0.23316, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2527, Train Loss:0.11866, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2528, Train Loss:0.13102, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2529, Train Loss:0.29800, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2530, Train Loss:0.04609, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2531, Train Loss:0.32579, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2532, Train Loss:0.12344, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2533, Train Loss:0.25062, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2534, Train Loss:0.07939, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2535, Train Loss:0.15967, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2536, Train Loss:0.25787, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2537, Train Loss:0.13144, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2538, Train Loss:0.05564, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2539, Train Loss:0.18342, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2540, Train Loss:0.00174, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2541, Train Loss:0.00391, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2542, Train Loss:0.07868, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2543, Train Loss:0.06275, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2544, Train Loss:0.10244, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2545, Train Loss:0.04400, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2546, Train Loss:0.17376, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2547, Train Loss:0.05292, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2548, Train Loss:0.48648, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2549, Train Loss:0.03659, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2550, Train Loss:0.30372, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2551, Train Loss:0.00491, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2552, Train Loss:0.04799, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2553, Train Loss:0.05969, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2554, Train Loss:0.02151, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2555, Train Loss:0.20548, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2556, Train Loss:0.00273, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2557, Train Loss:0.11236, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2558, Train Loss:0.05213, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2559, Train Loss:0.28609, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2560, Train Loss:0.52519, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2561, Train Loss:0.03477, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2562, Train Loss:0.49535, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2563, Train Loss:0.10663, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2564, Train Loss:0.15730, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2565, Train Loss:0.36588, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2566, Train Loss:0.66071, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2567, Train Loss:0.06252, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2568, Train Loss:0.53042, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2569, Train Loss:0.23868, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2570, Train Loss:0.04850, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2571, Train Loss:0.61588, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2572, Train Loss:0.24388, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2573, Train Loss:0.03597, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2574, Train Loss:0.11538, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2575, Train Loss:0.00864, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2576, Train Loss:0.10711, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2577, Train Loss:0.11770, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2578, Train Loss:0.10790, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2579, Train Loss:0.39567, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2580, Train Loss:1.12597, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2581, Train Loss:0.28393, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2582, Train Loss:0.13923, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2583, Train Loss:0.34309, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2584, Train Loss:0.16335, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2585, Train Loss:0.26918, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2586, Train Loss:0.23915, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2587, Train Loss:0.09427, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2588, Train Loss:0.36142, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2589, Train Loss:0.05450, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2590, Train Loss:0.00751, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2591, Train Loss:0.15039, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2592, Train Loss:0.18570, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2593, Train Loss:0.06249, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2594, Train Loss:0.01877, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2595, Train Loss:0.06066, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2596, Train Loss:0.31646, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2597, Train Loss:0.00524, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2598, Train Loss:0.04104, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2599, Train Loss:0.08771, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2600, Train Loss:0.36355, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2601, Train Loss:0.01230, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2602, Train Loss:0.69554, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2603, Train Loss:0.18287, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2604, Train Loss:0.17276, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2605, Train Loss:0.09591, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2606, Train Loss:0.31526, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2607, Train Loss:0.14896, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2608, Train Loss:0.21197, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2609, Train Loss:0.03461, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2610, Train Loss:0.07952, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2611, Train Loss:0.13100, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2612, Train Loss:0.01157, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2613, Train Loss:0.16095, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2614, Train Loss:0.02967, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2615, Train Loss:0.05049, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2616, Train Loss:0.04814, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2617, Train Loss:0.03179, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2618, Train Loss:0.63972, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2619, Train Loss:0.05921, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2620, Train Loss:0.13741, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2621, Train Loss:0.17264, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2622, Train Loss:0.04372, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2623, Train Loss:0.91075, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2624, Train Loss:0.00439, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2625, Train Loss:0.18089, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2626, Train Loss:0.33900, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2627, Train Loss:0.53713, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2628, Train Loss:0.06601, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2629, Train Loss:0.47921, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2630, Train Loss:0.50741, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2631, Train Loss:0.73559, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2632, Train Loss:0.51117, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2633, Train Loss:1.01118, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2634, Train Loss:0.69616, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2635, Train Loss:0.22879, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2636, Train Loss:0.57028, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2637, Train Loss:0.13114, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2638, Train Loss:0.41733, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2639, Train Loss:0.38313, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2640, Train Loss:0.14387, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2641, Train Loss:0.30092, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2642, Train Loss:0.48310, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2643, Train Loss:0.27752, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2644, Train Loss:0.02089, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2645, Train Loss:0.20266, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2646, Train Loss:0.14624, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2647, Train Loss:0.20498, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2648, Train Loss:0.16283, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2649, Train Loss:0.05412, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2650, Train Loss:0.20227, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2651, Train Loss:0.56256, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2652, Train Loss:0.29142, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2653, Train Loss:0.08554, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2654, Train Loss:0.22619, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2655, Train Loss:0.07190, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2656, Train Loss:0.05385, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2657, Train Loss:0.44459, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2658, Train Loss:0.06961, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2659, Train Loss:0.05387, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2660, Train Loss:0.42004, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2661, Train Loss:0.16317, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2662, Train Loss:0.13712, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2663, Train Loss:0.20275, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2664, Train Loss:0.45993, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2665, Train Loss:0.46448, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2666, Train Loss:0.00642, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2667, Train Loss:0.34385, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2668, Train Loss:0.06211, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2669, Train Loss:0.74202, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2670, Train Loss:0.68174, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2671, Train Loss:0.00760, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2672, Train Loss:0.53740, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2673, Train Loss:0.42066, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2674, Train Loss:0.11358, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2675, Train Loss:0.09575, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2676, Train Loss:0.06859, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2677, Train Loss:0.15073, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2678, Train Loss:0.45015, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2679, Train Loss:0.64293, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2680, Train Loss:0.03180, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2681, Train Loss:0.18833, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2682, Train Loss:0.07408, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2683, Train Loss:0.22626, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2684, Train Loss:0.11507, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2685, Train Loss:0.02125, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2686, Train Loss:0.35957, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2687, Train Loss:0.28986, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2688, Train Loss:0.17579, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2689, Train Loss:0.02228, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2690, Train Loss:0.34093, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2691, Train Loss:0.63974, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2692, Train Loss:0.66480, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2693, Train Loss:0.34459, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2694, Train Loss:0.04583, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2695, Train Loss:0.21926, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2696, Train Loss:0.08712, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2697, Train Loss:0.24448, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2698, Train Loss:0.63623, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2699, Train Loss:0.51247, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2700, Train Loss:0.15679, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2701, Train Loss:0.01892, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2702, Train Loss:0.51731, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2703, Train Loss:0.25838, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2704, Train Loss:0.19397, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2705, Train Loss:0.07279, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2706, Train Loss:0.27909, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2707, Train Loss:0.10753, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2708, Train Loss:0.22771, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2709, Train Loss:0.57180, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2710, Train Loss:0.13905, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2711, Train Loss:0.59885, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2712, Train Loss:0.21679, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2713, Train Loss:0.16330, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2714, Train Loss:0.00629, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2715, Train Loss:0.01059, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2716, Train Loss:0.18505, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2717, Train Loss:0.11659, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2718, Train Loss:0.12260, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2719, Train Loss:0.14842, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2720, Train Loss:0.30177, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2721, Train Loss:0.18129, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2722, Train Loss:0.12323, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2723, Train Loss:0.23106, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2724, Train Loss:0.08136, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2725, Train Loss:0.12260, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2726, Train Loss:0.20480, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2727, Train Loss:0.14194, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2728, Train Loss:0.40357, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2729, Train Loss:0.48334, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2730, Train Loss:0.13621, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2731, Train Loss:0.39445, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2732, Train Loss:0.14053, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2733, Train Loss:0.08004, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2734, Train Loss:0.01077, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2735, Train Loss:0.16480, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2736, Train Loss:0.00190, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2737, Train Loss:0.16499, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2738, Train Loss:0.08971, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2739, Train Loss:0.56560, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2740, Train Loss:0.42650, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2741, Train Loss:0.61330, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2742, Train Loss:0.03635, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2743, Train Loss:0.05960, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2744, Train Loss:0.10800, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2745, Train Loss:0.00768, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2746, Train Loss:0.04835, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2747, Train Loss:0.30040, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2748, Train Loss:0.19801, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2749, Train Loss:0.12673, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2750, Train Loss:0.02429, Dev Loss:0.26627\n",
      "Epoch:[9/100], step:2751, Train Loss:0.02018, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2752, Train Loss:0.00777, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2753, Train Loss:0.11671, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2754, Train Loss:0.35114, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2755, Train Loss:0.10914, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2756, Train Loss:0.44787, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2757, Train Loss:0.44117, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2758, Train Loss:0.10652, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2759, Train Loss:0.09471, Dev Loss:0.19179\n",
      "Epoch:[9/100], step:2760, Train Loss:0.68887, Dev Loss:0.19179\n",
      "Start Epoch: 10, Steps: 17\n",
      "Epoch:[10/100], step:2761, Train Loss:0.12797, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2762, Train Loss:0.11552, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2763, Train Loss:0.26262, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2764, Train Loss:0.12594, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2765, Train Loss:0.15577, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2766, Train Loss:0.00250, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2767, Train Loss:0.00079, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2768, Train Loss:0.03934, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2769, Train Loss:0.00211, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2770, Train Loss:0.77387, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2771, Train Loss:0.08353, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2772, Train Loss:0.33525, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2773, Train Loss:0.11026, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2774, Train Loss:0.07986, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2775, Train Loss:0.38147, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2776, Train Loss:0.14905, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2777, Train Loss:0.16610, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2778, Train Loss:0.16102, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2779, Train Loss:0.28508, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2780, Train Loss:0.06932, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2781, Train Loss:0.12605, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2782, Train Loss:0.03326, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2783, Train Loss:0.41788, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2784, Train Loss:0.09468, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2785, Train Loss:0.10351, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2786, Train Loss:0.18055, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2787, Train Loss:0.01718, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2788, Train Loss:0.01328, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2789, Train Loss:0.16916, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2790, Train Loss:0.15408, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2791, Train Loss:0.03238, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2792, Train Loss:0.44516, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2793, Train Loss:0.19854, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2794, Train Loss:0.46044, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2795, Train Loss:0.43539, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2796, Train Loss:0.08813, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2797, Train Loss:0.19377, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2798, Train Loss:0.25548, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2799, Train Loss:0.05869, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2800, Train Loss:0.07039, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2801, Train Loss:0.01314, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2802, Train Loss:0.00253, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2803, Train Loss:0.00999, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2804, Train Loss:0.18613, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2805, Train Loss:0.35336, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2806, Train Loss:0.12446, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2807, Train Loss:0.41998, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2808, Train Loss:0.02673, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2809, Train Loss:0.07521, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2810, Train Loss:0.04292, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2811, Train Loss:0.42061, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2812, Train Loss:0.26932, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2813, Train Loss:0.24608, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2814, Train Loss:0.05714, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2815, Train Loss:0.22232, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2816, Train Loss:0.05276, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2817, Train Loss:0.02156, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2818, Train Loss:0.50340, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2819, Train Loss:0.21085, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2820, Train Loss:0.26377, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2821, Train Loss:0.05358, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2822, Train Loss:0.01947, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2823, Train Loss:0.00477, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2824, Train Loss:0.00096, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2825, Train Loss:0.12569, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2826, Train Loss:0.07169, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2827, Train Loss:0.02859, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2828, Train Loss:0.68068, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2829, Train Loss:0.68150, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2830, Train Loss:0.10204, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2831, Train Loss:0.04817, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2832, Train Loss:0.15348, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2833, Train Loss:0.06912, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2834, Train Loss:0.32963, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2835, Train Loss:0.16035, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2836, Train Loss:0.00059, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2837, Train Loss:0.23175, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2838, Train Loss:0.03325, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2839, Train Loss:0.22693, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2840, Train Loss:0.11751, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2841, Train Loss:0.01615, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2842, Train Loss:0.00616, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2843, Train Loss:0.00889, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2844, Train Loss:0.46842, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2845, Train Loss:0.34227, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2846, Train Loss:1.03756, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2847, Train Loss:0.23680, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2848, Train Loss:0.11679, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2849, Train Loss:0.04309, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2850, Train Loss:0.58656, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2851, Train Loss:0.19003, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2852, Train Loss:0.16373, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2853, Train Loss:0.00365, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2854, Train Loss:0.23045, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2855, Train Loss:0.03290, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2856, Train Loss:0.10924, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2857, Train Loss:0.05946, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2858, Train Loss:0.07612, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2859, Train Loss:0.24296, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2860, Train Loss:0.64537, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2861, Train Loss:0.11600, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2862, Train Loss:0.42002, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2863, Train Loss:0.17949, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2864, Train Loss:0.09337, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2865, Train Loss:0.17611, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2866, Train Loss:0.39643, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2867, Train Loss:0.13604, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2868, Train Loss:0.39055, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2869, Train Loss:0.20782, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2870, Train Loss:0.47768, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2871, Train Loss:0.63166, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2872, Train Loss:0.41286, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2873, Train Loss:0.05715, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2874, Train Loss:0.00795, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2875, Train Loss:0.19076, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2876, Train Loss:0.09452, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2877, Train Loss:0.07328, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2878, Train Loss:0.14886, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2879, Train Loss:0.24220, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2880, Train Loss:0.00091, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2881, Train Loss:0.07185, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2882, Train Loss:0.00571, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2883, Train Loss:0.14991, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2884, Train Loss:0.17173, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2885, Train Loss:0.00057, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2886, Train Loss:0.16605, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2887, Train Loss:0.20366, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2888, Train Loss:0.25640, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2889, Train Loss:0.70224, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2890, Train Loss:0.05520, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2891, Train Loss:0.12635, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2892, Train Loss:0.02134, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2893, Train Loss:0.03013, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2894, Train Loss:0.02614, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2895, Train Loss:0.01547, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2896, Train Loss:0.01099, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2897, Train Loss:0.14814, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2898, Train Loss:0.19300, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2899, Train Loss:0.41865, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2900, Train Loss:0.18362, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2901, Train Loss:0.59620, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2902, Train Loss:0.08966, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2903, Train Loss:0.03290, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2904, Train Loss:0.00057, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2905, Train Loss:0.79928, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2906, Train Loss:0.00112, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2907, Train Loss:0.35120, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2908, Train Loss:0.10995, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2909, Train Loss:0.13517, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2910, Train Loss:0.32944, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2911, Train Loss:0.09074, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2912, Train Loss:0.20571, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2913, Train Loss:0.05774, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2914, Train Loss:0.32302, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2915, Train Loss:0.14561, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2916, Train Loss:0.09659, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2917, Train Loss:0.49110, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2918, Train Loss:0.01584, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2919, Train Loss:0.23855, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2920, Train Loss:0.52907, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2921, Train Loss:0.37149, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2922, Train Loss:0.25238, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2923, Train Loss:0.07305, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2924, Train Loss:0.35581, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2925, Train Loss:0.16036, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2926, Train Loss:0.49942, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2927, Train Loss:0.16799, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2928, Train Loss:0.34205, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2929, Train Loss:0.12849, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2930, Train Loss:0.00350, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2931, Train Loss:0.12390, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2932, Train Loss:0.02678, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2933, Train Loss:0.09744, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2934, Train Loss:0.08018, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2935, Train Loss:0.37628, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2936, Train Loss:0.10944, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2937, Train Loss:0.15205, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2938, Train Loss:0.11823, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2939, Train Loss:0.41953, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2940, Train Loss:0.36158, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2941, Train Loss:0.51218, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2942, Train Loss:0.32032, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2943, Train Loss:0.03418, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2944, Train Loss:0.08609, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2945, Train Loss:0.11401, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2946, Train Loss:0.31447, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2947, Train Loss:0.01472, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2948, Train Loss:0.07376, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2949, Train Loss:0.05463, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2950, Train Loss:0.03161, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2951, Train Loss:0.01331, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2952, Train Loss:0.16664, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2953, Train Loss:0.12139, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2954, Train Loss:0.24716, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2955, Train Loss:1.71529, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2956, Train Loss:0.09362, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2957, Train Loss:0.09173, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2958, Train Loss:0.07933, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2959, Train Loss:0.14115, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2960, Train Loss:0.02589, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2961, Train Loss:0.15901, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2962, Train Loss:0.39587, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2963, Train Loss:0.13646, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2964, Train Loss:0.05741, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2965, Train Loss:0.08877, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2966, Train Loss:0.04229, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2967, Train Loss:0.24326, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2968, Train Loss:0.55389, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2969, Train Loss:0.04333, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2970, Train Loss:0.19863, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2971, Train Loss:0.63976, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2972, Train Loss:0.16056, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2973, Train Loss:0.36654, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2974, Train Loss:0.00799, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2975, Train Loss:0.16226, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2976, Train Loss:0.21454, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2977, Train Loss:0.14535, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2978, Train Loss:0.12921, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2979, Train Loss:0.21653, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2980, Train Loss:0.14269, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2981, Train Loss:0.14603, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2982, Train Loss:0.07434, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2983, Train Loss:0.24757, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2984, Train Loss:0.00168, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2985, Train Loss:0.15689, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2986, Train Loss:0.60834, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2987, Train Loss:0.08975, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2988, Train Loss:0.01454, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2989, Train Loss:0.31653, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2990, Train Loss:0.04918, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2991, Train Loss:0.10195, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2992, Train Loss:0.09137, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2993, Train Loss:0.00205, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2994, Train Loss:0.44757, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2995, Train Loss:0.64157, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2996, Train Loss:0.45292, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2997, Train Loss:0.01809, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2998, Train Loss:0.10639, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:2999, Train Loss:0.01732, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:3000, Train Loss:0.09578, Dev Loss:0.19179\n",
      "Epoch:[10/100], step:3001, Train Loss:0.32440, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3002, Train Loss:0.00180, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3003, Train Loss:0.02343, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3004, Train Loss:0.08835, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3005, Train Loss:0.25241, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3006, Train Loss:0.04000, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3007, Train Loss:0.21942, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3008, Train Loss:0.02074, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3009, Train Loss:0.01689, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3010, Train Loss:0.00341, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3011, Train Loss:0.10756, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3012, Train Loss:0.00465, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3013, Train Loss:0.00092, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3014, Train Loss:0.26951, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3015, Train Loss:0.17811, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3016, Train Loss:0.00091, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3017, Train Loss:0.53710, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3018, Train Loss:0.04518, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3019, Train Loss:0.00168, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3020, Train Loss:0.08013, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3021, Train Loss:0.02607, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3022, Train Loss:0.21410, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3023, Train Loss:0.01595, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3024, Train Loss:0.44003, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3025, Train Loss:0.06779, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3026, Train Loss:0.09691, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3027, Train Loss:0.30210, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3028, Train Loss:0.00305, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3029, Train Loss:0.05843, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3030, Train Loss:0.08025, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3031, Train Loss:0.36876, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3032, Train Loss:0.04620, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3033, Train Loss:0.36690, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3034, Train Loss:0.01068, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3035, Train Loss:0.17974, Dev Loss:0.16753\n",
      "Epoch:[10/100], step:3036, Train Loss:0.08555, Dev Loss:0.16753\n",
      "Start Epoch: 11, Steps: 17\n",
      "Epoch:[11/100], step:3037, Train Loss:0.00159, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3038, Train Loss:0.05755, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3039, Train Loss:0.00219, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3040, Train Loss:0.34731, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3041, Train Loss:0.42819, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3042, Train Loss:0.33802, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3043, Train Loss:0.41245, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3044, Train Loss:0.01905, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3045, Train Loss:0.00357, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3046, Train Loss:0.05334, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3047, Train Loss:0.00842, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3048, Train Loss:0.05407, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3049, Train Loss:0.26662, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3050, Train Loss:0.17356, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3051, Train Loss:0.16422, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3052, Train Loss:0.07940, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3053, Train Loss:0.18061, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3054, Train Loss:0.01183, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3055, Train Loss:0.16689, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3056, Train Loss:0.15073, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3057, Train Loss:0.03958, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3058, Train Loss:0.50232, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3059, Train Loss:0.16845, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3060, Train Loss:0.20490, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3061, Train Loss:0.02186, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3062, Train Loss:0.13086, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3063, Train Loss:0.82503, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3064, Train Loss:0.12736, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3065, Train Loss:0.10083, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3066, Train Loss:0.17327, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3067, Train Loss:0.00300, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3068, Train Loss:0.02456, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3069, Train Loss:0.01312, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3070, Train Loss:0.61569, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3071, Train Loss:0.16281, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3072, Train Loss:0.03043, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3073, Train Loss:0.06202, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3074, Train Loss:0.08349, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3075, Train Loss:0.02607, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3076, Train Loss:0.31041, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3077, Train Loss:0.08337, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3078, Train Loss:0.36554, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3079, Train Loss:0.02206, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3080, Train Loss:0.72019, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3081, Train Loss:0.00346, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3082, Train Loss:0.00577, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3083, Train Loss:0.09251, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3084, Train Loss:0.13044, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3085, Train Loss:0.58013, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3086, Train Loss:0.08889, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3087, Train Loss:0.12189, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3088, Train Loss:0.04358, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3089, Train Loss:0.04952, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3090, Train Loss:0.32898, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3091, Train Loss:0.16604, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3092, Train Loss:0.19643, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3093, Train Loss:0.05747, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3094, Train Loss:0.01992, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3095, Train Loss:0.10567, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3096, Train Loss:0.11313, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3097, Train Loss:0.08901, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3098, Train Loss:0.34087, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3099, Train Loss:0.36183, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3100, Train Loss:0.10576, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3101, Train Loss:0.00505, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3102, Train Loss:0.04323, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3103, Train Loss:0.22909, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3104, Train Loss:0.00358, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3105, Train Loss:0.02977, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3106, Train Loss:0.33457, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3107, Train Loss:0.00102, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3108, Train Loss:0.02765, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3109, Train Loss:0.04452, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3110, Train Loss:0.18802, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3111, Train Loss:0.29742, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3112, Train Loss:0.18377, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3113, Train Loss:0.01631, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3114, Train Loss:0.00969, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3115, Train Loss:0.00827, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3116, Train Loss:0.08300, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3117, Train Loss:0.34205, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3118, Train Loss:0.28785, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3119, Train Loss:0.00555, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3120, Train Loss:0.03018, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3121, Train Loss:0.00083, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3122, Train Loss:0.19226, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3123, Train Loss:0.00199, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3124, Train Loss:0.00213, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3125, Train Loss:0.19232, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3126, Train Loss:0.02125, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3127, Train Loss:0.32903, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3128, Train Loss:0.06244, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3129, Train Loss:0.13334, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3130, Train Loss:0.06508, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3131, Train Loss:0.46748, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3132, Train Loss:0.00066, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3133, Train Loss:0.16146, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3134, Train Loss:0.00319, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3135, Train Loss:0.10392, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3136, Train Loss:0.00825, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3137, Train Loss:0.00670, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3138, Train Loss:0.21383, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3139, Train Loss:0.45617, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3140, Train Loss:0.10627, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3141, Train Loss:0.02825, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3142, Train Loss:0.00722, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3143, Train Loss:0.00911, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3144, Train Loss:0.00786, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3145, Train Loss:0.23743, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3146, Train Loss:0.16840, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3147, Train Loss:0.01430, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3148, Train Loss:0.34107, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3149, Train Loss:0.03501, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3150, Train Loss:0.69598, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3151, Train Loss:0.29750, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3152, Train Loss:0.00123, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3153, Train Loss:0.03569, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3154, Train Loss:0.33691, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3155, Train Loss:0.06613, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3156, Train Loss:0.19796, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3157, Train Loss:0.13176, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3158, Train Loss:0.06993, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3159, Train Loss:0.10500, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3160, Train Loss:0.27157, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3161, Train Loss:0.33658, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3162, Train Loss:0.27799, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3163, Train Loss:0.04285, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3164, Train Loss:0.63347, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3165, Train Loss:0.01375, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3166, Train Loss:0.29118, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3167, Train Loss:0.42508, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3168, Train Loss:0.06746, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3169, Train Loss:0.34358, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3170, Train Loss:0.01323, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3171, Train Loss:0.01567, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3172, Train Loss:0.24993, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3173, Train Loss:0.17334, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3174, Train Loss:0.01638, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3175, Train Loss:0.13073, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3176, Train Loss:0.18644, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3177, Train Loss:0.00822, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3178, Train Loss:0.99887, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3179, Train Loss:0.18676, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3180, Train Loss:0.03446, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3181, Train Loss:0.05232, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3182, Train Loss:0.10644, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3183, Train Loss:0.03064, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3184, Train Loss:0.03126, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3185, Train Loss:0.05333, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3186, Train Loss:0.19144, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3187, Train Loss:0.46905, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3188, Train Loss:0.06078, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3189, Train Loss:1.27654, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3190, Train Loss:0.20803, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3191, Train Loss:0.10992, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3192, Train Loss:0.16212, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3193, Train Loss:0.05700, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3194, Train Loss:0.16171, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3195, Train Loss:0.08461, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3196, Train Loss:0.26122, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3197, Train Loss:0.10235, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3198, Train Loss:0.56633, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3199, Train Loss:0.05623, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3200, Train Loss:0.09406, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3201, Train Loss:0.18795, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3202, Train Loss:0.21381, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3203, Train Loss:0.02518, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3204, Train Loss:0.42838, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3205, Train Loss:0.05649, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3206, Train Loss:0.05160, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3207, Train Loss:0.17701, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3208, Train Loss:0.56782, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3209, Train Loss:0.78577, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3210, Train Loss:0.36100, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3211, Train Loss:0.32674, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3212, Train Loss:0.27794, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3213, Train Loss:0.09156, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3214, Train Loss:0.13462, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3215, Train Loss:0.03559, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3216, Train Loss:0.21258, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3217, Train Loss:0.04711, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3218, Train Loss:0.00341, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3219, Train Loss:0.12902, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3220, Train Loss:0.14532, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3221, Train Loss:0.01864, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3222, Train Loss:0.15228, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3223, Train Loss:0.48166, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3224, Train Loss:0.24106, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3225, Train Loss:0.45655, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3226, Train Loss:0.22987, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3227, Train Loss:0.34408, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3228, Train Loss:0.07432, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3229, Train Loss:0.19759, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3230, Train Loss:0.41663, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3231, Train Loss:1.32050, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3232, Train Loss:0.04593, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3233, Train Loss:0.01248, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3234, Train Loss:0.12799, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3235, Train Loss:0.20048, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3236, Train Loss:0.49291, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3237, Train Loss:0.09418, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3238, Train Loss:0.03908, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3239, Train Loss:0.29098, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3240, Train Loss:0.13770, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3241, Train Loss:0.05369, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3242, Train Loss:0.30806, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3243, Train Loss:0.08568, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3244, Train Loss:0.05189, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3245, Train Loss:0.02136, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3246, Train Loss:0.17055, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3247, Train Loss:0.16682, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3248, Train Loss:0.40497, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3249, Train Loss:0.01505, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3250, Train Loss:0.04943, Dev Loss:0.16753\n",
      "Epoch:[11/100], step:3251, Train Loss:0.47616, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3252, Train Loss:0.12269, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3253, Train Loss:0.03504, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3254, Train Loss:0.37851, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3255, Train Loss:0.15246, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3256, Train Loss:0.08491, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3257, Train Loss:0.00252, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3258, Train Loss:0.00173, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3259, Train Loss:0.18245, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3260, Train Loss:0.29600, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3261, Train Loss:0.21024, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3262, Train Loss:0.18971, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3263, Train Loss:0.21917, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3264, Train Loss:0.04686, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3265, Train Loss:0.25453, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3266, Train Loss:0.36059, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3267, Train Loss:0.01481, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3268, Train Loss:0.36947, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3269, Train Loss:0.29007, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3270, Train Loss:0.36372, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3271, Train Loss:0.32577, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3272, Train Loss:0.02799, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3273, Train Loss:0.03778, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3274, Train Loss:0.21653, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3275, Train Loss:0.00476, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3276, Train Loss:0.03870, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3277, Train Loss:0.23826, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3278, Train Loss:0.06878, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3279, Train Loss:0.08782, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3280, Train Loss:0.47870, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3281, Train Loss:0.09255, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3282, Train Loss:0.33910, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3283, Train Loss:0.15703, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3284, Train Loss:0.08314, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3285, Train Loss:0.45044, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3286, Train Loss:0.41661, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3287, Train Loss:0.25688, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3288, Train Loss:0.00249, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3289, Train Loss:0.00339, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3290, Train Loss:0.00831, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3291, Train Loss:0.18436, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3292, Train Loss:0.27145, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3293, Train Loss:0.21353, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3294, Train Loss:0.07056, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3295, Train Loss:0.46688, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3296, Train Loss:0.12148, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3297, Train Loss:0.01705, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3298, Train Loss:0.30484, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3299, Train Loss:0.24537, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3300, Train Loss:0.14555, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3301, Train Loss:0.44671, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3302, Train Loss:0.05821, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3303, Train Loss:0.60825, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3304, Train Loss:0.04227, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3305, Train Loss:0.15129, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3306, Train Loss:0.68042, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3307, Train Loss:0.45988, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3308, Train Loss:0.09809, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3309, Train Loss:0.08694, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3310, Train Loss:1.06894, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3311, Train Loss:0.08388, Dev Loss:0.29477\n",
      "Epoch:[11/100], step:3312, Train Loss:0.26229, Dev Loss:0.29477\n",
      "Start Epoch: 12, Steps: 17\n",
      "Epoch:[12/100], step:3313, Train Loss:0.24767, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3314, Train Loss:0.71353, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3315, Train Loss:0.01300, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3316, Train Loss:0.18362, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3317, Train Loss:0.24387, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3318, Train Loss:0.06287, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3319, Train Loss:0.35028, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3320, Train Loss:0.02474, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3321, Train Loss:0.66304, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3322, Train Loss:0.56688, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3323, Train Loss:0.15316, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3324, Train Loss:0.19165, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3325, Train Loss:0.28494, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3326, Train Loss:0.08529, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3327, Train Loss:0.08715, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3328, Train Loss:0.20193, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3329, Train Loss:0.13983, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3330, Train Loss:0.02979, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3331, Train Loss:0.04345, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3332, Train Loss:0.01212, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3333, Train Loss:0.22787, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3334, Train Loss:0.29634, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3335, Train Loss:0.01596, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3336, Train Loss:0.03206, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3337, Train Loss:0.81396, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3338, Train Loss:0.01904, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3339, Train Loss:0.01834, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3340, Train Loss:0.07561, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3341, Train Loss:0.14983, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3342, Train Loss:0.14497, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3343, Train Loss:0.49164, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3344, Train Loss:0.53095, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3345, Train Loss:0.02505, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3346, Train Loss:0.23468, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3347, Train Loss:0.09416, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3348, Train Loss:0.05586, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3349, Train Loss:0.12052, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3350, Train Loss:0.03083, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3351, Train Loss:0.42855, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3352, Train Loss:0.31320, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3353, Train Loss:0.62666, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3354, Train Loss:0.01345, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3355, Train Loss:0.00200, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3356, Train Loss:0.35156, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3357, Train Loss:0.11867, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3358, Train Loss:0.00406, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3359, Train Loss:0.00373, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3360, Train Loss:0.13163, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3361, Train Loss:0.06006, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3362, Train Loss:0.09806, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3363, Train Loss:0.12128, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3364, Train Loss:0.09514, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3365, Train Loss:0.22389, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3366, Train Loss:0.35044, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3367, Train Loss:0.10271, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3368, Train Loss:0.00031, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3369, Train Loss:0.46030, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3370, Train Loss:0.15692, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3371, Train Loss:0.37186, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3372, Train Loss:0.13598, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3373, Train Loss:0.00966, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3374, Train Loss:0.07376, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3375, Train Loss:0.46348, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3376, Train Loss:0.20669, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3377, Train Loss:0.00922, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3378, Train Loss:0.59236, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3379, Train Loss:0.01396, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3380, Train Loss:0.26736, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3381, Train Loss:0.40422, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3382, Train Loss:0.02025, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3383, Train Loss:0.07229, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3384, Train Loss:0.03683, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3385, Train Loss:0.01240, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3386, Train Loss:0.02438, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3387, Train Loss:0.15333, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3388, Train Loss:0.46546, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3389, Train Loss:1.57901, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3390, Train Loss:0.66550, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3391, Train Loss:0.37698, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3392, Train Loss:0.58486, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3393, Train Loss:0.02269, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3394, Train Loss:0.40399, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3395, Train Loss:0.37027, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3396, Train Loss:0.59629, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3397, Train Loss:0.53664, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3398, Train Loss:0.14887, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3399, Train Loss:0.49049, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3400, Train Loss:0.23882, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3401, Train Loss:0.07981, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3402, Train Loss:0.20222, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3403, Train Loss:0.21391, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3404, Train Loss:0.29019, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3405, Train Loss:0.51290, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3406, Train Loss:0.10579, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3407, Train Loss:0.57517, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3408, Train Loss:0.04904, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3409, Train Loss:0.14465, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3410, Train Loss:0.57296, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3411, Train Loss:0.45483, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3412, Train Loss:0.19987, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3413, Train Loss:0.03312, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3414, Train Loss:0.33162, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3415, Train Loss:0.40116, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3416, Train Loss:0.02174, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3417, Train Loss:0.33354, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3418, Train Loss:0.00282, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3419, Train Loss:0.09757, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3420, Train Loss:0.52454, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3421, Train Loss:0.16826, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3422, Train Loss:0.23895, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3423, Train Loss:0.20511, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3424, Train Loss:0.13057, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3425, Train Loss:0.08465, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3426, Train Loss:0.33544, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3427, Train Loss:0.07000, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3428, Train Loss:0.04616, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3429, Train Loss:0.13385, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3430, Train Loss:0.37119, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3431, Train Loss:0.07382, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3432, Train Loss:0.00290, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3433, Train Loss:0.33227, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3434, Train Loss:0.07989, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3435, Train Loss:0.06763, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3436, Train Loss:0.20281, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3437, Train Loss:0.07876, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3438, Train Loss:0.43338, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3439, Train Loss:0.24039, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3440, Train Loss:0.10740, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3441, Train Loss:0.01458, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3442, Train Loss:0.77993, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3443, Train Loss:0.00412, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3444, Train Loss:0.05834, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3445, Train Loss:0.04089, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3446, Train Loss:0.13561, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3447, Train Loss:0.08738, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3448, Train Loss:0.32197, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3449, Train Loss:0.02595, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3450, Train Loss:0.00264, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3451, Train Loss:0.09773, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3452, Train Loss:0.01935, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3453, Train Loss:0.14196, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3454, Train Loss:0.28718, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3455, Train Loss:0.05087, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3456, Train Loss:0.24377, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3457, Train Loss:0.10475, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3458, Train Loss:0.06577, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3459, Train Loss:0.03985, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3460, Train Loss:0.04240, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3461, Train Loss:0.00200, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3462, Train Loss:0.11355, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3463, Train Loss:0.25919, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3464, Train Loss:0.00390, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3465, Train Loss:0.01442, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3466, Train Loss:1.11691, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3467, Train Loss:0.73408, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3468, Train Loss:0.19343, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3469, Train Loss:0.09428, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3470, Train Loss:0.19902, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3471, Train Loss:0.73592, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3472, Train Loss:0.07576, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3473, Train Loss:0.24720, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3474, Train Loss:0.04025, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3475, Train Loss:0.29654, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3476, Train Loss:0.14539, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3477, Train Loss:0.13673, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3478, Train Loss:0.25231, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3479, Train Loss:0.09122, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3480, Train Loss:0.05538, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3481, Train Loss:0.18851, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3482, Train Loss:0.10524, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3483, Train Loss:0.06912, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3484, Train Loss:0.03337, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3485, Train Loss:0.39326, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3486, Train Loss:0.14912, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3487, Train Loss:0.04182, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3488, Train Loss:0.18255, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3489, Train Loss:0.00056, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3490, Train Loss:0.09142, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3491, Train Loss:0.02975, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3492, Train Loss:0.03294, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3493, Train Loss:0.15120, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3494, Train Loss:0.07540, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3495, Train Loss:0.01197, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3496, Train Loss:0.00090, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3497, Train Loss:0.28637, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3498, Train Loss:0.01187, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3499, Train Loss:0.06267, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3500, Train Loss:0.11749, Dev Loss:0.29477\n",
      "Epoch:[12/100], step:3501, Train Loss:0.00158, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3502, Train Loss:0.09663, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3503, Train Loss:0.01136, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3504, Train Loss:0.00413, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3505, Train Loss:0.07684, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3506, Train Loss:0.10775, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3507, Train Loss:0.04490, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3508, Train Loss:0.02291, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3509, Train Loss:0.01928, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3510, Train Loss:0.08100, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3511, Train Loss:0.09098, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3512, Train Loss:0.00031, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3513, Train Loss:0.02600, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3514, Train Loss:0.00661, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3515, Train Loss:0.14523, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3516, Train Loss:0.25110, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3517, Train Loss:0.55128, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3518, Train Loss:0.10365, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3519, Train Loss:0.00017, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3520, Train Loss:0.00435, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3521, Train Loss:0.02782, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3522, Train Loss:0.00076, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3523, Train Loss:0.07815, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3524, Train Loss:0.35666, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3525, Train Loss:0.05148, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3526, Train Loss:0.34039, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3527, Train Loss:0.04248, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3528, Train Loss:0.10727, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3529, Train Loss:0.00180, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3530, Train Loss:0.01454, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3531, Train Loss:0.00178, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3532, Train Loss:0.10298, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3533, Train Loss:0.29175, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3534, Train Loss:0.00683, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3535, Train Loss:0.60614, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3536, Train Loss:0.11722, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3537, Train Loss:0.23972, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3538, Train Loss:0.15496, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3539, Train Loss:0.01774, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3540, Train Loss:0.69481, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3541, Train Loss:0.91673, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3542, Train Loss:0.22021, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3543, Train Loss:0.18604, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3544, Train Loss:0.06338, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3545, Train Loss:0.13483, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3546, Train Loss:0.14995, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3547, Train Loss:0.08751, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3548, Train Loss:0.06506, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3549, Train Loss:0.06649, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3550, Train Loss:0.05993, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3551, Train Loss:0.02017, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3552, Train Loss:0.07044, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3553, Train Loss:0.41796, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3554, Train Loss:0.08506, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3555, Train Loss:0.24706, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3556, Train Loss:0.10037, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3557, Train Loss:0.18101, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3558, Train Loss:0.24107, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3559, Train Loss:0.20225, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3560, Train Loss:0.03805, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3561, Train Loss:0.13488, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3562, Train Loss:0.05611, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3563, Train Loss:0.15974, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3564, Train Loss:0.14127, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3565, Train Loss:0.31159, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3566, Train Loss:0.01316, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3567, Train Loss:0.00408, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3568, Train Loss:0.31345, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3569, Train Loss:0.08321, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3570, Train Loss:0.22599, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3571, Train Loss:0.06601, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3572, Train Loss:0.20264, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3573, Train Loss:0.00965, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3574, Train Loss:0.11231, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3575, Train Loss:0.27066, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3576, Train Loss:0.33615, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3577, Train Loss:0.32361, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3578, Train Loss:0.05647, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3579, Train Loss:0.00254, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3580, Train Loss:0.09627, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3581, Train Loss:0.32952, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3582, Train Loss:0.62037, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3583, Train Loss:0.11077, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3584, Train Loss:0.03817, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3585, Train Loss:0.34739, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3586, Train Loss:0.45889, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3587, Train Loss:0.22456, Dev Loss:0.13167\n",
      "Epoch:[12/100], step:3588, Train Loss:0.04991, Dev Loss:0.13167\n",
      "Start Epoch: 13, Steps: 17\n",
      "Epoch:[13/100], step:3589, Train Loss:0.19682, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3590, Train Loss:0.00751, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3591, Train Loss:0.07609, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3592, Train Loss:0.13280, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3593, Train Loss:0.11861, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3594, Train Loss:0.03309, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3595, Train Loss:0.22376, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3596, Train Loss:0.21738, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3597, Train Loss:0.34775, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3598, Train Loss:0.18346, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3599, Train Loss:0.38826, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3600, Train Loss:0.36943, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3601, Train Loss:0.29590, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3602, Train Loss:0.02010, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3603, Train Loss:0.10339, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3604, Train Loss:0.30782, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3605, Train Loss:0.03117, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3606, Train Loss:0.00992, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3607, Train Loss:0.02245, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3608, Train Loss:0.64471, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3609, Train Loss:0.08094, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3610, Train Loss:0.00131, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3611, Train Loss:0.03010, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3612, Train Loss:0.17109, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3613, Train Loss:0.00536, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3614, Train Loss:0.06789, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3615, Train Loss:0.20744, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3616, Train Loss:0.21700, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3617, Train Loss:0.01637, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3618, Train Loss:0.05773, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3619, Train Loss:0.05516, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3620, Train Loss:0.09579, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3621, Train Loss:0.05738, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3622, Train Loss:0.03026, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3623, Train Loss:0.05029, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3624, Train Loss:0.15199, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3625, Train Loss:0.07334, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3626, Train Loss:0.00807, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3627, Train Loss:0.16872, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3628, Train Loss:0.04926, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3629, Train Loss:0.00020, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3630, Train Loss:0.65778, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3631, Train Loss:0.31708, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3632, Train Loss:0.00411, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3633, Train Loss:0.05230, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3634, Train Loss:0.00255, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3635, Train Loss:0.00396, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3636, Train Loss:0.43658, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3637, Train Loss:0.09435, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3638, Train Loss:0.03538, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3639, Train Loss:0.00053, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3640, Train Loss:0.19754, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3641, Train Loss:0.11355, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3642, Train Loss:0.00174, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3643, Train Loss:0.12840, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3644, Train Loss:0.02712, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3645, Train Loss:0.24499, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3646, Train Loss:0.07840, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3647, Train Loss:0.10393, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3648, Train Loss:0.09215, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3649, Train Loss:0.11601, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3650, Train Loss:0.25531, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3651, Train Loss:0.14411, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3652, Train Loss:0.00006, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3653, Train Loss:0.03736, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3654, Train Loss:0.42223, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3655, Train Loss:0.05443, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3656, Train Loss:0.01321, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3657, Train Loss:0.09693, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3658, Train Loss:0.70503, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3659, Train Loss:0.54592, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3660, Train Loss:0.02716, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3661, Train Loss:0.03613, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3662, Train Loss:0.09102, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3663, Train Loss:0.32320, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3664, Train Loss:0.06276, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3665, Train Loss:0.03951, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3666, Train Loss:0.30886, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3667, Train Loss:0.02076, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3668, Train Loss:0.08287, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3669, Train Loss:0.34784, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3670, Train Loss:0.38220, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3671, Train Loss:0.17089, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3672, Train Loss:0.45492, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3673, Train Loss:0.22851, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3674, Train Loss:0.06384, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3675, Train Loss:0.14845, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3676, Train Loss:0.06554, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3677, Train Loss:0.02704, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3678, Train Loss:0.35846, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3679, Train Loss:0.00295, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3680, Train Loss:0.00615, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3681, Train Loss:0.33942, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3682, Train Loss:0.19813, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3683, Train Loss:0.11970, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3684, Train Loss:0.08817, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3685, Train Loss:0.21961, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3686, Train Loss:0.05307, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3687, Train Loss:0.15203, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3688, Train Loss:0.23902, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3689, Train Loss:0.06571, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3690, Train Loss:0.01619, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3691, Train Loss:0.07197, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3692, Train Loss:0.01206, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3693, Train Loss:0.02240, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3694, Train Loss:0.01087, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3695, Train Loss:0.07534, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3696, Train Loss:0.45794, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3697, Train Loss:0.33338, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3698, Train Loss:0.08134, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3699, Train Loss:0.05941, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3700, Train Loss:0.00346, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3701, Train Loss:0.00431, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3702, Train Loss:0.31904, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3703, Train Loss:0.00091, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3704, Train Loss:0.01610, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3705, Train Loss:0.17261, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3706, Train Loss:0.02410, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3707, Train Loss:0.20392, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3708, Train Loss:0.39760, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3709, Train Loss:0.41298, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3710, Train Loss:0.00107, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3711, Train Loss:0.24487, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3712, Train Loss:0.42996, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3713, Train Loss:0.39782, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3714, Train Loss:0.00057, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3715, Train Loss:0.09747, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3716, Train Loss:0.14605, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3717, Train Loss:0.25460, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3718, Train Loss:0.11268, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3719, Train Loss:0.14322, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3720, Train Loss:0.39130, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3721, Train Loss:0.01238, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3722, Train Loss:0.10131, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3723, Train Loss:0.05973, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3724, Train Loss:0.00166, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3725, Train Loss:0.82197, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3726, Train Loss:0.11854, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3727, Train Loss:0.10718, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3728, Train Loss:0.50912, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3729, Train Loss:0.03781, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3730, Train Loss:0.12604, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3731, Train Loss:0.18017, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3732, Train Loss:0.05388, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3733, Train Loss:0.15521, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3734, Train Loss:0.11594, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3735, Train Loss:0.08474, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3736, Train Loss:0.27967, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3737, Train Loss:0.12501, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3738, Train Loss:0.06448, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3739, Train Loss:0.13330, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3740, Train Loss:0.42684, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3741, Train Loss:0.19018, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3742, Train Loss:0.24961, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3743, Train Loss:0.05498, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3744, Train Loss:0.08279, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3745, Train Loss:0.00070, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3746, Train Loss:0.13585, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3747, Train Loss:0.23021, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3748, Train Loss:0.01649, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3749, Train Loss:0.45664, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3750, Train Loss:0.37333, Dev Loss:0.13167\n",
      "Epoch:[13/100], step:3751, Train Loss:0.32845, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3752, Train Loss:0.33616, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3753, Train Loss:0.11740, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3754, Train Loss:0.19934, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3755, Train Loss:0.28161, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3756, Train Loss:0.11619, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3757, Train Loss:0.08354, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3758, Train Loss:0.24537, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3759, Train Loss:0.03595, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3760, Train Loss:0.34512, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3761, Train Loss:0.16177, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3762, Train Loss:0.34110, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3763, Train Loss:0.06484, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3764, Train Loss:0.84950, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3765, Train Loss:0.03074, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3766, Train Loss:0.00880, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3767, Train Loss:0.24004, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3768, Train Loss:0.28068, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3769, Train Loss:0.08501, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3770, Train Loss:0.30177, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3771, Train Loss:0.00466, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3772, Train Loss:0.09265, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3773, Train Loss:0.14319, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3774, Train Loss:0.02700, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3775, Train Loss:0.02787, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3776, Train Loss:0.11080, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3777, Train Loss:0.15268, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3778, Train Loss:0.04368, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3779, Train Loss:0.07035, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3780, Train Loss:0.16383, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3781, Train Loss:0.23280, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3782, Train Loss:0.25804, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3783, Train Loss:0.01992, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3784, Train Loss:0.00140, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3785, Train Loss:0.07614, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3786, Train Loss:0.17483, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3787, Train Loss:0.07023, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3788, Train Loss:0.36662, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3789, Train Loss:0.17258, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3790, Train Loss:0.00121, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3791, Train Loss:0.04202, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3792, Train Loss:0.03984, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3793, Train Loss:0.37436, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3794, Train Loss:0.01792, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3795, Train Loss:0.40834, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3796, Train Loss:0.04024, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3797, Train Loss:0.08819, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3798, Train Loss:0.16622, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3799, Train Loss:0.00243, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3800, Train Loss:0.00016, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3801, Train Loss:0.19853, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3802, Train Loss:0.17233, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3803, Train Loss:0.70411, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3804, Train Loss:0.02955, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3805, Train Loss:0.12215, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3806, Train Loss:0.03498, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3807, Train Loss:0.01332, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3808, Train Loss:0.02826, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3809, Train Loss:0.12413, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3810, Train Loss:0.04738, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3811, Train Loss:0.11315, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3812, Train Loss:0.00663, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3813, Train Loss:0.38210, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3814, Train Loss:0.12007, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3815, Train Loss:0.11231, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3816, Train Loss:0.01383, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3817, Train Loss:0.27016, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3818, Train Loss:0.30004, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3819, Train Loss:0.03666, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3820, Train Loss:0.05495, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3821, Train Loss:0.21106, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3822, Train Loss:0.43347, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3823, Train Loss:0.12513, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3824, Train Loss:0.24951, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3825, Train Loss:0.06434, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3826, Train Loss:0.30752, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3827, Train Loss:0.23358, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3828, Train Loss:0.17127, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3829, Train Loss:0.19880, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3830, Train Loss:0.18790, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3831, Train Loss:0.04408, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3832, Train Loss:0.00200, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3833, Train Loss:0.33129, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3834, Train Loss:0.04649, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3835, Train Loss:0.51516, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3836, Train Loss:0.65543, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3837, Train Loss:0.12210, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3838, Train Loss:0.18779, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3839, Train Loss:0.57595, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3840, Train Loss:0.00424, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3841, Train Loss:0.05387, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3842, Train Loss:0.02088, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3843, Train Loss:0.09612, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3844, Train Loss:0.44712, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3845, Train Loss:0.03189, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3846, Train Loss:0.56095, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3847, Train Loss:0.64917, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3848, Train Loss:0.33602, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3849, Train Loss:0.02410, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3850, Train Loss:0.01852, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3851, Train Loss:0.65021, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3852, Train Loss:0.11761, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3853, Train Loss:0.13223, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3854, Train Loss:0.08715, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3855, Train Loss:0.08831, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3856, Train Loss:0.10523, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3857, Train Loss:0.30824, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3858, Train Loss:0.03232, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3859, Train Loss:0.30458, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3860, Train Loss:0.04850, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3861, Train Loss:0.20033, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3862, Train Loss:0.06778, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3863, Train Loss:0.04787, Dev Loss:0.17583\n",
      "Epoch:[13/100], step:3864, Train Loss:0.61646, Dev Loss:0.17583\n",
      "Start Epoch: 14, Steps: 17\n",
      "Epoch:[14/100], step:3865, Train Loss:0.13966, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3866, Train Loss:0.15392, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3867, Train Loss:0.16920, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3868, Train Loss:0.07606, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3869, Train Loss:0.01232, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3870, Train Loss:0.33392, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3871, Train Loss:0.22526, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3872, Train Loss:0.03909, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3873, Train Loss:0.08523, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3874, Train Loss:0.10740, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3875, Train Loss:0.06822, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3876, Train Loss:0.12945, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3877, Train Loss:0.09982, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3878, Train Loss:0.71084, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3879, Train Loss:0.48325, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3880, Train Loss:0.16433, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3881, Train Loss:0.04141, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3882, Train Loss:0.70572, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3883, Train Loss:0.01794, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3884, Train Loss:0.15462, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3885, Train Loss:0.12782, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3886, Train Loss:0.16161, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3887, Train Loss:0.01941, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3888, Train Loss:0.19018, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3889, Train Loss:0.49012, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3890, Train Loss:0.46599, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3891, Train Loss:0.46856, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3892, Train Loss:0.00060, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3893, Train Loss:1.20318, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3894, Train Loss:0.15024, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3895, Train Loss:0.09009, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3896, Train Loss:0.07840, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3897, Train Loss:0.52462, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3898, Train Loss:0.44297, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3899, Train Loss:0.20195, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3900, Train Loss:0.02681, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3901, Train Loss:0.11744, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3902, Train Loss:0.31059, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3903, Train Loss:0.13166, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3904, Train Loss:0.33564, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3905, Train Loss:0.29648, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3906, Train Loss:0.01495, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3907, Train Loss:0.13572, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3908, Train Loss:0.22053, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3909, Train Loss:0.22456, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3910, Train Loss:0.19289, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3911, Train Loss:0.06850, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3912, Train Loss:0.08679, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3913, Train Loss:0.16405, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3914, Train Loss:0.00238, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3915, Train Loss:0.00389, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3916, Train Loss:0.65230, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3917, Train Loss:0.00297, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3918, Train Loss:0.47971, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3919, Train Loss:0.06505, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3920, Train Loss:0.00758, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3921, Train Loss:0.16700, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3922, Train Loss:0.06214, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3923, Train Loss:0.22971, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3924, Train Loss:0.67025, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3925, Train Loss:0.03106, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3926, Train Loss:0.15678, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3927, Train Loss:0.02183, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3928, Train Loss:0.00392, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3929, Train Loss:0.01636, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3930, Train Loss:0.01816, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3931, Train Loss:0.22067, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3932, Train Loss:0.00367, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3933, Train Loss:0.00380, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3934, Train Loss:0.28643, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3935, Train Loss:0.00922, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3936, Train Loss:0.15095, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3937, Train Loss:0.40717, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3938, Train Loss:0.38347, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3939, Train Loss:0.21067, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3940, Train Loss:0.08331, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3941, Train Loss:0.05309, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3942, Train Loss:0.12021, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3943, Train Loss:0.03791, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3944, Train Loss:0.31575, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3945, Train Loss:0.26826, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3946, Train Loss:0.48644, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3947, Train Loss:0.06180, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3948, Train Loss:0.11409, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3949, Train Loss:0.01539, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3950, Train Loss:0.03219, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3951, Train Loss:0.05529, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3952, Train Loss:0.03401, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3953, Train Loss:0.37873, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3954, Train Loss:0.15692, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3955, Train Loss:0.01330, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3956, Train Loss:0.00536, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3957, Train Loss:0.16963, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3958, Train Loss:0.35853, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3959, Train Loss:0.00287, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3960, Train Loss:0.33590, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3961, Train Loss:0.00023, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3962, Train Loss:0.01602, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3963, Train Loss:0.09837, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3964, Train Loss:0.07771, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3965, Train Loss:0.45634, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3966, Train Loss:0.37758, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3967, Train Loss:0.36413, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3968, Train Loss:0.64988, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3969, Train Loss:0.17957, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3970, Train Loss:0.40160, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3971, Train Loss:0.31681, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3972, Train Loss:0.01824, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3973, Train Loss:0.00264, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3974, Train Loss:0.04197, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3975, Train Loss:0.35009, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3976, Train Loss:0.09986, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3977, Train Loss:0.00330, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3978, Train Loss:0.04705, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3979, Train Loss:0.00099, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3980, Train Loss:0.52862, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3981, Train Loss:0.04304, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3982, Train Loss:0.14667, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3983, Train Loss:0.17870, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3984, Train Loss:0.07969, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3985, Train Loss:0.07973, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3986, Train Loss:0.05640, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3987, Train Loss:0.16978, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3988, Train Loss:0.00008, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3989, Train Loss:0.07798, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3990, Train Loss:0.31789, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3991, Train Loss:0.24360, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3992, Train Loss:0.00115, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3993, Train Loss:0.34718, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3994, Train Loss:0.00706, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3995, Train Loss:0.32681, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3996, Train Loss:0.03407, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3997, Train Loss:0.23466, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3998, Train Loss:0.19942, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:3999, Train Loss:0.10668, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:4000, Train Loss:0.00094, Dev Loss:0.17583\n",
      "Epoch:[14/100], step:4001, Train Loss:0.19037, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4002, Train Loss:0.25512, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4003, Train Loss:0.23719, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4004, Train Loss:0.08424, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4005, Train Loss:0.23603, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4006, Train Loss:0.04388, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4007, Train Loss:0.30196, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4008, Train Loss:0.07051, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4009, Train Loss:0.20680, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4010, Train Loss:0.29332, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4011, Train Loss:0.18326, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4012, Train Loss:0.00289, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4013, Train Loss:0.04108, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4014, Train Loss:0.00212, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4015, Train Loss:0.01910, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4016, Train Loss:0.27414, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4017, Train Loss:0.11313, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4018, Train Loss:0.01279, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4019, Train Loss:0.39259, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4020, Train Loss:0.09999, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4021, Train Loss:0.13791, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4022, Train Loss:0.14901, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4023, Train Loss:0.11687, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4024, Train Loss:0.00312, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4025, Train Loss:0.11376, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4026, Train Loss:0.31522, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4027, Train Loss:0.13715, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4028, Train Loss:0.10802, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4029, Train Loss:0.00479, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4030, Train Loss:0.02742, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4031, Train Loss:0.14613, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4032, Train Loss:0.01826, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4033, Train Loss:0.10803, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4034, Train Loss:0.00934, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4035, Train Loss:0.26988, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4036, Train Loss:0.39966, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4037, Train Loss:0.12759, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4038, Train Loss:0.01781, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4039, Train Loss:0.14019, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4040, Train Loss:0.02721, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4041, Train Loss:0.07238, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4042, Train Loss:0.00098, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4043, Train Loss:0.07318, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4044, Train Loss:0.14174, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4045, Train Loss:0.20638, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4046, Train Loss:0.61634, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4047, Train Loss:0.59644, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4048, Train Loss:0.19724, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4049, Train Loss:0.00383, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4050, Train Loss:0.26285, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4051, Train Loss:0.02755, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4052, Train Loss:0.00529, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4053, Train Loss:0.18890, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4054, Train Loss:0.05232, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4055, Train Loss:0.25388, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4056, Train Loss:0.06837, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4057, Train Loss:0.36255, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4058, Train Loss:0.02985, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4059, Train Loss:1.10798, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4060, Train Loss:0.97617, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4061, Train Loss:0.25519, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4062, Train Loss:0.02196, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4063, Train Loss:0.16617, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4064, Train Loss:0.67863, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4065, Train Loss:0.04907, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4066, Train Loss:0.15391, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4067, Train Loss:0.41300, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4068, Train Loss:0.13926, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4069, Train Loss:0.47442, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4070, Train Loss:0.06179, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4071, Train Loss:0.22207, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4072, Train Loss:0.12876, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4073, Train Loss:0.20263, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4074, Train Loss:0.13609, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4075, Train Loss:0.05451, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4076, Train Loss:0.07994, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4077, Train Loss:0.09484, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4078, Train Loss:0.26578, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4079, Train Loss:0.09016, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4080, Train Loss:0.05930, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4081, Train Loss:0.26399, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4082, Train Loss:0.06627, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4083, Train Loss:0.18665, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4084, Train Loss:0.28499, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4085, Train Loss:0.20673, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4086, Train Loss:0.17416, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4087, Train Loss:0.34957, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4088, Train Loss:0.00404, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4089, Train Loss:0.01407, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4090, Train Loss:0.09370, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4091, Train Loss:0.00921, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4092, Train Loss:0.00239, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4093, Train Loss:0.00395, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4094, Train Loss:0.03741, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4095, Train Loss:0.10440, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4096, Train Loss:0.54130, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4097, Train Loss:0.02335, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4098, Train Loss:0.18531, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4099, Train Loss:0.31865, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4100, Train Loss:0.06547, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4101, Train Loss:0.14171, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4102, Train Loss:0.13706, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4103, Train Loss:0.09001, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4104, Train Loss:0.02239, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4105, Train Loss:0.43744, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4106, Train Loss:0.10668, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4107, Train Loss:0.04304, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4108, Train Loss:0.06191, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4109, Train Loss:0.00046, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4110, Train Loss:0.06463, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4111, Train Loss:0.21467, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4112, Train Loss:0.07867, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4113, Train Loss:0.02050, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4114, Train Loss:0.49329, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4115, Train Loss:0.00007, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4116, Train Loss:0.12592, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4117, Train Loss:0.04200, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4118, Train Loss:0.10482, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4119, Train Loss:0.20283, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4120, Train Loss:0.62147, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4121, Train Loss:0.20209, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4122, Train Loss:0.02084, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4123, Train Loss:0.12459, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4124, Train Loss:0.70334, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4125, Train Loss:0.39237, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4126, Train Loss:0.27666, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4127, Train Loss:0.01088, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4128, Train Loss:0.74234, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4129, Train Loss:0.03560, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4130, Train Loss:0.02094, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4131, Train Loss:0.15857, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4132, Train Loss:0.00184, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4133, Train Loss:0.22335, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4134, Train Loss:0.26348, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4135, Train Loss:0.00184, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4136, Train Loss:0.35294, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4137, Train Loss:0.05154, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4138, Train Loss:0.26385, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4139, Train Loss:0.06593, Dev Loss:0.26858\n",
      "Epoch:[14/100], step:4140, Train Loss:0.09985, Dev Loss:0.26858\n",
      "Start Epoch: 15, Steps: 17\n",
      "Epoch:[15/100], step:4141, Train Loss:0.48781, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4142, Train Loss:0.39122, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4143, Train Loss:0.00957, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4144, Train Loss:0.10131, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4145, Train Loss:0.07268, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4146, Train Loss:0.17446, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4147, Train Loss:0.02790, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4148, Train Loss:0.27348, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4149, Train Loss:0.22443, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4150, Train Loss:0.47333, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4151, Train Loss:0.03041, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4152, Train Loss:0.17277, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4153, Train Loss:0.29521, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4154, Train Loss:0.00376, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4155, Train Loss:0.23505, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4156, Train Loss:0.08440, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4157, Train Loss:0.48399, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4158, Train Loss:0.02136, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4159, Train Loss:0.08677, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4160, Train Loss:0.00130, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4161, Train Loss:0.03917, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4162, Train Loss:0.01621, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4163, Train Loss:0.00167, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4164, Train Loss:0.59931, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4165, Train Loss:0.05236, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4166, Train Loss:0.02660, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4167, Train Loss:0.06588, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4168, Train Loss:0.16573, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4169, Train Loss:0.00110, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4170, Train Loss:0.00307, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4171, Train Loss:0.01506, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4172, Train Loss:0.00077, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4173, Train Loss:0.02561, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4174, Train Loss:0.22976, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4175, Train Loss:0.55640, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4176, Train Loss:0.13769, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4177, Train Loss:0.00954, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4178, Train Loss:0.00202, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4179, Train Loss:0.02297, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4180, Train Loss:0.12287, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4181, Train Loss:0.00038, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4182, Train Loss:0.23719, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4183, Train Loss:0.03018, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4184, Train Loss:0.14235, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4185, Train Loss:0.05090, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4186, Train Loss:0.04956, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4187, Train Loss:0.03538, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4188, Train Loss:0.00014, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4189, Train Loss:0.08295, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4190, Train Loss:0.36919, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4191, Train Loss:0.25170, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4192, Train Loss:0.00323, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4193, Train Loss:0.24990, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4194, Train Loss:0.00054, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4195, Train Loss:0.19603, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4196, Train Loss:0.40350, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4197, Train Loss:0.16998, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4198, Train Loss:0.12464, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4199, Train Loss:0.27334, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4200, Train Loss:0.18257, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4201, Train Loss:0.24766, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4202, Train Loss:0.02480, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4203, Train Loss:0.26102, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4204, Train Loss:0.00087, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4205, Train Loss:0.15254, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4206, Train Loss:0.59495, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4207, Train Loss:0.14617, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4208, Train Loss:0.08404, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4209, Train Loss:0.16709, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4210, Train Loss:0.00950, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4211, Train Loss:0.11559, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4212, Train Loss:0.01165, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4213, Train Loss:0.03401, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4214, Train Loss:0.12293, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4215, Train Loss:0.05952, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4216, Train Loss:0.19414, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4217, Train Loss:0.04837, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4218, Train Loss:0.15416, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4219, Train Loss:0.47035, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4220, Train Loss:0.00231, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4221, Train Loss:0.14929, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4222, Train Loss:0.00871, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4223, Train Loss:0.03402, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4224, Train Loss:0.00027, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4225, Train Loss:0.28171, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4226, Train Loss:0.01402, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4227, Train Loss:0.07047, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4228, Train Loss:0.22465, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4229, Train Loss:0.22184, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4230, Train Loss:0.06506, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4231, Train Loss:0.27741, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4232, Train Loss:0.07776, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4233, Train Loss:0.04706, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4234, Train Loss:0.09402, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4235, Train Loss:0.00394, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4236, Train Loss:0.00062, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4237, Train Loss:0.16182, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4238, Train Loss:0.40142, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4239, Train Loss:0.11212, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4240, Train Loss:0.00576, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4241, Train Loss:0.23076, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4242, Train Loss:0.36137, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4243, Train Loss:0.30421, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4244, Train Loss:0.00092, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4245, Train Loss:0.23255, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4246, Train Loss:0.11357, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4247, Train Loss:0.00000, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4248, Train Loss:0.09079, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4249, Train Loss:0.00436, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4250, Train Loss:0.41748, Dev Loss:0.26858\n",
      "Epoch:[15/100], step:4251, Train Loss:0.58541, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4252, Train Loss:0.01319, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4253, Train Loss:0.00313, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4254, Train Loss:0.34029, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4255, Train Loss:0.31882, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4256, Train Loss:0.24537, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4257, Train Loss:0.23210, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4258, Train Loss:0.22984, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4259, Train Loss:0.87815, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4260, Train Loss:0.30445, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4261, Train Loss:0.22329, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4262, Train Loss:0.02152, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4263, Train Loss:0.68401, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4264, Train Loss:0.28611, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4265, Train Loss:0.54282, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4266, Train Loss:0.09896, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4267, Train Loss:0.76476, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4268, Train Loss:0.01334, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4269, Train Loss:0.93572, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4270, Train Loss:0.54508, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4271, Train Loss:0.29675, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4272, Train Loss:0.14450, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4273, Train Loss:0.17810, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4274, Train Loss:0.01247, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4275, Train Loss:0.10936, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4276, Train Loss:0.27033, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4277, Train Loss:0.02745, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4278, Train Loss:0.00414, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4279, Train Loss:0.16657, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4280, Train Loss:0.00204, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4281, Train Loss:0.00304, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4282, Train Loss:0.00238, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4283, Train Loss:0.33861, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4284, Train Loss:0.00437, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4285, Train Loss:0.22940, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4286, Train Loss:0.01980, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4287, Train Loss:0.39421, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4288, Train Loss:0.16612, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4289, Train Loss:0.29104, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4290, Train Loss:0.14654, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4291, Train Loss:0.16022, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4292, Train Loss:0.23372, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4293, Train Loss:0.10821, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4294, Train Loss:0.00099, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4295, Train Loss:0.14731, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4296, Train Loss:0.26798, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4297, Train Loss:0.00332, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4298, Train Loss:0.01218, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4299, Train Loss:0.03230, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4300, Train Loss:0.04411, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4301, Train Loss:0.16498, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4302, Train Loss:0.00353, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4303, Train Loss:0.56042, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4304, Train Loss:0.12443, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4305, Train Loss:0.12082, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4306, Train Loss:0.00011, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4307, Train Loss:0.03105, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4308, Train Loss:0.04914, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4309, Train Loss:0.06228, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4310, Train Loss:0.09443, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4311, Train Loss:0.10609, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4312, Train Loss:0.06453, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4313, Train Loss:0.00016, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4314, Train Loss:0.02861, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4315, Train Loss:0.13686, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4316, Train Loss:0.03164, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4317, Train Loss:0.00296, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4318, Train Loss:0.23188, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4319, Train Loss:0.63232, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4320, Train Loss:0.01360, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4321, Train Loss:0.00788, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4322, Train Loss:0.00782, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4323, Train Loss:0.24491, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4324, Train Loss:0.06062, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4325, Train Loss:0.13452, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4326, Train Loss:0.05107, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4327, Train Loss:0.52468, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4328, Train Loss:0.00525, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4329, Train Loss:0.03685, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4330, Train Loss:0.04439, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4331, Train Loss:0.51806, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4332, Train Loss:0.00043, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4333, Train Loss:0.07648, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4334, Train Loss:0.25992, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4335, Train Loss:0.01613, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4336, Train Loss:0.32139, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4337, Train Loss:0.30749, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4338, Train Loss:0.04834, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4339, Train Loss:0.07066, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4340, Train Loss:0.09422, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4341, Train Loss:0.13197, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4342, Train Loss:0.35318, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4343, Train Loss:0.10563, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4344, Train Loss:0.20697, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4345, Train Loss:0.01390, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4346, Train Loss:0.74506, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4347, Train Loss:0.09301, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4348, Train Loss:0.11253, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4349, Train Loss:0.19868, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4350, Train Loss:0.10802, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4351, Train Loss:0.00135, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4352, Train Loss:0.00353, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4353, Train Loss:0.67218, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4354, Train Loss:0.10451, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4355, Train Loss:0.04083, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4356, Train Loss:0.25657, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4357, Train Loss:0.12716, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4358, Train Loss:0.12376, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4359, Train Loss:0.12026, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4360, Train Loss:0.02505, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4361, Train Loss:0.12836, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4362, Train Loss:0.24726, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4363, Train Loss:0.14191, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4364, Train Loss:0.02235, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4365, Train Loss:0.75956, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4366, Train Loss:0.24718, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4367, Train Loss:0.28007, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4368, Train Loss:0.27526, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4369, Train Loss:0.00317, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4370, Train Loss:0.00853, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4371, Train Loss:0.12126, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4372, Train Loss:0.23006, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4373, Train Loss:0.02196, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4374, Train Loss:0.06824, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4375, Train Loss:0.98472, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4376, Train Loss:0.02917, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4377, Train Loss:0.00333, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4378, Train Loss:0.19703, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4379, Train Loss:0.01554, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4380, Train Loss:0.10465, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4381, Train Loss:0.05289, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4382, Train Loss:0.04117, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4383, Train Loss:0.21459, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4384, Train Loss:0.03080, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4385, Train Loss:0.03699, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4386, Train Loss:0.11243, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4387, Train Loss:0.23043, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4388, Train Loss:0.29448, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4389, Train Loss:0.24592, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4390, Train Loss:0.03074, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4391, Train Loss:0.27745, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4392, Train Loss:0.23391, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4393, Train Loss:0.59244, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4394, Train Loss:0.09687, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4395, Train Loss:0.06961, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4396, Train Loss:0.01805, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4397, Train Loss:0.14427, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4398, Train Loss:0.17643, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4399, Train Loss:0.12707, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4400, Train Loss:0.05381, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4401, Train Loss:0.16160, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4402, Train Loss:0.09683, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4403, Train Loss:0.16520, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4404, Train Loss:0.00268, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4405, Train Loss:0.49744, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4406, Train Loss:0.58078, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4407, Train Loss:0.00525, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4408, Train Loss:0.02314, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4409, Train Loss:0.00042, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4410, Train Loss:0.18324, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4411, Train Loss:0.27770, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4412, Train Loss:0.40727, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4413, Train Loss:0.09968, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4414, Train Loss:0.21678, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4415, Train Loss:0.21524, Dev Loss:0.15886\n",
      "Epoch:[15/100], step:4416, Train Loss:0.03967, Dev Loss:0.15886\n",
      "Start Epoch: 16, Steps: 17\n",
      "Epoch:[16/100], step:4417, Train Loss:0.16992, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4418, Train Loss:0.46942, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4419, Train Loss:0.06321, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4420, Train Loss:0.65249, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4421, Train Loss:0.28406, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4422, Train Loss:0.00658, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4423, Train Loss:0.03462, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4424, Train Loss:0.27385, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4425, Train Loss:0.16204, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4426, Train Loss:0.23373, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4427, Train Loss:0.11110, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4428, Train Loss:0.23389, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4429, Train Loss:0.02263, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4430, Train Loss:0.37134, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4431, Train Loss:0.04718, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4432, Train Loss:0.11050, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4433, Train Loss:0.23885, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4434, Train Loss:0.77078, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4435, Train Loss:0.00444, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4436, Train Loss:0.15431, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4437, Train Loss:0.26243, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4438, Train Loss:0.25636, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4439, Train Loss:0.54862, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4440, Train Loss:0.07131, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4441, Train Loss:0.56029, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4442, Train Loss:0.16778, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4443, Train Loss:0.08033, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4444, Train Loss:0.19647, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4445, Train Loss:0.19591, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4446, Train Loss:0.02872, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4447, Train Loss:0.40651, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4448, Train Loss:0.19565, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4449, Train Loss:0.06719, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4450, Train Loss:0.02103, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4451, Train Loss:0.22368, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4452, Train Loss:0.10079, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4453, Train Loss:0.00195, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4454, Train Loss:0.02013, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4455, Train Loss:0.41689, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4456, Train Loss:0.01304, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4457, Train Loss:0.00019, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4458, Train Loss:0.36523, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4459, Train Loss:0.00056, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4460, Train Loss:0.05204, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4461, Train Loss:0.18408, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4462, Train Loss:0.10230, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4463, Train Loss:0.03731, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4464, Train Loss:0.00114, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4465, Train Loss:0.14830, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4466, Train Loss:0.20721, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4467, Train Loss:0.00647, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4468, Train Loss:0.18373, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4469, Train Loss:0.05636, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4470, Train Loss:0.36737, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4471, Train Loss:0.00562, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4472, Train Loss:0.34243, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4473, Train Loss:0.23621, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4474, Train Loss:0.08478, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4475, Train Loss:0.00302, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4476, Train Loss:0.00043, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4477, Train Loss:0.19304, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4478, Train Loss:0.07046, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4479, Train Loss:0.00250, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4480, Train Loss:0.23293, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4481, Train Loss:0.07858, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4482, Train Loss:0.24519, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4483, Train Loss:0.01436, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4484, Train Loss:0.01604, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4485, Train Loss:0.09441, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4486, Train Loss:0.17043, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4487, Train Loss:0.49896, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4488, Train Loss:0.03716, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4489, Train Loss:0.19282, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4490, Train Loss:0.11309, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4491, Train Loss:0.02208, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4492, Train Loss:0.13596, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4493, Train Loss:0.13164, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4494, Train Loss:0.50694, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4495, Train Loss:0.11172, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4496, Train Loss:0.01810, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4497, Train Loss:0.25914, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4498, Train Loss:0.24515, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4499, Train Loss:0.03128, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4500, Train Loss:0.05101, Dev Loss:0.15886\n",
      "Epoch:[16/100], step:4501, Train Loss:0.11162, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4502, Train Loss:0.00222, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4503, Train Loss:0.21709, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4504, Train Loss:0.01167, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4505, Train Loss:0.30878, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4506, Train Loss:0.16917, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4507, Train Loss:0.22109, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4508, Train Loss:0.10196, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4509, Train Loss:0.04648, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4510, Train Loss:0.04272, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4511, Train Loss:0.30571, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4512, Train Loss:0.00461, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4513, Train Loss:0.45815, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4514, Train Loss:0.01358, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4515, Train Loss:0.12654, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4516, Train Loss:0.27865, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4517, Train Loss:0.00111, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4518, Train Loss:0.00060, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4519, Train Loss:0.14954, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4520, Train Loss:0.28928, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4521, Train Loss:0.00012, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4522, Train Loss:0.00048, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4523, Train Loss:0.05161, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4524, Train Loss:0.44440, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4525, Train Loss:0.00032, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4526, Train Loss:0.23876, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4527, Train Loss:0.03221, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4528, Train Loss:0.04344, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4529, Train Loss:0.06417, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4530, Train Loss:0.23610, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4531, Train Loss:0.27613, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4532, Train Loss:0.00001, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4533, Train Loss:0.38721, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4534, Train Loss:0.22868, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4535, Train Loss:0.36032, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4536, Train Loss:0.10538, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4537, Train Loss:0.16210, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4538, Train Loss:0.09879, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4539, Train Loss:0.00005, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4540, Train Loss:0.00043, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4541, Train Loss:0.31057, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4542, Train Loss:0.02299, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4543, Train Loss:0.08650, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4544, Train Loss:0.23026, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4545, Train Loss:0.00041, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4546, Train Loss:0.00932, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4547, Train Loss:0.28687, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4548, Train Loss:0.03375, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4549, Train Loss:0.05289, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4550, Train Loss:0.06553, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4551, Train Loss:0.12960, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4552, Train Loss:0.23928, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4553, Train Loss:0.23028, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4554, Train Loss:0.16303, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4555, Train Loss:0.08552, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4556, Train Loss:0.02867, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4557, Train Loss:0.00010, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4558, Train Loss:0.18628, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4559, Train Loss:0.07590, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4560, Train Loss:0.00426, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4561, Train Loss:0.00791, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4562, Train Loss:0.02518, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4563, Train Loss:0.16880, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4564, Train Loss:0.13592, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4565, Train Loss:0.06981, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4566, Train Loss:0.40366, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4567, Train Loss:0.16085, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4568, Train Loss:0.11969, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4569, Train Loss:0.00134, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4570, Train Loss:0.10648, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4571, Train Loss:0.05734, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4572, Train Loss:0.00145, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4573, Train Loss:0.00047, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4574, Train Loss:0.32611, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4575, Train Loss:0.01601, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4576, Train Loss:0.00092, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4577, Train Loss:0.11658, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4578, Train Loss:0.61103, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4579, Train Loss:0.00585, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4580, Train Loss:0.01429, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4581, Train Loss:0.15800, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4582, Train Loss:0.65306, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4583, Train Loss:0.10170, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4584, Train Loss:0.67805, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4585, Train Loss:0.23894, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4586, Train Loss:0.33167, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4587, Train Loss:0.04594, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4588, Train Loss:0.22383, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4589, Train Loss:0.14279, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4590, Train Loss:0.28151, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4591, Train Loss:0.54466, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4592, Train Loss:0.11985, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4593, Train Loss:0.00830, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4594, Train Loss:0.37234, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4595, Train Loss:0.14796, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4596, Train Loss:0.09357, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4597, Train Loss:0.23797, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4598, Train Loss:0.13908, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4599, Train Loss:0.10445, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4600, Train Loss:0.40246, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4601, Train Loss:0.12202, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4602, Train Loss:0.07181, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4603, Train Loss:0.04013, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4604, Train Loss:0.07380, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4605, Train Loss:0.07844, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4606, Train Loss:0.17313, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4607, Train Loss:0.00312, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4608, Train Loss:0.00025, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4609, Train Loss:0.43860, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4610, Train Loss:0.04994, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4611, Train Loss:0.13022, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4612, Train Loss:0.45804, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4613, Train Loss:0.04661, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4614, Train Loss:0.08712, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4615, Train Loss:0.61055, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4616, Train Loss:0.01081, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4617, Train Loss:0.44398, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4618, Train Loss:0.01127, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4619, Train Loss:0.06315, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4620, Train Loss:0.12196, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4621, Train Loss:0.03310, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4622, Train Loss:0.11762, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4623, Train Loss:0.12683, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4624, Train Loss:0.00461, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4625, Train Loss:0.05317, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4626, Train Loss:0.05425, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4627, Train Loss:0.29110, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4628, Train Loss:0.25015, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4629, Train Loss:0.12112, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4630, Train Loss:0.02955, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4631, Train Loss:0.90214, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4632, Train Loss:0.26144, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4633, Train Loss:0.29862, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4634, Train Loss:0.64946, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4635, Train Loss:0.01225, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4636, Train Loss:0.01422, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4637, Train Loss:0.34577, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4638, Train Loss:0.11976, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4639, Train Loss:0.15887, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4640, Train Loss:0.00601, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4641, Train Loss:0.01750, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4642, Train Loss:0.00035, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4643, Train Loss:0.00050, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4644, Train Loss:0.00042, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4645, Train Loss:0.05866, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4646, Train Loss:0.40678, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4647, Train Loss:0.62581, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4648, Train Loss:0.23403, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4649, Train Loss:0.00931, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4650, Train Loss:0.18787, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4651, Train Loss:0.28051, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4652, Train Loss:0.06602, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4653, Train Loss:0.12971, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4654, Train Loss:0.02756, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4655, Train Loss:0.06909, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4656, Train Loss:0.45881, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4657, Train Loss:0.15688, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4658, Train Loss:0.16360, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4659, Train Loss:0.03933, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4660, Train Loss:0.32246, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4661, Train Loss:0.00754, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4662, Train Loss:0.15155, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4663, Train Loss:0.19956, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4664, Train Loss:0.18038, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4665, Train Loss:0.31108, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4666, Train Loss:0.07159, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4667, Train Loss:0.74189, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4668, Train Loss:0.46770, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4669, Train Loss:0.02342, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4670, Train Loss:0.18312, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4671, Train Loss:0.23291, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4672, Train Loss:0.19289, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4673, Train Loss:0.12218, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4674, Train Loss:0.15575, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4675, Train Loss:0.30096, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4676, Train Loss:0.27260, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4677, Train Loss:0.01419, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4678, Train Loss:0.09224, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4679, Train Loss:0.22711, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4680, Train Loss:0.13439, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4681, Train Loss:0.20944, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4682, Train Loss:0.22730, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4683, Train Loss:0.06962, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4684, Train Loss:0.51865, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4685, Train Loss:0.07356, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4686, Train Loss:0.06293, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4687, Train Loss:0.10032, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4688, Train Loss:0.36968, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4689, Train Loss:0.17834, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4690, Train Loss:0.06615, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4691, Train Loss:0.13336, Dev Loss:0.18733\n",
      "Epoch:[16/100], step:4692, Train Loss:0.18086, Dev Loss:0.18733\n",
      "Start Epoch: 17, Steps: 17\n",
      "Epoch:[17/100], step:4693, Train Loss:0.00945, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4694, Train Loss:0.01290, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4695, Train Loss:0.10538, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4696, Train Loss:0.00664, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4697, Train Loss:0.06015, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4698, Train Loss:0.10164, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4699, Train Loss:0.10210, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4700, Train Loss:0.27481, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4701, Train Loss:0.29466, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4702, Train Loss:0.01965, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4703, Train Loss:0.00167, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4704, Train Loss:0.03031, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4705, Train Loss:0.57895, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4706, Train Loss:0.03315, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4707, Train Loss:0.00072, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4708, Train Loss:0.02190, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4709, Train Loss:0.12283, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4710, Train Loss:0.00034, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4711, Train Loss:0.14524, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4712, Train Loss:0.31454, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4713, Train Loss:0.01665, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4714, Train Loss:0.02785, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4715, Train Loss:0.19267, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4716, Train Loss:0.00216, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4717, Train Loss:0.66631, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4718, Train Loss:0.19221, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4719, Train Loss:0.00388, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4720, Train Loss:0.00840, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4721, Train Loss:0.36674, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4722, Train Loss:0.58338, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4723, Train Loss:0.01112, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4724, Train Loss:0.07461, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4725, Train Loss:0.00065, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4726, Train Loss:0.05150, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4727, Train Loss:0.05080, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4728, Train Loss:0.24001, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4729, Train Loss:0.50009, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4730, Train Loss:0.16901, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4731, Train Loss:0.09074, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4732, Train Loss:0.06075, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4733, Train Loss:0.19266, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4734, Train Loss:0.08117, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4735, Train Loss:0.17100, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4736, Train Loss:0.02114, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4737, Train Loss:0.01497, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4738, Train Loss:0.47453, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4739, Train Loss:0.05143, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4740, Train Loss:0.04654, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4741, Train Loss:0.03568, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4742, Train Loss:0.15521, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4743, Train Loss:0.06249, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4744, Train Loss:0.06792, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4745, Train Loss:0.20137, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4746, Train Loss:0.39450, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4747, Train Loss:0.40052, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4748, Train Loss:0.73451, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4749, Train Loss:0.29428, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4750, Train Loss:0.11026, Dev Loss:0.18733\n",
      "Epoch:[17/100], step:4751, Train Loss:0.40734, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4752, Train Loss:0.01744, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4753, Train Loss:0.00804, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4754, Train Loss:0.00072, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4755, Train Loss:0.05456, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4756, Train Loss:0.03118, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4757, Train Loss:0.20993, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4758, Train Loss:0.12486, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4759, Train Loss:0.04929, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4760, Train Loss:0.32365, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4761, Train Loss:0.17341, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4762, Train Loss:0.27426, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4763, Train Loss:0.29361, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4764, Train Loss:0.04439, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4765, Train Loss:0.27037, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4766, Train Loss:0.15857, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4767, Train Loss:0.19821, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4768, Train Loss:0.10517, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4769, Train Loss:0.02890, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4770, Train Loss:0.00379, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4771, Train Loss:0.28012, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4772, Train Loss:0.00802, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4773, Train Loss:0.10659, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4774, Train Loss:0.32299, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4775, Train Loss:0.62590, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4776, Train Loss:0.03338, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4777, Train Loss:0.02081, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4778, Train Loss:0.13694, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4779, Train Loss:0.24553, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4780, Train Loss:0.00117, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4781, Train Loss:0.17559, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4782, Train Loss:0.52434, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4783, Train Loss:0.16835, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4784, Train Loss:0.02122, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4785, Train Loss:0.07808, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4786, Train Loss:0.02167, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4787, Train Loss:0.01674, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4788, Train Loss:0.20682, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4789, Train Loss:0.03913, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4790, Train Loss:0.49400, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4791, Train Loss:0.05246, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4792, Train Loss:0.01639, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4793, Train Loss:0.11832, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4794, Train Loss:0.00138, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4795, Train Loss:0.13016, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4796, Train Loss:0.00726, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4797, Train Loss:0.02367, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4798, Train Loss:0.05915, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4799, Train Loss:0.02056, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4800, Train Loss:0.00241, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4801, Train Loss:0.00755, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4802, Train Loss:0.00631, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4803, Train Loss:0.00445, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4804, Train Loss:0.09654, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4805, Train Loss:0.07280, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4806, Train Loss:0.09706, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4807, Train Loss:0.17006, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4808, Train Loss:0.01417, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4809, Train Loss:0.51605, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4810, Train Loss:0.00474, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4811, Train Loss:0.13999, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4812, Train Loss:0.36474, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4813, Train Loss:0.40526, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4814, Train Loss:0.10235, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4815, Train Loss:0.23946, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4816, Train Loss:0.22043, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4817, Train Loss:0.31611, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4818, Train Loss:0.06296, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4819, Train Loss:0.42736, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4820, Train Loss:0.03282, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4821, Train Loss:0.08854, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4822, Train Loss:0.32386, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4823, Train Loss:0.09090, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4824, Train Loss:0.06866, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4825, Train Loss:0.04405, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4826, Train Loss:0.02467, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4827, Train Loss:0.02897, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4828, Train Loss:0.02163, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4829, Train Loss:0.00398, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4830, Train Loss:0.00037, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4831, Train Loss:0.16461, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4832, Train Loss:0.07471, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4833, Train Loss:0.00393, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4834, Train Loss:0.07055, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4835, Train Loss:0.10748, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4836, Train Loss:0.00333, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4837, Train Loss:0.08644, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4838, Train Loss:0.00006, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4839, Train Loss:0.00000, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4840, Train Loss:0.34004, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4841, Train Loss:0.20164, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4842, Train Loss:0.08394, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4843, Train Loss:0.01411, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4844, Train Loss:0.12198, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4845, Train Loss:0.00000, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4846, Train Loss:0.28284, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4847, Train Loss:0.03061, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4848, Train Loss:0.09541, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4849, Train Loss:0.09313, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4850, Train Loss:0.02893, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4851, Train Loss:0.00006, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4852, Train Loss:0.03600, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4853, Train Loss:0.11270, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4854, Train Loss:0.12679, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4855, Train Loss:0.08346, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4856, Train Loss:0.30039, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4857, Train Loss:0.04665, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4858, Train Loss:0.11549, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4859, Train Loss:0.00030, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4860, Train Loss:0.13584, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4861, Train Loss:0.00046, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4862, Train Loss:0.13470, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4863, Train Loss:0.02887, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4864, Train Loss:0.40375, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4865, Train Loss:0.00016, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4866, Train Loss:0.05413, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4867, Train Loss:0.00050, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4868, Train Loss:0.18416, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4869, Train Loss:0.00094, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4870, Train Loss:0.15803, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4871, Train Loss:0.01200, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4872, Train Loss:0.05912, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4873, Train Loss:0.12013, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4874, Train Loss:1.85152, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4875, Train Loss:0.07627, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4876, Train Loss:0.12152, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4877, Train Loss:0.08086, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4878, Train Loss:0.21002, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4879, Train Loss:0.00229, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4880, Train Loss:0.18315, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4881, Train Loss:0.12425, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4882, Train Loss:0.05437, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4883, Train Loss:0.16677, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4884, Train Loss:0.04557, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4885, Train Loss:0.00017, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4886, Train Loss:0.00277, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4887, Train Loss:0.03016, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4888, Train Loss:0.02848, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4889, Train Loss:0.00601, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4890, Train Loss:0.18592, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4891, Train Loss:0.12869, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4892, Train Loss:0.01011, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4893, Train Loss:0.47484, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4894, Train Loss:0.05154, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4895, Train Loss:0.15336, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4896, Train Loss:0.07204, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4897, Train Loss:0.01369, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4898, Train Loss:0.01769, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4899, Train Loss:0.50714, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4900, Train Loss:0.00151, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4901, Train Loss:1.00376, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4902, Train Loss:0.00000, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4903, Train Loss:0.02081, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4904, Train Loss:0.20865, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4905, Train Loss:0.36998, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4906, Train Loss:1.35333, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4907, Train Loss:0.06829, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4908, Train Loss:0.01761, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4909, Train Loss:0.07476, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4910, Train Loss:0.18545, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4911, Train Loss:0.12359, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4912, Train Loss:0.07064, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4913, Train Loss:0.09546, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4914, Train Loss:0.05358, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4915, Train Loss:0.41585, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4916, Train Loss:0.12800, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4917, Train Loss:0.02723, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4918, Train Loss:0.10679, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4919, Train Loss:0.21645, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4920, Train Loss:0.13670, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4921, Train Loss:0.14018, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4922, Train Loss:0.16187, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4923, Train Loss:0.11443, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4924, Train Loss:0.33050, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4925, Train Loss:0.04226, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4926, Train Loss:0.11308, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4927, Train Loss:0.01138, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4928, Train Loss:0.08136, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4929, Train Loss:0.17396, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4930, Train Loss:0.10973, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4931, Train Loss:0.14037, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4932, Train Loss:0.21875, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4933, Train Loss:0.02705, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4934, Train Loss:0.40420, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4935, Train Loss:0.32928, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4936, Train Loss:0.07605, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4937, Train Loss:0.00311, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4938, Train Loss:0.00139, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4939, Train Loss:0.00086, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4940, Train Loss:0.16914, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4941, Train Loss:0.04993, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4942, Train Loss:0.08270, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4943, Train Loss:0.00000, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4944, Train Loss:0.52134, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4945, Train Loss:0.01591, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4946, Train Loss:0.87885, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4947, Train Loss:0.88664, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4948, Train Loss:0.00035, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4949, Train Loss:0.10625, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4950, Train Loss:0.09114, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4951, Train Loss:0.31973, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4952, Train Loss:0.07706, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4953, Train Loss:0.01940, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4954, Train Loss:0.08231, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4955, Train Loss:0.00027, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4956, Train Loss:0.00066, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4957, Train Loss:0.56317, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4958, Train Loss:0.80302, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4959, Train Loss:0.11577, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4960, Train Loss:0.02541, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4961, Train Loss:0.34162, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4962, Train Loss:0.31067, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4963, Train Loss:0.46259, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4964, Train Loss:0.01150, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4965, Train Loss:0.10292, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4966, Train Loss:0.54068, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4967, Train Loss:0.09964, Dev Loss:0.17075\n",
      "Epoch:[17/100], step:4968, Train Loss:0.00806, Dev Loss:0.17075\n",
      "Start Epoch: 18, Steps: 17\n",
      "Epoch:[18/100], step:4969, Train Loss:0.10198, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4970, Train Loss:0.10760, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4971, Train Loss:0.39743, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4972, Train Loss:0.07151, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4973, Train Loss:0.00353, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4974, Train Loss:0.26348, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4975, Train Loss:0.07443, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4976, Train Loss:0.08030, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4977, Train Loss:0.04695, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4978, Train Loss:0.13294, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4979, Train Loss:0.04645, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4980, Train Loss:0.15593, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4981, Train Loss:0.10165, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4982, Train Loss:0.00192, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4983, Train Loss:0.45011, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4984, Train Loss:0.19786, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4985, Train Loss:0.11549, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4986, Train Loss:0.22731, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4987, Train Loss:0.29841, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4988, Train Loss:0.11961, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4989, Train Loss:0.33298, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4990, Train Loss:0.01641, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4991, Train Loss:0.22757, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4992, Train Loss:0.44324, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4993, Train Loss:0.00013, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4994, Train Loss:0.00038, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4995, Train Loss:0.09343, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4996, Train Loss:0.04603, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4997, Train Loss:0.18859, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4998, Train Loss:0.14390, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:4999, Train Loss:0.59352, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:5000, Train Loss:0.26133, Dev Loss:0.17075\n",
      "Epoch:[18/100], step:5001, Train Loss:0.30904, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5002, Train Loss:0.28184, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5003, Train Loss:0.12371, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5004, Train Loss:0.62563, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5005, Train Loss:0.16166, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5006, Train Loss:0.55590, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5007, Train Loss:0.13037, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5008, Train Loss:0.04619, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5009, Train Loss:0.32964, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5010, Train Loss:0.06835, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5011, Train Loss:0.07180, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5012, Train Loss:0.03022, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5013, Train Loss:0.43509, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5014, Train Loss:0.00920, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5015, Train Loss:0.00164, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5016, Train Loss:0.23104, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5017, Train Loss:0.08597, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5018, Train Loss:0.38266, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5019, Train Loss:0.00276, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5020, Train Loss:0.00141, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5021, Train Loss:0.13784, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5022, Train Loss:0.20982, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5023, Train Loss:0.13554, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5024, Train Loss:0.00677, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5025, Train Loss:0.00270, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5026, Train Loss:0.40996, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5027, Train Loss:0.20712, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5028, Train Loss:0.17276, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5029, Train Loss:0.01103, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5030, Train Loss:0.01322, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5031, Train Loss:0.09753, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5032, Train Loss:0.00020, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5033, Train Loss:0.06712, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5034, Train Loss:0.03173, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5035, Train Loss:0.17769, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5036, Train Loss:0.00874, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5037, Train Loss:0.08313, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5038, Train Loss:0.00313, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5039, Train Loss:0.05952, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5040, Train Loss:0.51783, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5041, Train Loss:0.01784, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5042, Train Loss:0.00006, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5043, Train Loss:0.12161, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5044, Train Loss:0.09522, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5045, Train Loss:0.59426, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5046, Train Loss:0.05877, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5047, Train Loss:0.08828, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5048, Train Loss:0.00756, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5049, Train Loss:0.00002, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5050, Train Loss:0.11057, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5051, Train Loss:0.46121, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5052, Train Loss:0.06040, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5053, Train Loss:0.00018, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5054, Train Loss:0.00146, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5055, Train Loss:0.47030, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5056, Train Loss:0.10232, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5057, Train Loss:0.01010, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5058, Train Loss:0.02582, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5059, Train Loss:0.24272, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5060, Train Loss:0.10079, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5061, Train Loss:0.36779, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5062, Train Loss:0.00426, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5063, Train Loss:0.11795, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5064, Train Loss:0.40353, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5065, Train Loss:0.04771, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5066, Train Loss:0.48261, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5067, Train Loss:0.11720, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5068, Train Loss:0.05259, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5069, Train Loss:0.01966, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5070, Train Loss:0.04853, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5071, Train Loss:0.00134, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5072, Train Loss:0.11681, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5073, Train Loss:1.95265, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5074, Train Loss:0.12075, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5075, Train Loss:0.27277, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5076, Train Loss:0.65570, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5077, Train Loss:0.02598, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5078, Train Loss:0.05278, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5079, Train Loss:0.00766, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5080, Train Loss:0.07327, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5081, Train Loss:0.65968, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5082, Train Loss:0.00896, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5083, Train Loss:0.17999, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5084, Train Loss:0.07717, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5085, Train Loss:0.20206, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5086, Train Loss:0.01033, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5087, Train Loss:0.00073, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5088, Train Loss:0.18716, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5089, Train Loss:0.01677, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5090, Train Loss:0.09765, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5091, Train Loss:0.29508, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5092, Train Loss:0.07350, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5093, Train Loss:0.42790, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5094, Train Loss:0.17416, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5095, Train Loss:0.06197, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5096, Train Loss:0.20878, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5097, Train Loss:0.01825, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5098, Train Loss:0.03543, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5099, Train Loss:0.00103, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5100, Train Loss:0.03307, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5101, Train Loss:0.00481, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5102, Train Loss:0.10154, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5103, Train Loss:0.15164, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5104, Train Loss:0.00148, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5105, Train Loss:0.00243, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5106, Train Loss:0.00416, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5107, Train Loss:0.02182, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5108, Train Loss:0.04669, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5109, Train Loss:0.12913, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5110, Train Loss:0.00800, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5111, Train Loss:0.26832, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5112, Train Loss:0.19719, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5113, Train Loss:0.51572, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5114, Train Loss:0.71175, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5115, Train Loss:0.18252, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5116, Train Loss:0.00234, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5117, Train Loss:0.00812, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5118, Train Loss:0.12362, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5119, Train Loss:0.00808, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5120, Train Loss:0.19168, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5121, Train Loss:0.49137, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5122, Train Loss:0.32989, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5123, Train Loss:0.15990, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5124, Train Loss:0.69422, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5125, Train Loss:0.04872, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5126, Train Loss:0.09688, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5127, Train Loss:0.39519, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5128, Train Loss:0.05343, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5129, Train Loss:0.06982, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5130, Train Loss:0.49551, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5131, Train Loss:0.00050, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5132, Train Loss:0.08444, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5133, Train Loss:0.26622, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5134, Train Loss:0.78856, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5135, Train Loss:0.03574, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5136, Train Loss:0.12231, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5137, Train Loss:0.18550, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5138, Train Loss:0.35944, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5139, Train Loss:0.29957, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5140, Train Loss:0.16164, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5141, Train Loss:0.13822, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5142, Train Loss:0.09079, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5143, Train Loss:0.06130, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5144, Train Loss:0.22625, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5145, Train Loss:0.18121, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5146, Train Loss:0.11696, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5147, Train Loss:0.12998, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5148, Train Loss:0.03369, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5149, Train Loss:0.41770, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5150, Train Loss:0.00359, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5151, Train Loss:0.05444, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5152, Train Loss:0.00786, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5153, Train Loss:0.10701, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5154, Train Loss:0.55492, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5155, Train Loss:0.50639, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5156, Train Loss:0.11546, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5157, Train Loss:0.07014, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5158, Train Loss:0.06417, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5159, Train Loss:0.18017, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5160, Train Loss:0.38986, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5161, Train Loss:0.18001, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5162, Train Loss:0.15222, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5163, Train Loss:0.17722, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5164, Train Loss:0.10174, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5165, Train Loss:0.06091, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5166, Train Loss:0.24247, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5167, Train Loss:0.28028, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5168, Train Loss:0.40819, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5169, Train Loss:0.01618, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5170, Train Loss:0.24859, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5171, Train Loss:0.00628, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5172, Train Loss:0.19390, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5173, Train Loss:0.12980, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5174, Train Loss:0.16169, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5175, Train Loss:0.00054, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5176, Train Loss:0.01421, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5177, Train Loss:0.02153, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5178, Train Loss:0.77314, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5179, Train Loss:0.00662, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5180, Train Loss:0.00015, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5181, Train Loss:0.10562, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5182, Train Loss:0.03223, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5183, Train Loss:0.17263, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5184, Train Loss:0.08824, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5185, Train Loss:0.02427, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5186, Train Loss:0.10685, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5187, Train Loss:0.03023, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5188, Train Loss:0.50328, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5189, Train Loss:0.13950, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5190, Train Loss:0.07260, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5191, Train Loss:0.08582, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5192, Train Loss:0.50245, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5193, Train Loss:0.05855, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5194, Train Loss:0.19415, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5195, Train Loss:0.01206, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5196, Train Loss:0.01143, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5197, Train Loss:0.01666, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5198, Train Loss:0.06520, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5199, Train Loss:0.14622, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5200, Train Loss:0.03359, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5201, Train Loss:0.01382, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5202, Train Loss:0.64095, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5203, Train Loss:0.20714, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5204, Train Loss:0.39260, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5205, Train Loss:0.48696, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5206, Train Loss:0.42543, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5207, Train Loss:0.05815, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5208, Train Loss:0.11659, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5209, Train Loss:0.08422, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5210, Train Loss:0.19581, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5211, Train Loss:0.20384, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5212, Train Loss:0.78679, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5213, Train Loss:0.08313, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5214, Train Loss:0.12884, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5215, Train Loss:0.19890, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5216, Train Loss:0.07884, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5217, Train Loss:0.00374, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5218, Train Loss:0.10860, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5219, Train Loss:0.04847, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5220, Train Loss:0.10261, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5221, Train Loss:0.11937, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5222, Train Loss:0.28447, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5223, Train Loss:0.18295, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5224, Train Loss:0.29197, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5225, Train Loss:0.00872, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5226, Train Loss:0.14490, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5227, Train Loss:0.09280, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5228, Train Loss:0.07132, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5229, Train Loss:0.12782, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5230, Train Loss:0.10675, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5231, Train Loss:0.13033, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5232, Train Loss:0.00272, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5233, Train Loss:0.07734, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5234, Train Loss:0.70991, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5235, Train Loss:0.09604, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5236, Train Loss:0.23925, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5237, Train Loss:0.00018, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5238, Train Loss:0.17835, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5239, Train Loss:0.06079, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5240, Train Loss:0.34491, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5241, Train Loss:0.01397, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5242, Train Loss:0.25216, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5243, Train Loss:0.04847, Dev Loss:0.15175\n",
      "Epoch:[18/100], step:5244, Train Loss:0.00257, Dev Loss:0.15175\n",
      "Start Epoch: 19, Steps: 17\n",
      "Epoch:[19/100], step:5245, Train Loss:0.07408, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5246, Train Loss:0.02459, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5247, Train Loss:0.39869, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5248, Train Loss:0.03560, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5249, Train Loss:0.05220, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5250, Train Loss:0.39643, Dev Loss:0.15175\n",
      "Epoch:[19/100], step:5251, Train Loss:0.01217, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5252, Train Loss:0.43457, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5253, Train Loss:0.33003, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5254, Train Loss:0.00282, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5255, Train Loss:0.02457, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5256, Train Loss:0.31276, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5257, Train Loss:0.03659, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5258, Train Loss:0.25490, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5259, Train Loss:0.03619, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5260, Train Loss:0.03689, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5261, Train Loss:0.03148, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5262, Train Loss:0.19070, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5263, Train Loss:0.01560, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5264, Train Loss:0.32637, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5265, Train Loss:0.02564, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5266, Train Loss:0.07044, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5267, Train Loss:0.00308, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5268, Train Loss:0.69677, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5269, Train Loss:0.10356, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5270, Train Loss:0.07517, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5271, Train Loss:0.12806, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5272, Train Loss:0.16447, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5273, Train Loss:0.01412, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5274, Train Loss:0.33650, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5275, Train Loss:0.00346, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5276, Train Loss:0.05646, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5277, Train Loss:0.03389, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5278, Train Loss:0.00015, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5279, Train Loss:0.00944, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5280, Train Loss:0.19504, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5281, Train Loss:0.00002, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5282, Train Loss:0.36784, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5283, Train Loss:0.03786, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5284, Train Loss:0.19512, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5285, Train Loss:0.36833, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5286, Train Loss:0.74843, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5287, Train Loss:0.09164, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5288, Train Loss:0.00355, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5289, Train Loss:0.08824, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5290, Train Loss:0.13366, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5291, Train Loss:0.00700, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5292, Train Loss:0.39735, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5293, Train Loss:0.36248, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5294, Train Loss:0.54972, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5295, Train Loss:0.11304, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5296, Train Loss:0.00000, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5297, Train Loss:0.27730, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5298, Train Loss:0.25651, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5299, Train Loss:0.00698, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5300, Train Loss:0.25994, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5301, Train Loss:0.62870, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5302, Train Loss:0.14973, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5303, Train Loss:0.16029, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5304, Train Loss:0.13657, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5305, Train Loss:0.00143, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5306, Train Loss:0.04503, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5307, Train Loss:0.48385, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5308, Train Loss:0.13320, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5309, Train Loss:0.14446, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5310, Train Loss:0.35980, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5311, Train Loss:0.09188, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5312, Train Loss:0.53563, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5313, Train Loss:0.23640, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5314, Train Loss:0.76179, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5315, Train Loss:0.04695, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5316, Train Loss:0.09167, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5317, Train Loss:0.04048, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5318, Train Loss:0.00914, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5319, Train Loss:0.06128, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5320, Train Loss:0.05224, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5321, Train Loss:0.01269, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5322, Train Loss:0.30209, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5323, Train Loss:0.05245, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5324, Train Loss:0.13168, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5325, Train Loss:0.11378, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5326, Train Loss:0.04407, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5327, Train Loss:0.05381, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5328, Train Loss:0.15368, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5329, Train Loss:0.13926, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5330, Train Loss:0.29636, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5331, Train Loss:0.22366, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5332, Train Loss:0.30668, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5333, Train Loss:0.01263, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5334, Train Loss:0.06405, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5335, Train Loss:0.26811, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5336, Train Loss:0.12049, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5337, Train Loss:0.02788, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5338, Train Loss:0.03073, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5339, Train Loss:0.01385, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5340, Train Loss:0.00367, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5341, Train Loss:0.13411, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5342, Train Loss:0.47975, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5343, Train Loss:0.00417, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5344, Train Loss:0.00003, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5345, Train Loss:0.38594, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5346, Train Loss:0.14570, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5347, Train Loss:0.04400, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5348, Train Loss:0.14630, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5349, Train Loss:0.00624, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5350, Train Loss:0.00018, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5351, Train Loss:0.52667, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5352, Train Loss:0.06473, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5353, Train Loss:0.12070, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5354, Train Loss:0.05005, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5355, Train Loss:0.07705, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5356, Train Loss:0.00094, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5357, Train Loss:0.00378, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5358, Train Loss:0.00050, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5359, Train Loss:0.00101, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5360, Train Loss:0.06661, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5361, Train Loss:0.01124, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5362, Train Loss:0.00267, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5363, Train Loss:0.26711, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5364, Train Loss:0.22602, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5365, Train Loss:0.00364, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5366, Train Loss:0.00093, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5367, Train Loss:0.00373, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5368, Train Loss:0.01418, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5369, Train Loss:0.00035, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5370, Train Loss:0.00062, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5371, Train Loss:0.11671, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5372, Train Loss:0.17240, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5373, Train Loss:0.05492, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5374, Train Loss:0.04267, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5375, Train Loss:0.02212, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5376, Train Loss:0.09539, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5377, Train Loss:1.85181, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5378, Train Loss:0.02251, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5379, Train Loss:0.00017, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5380, Train Loss:0.18697, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5381, Train Loss:0.11956, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5382, Train Loss:0.19026, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5383, Train Loss:0.02620, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5384, Train Loss:0.05553, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5385, Train Loss:0.02764, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5386, Train Loss:0.27358, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5387, Train Loss:0.29865, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5388, Train Loss:0.35627, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5389, Train Loss:0.02930, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5390, Train Loss:0.09972, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5391, Train Loss:0.01073, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5392, Train Loss:0.31316, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5393, Train Loss:0.02007, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5394, Train Loss:0.02980, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5395, Train Loss:0.11953, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5396, Train Loss:0.01304, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5397, Train Loss:0.01804, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5398, Train Loss:0.26466, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5399, Train Loss:0.12968, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5400, Train Loss:0.11314, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5401, Train Loss:0.18611, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5402, Train Loss:0.00021, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5403, Train Loss:0.06480, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5404, Train Loss:0.00463, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5405, Train Loss:0.00008, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5406, Train Loss:0.00000, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5407, Train Loss:0.08351, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5408, Train Loss:0.00794, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5409, Train Loss:0.00016, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5410, Train Loss:0.00064, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5411, Train Loss:0.02180, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5412, Train Loss:0.00034, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5413, Train Loss:0.04893, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5414, Train Loss:0.00175, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5415, Train Loss:0.28095, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5416, Train Loss:0.00226, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5417, Train Loss:0.16228, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5418, Train Loss:0.87608, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5419, Train Loss:0.00011, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5420, Train Loss:0.04500, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5421, Train Loss:0.07808, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5422, Train Loss:0.00175, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5423, Train Loss:0.09475, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5424, Train Loss:0.27314, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5425, Train Loss:0.06351, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5426, Train Loss:0.09501, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5427, Train Loss:0.47537, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5428, Train Loss:0.05423, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5429, Train Loss:0.00534, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5430, Train Loss:0.01694, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5431, Train Loss:0.81477, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5432, Train Loss:0.03453, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5433, Train Loss:0.02850, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5434, Train Loss:0.00940, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5435, Train Loss:0.65678, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5436, Train Loss:0.06344, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5437, Train Loss:0.32599, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5438, Train Loss:0.04565, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5439, Train Loss:0.39925, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5440, Train Loss:0.27332, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5441, Train Loss:0.33876, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5442, Train Loss:0.01245, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5443, Train Loss:0.34445, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5444, Train Loss:0.04156, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5445, Train Loss:0.24105, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5446, Train Loss:0.34139, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5447, Train Loss:0.15986, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5448, Train Loss:0.00822, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5449, Train Loss:0.01046, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5450, Train Loss:0.19002, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5451, Train Loss:0.01206, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5452, Train Loss:0.07683, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5453, Train Loss:0.13689, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5454, Train Loss:0.03827, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5455, Train Loss:0.00267, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5456, Train Loss:0.04117, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5457, Train Loss:0.06262, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5458, Train Loss:0.13665, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5459, Train Loss:0.00406, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5460, Train Loss:0.23363, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5461, Train Loss:0.01689, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5462, Train Loss:0.19932, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5463, Train Loss:0.00072, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5464, Train Loss:0.00015, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5465, Train Loss:0.22351, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5466, Train Loss:0.21374, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5467, Train Loss:0.23464, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5468, Train Loss:0.28405, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5469, Train Loss:0.07180, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5470, Train Loss:0.10205, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5471, Train Loss:0.14167, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5472, Train Loss:0.02687, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5473, Train Loss:0.01117, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5474, Train Loss:0.37482, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5475, Train Loss:0.19952, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5476, Train Loss:0.11981, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5477, Train Loss:0.25091, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5478, Train Loss:0.00149, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5479, Train Loss:0.56585, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5480, Train Loss:0.37360, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5481, Train Loss:0.37572, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5482, Train Loss:0.00135, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5483, Train Loss:0.07670, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5484, Train Loss:0.05988, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5485, Train Loss:0.14134, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5486, Train Loss:0.11734, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5487, Train Loss:0.54405, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5488, Train Loss:1.61292, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5489, Train Loss:0.00587, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5490, Train Loss:0.39161, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5491, Train Loss:0.22066, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5492, Train Loss:0.39790, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5493, Train Loss:0.50845, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5494, Train Loss:0.02032, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5495, Train Loss:0.51577, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5496, Train Loss:0.16645, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5497, Train Loss:0.04875, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5498, Train Loss:0.15745, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5499, Train Loss:0.21791, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5500, Train Loss:0.26717, Dev Loss:0.11552\n",
      "Epoch:[19/100], step:5501, Train Loss:0.00685, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5502, Train Loss:0.10465, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5503, Train Loss:0.12349, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5504, Train Loss:0.17157, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5505, Train Loss:0.07588, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5506, Train Loss:0.20807, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5507, Train Loss:0.00097, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5508, Train Loss:0.16374, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5509, Train Loss:0.01342, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5510, Train Loss:0.08034, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5511, Train Loss:0.05078, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5512, Train Loss:0.00355, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5513, Train Loss:0.13562, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5514, Train Loss:0.00395, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5515, Train Loss:0.00474, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5516, Train Loss:0.09490, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5517, Train Loss:0.05467, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5518, Train Loss:0.35832, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5519, Train Loss:0.00111, Dev Loss:0.22778\n",
      "Epoch:[19/100], step:5520, Train Loss:0.23903, Dev Loss:0.22778\n",
      "Start Epoch: 20, Steps: 17\n",
      "Epoch:[20/100], step:5521, Train Loss:0.14278, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5522, Train Loss:0.00053, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5523, Train Loss:0.00232, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5524, Train Loss:0.10951, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5525, Train Loss:0.11434, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5526, Train Loss:0.04711, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5527, Train Loss:0.15054, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5528, Train Loss:0.00989, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5529, Train Loss:0.16087, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5530, Train Loss:0.00025, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5531, Train Loss:0.04257, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5532, Train Loss:0.00094, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5533, Train Loss:0.05927, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5534, Train Loss:0.27430, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5535, Train Loss:0.15266, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5536, Train Loss:0.03222, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5537, Train Loss:0.04544, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5538, Train Loss:0.00008, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5539, Train Loss:0.05531, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5540, Train Loss:0.01506, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5541, Train Loss:0.58493, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5542, Train Loss:0.04760, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5543, Train Loss:0.02063, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5544, Train Loss:0.07597, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5545, Train Loss:0.01001, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5546, Train Loss:0.00160, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5547, Train Loss:0.27187, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5548, Train Loss:0.60254, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5549, Train Loss:0.37984, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5550, Train Loss:0.02308, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5551, Train Loss:0.08427, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5552, Train Loss:0.02459, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5553, Train Loss:0.00009, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5554, Train Loss:0.01944, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5555, Train Loss:0.04427, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5556, Train Loss:0.12171, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5557, Train Loss:0.00290, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5558, Train Loss:0.14387, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5559, Train Loss:0.00510, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5560, Train Loss:0.25279, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5561, Train Loss:0.00212, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5562, Train Loss:0.00207, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5563, Train Loss:0.14318, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5564, Train Loss:0.57576, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5565, Train Loss:0.32662, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5566, Train Loss:0.35582, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5567, Train Loss:0.28775, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5568, Train Loss:0.00081, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5569, Train Loss:0.86648, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5570, Train Loss:0.75614, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5571, Train Loss:0.21065, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5572, Train Loss:0.49714, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5573, Train Loss:0.52919, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5574, Train Loss:0.25661, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5575, Train Loss:0.26830, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5576, Train Loss:0.04518, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5577, Train Loss:0.05965, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5578, Train Loss:0.19339, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5579, Train Loss:0.00167, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5580, Train Loss:0.51162, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5581, Train Loss:0.05137, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5582, Train Loss:0.07275, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5583, Train Loss:0.09126, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5584, Train Loss:0.07942, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5585, Train Loss:0.84927, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5586, Train Loss:0.05574, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5587, Train Loss:0.05662, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5588, Train Loss:0.30431, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5589, Train Loss:0.28470, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5590, Train Loss:0.17172, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5591, Train Loss:0.14381, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5592, Train Loss:0.30601, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5593, Train Loss:0.11537, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5594, Train Loss:0.29476, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5595, Train Loss:0.46927, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5596, Train Loss:0.62954, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5597, Train Loss:0.15602, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5598, Train Loss:0.00982, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5599, Train Loss:0.02277, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5600, Train Loss:0.20696, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5601, Train Loss:0.00303, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5602, Train Loss:0.45317, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5603, Train Loss:0.41475, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5604, Train Loss:0.19066, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5605, Train Loss:0.26826, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5606, Train Loss:1.19554, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5607, Train Loss:0.07308, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5608, Train Loss:0.11515, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5609, Train Loss:0.07623, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5610, Train Loss:0.04746, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5611, Train Loss:0.04354, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5612, Train Loss:0.15870, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5613, Train Loss:0.19720, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5614, Train Loss:0.10085, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5615, Train Loss:0.16175, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5616, Train Loss:0.07509, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5617, Train Loss:0.08331, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5618, Train Loss:0.05193, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5619, Train Loss:0.00015, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5620, Train Loss:0.00000, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5621, Train Loss:0.22966, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5622, Train Loss:0.15870, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5623, Train Loss:0.73233, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5624, Train Loss:0.08354, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5625, Train Loss:0.00225, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5626, Train Loss:0.00007, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5627, Train Loss:0.55244, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5628, Train Loss:0.01704, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5629, Train Loss:0.04879, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5630, Train Loss:0.00014, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5631, Train Loss:0.45857, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5632, Train Loss:0.74783, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5633, Train Loss:0.06941, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5634, Train Loss:0.12848, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5635, Train Loss:0.24345, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5636, Train Loss:0.01048, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5637, Train Loss:0.01348, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5638, Train Loss:0.00087, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5639, Train Loss:0.02476, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5640, Train Loss:0.00051, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5641, Train Loss:0.19851, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5642, Train Loss:0.10518, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5643, Train Loss:0.05226, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5644, Train Loss:0.08688, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5645, Train Loss:0.13747, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5646, Train Loss:0.85147, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5647, Train Loss:0.66708, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5648, Train Loss:0.00943, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5649, Train Loss:0.14973, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5650, Train Loss:0.03000, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5651, Train Loss:0.62960, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5652, Train Loss:0.12130, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5653, Train Loss:0.41487, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5654, Train Loss:0.45034, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5655, Train Loss:0.27985, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5656, Train Loss:0.38565, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5657, Train Loss:0.27952, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5658, Train Loss:0.15729, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5659, Train Loss:0.40987, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5660, Train Loss:0.01312, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5661, Train Loss:0.01486, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5662, Train Loss:0.04148, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5663, Train Loss:0.15067, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5664, Train Loss:0.04252, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5665, Train Loss:0.05743, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5666, Train Loss:0.20013, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5667, Train Loss:0.22960, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5668, Train Loss:0.36915, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5669, Train Loss:0.05286, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5670, Train Loss:0.09737, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5671, Train Loss:0.00022, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5672, Train Loss:0.21817, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5673, Train Loss:0.25311, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5674, Train Loss:0.07760, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5675, Train Loss:0.63343, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5676, Train Loss:0.00849, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5677, Train Loss:0.00444, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5678, Train Loss:0.02924, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5679, Train Loss:0.18073, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5680, Train Loss:0.04611, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5681, Train Loss:0.02645, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5682, Train Loss:0.17645, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5683, Train Loss:0.16411, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5684, Train Loss:0.00232, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5685, Train Loss:0.21620, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5686, Train Loss:0.05545, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5687, Train Loss:0.04722, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5688, Train Loss:0.06054, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5689, Train Loss:0.16437, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5690, Train Loss:0.17979, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5691, Train Loss:0.20365, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5692, Train Loss:0.01778, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5693, Train Loss:0.09414, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5694, Train Loss:0.18085, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5695, Train Loss:0.26083, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5696, Train Loss:0.00249, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5697, Train Loss:0.07464, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5698, Train Loss:0.00825, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5699, Train Loss:0.02261, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5700, Train Loss:0.68510, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5701, Train Loss:0.20527, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5702, Train Loss:0.00112, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5703, Train Loss:0.00462, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5704, Train Loss:0.30487, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5705, Train Loss:0.01293, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5706, Train Loss:0.20671, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5707, Train Loss:0.01657, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5708, Train Loss:0.02345, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5709, Train Loss:0.54667, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5710, Train Loss:0.22845, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5711, Train Loss:0.25737, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5712, Train Loss:0.31670, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5713, Train Loss:0.43159, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5714, Train Loss:0.32517, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5715, Train Loss:0.30430, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5716, Train Loss:0.14754, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5717, Train Loss:0.30225, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5718, Train Loss:0.31737, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5719, Train Loss:0.06455, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5720, Train Loss:0.14802, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5721, Train Loss:0.06133, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5722, Train Loss:0.00481, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5723, Train Loss:0.16810, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5724, Train Loss:0.05559, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5725, Train Loss:0.00398, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5726, Train Loss:0.01542, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5727, Train Loss:0.00645, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5728, Train Loss:0.04510, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5729, Train Loss:0.00000, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5730, Train Loss:0.49077, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5731, Train Loss:0.13947, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5732, Train Loss:0.00616, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5733, Train Loss:0.12588, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5734, Train Loss:0.51946, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5735, Train Loss:0.08477, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5736, Train Loss:0.36032, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5737, Train Loss:0.00036, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5738, Train Loss:0.00197, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5739, Train Loss:0.04941, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5740, Train Loss:0.02962, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5741, Train Loss:0.03118, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5742, Train Loss:0.24981, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5743, Train Loss:0.00715, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5744, Train Loss:0.00440, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5745, Train Loss:0.00004, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5746, Train Loss:0.00568, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5747, Train Loss:0.20464, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5748, Train Loss:0.63315, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5749, Train Loss:0.20116, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5750, Train Loss:0.04444, Dev Loss:0.22778\n",
      "Epoch:[20/100], step:5751, Train Loss:0.25219, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5752, Train Loss:0.14865, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5753, Train Loss:0.06926, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5754, Train Loss:0.14833, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5755, Train Loss:0.00198, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5756, Train Loss:0.10694, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5757, Train Loss:0.30379, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5758, Train Loss:0.00003, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5759, Train Loss:0.22054, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5760, Train Loss:0.00000, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5761, Train Loss:0.40010, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5762, Train Loss:0.04755, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5763, Train Loss:0.65572, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5764, Train Loss:0.00023, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5765, Train Loss:0.42955, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5766, Train Loss:0.07723, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5767, Train Loss:0.07013, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5768, Train Loss:0.20117, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5769, Train Loss:1.02852, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5770, Train Loss:0.05515, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5771, Train Loss:1.79793, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5772, Train Loss:0.71059, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5773, Train Loss:0.00115, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5774, Train Loss:0.07325, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5775, Train Loss:0.09464, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5776, Train Loss:0.13327, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5777, Train Loss:0.00365, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5778, Train Loss:0.00103, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5779, Train Loss:0.20108, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5780, Train Loss:0.55989, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5781, Train Loss:0.10418, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5782, Train Loss:0.14932, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5783, Train Loss:0.05753, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5784, Train Loss:0.05837, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5785, Train Loss:0.06398, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5786, Train Loss:0.03103, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5787, Train Loss:0.47837, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5788, Train Loss:0.08071, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5789, Train Loss:0.07576, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5790, Train Loss:0.00531, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5791, Train Loss:0.71246, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5792, Train Loss:0.09244, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5793, Train Loss:0.00731, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5794, Train Loss:0.02773, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5795, Train Loss:0.32827, Dev Loss:0.18399\n",
      "Epoch:[20/100], step:5796, Train Loss:0.04679, Dev Loss:0.18399\n",
      "Start Epoch: 21, Steps: 17\n",
      "Epoch:[21/100], step:5797, Train Loss:0.00301, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5798, Train Loss:0.23217, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5799, Train Loss:0.23387, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5800, Train Loss:0.08995, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5801, Train Loss:0.18821, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5802, Train Loss:0.15513, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5803, Train Loss:0.05930, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5804, Train Loss:0.02736, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5805, Train Loss:0.13356, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5806, Train Loss:0.00025, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5807, Train Loss:0.08188, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5808, Train Loss:0.16946, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5809, Train Loss:0.16413, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5810, Train Loss:0.17013, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5811, Train Loss:0.12724, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5812, Train Loss:0.23772, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5813, Train Loss:0.14914, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5814, Train Loss:0.02593, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5815, Train Loss:0.00240, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5816, Train Loss:0.06727, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5817, Train Loss:0.01217, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5818, Train Loss:0.00553, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5819, Train Loss:0.12981, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5820, Train Loss:0.26605, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5821, Train Loss:0.12274, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5822, Train Loss:0.01176, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5823, Train Loss:0.04517, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5824, Train Loss:0.88413, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5825, Train Loss:0.00299, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5826, Train Loss:0.07293, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5827, Train Loss:0.00234, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5828, Train Loss:0.01086, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5829, Train Loss:0.06206, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5830, Train Loss:0.00307, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5831, Train Loss:0.05592, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5832, Train Loss:0.24619, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5833, Train Loss:0.07507, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5834, Train Loss:0.33939, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5835, Train Loss:0.09716, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5836, Train Loss:0.00733, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5837, Train Loss:0.29177, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5838, Train Loss:0.04736, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5839, Train Loss:0.07126, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5840, Train Loss:0.04271, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5841, Train Loss:0.00014, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5842, Train Loss:0.09947, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5843, Train Loss:0.18795, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5844, Train Loss:0.00089, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5845, Train Loss:0.09130, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5846, Train Loss:0.32703, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5847, Train Loss:0.00094, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5848, Train Loss:0.02301, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5849, Train Loss:0.00009, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5850, Train Loss:0.13147, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5851, Train Loss:0.05914, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5852, Train Loss:0.24350, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5853, Train Loss:0.00012, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5854, Train Loss:0.34094, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5855, Train Loss:0.06855, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5856, Train Loss:0.00098, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5857, Train Loss:0.00001, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5858, Train Loss:0.12489, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5859, Train Loss:0.34066, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5860, Train Loss:0.04808, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5861, Train Loss:0.01677, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5862, Train Loss:0.00005, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5863, Train Loss:0.19841, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5864, Train Loss:0.08846, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5865, Train Loss:0.07309, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5866, Train Loss:0.05937, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5867, Train Loss:0.38200, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5868, Train Loss:0.27678, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5869, Train Loss:0.02117, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5870, Train Loss:0.09209, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5871, Train Loss:0.18664, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5872, Train Loss:0.50622, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5873, Train Loss:0.60521, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5874, Train Loss:0.01422, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5875, Train Loss:0.58264, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5876, Train Loss:0.06949, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5877, Train Loss:0.54511, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5878, Train Loss:0.86571, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5879, Train Loss:0.02250, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5880, Train Loss:0.39636, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5881, Train Loss:0.06701, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5882, Train Loss:0.00116, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5883, Train Loss:0.25741, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5884, Train Loss:0.33498, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5885, Train Loss:0.02174, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5886, Train Loss:0.18725, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5887, Train Loss:0.02225, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5888, Train Loss:0.00023, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5889, Train Loss:0.03503, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5890, Train Loss:0.49411, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5891, Train Loss:0.08390, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5892, Train Loss:0.08922, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5893, Train Loss:0.00239, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5894, Train Loss:0.60817, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5895, Train Loss:0.02935, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5896, Train Loss:0.05244, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5897, Train Loss:0.12702, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5898, Train Loss:0.21977, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5899, Train Loss:0.16554, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5900, Train Loss:0.05070, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5901, Train Loss:0.01288, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5902, Train Loss:0.06848, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5903, Train Loss:0.32261, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5904, Train Loss:0.00811, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5905, Train Loss:0.33311, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5906, Train Loss:0.21872, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5907, Train Loss:0.10932, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5908, Train Loss:0.27248, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5909, Train Loss:0.20590, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5910, Train Loss:0.03875, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5911, Train Loss:0.13519, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5912, Train Loss:0.01703, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5913, Train Loss:0.01200, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5914, Train Loss:0.02696, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5915, Train Loss:0.01256, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5916, Train Loss:0.35380, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5917, Train Loss:0.19838, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5918, Train Loss:0.00096, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5919, Train Loss:0.08373, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5920, Train Loss:0.00261, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5921, Train Loss:0.18359, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5922, Train Loss:0.00290, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5923, Train Loss:0.29599, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5924, Train Loss:0.00054, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5925, Train Loss:0.01505, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5926, Train Loss:0.00021, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5927, Train Loss:0.18451, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5928, Train Loss:0.00494, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5929, Train Loss:0.37078, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5930, Train Loss:0.16928, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5931, Train Loss:0.13824, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5932, Train Loss:0.14292, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5933, Train Loss:0.59155, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5934, Train Loss:0.10159, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5935, Train Loss:0.00013, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5936, Train Loss:0.13740, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5937, Train Loss:0.05495, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5938, Train Loss:0.03865, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5939, Train Loss:0.10123, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5940, Train Loss:0.00314, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5941, Train Loss:0.22780, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5942, Train Loss:0.00200, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5943, Train Loss:0.00301, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5944, Train Loss:0.00898, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5945, Train Loss:0.00327, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5946, Train Loss:0.09532, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5947, Train Loss:0.02095, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5948, Train Loss:0.00089, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5949, Train Loss:0.00283, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5950, Train Loss:0.27557, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5951, Train Loss:0.01137, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5952, Train Loss:0.00800, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5953, Train Loss:0.56481, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5954, Train Loss:0.21125, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5955, Train Loss:0.01013, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5956, Train Loss:0.00021, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5957, Train Loss:0.49376, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5958, Train Loss:0.00289, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5959, Train Loss:0.05931, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5960, Train Loss:0.20150, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5961, Train Loss:0.06564, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5962, Train Loss:0.02227, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5963, Train Loss:0.15679, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5964, Train Loss:0.00198, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5965, Train Loss:0.17185, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5966, Train Loss:0.00053, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5967, Train Loss:0.00015, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5968, Train Loss:0.00131, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5969, Train Loss:0.33001, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5970, Train Loss:0.43896, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5971, Train Loss:0.12474, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5972, Train Loss:0.09714, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5973, Train Loss:0.00003, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5974, Train Loss:0.01847, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5975, Train Loss:0.07569, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5976, Train Loss:0.04322, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5977, Train Loss:0.07521, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5978, Train Loss:0.00284, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5979, Train Loss:0.00087, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5980, Train Loss:0.53788, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5981, Train Loss:0.16709, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5982, Train Loss:0.28385, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5983, Train Loss:0.00269, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5984, Train Loss:0.03408, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5985, Train Loss:0.60001, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5986, Train Loss:0.14149, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5987, Train Loss:0.17101, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5988, Train Loss:0.15844, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5989, Train Loss:0.01926, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5990, Train Loss:0.08949, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5991, Train Loss:0.17267, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5992, Train Loss:0.06205, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5993, Train Loss:0.47099, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5994, Train Loss:0.49942, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5995, Train Loss:0.01903, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5996, Train Loss:0.10819, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5997, Train Loss:0.62770, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5998, Train Loss:0.47131, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:5999, Train Loss:0.01832, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:6000, Train Loss:0.38151, Dev Loss:0.18399\n",
      "Epoch:[21/100], step:6001, Train Loss:0.11923, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6002, Train Loss:0.00520, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6003, Train Loss:0.05368, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6004, Train Loss:0.32905, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6005, Train Loss:0.20090, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6006, Train Loss:0.07575, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6007, Train Loss:0.10015, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6008, Train Loss:0.11469, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6009, Train Loss:0.21139, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6010, Train Loss:0.12670, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6011, Train Loss:0.08331, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6012, Train Loss:0.23034, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6013, Train Loss:0.03233, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6014, Train Loss:0.02420, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6015, Train Loss:0.11993, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6016, Train Loss:0.02597, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6017, Train Loss:0.15639, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6018, Train Loss:0.01094, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6019, Train Loss:0.00276, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6020, Train Loss:0.00908, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6021, Train Loss:0.27858, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6022, Train Loss:0.15774, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6023, Train Loss:0.25158, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6024, Train Loss:0.37184, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6025, Train Loss:0.06586, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6026, Train Loss:0.00260, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6027, Train Loss:0.05967, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6028, Train Loss:0.12062, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6029, Train Loss:0.00457, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6030, Train Loss:0.00595, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6031, Train Loss:0.32680, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6032, Train Loss:0.02668, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6033, Train Loss:0.00189, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6034, Train Loss:0.00782, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6035, Train Loss:0.11231, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6036, Train Loss:0.00344, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6037, Train Loss:0.02968, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6038, Train Loss:0.17503, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6039, Train Loss:0.00022, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6040, Train Loss:0.21535, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6041, Train Loss:0.16248, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6042, Train Loss:0.29140, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6043, Train Loss:0.01881, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6044, Train Loss:0.01581, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6045, Train Loss:0.09950, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6046, Train Loss:0.15357, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6047, Train Loss:0.53564, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6048, Train Loss:0.56657, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6049, Train Loss:0.00264, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6050, Train Loss:0.00759, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6051, Train Loss:0.04845, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6052, Train Loss:1.04836, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6053, Train Loss:0.00189, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6054, Train Loss:0.19465, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6055, Train Loss:0.00546, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6056, Train Loss:0.00765, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6057, Train Loss:0.09434, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6058, Train Loss:0.10458, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6059, Train Loss:0.00163, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6060, Train Loss:0.00193, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6061, Train Loss:0.07246, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6062, Train Loss:0.27510, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6063, Train Loss:0.17545, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6064, Train Loss:0.30928, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6065, Train Loss:0.01600, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6066, Train Loss:0.10640, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6067, Train Loss:0.06578, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6068, Train Loss:0.07713, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6069, Train Loss:0.05447, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6070, Train Loss:0.36129, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6071, Train Loss:0.03484, Dev Loss:0.22406\n",
      "Epoch:[21/100], step:6072, Train Loss:0.44278, Dev Loss:0.22406\n",
      "Start Epoch: 22, Steps: 17\n",
      "Epoch:[22/100], step:6073, Train Loss:0.00009, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6074, Train Loss:0.04390, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6075, Train Loss:0.00840, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6076, Train Loss:0.00299, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6077, Train Loss:0.02626, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6078, Train Loss:0.67577, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6079, Train Loss:0.28869, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6080, Train Loss:0.04627, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6081, Train Loss:0.09911, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6082, Train Loss:0.00216, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6083, Train Loss:0.00018, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6084, Train Loss:0.07088, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6085, Train Loss:0.00861, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6086, Train Loss:0.06785, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6087, Train Loss:0.00033, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6088, Train Loss:0.06614, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6089, Train Loss:0.07091, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6090, Train Loss:0.00001, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6091, Train Loss:0.00907, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6092, Train Loss:0.83173, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6093, Train Loss:0.26349, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6094, Train Loss:0.00003, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6095, Train Loss:0.09494, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6096, Train Loss:0.00002, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6097, Train Loss:0.00014, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6098, Train Loss:0.25036, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6099, Train Loss:0.37444, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6100, Train Loss:0.20974, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6101, Train Loss:0.03739, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6102, Train Loss:0.09180, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6103, Train Loss:0.13343, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6104, Train Loss:0.01462, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6105, Train Loss:0.10539, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6106, Train Loss:0.11065, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6107, Train Loss:0.00001, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6108, Train Loss:0.10071, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6109, Train Loss:0.03243, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6110, Train Loss:0.00284, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6111, Train Loss:0.05096, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6112, Train Loss:0.09032, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6113, Train Loss:0.44170, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6114, Train Loss:0.00013, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6115, Train Loss:0.03806, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6116, Train Loss:0.40786, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6117, Train Loss:0.00420, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6118, Train Loss:0.00224, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6119, Train Loss:0.09814, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6120, Train Loss:0.53330, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6121, Train Loss:0.11136, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6122, Train Loss:0.19344, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6123, Train Loss:0.03413, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6124, Train Loss:0.07721, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6125, Train Loss:0.06042, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6126, Train Loss:0.12851, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6127, Train Loss:0.14027, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6128, Train Loss:0.05260, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6129, Train Loss:0.01895, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6130, Train Loss:0.00051, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6131, Train Loss:0.19132, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6132, Train Loss:0.36148, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6133, Train Loss:0.01427, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6134, Train Loss:0.10896, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6135, Train Loss:0.49095, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6136, Train Loss:0.05806, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6137, Train Loss:0.10494, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6138, Train Loss:0.12636, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6139, Train Loss:0.29539, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6140, Train Loss:0.00054, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6141, Train Loss:0.00034, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6142, Train Loss:0.76007, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6143, Train Loss:0.14278, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6144, Train Loss:0.00002, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6145, Train Loss:0.03489, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6146, Train Loss:0.10760, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6147, Train Loss:0.42672, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6148, Train Loss:0.13274, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6149, Train Loss:0.00097, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6150, Train Loss:0.20179, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6151, Train Loss:0.05485, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6152, Train Loss:0.20929, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6153, Train Loss:0.56909, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6154, Train Loss:0.21887, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6155, Train Loss:0.61563, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6156, Train Loss:0.16299, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6157, Train Loss:0.06281, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6158, Train Loss:0.05937, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6159, Train Loss:0.79319, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6160, Train Loss:0.09018, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6161, Train Loss:0.09728, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6162, Train Loss:0.04603, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6163, Train Loss:0.14849, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6164, Train Loss:0.11981, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6165, Train Loss:0.06761, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6166, Train Loss:0.10414, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6167, Train Loss:0.21986, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6168, Train Loss:0.11610, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6169, Train Loss:0.08024, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6170, Train Loss:0.21524, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6171, Train Loss:0.13255, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6172, Train Loss:1.78941, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6173, Train Loss:0.00257, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6174, Train Loss:0.00457, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6175, Train Loss:0.20680, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6176, Train Loss:0.44762, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6177, Train Loss:0.10252, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6178, Train Loss:0.02654, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6179, Train Loss:0.00018, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6180, Train Loss:0.16113, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6181, Train Loss:0.00279, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6182, Train Loss:0.18507, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6183, Train Loss:0.11477, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6184, Train Loss:0.39530, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6185, Train Loss:0.02519, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6186, Train Loss:0.00122, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6187, Train Loss:0.00238, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6188, Train Loss:0.10193, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6189, Train Loss:0.00439, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6190, Train Loss:0.14562, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6191, Train Loss:0.16010, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6192, Train Loss:0.26707, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6193, Train Loss:0.00154, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6194, Train Loss:0.00005, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6195, Train Loss:0.02914, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6196, Train Loss:0.27701, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6197, Train Loss:0.00961, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6198, Train Loss:0.22074, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6199, Train Loss:0.89557, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6200, Train Loss:0.22826, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6201, Train Loss:0.18867, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6202, Train Loss:0.11371, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6203, Train Loss:0.44595, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6204, Train Loss:0.12320, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6205, Train Loss:0.00294, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6206, Train Loss:0.06183, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6207, Train Loss:0.26882, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6208, Train Loss:0.27807, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6209, Train Loss:0.17875, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6210, Train Loss:0.00138, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6211, Train Loss:0.54943, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6212, Train Loss:0.02123, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6213, Train Loss:0.03829, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6214, Train Loss:0.00010, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6215, Train Loss:0.11691, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6216, Train Loss:0.36474, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6217, Train Loss:0.00072, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6218, Train Loss:0.23711, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6219, Train Loss:0.01286, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6220, Train Loss:0.00046, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6221, Train Loss:0.00268, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6222, Train Loss:0.15441, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6223, Train Loss:0.06996, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6224, Train Loss:0.01449, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6225, Train Loss:0.23959, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6226, Train Loss:0.37220, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6227, Train Loss:0.89864, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6228, Train Loss:0.25682, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6229, Train Loss:0.21433, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6230, Train Loss:0.00587, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6231, Train Loss:0.19809, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6232, Train Loss:0.17142, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6233, Train Loss:0.16805, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6234, Train Loss:0.00313, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6235, Train Loss:0.07882, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6236, Train Loss:0.18679, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6237, Train Loss:0.02276, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6238, Train Loss:0.32993, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6239, Train Loss:0.21561, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6240, Train Loss:0.09142, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6241, Train Loss:0.07753, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6242, Train Loss:0.01354, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6243, Train Loss:0.10479, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6244, Train Loss:0.01493, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6245, Train Loss:0.10359, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6246, Train Loss:0.15052, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6247, Train Loss:1.37230, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6248, Train Loss:0.00541, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6249, Train Loss:0.44065, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6250, Train Loss:0.04991, Dev Loss:0.22406\n",
      "Epoch:[22/100], step:6251, Train Loss:0.00222, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6252, Train Loss:0.04221, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6253, Train Loss:0.13385, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6254, Train Loss:0.08770, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6255, Train Loss:0.27820, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6256, Train Loss:0.00347, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6257, Train Loss:0.18884, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6258, Train Loss:0.18597, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6259, Train Loss:0.36835, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6260, Train Loss:0.36353, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6261, Train Loss:0.18219, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6262, Train Loss:0.31989, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6263, Train Loss:0.05870, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6264, Train Loss:0.05644, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6265, Train Loss:0.00114, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6266, Train Loss:0.29949, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6267, Train Loss:0.25144, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6268, Train Loss:0.18809, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6269, Train Loss:0.25314, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6270, Train Loss:0.52753, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6271, Train Loss:0.10866, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6272, Train Loss:0.00150, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6273, Train Loss:0.20766, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6274, Train Loss:0.12949, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6275, Train Loss:0.11008, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6276, Train Loss:0.07225, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6277, Train Loss:0.02791, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6278, Train Loss:0.66642, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6279, Train Loss:0.15834, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6280, Train Loss:0.00005, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6281, Train Loss:0.00756, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6282, Train Loss:0.16213, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6283, Train Loss:0.00080, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6284, Train Loss:0.00136, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6285, Train Loss:0.12152, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6286, Train Loss:0.05278, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6287, Train Loss:0.08594, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6288, Train Loss:0.34178, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6289, Train Loss:0.00284, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6290, Train Loss:0.41998, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6291, Train Loss:0.04673, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6292, Train Loss:0.00641, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6293, Train Loss:0.04490, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6294, Train Loss:0.04383, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6295, Train Loss:0.17076, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6296, Train Loss:0.57787, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6297, Train Loss:0.26434, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6298, Train Loss:0.63120, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6299, Train Loss:0.07746, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6300, Train Loss:0.06082, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6301, Train Loss:0.01891, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6302, Train Loss:0.00278, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6303, Train Loss:0.03493, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6304, Train Loss:0.00221, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6305, Train Loss:0.22850, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6306, Train Loss:0.00004, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6307, Train Loss:0.04273, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6308, Train Loss:0.00434, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6309, Train Loss:0.00541, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6310, Train Loss:0.00139, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6311, Train Loss:0.15789, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6312, Train Loss:0.00008, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6313, Train Loss:0.00426, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6314, Train Loss:0.00013, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6315, Train Loss:0.05126, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6316, Train Loss:0.00006, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6317, Train Loss:0.01794, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6318, Train Loss:0.01484, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6319, Train Loss:0.15204, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6320, Train Loss:0.00286, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6321, Train Loss:0.40587, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6322, Train Loss:0.02771, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6323, Train Loss:1.10653, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6324, Train Loss:0.00175, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6325, Train Loss:0.08042, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6326, Train Loss:0.00005, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6327, Train Loss:0.23883, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6328, Train Loss:0.68586, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6329, Train Loss:0.03044, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6330, Train Loss:0.00009, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6331, Train Loss:0.08185, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6332, Train Loss:0.02372, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6333, Train Loss:0.02428, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6334, Train Loss:0.13171, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6335, Train Loss:0.08138, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6336, Train Loss:0.19801, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6337, Train Loss:0.23474, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6338, Train Loss:0.00002, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6339, Train Loss:0.00003, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6340, Train Loss:0.00642, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6341, Train Loss:0.00008, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6342, Train Loss:0.07375, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6343, Train Loss:0.11717, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6344, Train Loss:0.38890, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6345, Train Loss:0.05783, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6346, Train Loss:0.14175, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6347, Train Loss:0.26649, Dev Loss:0.15950\n",
      "Epoch:[22/100], step:6348, Train Loss:0.01259, Dev Loss:0.15950\n",
      "Start Epoch: 23, Steps: 17\n",
      "Epoch:[23/100], step:6349, Train Loss:0.02899, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6350, Train Loss:0.35146, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6351, Train Loss:0.00521, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6352, Train Loss:0.07454, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6353, Train Loss:0.00444, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6354, Train Loss:0.20718, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6355, Train Loss:0.14793, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6356, Train Loss:0.03838, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6357, Train Loss:0.00138, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6358, Train Loss:0.00018, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6359, Train Loss:0.00160, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6360, Train Loss:0.23523, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6361, Train Loss:0.29315, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6362, Train Loss:0.06250, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6363, Train Loss:0.04419, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6364, Train Loss:0.00552, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6365, Train Loss:0.11938, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6366, Train Loss:0.06285, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6367, Train Loss:0.10320, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6368, Train Loss:0.04881, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6369, Train Loss:0.13225, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6370, Train Loss:0.00372, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6371, Train Loss:0.02327, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6372, Train Loss:0.39500, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6373, Train Loss:0.00075, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6374, Train Loss:0.07326, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6375, Train Loss:0.15926, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6376, Train Loss:0.00001, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6377, Train Loss:0.22202, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6378, Train Loss:0.00000, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6379, Train Loss:0.00756, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6380, Train Loss:0.04544, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6381, Train Loss:0.15651, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6382, Train Loss:0.19951, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6383, Train Loss:0.00012, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6384, Train Loss:0.00119, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6385, Train Loss:0.09271, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6386, Train Loss:0.00149, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6387, Train Loss:0.31599, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6388, Train Loss:0.01888, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6389, Train Loss:0.35847, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6390, Train Loss:0.38157, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6391, Train Loss:0.09679, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6392, Train Loss:0.00008, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6393, Train Loss:0.01793, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6394, Train Loss:0.00003, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6395, Train Loss:0.09448, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6396, Train Loss:0.00003, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6397, Train Loss:0.41411, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6398, Train Loss:0.18389, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6399, Train Loss:0.00107, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6400, Train Loss:0.00050, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6401, Train Loss:0.06393, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6402, Train Loss:0.21153, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6403, Train Loss:0.00868, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6404, Train Loss:0.23529, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6405, Train Loss:0.01539, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6406, Train Loss:0.00057, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6407, Train Loss:0.11224, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6408, Train Loss:0.00294, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6409, Train Loss:0.27105, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6410, Train Loss:0.00131, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6411, Train Loss:0.10909, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6412, Train Loss:0.32106, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6413, Train Loss:0.03153, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6414, Train Loss:0.05274, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6415, Train Loss:0.14855, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6416, Train Loss:0.21472, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6417, Train Loss:0.26841, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6418, Train Loss:0.09770, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6419, Train Loss:0.03265, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6420, Train Loss:0.00059, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6421, Train Loss:0.00034, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6422, Train Loss:0.16361, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6423, Train Loss:0.46408, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6424, Train Loss:0.07011, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6425, Train Loss:0.21699, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6426, Train Loss:0.15818, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6427, Train Loss:0.02065, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6428, Train Loss:0.40496, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6429, Train Loss:0.00545, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6430, Train Loss:0.12199, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6431, Train Loss:0.03498, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6432, Train Loss:0.00088, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6433, Train Loss:0.32112, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6434, Train Loss:1.00734, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6435, Train Loss:0.00173, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6436, Train Loss:0.01675, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6437, Train Loss:0.13940, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6438, Train Loss:0.06389, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6439, Train Loss:0.00085, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6440, Train Loss:0.00203, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6441, Train Loss:0.03779, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6442, Train Loss:0.00266, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6443, Train Loss:0.05296, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6444, Train Loss:0.02215, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6445, Train Loss:0.14935, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6446, Train Loss:0.19124, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6447, Train Loss:0.23317, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6448, Train Loss:0.19760, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6449, Train Loss:0.13940, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6450, Train Loss:0.82572, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6451, Train Loss:0.00831, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6452, Train Loss:0.00271, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6453, Train Loss:0.18312, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6454, Train Loss:0.11842, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6455, Train Loss:0.03141, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6456, Train Loss:0.31749, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6457, Train Loss:0.00160, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6458, Train Loss:0.13422, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6459, Train Loss:0.27069, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6460, Train Loss:0.01586, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6461, Train Loss:0.58213, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6462, Train Loss:0.00239, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6463, Train Loss:0.01659, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6464, Train Loss:0.31373, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6465, Train Loss:0.06431, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6466, Train Loss:0.04531, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6467, Train Loss:0.00397, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6468, Train Loss:0.01287, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6469, Train Loss:0.02032, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6470, Train Loss:0.06809, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6471, Train Loss:0.16560, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6472, Train Loss:0.29490, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6473, Train Loss:0.09926, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6474, Train Loss:0.00042, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6475, Train Loss:0.11440, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6476, Train Loss:0.34222, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6477, Train Loss:0.05346, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6478, Train Loss:0.00523, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6479, Train Loss:0.01224, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6480, Train Loss:0.49054, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6481, Train Loss:0.05439, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6482, Train Loss:0.51763, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6483, Train Loss:0.07512, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6484, Train Loss:0.17746, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6485, Train Loss:0.02694, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6486, Train Loss:0.20349, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6487, Train Loss:0.00232, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6488, Train Loss:0.04463, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6489, Train Loss:0.00005, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6490, Train Loss:0.07595, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6491, Train Loss:0.00009, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6492, Train Loss:0.06859, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6493, Train Loss:0.06754, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6494, Train Loss:0.07204, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6495, Train Loss:0.05991, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6496, Train Loss:0.60081, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6497, Train Loss:0.08125, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6498, Train Loss:0.55229, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6499, Train Loss:0.13613, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6500, Train Loss:0.34859, Dev Loss:0.15950\n",
      "Epoch:[23/100], step:6501, Train Loss:0.11773, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6502, Train Loss:0.00299, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6503, Train Loss:0.16922, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6504, Train Loss:0.00659, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6505, Train Loss:0.27360, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6506, Train Loss:0.00000, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6507, Train Loss:0.00004, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6508, Train Loss:0.03355, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6509, Train Loss:0.00201, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6510, Train Loss:0.04870, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6511, Train Loss:0.44383, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6512, Train Loss:0.00024, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6513, Train Loss:0.00014, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6514, Train Loss:0.03289, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6515, Train Loss:0.00028, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6516, Train Loss:0.00011, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6517, Train Loss:0.38976, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6518, Train Loss:0.04981, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6519, Train Loss:0.00543, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6520, Train Loss:0.00028, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6521, Train Loss:0.00062, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6522, Train Loss:0.17414, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6523, Train Loss:0.04418, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6524, Train Loss:0.01461, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6525, Train Loss:0.00146, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6526, Train Loss:0.15557, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6527, Train Loss:0.19139, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6528, Train Loss:0.00090, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6529, Train Loss:0.80245, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6530, Train Loss:0.14043, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6531, Train Loss:0.03624, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6532, Train Loss:1.06923, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6533, Train Loss:0.35401, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6534, Train Loss:0.08521, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6535, Train Loss:0.17642, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6536, Train Loss:0.10132, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6537, Train Loss:0.64562, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6538, Train Loss:0.17383, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6539, Train Loss:0.09339, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6540, Train Loss:0.31749, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6541, Train Loss:0.00157, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6542, Train Loss:0.11500, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6543, Train Loss:0.17918, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6544, Train Loss:0.00298, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6545, Train Loss:0.00007, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6546, Train Loss:0.27898, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6547, Train Loss:0.04934, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6548, Train Loss:0.11094, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6549, Train Loss:0.14165, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6550, Train Loss:0.34753, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6551, Train Loss:0.01332, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6552, Train Loss:0.00002, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6553, Train Loss:0.06138, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6554, Train Loss:0.00033, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6555, Train Loss:0.00030, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6556, Train Loss:0.01606, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6557, Train Loss:0.39291, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6558, Train Loss:0.04776, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6559, Train Loss:0.24513, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6560, Train Loss:0.00172, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6561, Train Loss:0.05270, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6562, Train Loss:0.01165, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6563, Train Loss:0.08537, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6564, Train Loss:0.18223, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6565, Train Loss:0.04427, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6566, Train Loss:0.20807, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6567, Train Loss:0.51688, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6568, Train Loss:0.06776, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6569, Train Loss:0.10936, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6570, Train Loss:0.00238, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6571, Train Loss:0.04067, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6572, Train Loss:0.00245, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6573, Train Loss:1.10807, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6574, Train Loss:0.00012, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6575, Train Loss:0.13024, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6576, Train Loss:0.00068, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6577, Train Loss:0.99312, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6578, Train Loss:0.02250, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6579, Train Loss:0.14663, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6580, Train Loss:0.03969, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6581, Train Loss:0.54295, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6582, Train Loss:0.13442, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6583, Train Loss:0.01626, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6584, Train Loss:0.13967, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6585, Train Loss:0.04819, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6586, Train Loss:0.13272, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6587, Train Loss:0.82872, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6588, Train Loss:0.37388, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6589, Train Loss:0.23178, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6590, Train Loss:0.13046, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6591, Train Loss:0.04608, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6592, Train Loss:0.00059, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6593, Train Loss:0.20425, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6594, Train Loss:0.20426, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6595, Train Loss:0.03399, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6596, Train Loss:0.16839, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6597, Train Loss:0.06312, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6598, Train Loss:0.02887, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6599, Train Loss:0.00134, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6600, Train Loss:0.33341, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6601, Train Loss:0.19398, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6602, Train Loss:0.05004, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6603, Train Loss:0.01211, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6604, Train Loss:0.00083, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6605, Train Loss:0.23823, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6606, Train Loss:0.00012, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6607, Train Loss:0.24145, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6608, Train Loss:0.01424, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6609, Train Loss:0.01251, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6610, Train Loss:0.09987, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6611, Train Loss:0.87440, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6612, Train Loss:0.16014, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6613, Train Loss:0.02437, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6614, Train Loss:0.02254, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6615, Train Loss:0.00012, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6616, Train Loss:0.29650, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6617, Train Loss:0.11386, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6618, Train Loss:0.05140, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6619, Train Loss:0.00429, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6620, Train Loss:0.08582, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6621, Train Loss:0.13167, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6622, Train Loss:0.28145, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6623, Train Loss:0.02965, Dev Loss:0.16086\n",
      "Epoch:[23/100], step:6624, Train Loss:0.30264, Dev Loss:0.16086\n",
      "Start Epoch: 24, Steps: 17\n",
      "Epoch:[24/100], step:6625, Train Loss:0.01023, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6626, Train Loss:0.00367, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6627, Train Loss:0.30738, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6628, Train Loss:0.13497, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6629, Train Loss:0.01927, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6630, Train Loss:0.07321, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6631, Train Loss:0.00021, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6632, Train Loss:0.07323, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6633, Train Loss:0.00029, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6634, Train Loss:0.72254, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6635, Train Loss:0.13186, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6636, Train Loss:0.04682, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6637, Train Loss:0.15098, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6638, Train Loss:0.21003, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6639, Train Loss:0.01638, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6640, Train Loss:0.03360, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6641, Train Loss:0.11990, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6642, Train Loss:0.07416, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6643, Train Loss:0.00602, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6644, Train Loss:0.13184, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6645, Train Loss:0.33711, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6646, Train Loss:0.65531, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6647, Train Loss:0.00207, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6648, Train Loss:0.13754, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6649, Train Loss:0.13922, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6650, Train Loss:0.00023, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6651, Train Loss:0.04293, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6652, Train Loss:0.34243, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6653, Train Loss:0.13850, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6654, Train Loss:0.00336, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6655, Train Loss:0.04162, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6656, Train Loss:0.26147, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6657, Train Loss:0.00239, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6658, Train Loss:0.00728, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6659, Train Loss:0.32316, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6660, Train Loss:0.00040, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6661, Train Loss:0.02863, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6662, Train Loss:0.02526, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6663, Train Loss:0.60804, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6664, Train Loss:0.24932, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6665, Train Loss:0.00468, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6666, Train Loss:0.00495, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6667, Train Loss:0.00010, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6668, Train Loss:0.07920, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6669, Train Loss:0.01981, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6670, Train Loss:0.03619, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6671, Train Loss:0.04591, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6672, Train Loss:0.23850, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6673, Train Loss:0.24589, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6674, Train Loss:0.02427, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6675, Train Loss:0.11837, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6676, Train Loss:0.14435, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6677, Train Loss:0.00940, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6678, Train Loss:0.27938, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6679, Train Loss:0.02640, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6680, Train Loss:0.24262, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6681, Train Loss:0.00537, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6682, Train Loss:0.22645, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6683, Train Loss:0.04162, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6684, Train Loss:0.02127, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6685, Train Loss:0.30117, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6686, Train Loss:0.33598, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6687, Train Loss:0.00001, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6688, Train Loss:0.54219, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6689, Train Loss:0.03920, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6690, Train Loss:0.06841, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6691, Train Loss:0.13497, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6692, Train Loss:0.07521, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6693, Train Loss:0.79848, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6694, Train Loss:0.24113, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6695, Train Loss:0.10661, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6696, Train Loss:0.08535, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6697, Train Loss:0.07880, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6698, Train Loss:0.04912, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6699, Train Loss:0.00535, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6700, Train Loss:0.37643, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6701, Train Loss:0.00862, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6702, Train Loss:0.00005, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6703, Train Loss:0.00322, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6704, Train Loss:0.15291, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6705, Train Loss:0.00003, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6706, Train Loss:0.00016, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6707, Train Loss:0.26032, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6708, Train Loss:0.02944, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6709, Train Loss:0.20151, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6710, Train Loss:0.00813, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6711, Train Loss:0.01607, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6712, Train Loss:0.00219, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6713, Train Loss:0.00563, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6714, Train Loss:0.18162, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6715, Train Loss:0.00098, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6716, Train Loss:0.00007, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6717, Train Loss:0.01636, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6718, Train Loss:0.00383, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6719, Train Loss:0.00040, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6720, Train Loss:0.14186, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6721, Train Loss:0.00015, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6722, Train Loss:0.70851, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6723, Train Loss:0.00135, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6724, Train Loss:0.00008, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6725, Train Loss:0.03090, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6726, Train Loss:0.07990, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6727, Train Loss:0.02718, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6728, Train Loss:0.08864, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6729, Train Loss:1.02291, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6730, Train Loss:0.32557, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6731, Train Loss:0.04150, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6732, Train Loss:0.06748, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6733, Train Loss:0.00055, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6734, Train Loss:0.00999, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6735, Train Loss:0.22593, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6736, Train Loss:0.00006, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6737, Train Loss:0.08030, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6738, Train Loss:0.00038, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6739, Train Loss:0.14880, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6740, Train Loss:0.26714, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6741, Train Loss:0.02047, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6742, Train Loss:1.28812, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6743, Train Loss:0.05864, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6744, Train Loss:0.15210, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6745, Train Loss:0.74002, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6746, Train Loss:0.00001, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6747, Train Loss:0.00716, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6748, Train Loss:0.19474, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6749, Train Loss:0.21307, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6750, Train Loss:0.00254, Dev Loss:0.16086\n",
      "Epoch:[24/100], step:6751, Train Loss:0.11975, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6752, Train Loss:0.00612, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6753, Train Loss:0.00052, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6754, Train Loss:0.00479, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6755, Train Loss:0.00172, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6756, Train Loss:0.00197, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6757, Train Loss:0.58744, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6758, Train Loss:0.01378, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6759, Train Loss:0.05248, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6760, Train Loss:0.12729, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6761, Train Loss:0.42470, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6762, Train Loss:0.00019, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6763, Train Loss:0.00666, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6764, Train Loss:0.07699, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6765, Train Loss:0.29775, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6766, Train Loss:0.00113, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6767, Train Loss:0.10229, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6768, Train Loss:0.00012, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6769, Train Loss:0.32855, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6770, Train Loss:0.10540, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6771, Train Loss:0.34716, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6772, Train Loss:0.22022, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6773, Train Loss:0.20070, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6774, Train Loss:0.04042, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6775, Train Loss:0.00137, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6776, Train Loss:0.03469, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6777, Train Loss:0.03566, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6778, Train Loss:0.04815, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6779, Train Loss:0.03733, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6780, Train Loss:0.16520, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6781, Train Loss:0.01404, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6782, Train Loss:0.00036, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6783, Train Loss:0.18651, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6784, Train Loss:0.00850, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6785, Train Loss:0.00521, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6786, Train Loss:0.41013, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6787, Train Loss:0.01345, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6788, Train Loss:0.07784, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6789, Train Loss:0.21361, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6790, Train Loss:0.00136, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6791, Train Loss:0.00019, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6792, Train Loss:0.01422, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6793, Train Loss:0.72257, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6794, Train Loss:0.00988, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6795, Train Loss:0.04649, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6796, Train Loss:0.00118, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6797, Train Loss:0.21140, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6798, Train Loss:0.47304, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6799, Train Loss:0.00012, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6800, Train Loss:0.00103, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6801, Train Loss:0.02047, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6802, Train Loss:0.17552, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6803, Train Loss:0.02351, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6804, Train Loss:0.10014, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6805, Train Loss:0.10308, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6806, Train Loss:0.15357, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6807, Train Loss:0.02300, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6808, Train Loss:0.07540, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6809, Train Loss:0.04687, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6810, Train Loss:0.09716, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6811, Train Loss:0.01964, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6812, Train Loss:0.06430, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6813, Train Loss:0.00213, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6814, Train Loss:0.00117, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6815, Train Loss:0.00142, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6816, Train Loss:0.02391, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6817, Train Loss:0.01673, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6818, Train Loss:0.00118, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6819, Train Loss:0.14648, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6820, Train Loss:0.23816, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6821, Train Loss:0.35946, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6822, Train Loss:0.10511, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6823, Train Loss:0.33544, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6824, Train Loss:0.01066, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6825, Train Loss:0.30873, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6826, Train Loss:0.10867, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6827, Train Loss:0.00718, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6828, Train Loss:0.04806, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6829, Train Loss:0.00569, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6830, Train Loss:0.12659, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6831, Train Loss:0.00141, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6832, Train Loss:0.47287, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6833, Train Loss:0.00042, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6834, Train Loss:0.00000, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6835, Train Loss:0.02739, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6836, Train Loss:0.05613, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6837, Train Loss:0.00076, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6838, Train Loss:0.00476, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6839, Train Loss:0.01328, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6840, Train Loss:0.00125, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6841, Train Loss:0.01442, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6842, Train Loss:0.00875, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6843, Train Loss:0.00035, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6844, Train Loss:0.01491, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6845, Train Loss:0.00352, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6846, Train Loss:0.22882, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6847, Train Loss:0.75719, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6848, Train Loss:0.00004, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6849, Train Loss:0.08561, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6850, Train Loss:0.60467, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6851, Train Loss:2.16573, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6852, Train Loss:0.03385, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6853, Train Loss:0.00212, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6854, Train Loss:0.01253, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6855, Train Loss:0.13814, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6856, Train Loss:0.58046, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6857, Train Loss:0.03401, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6858, Train Loss:0.14925, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6859, Train Loss:0.06895, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6860, Train Loss:0.09284, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6861, Train Loss:0.18307, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6862, Train Loss:0.00195, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6863, Train Loss:0.28404, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6864, Train Loss:0.14758, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6865, Train Loss:0.05405, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6866, Train Loss:0.09551, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6867, Train Loss:0.33127, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6868, Train Loss:0.56702, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6869, Train Loss:0.00092, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6870, Train Loss:0.79868, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6871, Train Loss:0.04455, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6872, Train Loss:0.55167, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6873, Train Loss:0.23800, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6874, Train Loss:0.11452, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6875, Train Loss:0.45236, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6876, Train Loss:0.03961, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6877, Train Loss:0.27064, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6878, Train Loss:0.29932, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6879, Train Loss:0.03151, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6880, Train Loss:0.21337, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6881, Train Loss:0.25629, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6882, Train Loss:0.08683, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6883, Train Loss:0.25419, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6884, Train Loss:0.37032, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6885, Train Loss:0.09308, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6886, Train Loss:0.27673, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6887, Train Loss:0.29956, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6888, Train Loss:0.32221, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6889, Train Loss:0.22681, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6890, Train Loss:0.03824, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6891, Train Loss:0.38111, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6892, Train Loss:0.09652, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6893, Train Loss:0.05708, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6894, Train Loss:0.00792, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6895, Train Loss:0.11631, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6896, Train Loss:0.00288, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6897, Train Loss:0.16098, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6898, Train Loss:0.00896, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6899, Train Loss:0.00145, Dev Loss:0.23387\n",
      "Epoch:[24/100], step:6900, Train Loss:0.01613, Dev Loss:0.23387\n",
      "Start Epoch: 25, Steps: 17\n",
      "Epoch:[25/100], step:6901, Train Loss:0.01917, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6902, Train Loss:0.77630, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6903, Train Loss:0.00086, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6904, Train Loss:0.04482, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6905, Train Loss:0.00016, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6906, Train Loss:0.01392, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6907, Train Loss:0.15298, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6908, Train Loss:0.16862, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6909, Train Loss:0.00006, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6910, Train Loss:0.00351, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6911, Train Loss:0.16397, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6912, Train Loss:0.22451, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6913, Train Loss:0.07690, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6914, Train Loss:0.18610, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6915, Train Loss:0.00015, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6916, Train Loss:0.00001, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6917, Train Loss:0.80269, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6918, Train Loss:0.01029, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6919, Train Loss:0.00149, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6920, Train Loss:0.12135, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6921, Train Loss:0.78834, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6922, Train Loss:0.12268, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6923, Train Loss:0.04704, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6924, Train Loss:0.16606, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6925, Train Loss:0.00003, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6926, Train Loss:0.05173, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6927, Train Loss:0.24071, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6928, Train Loss:0.07005, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6929, Train Loss:0.00137, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6930, Train Loss:0.00080, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6931, Train Loss:0.00115, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6932, Train Loss:0.00679, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6933, Train Loss:0.04813, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6934, Train Loss:0.61146, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6935, Train Loss:0.34908, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6936, Train Loss:0.00047, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6937, Train Loss:0.69913, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6938, Train Loss:0.00052, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6939, Train Loss:0.15519, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6940, Train Loss:0.05405, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6941, Train Loss:0.04331, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6942, Train Loss:0.14552, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6943, Train Loss:0.22713, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6944, Train Loss:0.06956, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6945, Train Loss:0.24806, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6946, Train Loss:0.65385, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6947, Train Loss:0.07786, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6948, Train Loss:0.22578, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6949, Train Loss:0.23523, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6950, Train Loss:0.00166, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6951, Train Loss:0.03900, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6952, Train Loss:0.02010, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6953, Train Loss:0.16473, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6954, Train Loss:0.06957, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6955, Train Loss:0.22438, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6956, Train Loss:0.15212, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6957, Train Loss:0.03018, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6958, Train Loss:0.20049, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6959, Train Loss:0.15996, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6960, Train Loss:0.00218, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6961, Train Loss:0.00028, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6962, Train Loss:0.02750, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6963, Train Loss:0.08652, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6964, Train Loss:0.00557, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6965, Train Loss:0.01260, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6966, Train Loss:0.00462, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6967, Train Loss:0.00685, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6968, Train Loss:0.16349, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6969, Train Loss:0.05383, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6970, Train Loss:0.26251, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6971, Train Loss:0.00031, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6972, Train Loss:0.00053, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6973, Train Loss:0.00390, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6974, Train Loss:0.09971, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6975, Train Loss:0.09161, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6976, Train Loss:0.00096, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6977, Train Loss:0.07869, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6978, Train Loss:0.04720, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6979, Train Loss:0.00436, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6980, Train Loss:0.00254, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6981, Train Loss:0.00493, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6982, Train Loss:0.45743, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6983, Train Loss:0.00430, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6984, Train Loss:0.50633, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6985, Train Loss:0.01037, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6986, Train Loss:0.00011, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6987, Train Loss:0.03765, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6988, Train Loss:0.01666, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6989, Train Loss:0.30771, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6990, Train Loss:0.00033, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6991, Train Loss:0.00059, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6992, Train Loss:0.42652, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6993, Train Loss:0.33998, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6994, Train Loss:0.00205, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6995, Train Loss:0.09685, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6996, Train Loss:0.02453, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6997, Train Loss:0.00956, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6998, Train Loss:0.00073, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:6999, Train Loss:0.25758, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:7000, Train Loss:0.05115, Dev Loss:0.23387\n",
      "Epoch:[25/100], step:7001, Train Loss:0.18230, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7002, Train Loss:0.23158, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7003, Train Loss:0.03220, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7004, Train Loss:0.02169, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7005, Train Loss:0.00095, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7006, Train Loss:0.00011, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7007, Train Loss:0.24814, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7008, Train Loss:0.00131, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7009, Train Loss:0.03505, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7010, Train Loss:0.00461, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7011, Train Loss:0.02662, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7012, Train Loss:0.09938, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7013, Train Loss:0.29494, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7014, Train Loss:0.00491, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7015, Train Loss:0.07474, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7016, Train Loss:0.22965, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7017, Train Loss:0.00008, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7018, Train Loss:0.73520, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7019, Train Loss:0.02627, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7020, Train Loss:0.15501, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7021, Train Loss:0.10282, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7022, Train Loss:0.07423, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7023, Train Loss:0.05387, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7024, Train Loss:0.18437, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7025, Train Loss:0.02193, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7026, Train Loss:0.00812, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7027, Train Loss:0.00540, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7028, Train Loss:0.00662, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7029, Train Loss:0.05346, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7030, Train Loss:0.04455, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7031, Train Loss:0.00027, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7032, Train Loss:0.11872, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7033, Train Loss:0.00000, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7034, Train Loss:0.15061, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7035, Train Loss:0.00739, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7036, Train Loss:0.05266, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7037, Train Loss:0.00111, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7038, Train Loss:0.07511, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7039, Train Loss:0.00002, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7040, Train Loss:0.05504, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7041, Train Loss:0.00007, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7042, Train Loss:0.85610, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7043, Train Loss:0.01251, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7044, Train Loss:0.00062, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7045, Train Loss:0.00001, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7046, Train Loss:0.00511, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7047, Train Loss:0.31326, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7048, Train Loss:0.00747, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7049, Train Loss:0.03972, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7050, Train Loss:0.06538, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7051, Train Loss:0.00617, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7052, Train Loss:0.00002, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7053, Train Loss:0.10154, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7054, Train Loss:0.38630, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7055, Train Loss:1.57411, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7056, Train Loss:0.05460, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7057, Train Loss:0.63240, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7058, Train Loss:0.24050, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7059, Train Loss:0.10970, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7060, Train Loss:0.03189, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7061, Train Loss:0.00540, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7062, Train Loss:0.14756, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7063, Train Loss:0.18340, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7064, Train Loss:0.03148, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7065, Train Loss:0.57423, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7066, Train Loss:0.05885, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7067, Train Loss:0.24062, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7068, Train Loss:0.28153, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7069, Train Loss:0.07566, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7070, Train Loss:0.00600, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7071, Train Loss:0.02529, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7072, Train Loss:0.13162, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7073, Train Loss:0.04640, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7074, Train Loss:0.77583, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7075, Train Loss:0.00052, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7076, Train Loss:0.05190, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7077, Train Loss:0.42613, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7078, Train Loss:0.02562, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7079, Train Loss:0.21995, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7080, Train Loss:0.06760, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7081, Train Loss:0.03773, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7082, Train Loss:0.26778, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7083, Train Loss:0.00002, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7084, Train Loss:0.01336, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7085, Train Loss:0.11593, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7086, Train Loss:1.68095, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7087, Train Loss:0.01120, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7088, Train Loss:0.32018, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7089, Train Loss:0.10997, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7090, Train Loss:0.00266, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7091, Train Loss:0.18307, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7092, Train Loss:0.13976, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7093, Train Loss:0.07890, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7094, Train Loss:0.17100, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7095, Train Loss:0.30321, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7096, Train Loss:0.17076, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7097, Train Loss:0.21080, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7098, Train Loss:0.18367, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7099, Train Loss:0.63133, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7100, Train Loss:0.02844, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7101, Train Loss:0.23731, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7102, Train Loss:0.32296, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7103, Train Loss:0.41810, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7104, Train Loss:0.03893, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7105, Train Loss:0.01138, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7106, Train Loss:0.04984, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7107, Train Loss:0.01316, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7108, Train Loss:0.08504, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7109, Train Loss:0.23778, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7110, Train Loss:0.04419, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7111, Train Loss:0.03065, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7112, Train Loss:0.11075, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7113, Train Loss:0.12829, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7114, Train Loss:0.24796, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7115, Train Loss:0.17930, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7116, Train Loss:0.35970, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7117, Train Loss:0.33630, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7118, Train Loss:0.08949, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7119, Train Loss:0.00179, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7120, Train Loss:0.32004, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7121, Train Loss:0.02550, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7122, Train Loss:0.00010, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7123, Train Loss:0.40527, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7124, Train Loss:0.24795, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7125, Train Loss:0.15359, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7126, Train Loss:0.26288, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7127, Train Loss:0.22447, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7128, Train Loss:0.61563, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7129, Train Loss:0.31468, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7130, Train Loss:0.07294, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7131, Train Loss:0.18288, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7132, Train Loss:0.14967, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7133, Train Loss:0.28831, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7134, Train Loss:0.00576, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7135, Train Loss:0.21891, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7136, Train Loss:0.13820, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7137, Train Loss:0.00796, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7138, Train Loss:0.01436, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7139, Train Loss:0.00397, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7140, Train Loss:0.18095, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7141, Train Loss:0.51714, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7142, Train Loss:0.00476, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7143, Train Loss:0.00287, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7144, Train Loss:0.00005, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7145, Train Loss:0.19937, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7146, Train Loss:0.00888, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7147, Train Loss:0.15148, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7148, Train Loss:0.00224, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7149, Train Loss:0.01168, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7150, Train Loss:0.02111, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7151, Train Loss:0.73234, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7152, Train Loss:0.00013, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7153, Train Loss:0.19009, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7154, Train Loss:0.05326, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7155, Train Loss:0.16831, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7156, Train Loss:0.17132, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7157, Train Loss:0.31648, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7158, Train Loss:0.03622, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7159, Train Loss:0.08311, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7160, Train Loss:0.03998, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7161, Train Loss:0.14710, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7162, Train Loss:0.19427, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7163, Train Loss:0.03396, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7164, Train Loss:0.23768, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7165, Train Loss:0.00017, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7166, Train Loss:0.00000, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7167, Train Loss:0.00035, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7168, Train Loss:0.30090, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7169, Train Loss:0.12061, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7170, Train Loss:0.18460, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7171, Train Loss:0.03867, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7172, Train Loss:0.06562, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7173, Train Loss:0.04246, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7174, Train Loss:0.10063, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7175, Train Loss:0.07661, Dev Loss:0.13203\n",
      "Epoch:[25/100], step:7176, Train Loss:0.18876, Dev Loss:0.13203\n",
      "Start Epoch: 26, Steps: 17\n",
      "Epoch:[26/100], step:7177, Train Loss:0.07218, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7178, Train Loss:0.00687, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7179, Train Loss:0.02975, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7180, Train Loss:0.00214, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7181, Train Loss:0.16860, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7182, Train Loss:0.15389, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7183, Train Loss:0.00474, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7184, Train Loss:0.33832, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7185, Train Loss:0.00019, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7186, Train Loss:0.11701, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7187, Train Loss:0.18467, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7188, Train Loss:0.00002, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7189, Train Loss:0.00638, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7190, Train Loss:0.05680, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7191, Train Loss:0.08776, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7192, Train Loss:0.17680, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7193, Train Loss:0.00001, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7194, Train Loss:0.14925, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7195, Train Loss:0.18596, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7196, Train Loss:0.03238, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7197, Train Loss:0.22227, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7198, Train Loss:0.11888, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7199, Train Loss:0.09374, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7200, Train Loss:0.09654, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7201, Train Loss:0.23951, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7202, Train Loss:0.00030, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7203, Train Loss:0.13169, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7204, Train Loss:0.25844, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7205, Train Loss:0.27356, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7206, Train Loss:0.08452, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7207, Train Loss:0.11580, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7208, Train Loss:0.26164, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7209, Train Loss:0.01270, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7210, Train Loss:0.00023, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7211, Train Loss:0.13558, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7212, Train Loss:0.22544, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7213, Train Loss:0.06344, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7214, Train Loss:0.10048, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7215, Train Loss:0.09657, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7216, Train Loss:0.00576, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7217, Train Loss:0.21548, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7218, Train Loss:0.00011, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7219, Train Loss:0.02601, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7220, Train Loss:0.03278, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7221, Train Loss:0.00007, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7222, Train Loss:0.00003, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7223, Train Loss:0.11998, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7224, Train Loss:0.30886, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7225, Train Loss:0.44343, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7226, Train Loss:0.00041, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7227, Train Loss:0.01883, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7228, Train Loss:0.13101, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7229, Train Loss:0.23112, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7230, Train Loss:0.17146, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7231, Train Loss:0.00438, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7232, Train Loss:0.14336, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7233, Train Loss:0.07878, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7234, Train Loss:0.13747, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7235, Train Loss:0.01585, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7236, Train Loss:0.00014, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7237, Train Loss:0.00019, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7238, Train Loss:0.11528, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7239, Train Loss:0.01041, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7240, Train Loss:0.00233, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7241, Train Loss:0.21729, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7242, Train Loss:0.00006, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7243, Train Loss:0.01997, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7244, Train Loss:0.02015, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7245, Train Loss:0.12798, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7246, Train Loss:0.07609, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7247, Train Loss:0.00358, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7248, Train Loss:0.01257, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7249, Train Loss:0.09627, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7250, Train Loss:0.10726, Dev Loss:0.13203\n",
      "Epoch:[26/100], step:7251, Train Loss:0.00494, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7252, Train Loss:0.00002, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7253, Train Loss:0.01125, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7254, Train Loss:0.03226, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7255, Train Loss:0.13165, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7256, Train Loss:0.00005, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7257, Train Loss:0.00037, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7258, Train Loss:0.03487, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7259, Train Loss:0.07119, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7260, Train Loss:0.00124, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7261, Train Loss:0.09326, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7262, Train Loss:0.00004, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7263, Train Loss:0.05276, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7264, Train Loss:0.07464, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7265, Train Loss:0.19056, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7266, Train Loss:0.52641, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7267, Train Loss:0.19135, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7268, Train Loss:0.01120, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7269, Train Loss:0.20139, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7270, Train Loss:0.10046, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7271, Train Loss:0.01547, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7272, Train Loss:0.02832, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7273, Train Loss:0.09021, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7274, Train Loss:0.00547, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7275, Train Loss:0.11526, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7276, Train Loss:0.20380, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7277, Train Loss:0.05185, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7278, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7279, Train Loss:0.11153, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7280, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7281, Train Loss:0.02431, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7282, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7283, Train Loss:0.07594, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7284, Train Loss:0.03289, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7285, Train Loss:0.09991, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7286, Train Loss:0.10569, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7287, Train Loss:0.04614, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7288, Train Loss:0.00036, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7289, Train Loss:0.00378, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7290, Train Loss:0.08838, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7291, Train Loss:0.00127, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7292, Train Loss:0.00006, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7293, Train Loss:0.00067, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7294, Train Loss:0.00012, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7295, Train Loss:0.00093, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7296, Train Loss:0.12367, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7297, Train Loss:0.09003, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7298, Train Loss:0.30973, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7299, Train Loss:0.00005, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7300, Train Loss:0.00341, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7301, Train Loss:0.12130, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7302, Train Loss:0.00032, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7303, Train Loss:0.00008, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7304, Train Loss:0.02401, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7305, Train Loss:0.08908, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7306, Train Loss:0.02522, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7307, Train Loss:0.23692, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7308, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7309, Train Loss:0.00243, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7310, Train Loss:0.12005, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7311, Train Loss:0.08667, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7312, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7313, Train Loss:0.32457, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7314, Train Loss:0.00178, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7315, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7316, Train Loss:0.01004, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7317, Train Loss:0.00024, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7318, Train Loss:0.00005, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7319, Train Loss:0.13743, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7320, Train Loss:0.09680, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7321, Train Loss:0.01607, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7322, Train Loss:0.31329, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7323, Train Loss:0.04280, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7324, Train Loss:0.09531, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7325, Train Loss:0.01904, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7326, Train Loss:0.11914, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7327, Train Loss:0.20843, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7328, Train Loss:0.00704, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7329, Train Loss:0.37531, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7330, Train Loss:0.04808, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7331, Train Loss:0.13123, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7332, Train Loss:0.11062, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7333, Train Loss:0.13992, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7334, Train Loss:0.00012, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7335, Train Loss:0.05150, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7336, Train Loss:0.00027, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7337, Train Loss:0.12225, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7338, Train Loss:0.04126, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7339, Train Loss:0.00057, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7340, Train Loss:0.03008, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7341, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7342, Train Loss:1.11565, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7343, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7344, Train Loss:0.06205, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7345, Train Loss:0.00006, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7346, Train Loss:1.02742, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7347, Train Loss:0.00231, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7348, Train Loss:0.07015, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7349, Train Loss:0.00023, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7350, Train Loss:0.62448, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7351, Train Loss:0.09992, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7352, Train Loss:0.35430, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7353, Train Loss:0.26096, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7354, Train Loss:0.26148, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7355, Train Loss:0.33932, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7356, Train Loss:0.66316, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7357, Train Loss:0.84806, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7358, Train Loss:0.28601, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7359, Train Loss:0.87166, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7360, Train Loss:0.01555, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7361, Train Loss:0.16448, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7362, Train Loss:0.28216, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7363, Train Loss:1.51861, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7364, Train Loss:0.03017, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7365, Train Loss:0.41895, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7366, Train Loss:0.15002, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7367, Train Loss:0.06876, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7368, Train Loss:0.06179, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7369, Train Loss:0.07076, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7370, Train Loss:0.00559, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7371, Train Loss:0.14772, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7372, Train Loss:0.02162, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7373, Train Loss:0.00226, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7374, Train Loss:0.01969, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7375, Train Loss:0.11142, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7376, Train Loss:0.31503, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7377, Train Loss:0.12467, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7378, Train Loss:0.12388, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7379, Train Loss:0.83433, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7380, Train Loss:0.04494, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7381, Train Loss:0.07546, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7382, Train Loss:0.17498, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7383, Train Loss:0.03987, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7384, Train Loss:0.11719, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7385, Train Loss:0.64987, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7386, Train Loss:0.04003, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7387, Train Loss:0.00672, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7388, Train Loss:0.17368, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7389, Train Loss:0.03261, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7390, Train Loss:0.13177, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7391, Train Loss:0.08948, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7392, Train Loss:0.00007, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7393, Train Loss:0.00014, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7394, Train Loss:0.22858, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7395, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7396, Train Loss:0.00016, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7397, Train Loss:0.00227, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7398, Train Loss:0.09688, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7399, Train Loss:0.03517, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7400, Train Loss:0.04727, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7401, Train Loss:0.38588, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7402, Train Loss:0.01161, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7403, Train Loss:0.72121, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7404, Train Loss:0.05201, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7405, Train Loss:0.00060, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7406, Train Loss:0.00010, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7407, Train Loss:0.67538, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7408, Train Loss:0.00638, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7409, Train Loss:0.04254, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7410, Train Loss:0.19794, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7411, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7412, Train Loss:0.10032, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7413, Train Loss:0.00010, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7414, Train Loss:0.23305, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7415, Train Loss:0.00010, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7416, Train Loss:0.21382, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7417, Train Loss:0.00046, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7418, Train Loss:0.07805, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7419, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7420, Train Loss:0.05597, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7421, Train Loss:0.40907, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7422, Train Loss:0.00644, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7423, Train Loss:0.08222, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7424, Train Loss:0.07346, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7425, Train Loss:0.39602, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7426, Train Loss:0.00022, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7427, Train Loss:0.31598, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7428, Train Loss:0.02520, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7429, Train Loss:0.00247, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7430, Train Loss:0.03289, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7431, Train Loss:0.09048, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7432, Train Loss:0.07033, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7433, Train Loss:0.00010, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7434, Train Loss:0.07417, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7435, Train Loss:0.00012, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7436, Train Loss:0.00382, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7437, Train Loss:0.00006, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7438, Train Loss:0.02224, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7439, Train Loss:0.01576, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7440, Train Loss:0.02800, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7441, Train Loss:0.00249, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7442, Train Loss:0.16971, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7443, Train Loss:0.00325, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7444, Train Loss:0.15321, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7445, Train Loss:0.21835, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7446, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7447, Train Loss:0.44217, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7448, Train Loss:0.00152, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7449, Train Loss:0.01143, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7450, Train Loss:0.23522, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7451, Train Loss:0.07757, Dev Loss:0.11436\n",
      "Epoch:[26/100], step:7452, Train Loss:0.38652, Dev Loss:0.11436\n",
      "Start Epoch: 27, Steps: 17\n",
      "Epoch:[27/100], step:7453, Train Loss:0.43618, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7454, Train Loss:0.01750, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7455, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7456, Train Loss:0.26550, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7457, Train Loss:0.00001, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7458, Train Loss:0.00010, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7459, Train Loss:0.00888, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7460, Train Loss:0.04610, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7461, Train Loss:0.04112, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7462, Train Loss:0.00006, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7463, Train Loss:0.00000, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7464, Train Loss:0.00195, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7465, Train Loss:0.03090, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7466, Train Loss:0.08775, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7467, Train Loss:0.44750, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7468, Train Loss:0.46989, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7469, Train Loss:1.12274, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7470, Train Loss:0.00570, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7471, Train Loss:0.00165, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7472, Train Loss:0.03663, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7473, Train Loss:0.05766, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7474, Train Loss:0.17865, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7475, Train Loss:0.08304, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7476, Train Loss:0.00696, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7477, Train Loss:0.04531, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7478, Train Loss:0.13234, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7479, Train Loss:0.00521, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7480, Train Loss:0.03072, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7481, Train Loss:0.01591, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7482, Train Loss:0.00107, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7483, Train Loss:0.08605, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7484, Train Loss:0.21651, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7485, Train Loss:0.31370, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7486, Train Loss:0.23258, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7487, Train Loss:0.22736, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7488, Train Loss:0.62794, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7489, Train Loss:0.06991, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7490, Train Loss:0.20312, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7491, Train Loss:0.02385, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7492, Train Loss:0.00051, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7493, Train Loss:0.05525, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7494, Train Loss:0.00004, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7495, Train Loss:0.01805, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7496, Train Loss:0.14635, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7497, Train Loss:0.14316, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7498, Train Loss:0.00703, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7499, Train Loss:0.08224, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7500, Train Loss:0.30080, Dev Loss:0.11436\n",
      "Epoch:[27/100], step:7501, Train Loss:0.40461, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7502, Train Loss:0.75821, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7503, Train Loss:0.07138, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7504, Train Loss:0.08027, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7505, Train Loss:0.59707, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7506, Train Loss:0.00372, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7507, Train Loss:0.00170, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7508, Train Loss:0.24008, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7509, Train Loss:0.35074, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7510, Train Loss:0.00036, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7511, Train Loss:0.00098, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7512, Train Loss:0.00107, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7513, Train Loss:0.00353, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7514, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7515, Train Loss:0.00144, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7516, Train Loss:0.00861, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7517, Train Loss:0.11933, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7518, Train Loss:0.03309, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7519, Train Loss:0.13665, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7520, Train Loss:0.01586, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7521, Train Loss:0.07165, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7522, Train Loss:0.13225, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7523, Train Loss:0.12962, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7524, Train Loss:0.10597, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7525, Train Loss:0.00623, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7526, Train Loss:0.18077, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7527, Train Loss:0.00284, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7528, Train Loss:0.25358, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7529, Train Loss:0.11985, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7530, Train Loss:0.07395, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7531, Train Loss:0.00271, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7532, Train Loss:0.04186, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7533, Train Loss:0.00001, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7534, Train Loss:0.00003, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7535, Train Loss:0.13717, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7536, Train Loss:0.01534, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7537, Train Loss:0.00227, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7538, Train Loss:0.23289, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7539, Train Loss:0.00010, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7540, Train Loss:0.00009, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7541, Train Loss:0.04764, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7542, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7543, Train Loss:0.04697, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7544, Train Loss:0.02405, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7545, Train Loss:0.00004, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7546, Train Loss:0.08684, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7547, Train Loss:0.08206, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7548, Train Loss:0.00002, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7549, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7550, Train Loss:0.00007, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7551, Train Loss:0.11096, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7552, Train Loss:0.03173, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7553, Train Loss:0.00005, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7554, Train Loss:0.00193, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7555, Train Loss:0.11024, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7556, Train Loss:0.27676, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7557, Train Loss:0.14338, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7558, Train Loss:0.00017, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7559, Train Loss:0.67189, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7560, Train Loss:0.19644, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7561, Train Loss:0.17974, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7562, Train Loss:0.00002, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7563, Train Loss:0.25720, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7564, Train Loss:0.48622, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7565, Train Loss:0.57050, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7566, Train Loss:1.38388, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7567, Train Loss:0.21058, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7568, Train Loss:0.51323, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7569, Train Loss:0.02280, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7570, Train Loss:0.82246, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7571, Train Loss:0.37057, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7572, Train Loss:0.28655, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7573, Train Loss:0.24604, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7574, Train Loss:0.43723, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7575, Train Loss:0.02548, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7576, Train Loss:0.08297, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7577, Train Loss:0.04412, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7578, Train Loss:0.02373, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7579, Train Loss:0.00186, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7580, Train Loss:0.05026, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7581, Train Loss:0.18550, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7582, Train Loss:0.06115, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7583, Train Loss:0.24975, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7584, Train Loss:0.21824, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7585, Train Loss:0.02835, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7586, Train Loss:0.02541, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7587, Train Loss:0.01839, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7588, Train Loss:0.09149, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7589, Train Loss:0.02819, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7590, Train Loss:0.00330, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7591, Train Loss:0.01469, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7592, Train Loss:0.43827, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7593, Train Loss:0.16968, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7594, Train Loss:0.02104, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7595, Train Loss:0.12038, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7596, Train Loss:0.00549, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7597, Train Loss:0.00529, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7598, Train Loss:0.13367, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7599, Train Loss:0.00522, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7600, Train Loss:0.00606, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7601, Train Loss:0.06936, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7602, Train Loss:0.14150, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7603, Train Loss:0.01234, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7604, Train Loss:0.25716, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7605, Train Loss:0.02958, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7606, Train Loss:0.01814, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7607, Train Loss:0.00308, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7608, Train Loss:0.15276, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7609, Train Loss:0.00390, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7610, Train Loss:0.00525, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7611, Train Loss:0.00312, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7612, Train Loss:0.00131, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7613, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7614, Train Loss:0.04891, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7615, Train Loss:0.00399, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7616, Train Loss:0.02468, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7617, Train Loss:0.01285, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7618, Train Loss:0.05362, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7619, Train Loss:0.32254, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7620, Train Loss:0.03784, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7621, Train Loss:0.07156, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7622, Train Loss:0.00003, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7623, Train Loss:0.00015, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7624, Train Loss:0.09503, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7625, Train Loss:0.00170, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7626, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7627, Train Loss:0.14182, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7628, Train Loss:0.00000, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7629, Train Loss:0.00002, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7630, Train Loss:0.00020, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7631, Train Loss:0.00277, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7632, Train Loss:0.20143, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7633, Train Loss:0.00464, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7634, Train Loss:0.00031, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7635, Train Loss:0.01873, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7636, Train Loss:0.04115, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7637, Train Loss:0.18639, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7638, Train Loss:0.00264, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7639, Train Loss:0.00001, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7640, Train Loss:0.00005, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7641, Train Loss:0.09623, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7642, Train Loss:0.00020, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7643, Train Loss:0.17495, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7644, Train Loss:0.17314, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7645, Train Loss:0.18175, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7646, Train Loss:0.41855, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7647, Train Loss:1.09170, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7648, Train Loss:0.00003, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7649, Train Loss:0.28137, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7650, Train Loss:0.09421, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7651, Train Loss:0.16780, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7652, Train Loss:0.00006, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7653, Train Loss:0.03391, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7654, Train Loss:0.00059, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7655, Train Loss:0.10220, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7656, Train Loss:0.00016, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7657, Train Loss:0.00176, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7658, Train Loss:0.00574, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7659, Train Loss:0.09859, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7660, Train Loss:0.02360, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7661, Train Loss:0.00092, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7662, Train Loss:0.04840, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7663, Train Loss:0.07921, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7664, Train Loss:0.12714, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7665, Train Loss:0.10702, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7666, Train Loss:0.06275, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7667, Train Loss:0.06853, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7668, Train Loss:0.55416, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7669, Train Loss:0.05330, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7670, Train Loss:0.11076, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7671, Train Loss:1.09031, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7672, Train Loss:0.27857, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7673, Train Loss:0.12218, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7674, Train Loss:0.00420, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7675, Train Loss:0.15174, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7676, Train Loss:0.12722, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7677, Train Loss:0.03053, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7678, Train Loss:0.04507, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7679, Train Loss:0.11110, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7680, Train Loss:0.04142, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7681, Train Loss:0.02910, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7682, Train Loss:0.24298, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7683, Train Loss:0.08815, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7684, Train Loss:0.21603, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7685, Train Loss:0.00667, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7686, Train Loss:0.05261, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7687, Train Loss:0.09534, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7688, Train Loss:0.22043, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7689, Train Loss:0.00027, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7690, Train Loss:0.05324, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7691, Train Loss:0.07676, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7692, Train Loss:0.59453, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7693, Train Loss:0.21237, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7694, Train Loss:0.05941, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7695, Train Loss:0.10018, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7696, Train Loss:0.00268, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7697, Train Loss:0.08053, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7698, Train Loss:0.00304, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7699, Train Loss:0.00061, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7700, Train Loss:0.00881, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7701, Train Loss:0.00787, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7702, Train Loss:0.00755, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7703, Train Loss:0.10296, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7704, Train Loss:0.00213, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7705, Train Loss:0.11866, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7706, Train Loss:0.00273, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7707, Train Loss:0.03117, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7708, Train Loss:0.06847, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7709, Train Loss:0.09082, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7710, Train Loss:0.00033, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7711, Train Loss:0.31788, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7712, Train Loss:0.01966, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7713, Train Loss:0.23102, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7714, Train Loss:0.08920, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7715, Train Loss:0.08591, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7716, Train Loss:0.00131, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7717, Train Loss:0.00091, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7718, Train Loss:0.00235, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7719, Train Loss:0.02573, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7720, Train Loss:0.34472, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7721, Train Loss:0.10784, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7722, Train Loss:0.05888, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7723, Train Loss:0.01215, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7724, Train Loss:0.03599, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7725, Train Loss:0.06934, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7726, Train Loss:0.00282, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7727, Train Loss:0.43562, Dev Loss:0.14199\n",
      "Epoch:[27/100], step:7728, Train Loss:0.00036, Dev Loss:0.14199\n",
      "Start Epoch: 28, Steps: 17\n",
      "Epoch:[28/100], step:7729, Train Loss:0.08984, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7730, Train Loss:0.01764, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7731, Train Loss:0.44446, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7732, Train Loss:0.01326, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7733, Train Loss:0.00003, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7734, Train Loss:0.08004, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7735, Train Loss:0.00054, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7736, Train Loss:0.03252, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7737, Train Loss:0.05183, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7738, Train Loss:0.00001, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7739, Train Loss:0.11932, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7740, Train Loss:0.00399, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7741, Train Loss:0.00606, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7742, Train Loss:0.10613, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7743, Train Loss:0.00034, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7744, Train Loss:0.00293, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7745, Train Loss:0.09735, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7746, Train Loss:0.91416, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7747, Train Loss:0.20401, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7748, Train Loss:0.00734, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7749, Train Loss:0.00015, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7750, Train Loss:0.00235, Dev Loss:0.14199\n",
      "Epoch:[28/100], step:7751, Train Loss:0.00006, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7752, Train Loss:0.37273, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7753, Train Loss:0.17415, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7754, Train Loss:0.10425, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7755, Train Loss:0.22606, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7756, Train Loss:0.27244, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7757, Train Loss:0.32711, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7758, Train Loss:0.00006, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7759, Train Loss:0.08021, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7760, Train Loss:0.07152, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7761, Train Loss:0.20837, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7762, Train Loss:0.07006, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7763, Train Loss:0.01838, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7764, Train Loss:0.16951, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7765, Train Loss:0.06593, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7766, Train Loss:0.15643, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7767, Train Loss:0.00041, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7768, Train Loss:0.00016, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7769, Train Loss:0.05130, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7770, Train Loss:0.52103, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7771, Train Loss:0.08867, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7772, Train Loss:0.28413, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7773, Train Loss:0.00002, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7774, Train Loss:0.90659, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7775, Train Loss:0.00474, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7776, Train Loss:0.01389, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7777, Train Loss:0.00690, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7778, Train Loss:0.08679, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7779, Train Loss:0.07008, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7780, Train Loss:0.17037, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7781, Train Loss:0.07297, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7782, Train Loss:0.23851, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7783, Train Loss:0.55395, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7784, Train Loss:0.18282, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7785, Train Loss:0.02841, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7786, Train Loss:0.06024, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7787, Train Loss:0.05892, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7788, Train Loss:0.05048, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7789, Train Loss:0.01089, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7790, Train Loss:0.42517, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7791, Train Loss:0.33860, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7792, Train Loss:0.00001, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7793, Train Loss:0.00074, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7794, Train Loss:0.06706, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7795, Train Loss:0.02491, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7796, Train Loss:0.40068, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7797, Train Loss:0.05309, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7798, Train Loss:0.00450, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7799, Train Loss:0.26674, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7800, Train Loss:0.05204, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7801, Train Loss:0.09839, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7802, Train Loss:0.05681, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7803, Train Loss:0.00379, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7804, Train Loss:0.00290, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7805, Train Loss:0.00442, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7806, Train Loss:0.01386, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7807, Train Loss:0.01028, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7808, Train Loss:0.14474, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7809, Train Loss:0.00041, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7810, Train Loss:0.00100, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7811, Train Loss:0.07641, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7812, Train Loss:0.08565, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7813, Train Loss:0.33233, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7814, Train Loss:0.00032, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7815, Train Loss:0.01978, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7816, Train Loss:0.08583, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7817, Train Loss:0.29878, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7818, Train Loss:0.18584, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7819, Train Loss:0.16550, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7820, Train Loss:0.00363, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7821, Train Loss:0.01380, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7822, Train Loss:0.00000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7823, Train Loss:0.12935, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7824, Train Loss:0.00598, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7825, Train Loss:0.00279, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7826, Train Loss:0.12283, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7827, Train Loss:0.00713, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7828, Train Loss:0.00246, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7829, Train Loss:0.01922, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7830, Train Loss:0.00187, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7831, Train Loss:0.00001, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7832, Train Loss:0.02455, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7833, Train Loss:0.00125, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7834, Train Loss:0.00033, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7835, Train Loss:0.00155, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7836, Train Loss:0.23528, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7837, Train Loss:0.14406, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7838, Train Loss:0.00069, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7839, Train Loss:0.10333, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7840, Train Loss:0.00105, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7841, Train Loss:0.14930, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7842, Train Loss:0.08291, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7843, Train Loss:0.00008, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7844, Train Loss:0.02290, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7845, Train Loss:0.53666, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7846, Train Loss:0.04516, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7847, Train Loss:0.00254, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7848, Train Loss:0.00002, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7849, Train Loss:0.00344, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7850, Train Loss:0.00934, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7851, Train Loss:0.28399, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7852, Train Loss:0.08014, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7853, Train Loss:0.00074, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7854, Train Loss:0.06947, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7855, Train Loss:0.13690, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7856, Train Loss:0.00774, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7857, Train Loss:0.05133, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7858, Train Loss:0.00065, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7859, Train Loss:0.09858, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7860, Train Loss:0.02581, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7861, Train Loss:0.30896, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7862, Train Loss:0.12256, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7863, Train Loss:0.12360, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7864, Train Loss:0.81609, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7865, Train Loss:0.00002, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7866, Train Loss:0.67501, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7867, Train Loss:0.01685, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7868, Train Loss:0.00080, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7869, Train Loss:0.13932, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7870, Train Loss:0.30413, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7871, Train Loss:0.30983, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7872, Train Loss:0.12799, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7873, Train Loss:0.35152, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7874, Train Loss:0.53923, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7875, Train Loss:0.09850, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7876, Train Loss:0.10918, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7877, Train Loss:0.71245, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7878, Train Loss:0.00284, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7879, Train Loss:0.42418, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7880, Train Loss:0.15532, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7881, Train Loss:0.06284, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7882, Train Loss:0.47000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7883, Train Loss:0.07974, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7884, Train Loss:0.78626, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7885, Train Loss:0.07965, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7886, Train Loss:0.04145, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7887, Train Loss:0.19924, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7888, Train Loss:0.21627, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7889, Train Loss:0.26872, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7890, Train Loss:0.00106, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7891, Train Loss:0.08182, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7892, Train Loss:0.04773, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7893, Train Loss:0.00185, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7894, Train Loss:0.48292, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7895, Train Loss:0.02946, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7896, Train Loss:0.05295, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7897, Train Loss:0.06124, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7898, Train Loss:0.00263, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7899, Train Loss:0.00417, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7900, Train Loss:0.04910, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7901, Train Loss:0.00907, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7902, Train Loss:0.00889, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7903, Train Loss:0.46382, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7904, Train Loss:0.00357, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7905, Train Loss:0.01455, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7906, Train Loss:0.03512, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7907, Train Loss:0.00263, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7908, Train Loss:0.00528, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7909, Train Loss:0.05434, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7910, Train Loss:0.00542, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7911, Train Loss:0.08915, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7912, Train Loss:0.00688, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7913, Train Loss:0.26826, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7914, Train Loss:0.03782, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7915, Train Loss:0.06898, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7916, Train Loss:0.00381, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7917, Train Loss:0.01648, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7918, Train Loss:0.00016, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7919, Train Loss:0.16085, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7920, Train Loss:0.04852, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7921, Train Loss:0.00494, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7922, Train Loss:0.05332, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7923, Train Loss:0.01461, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7924, Train Loss:0.09026, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7925, Train Loss:0.00015, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7926, Train Loss:0.10064, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7927, Train Loss:0.00209, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7928, Train Loss:0.15355, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7929, Train Loss:0.00001, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7930, Train Loss:0.20540, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7931, Train Loss:0.00037, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7932, Train Loss:0.05786, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7933, Train Loss:0.00034, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7934, Train Loss:0.04394, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7935, Train Loss:0.00031, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7936, Train Loss:0.00309, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7937, Train Loss:0.00122, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7938, Train Loss:0.00094, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7939, Train Loss:0.24350, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7940, Train Loss:0.11453, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7941, Train Loss:0.05666, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7942, Train Loss:0.04109, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7943, Train Loss:0.13253, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7944, Train Loss:0.11227, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7945, Train Loss:0.19341, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7946, Train Loss:0.07092, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7947, Train Loss:0.00257, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7948, Train Loss:0.12172, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7949, Train Loss:0.03139, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7950, Train Loss:0.12017, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7951, Train Loss:0.00157, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7952, Train Loss:0.18420, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7953, Train Loss:0.00098, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7954, Train Loss:0.08325, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7955, Train Loss:0.00834, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7956, Train Loss:0.01991, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7957, Train Loss:0.00034, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7958, Train Loss:0.02562, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7959, Train Loss:0.10866, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7960, Train Loss:0.11112, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7961, Train Loss:0.03315, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7962, Train Loss:0.00520, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7963, Train Loss:0.00027, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7964, Train Loss:0.16397, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7965, Train Loss:0.07417, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7966, Train Loss:0.00238, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7967, Train Loss:0.00027, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7968, Train Loss:0.00009, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7969, Train Loss:0.33207, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7970, Train Loss:0.00000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7971, Train Loss:0.25805, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7972, Train Loss:0.00008, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7973, Train Loss:0.02033, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7974, Train Loss:0.00184, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7975, Train Loss:0.00462, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7976, Train Loss:0.00003, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7977, Train Loss:0.00000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7978, Train Loss:0.08033, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7979, Train Loss:0.07239, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7980, Train Loss:0.03788, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7981, Train Loss:0.11980, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7982, Train Loss:0.01560, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7983, Train Loss:0.15086, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7984, Train Loss:0.03282, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7985, Train Loss:0.00004, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7986, Train Loss:0.10926, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7987, Train Loss:0.00000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7988, Train Loss:0.00083, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7989, Train Loss:0.10766, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7990, Train Loss:0.07044, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7991, Train Loss:0.20007, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7992, Train Loss:0.03019, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7993, Train Loss:0.02572, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7994, Train Loss:0.00479, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7995, Train Loss:0.03320, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7996, Train Loss:0.00012, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7997, Train Loss:0.00003, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7998, Train Loss:0.05923, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:7999, Train Loss:0.00000, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:8000, Train Loss:0.00001, Dev Loss:0.14103\n",
      "Epoch:[28/100], step:8001, Train Loss:0.03902, Dev Loss:0.14913\n",
      "Epoch:[28/100], step:8002, Train Loss:0.04793, Dev Loss:0.14913\n",
      "Epoch:[28/100], step:8003, Train Loss:0.40096, Dev Loss:0.14913\n",
      "Epoch:[28/100], step:8004, Train Loss:0.32671, Dev Loss:0.14913\n",
      "Start Epoch: 29, Steps: 17\n",
      "Epoch:[29/100], step:8005, Train Loss:0.00070, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8006, Train Loss:0.00066, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8007, Train Loss:0.00000, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8008, Train Loss:0.13814, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8009, Train Loss:0.00470, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8010, Train Loss:0.09612, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8011, Train Loss:0.17016, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8012, Train Loss:0.01075, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8013, Train Loss:0.32427, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8014, Train Loss:0.13464, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8015, Train Loss:0.19565, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8016, Train Loss:0.05399, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8017, Train Loss:0.20216, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8018, Train Loss:0.08847, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8019, Train Loss:0.00268, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8020, Train Loss:0.05972, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8021, Train Loss:0.11186, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8022, Train Loss:0.03228, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8023, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8024, Train Loss:0.00633, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8025, Train Loss:0.02756, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8026, Train Loss:0.27996, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8027, Train Loss:0.01003, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8028, Train Loss:0.00228, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8029, Train Loss:0.15462, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8030, Train Loss:0.17411, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8031, Train Loss:0.00003, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8032, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8033, Train Loss:0.13461, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8034, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8035, Train Loss:0.03947, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8036, Train Loss:0.00009, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8037, Train Loss:0.00047, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8038, Train Loss:0.06654, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8039, Train Loss:0.02922, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8040, Train Loss:0.03218, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8041, Train Loss:0.03263, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8042, Train Loss:0.00447, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8043, Train Loss:0.47564, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8044, Train Loss:0.00292, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8045, Train Loss:0.00019, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8046, Train Loss:0.04999, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8047, Train Loss:0.00468, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8048, Train Loss:0.00238, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8049, Train Loss:0.00019, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8050, Train Loss:0.00003, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8051, Train Loss:0.06380, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8052, Train Loss:0.01171, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8053, Train Loss:0.00373, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8054, Train Loss:0.00434, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8055, Train Loss:0.17063, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8056, Train Loss:0.01467, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8057, Train Loss:0.05238, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8058, Train Loss:0.00071, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8059, Train Loss:0.14885, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8060, Train Loss:0.00011, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8061, Train Loss:0.00128, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8062, Train Loss:0.02447, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8063, Train Loss:0.00382, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8064, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8065, Train Loss:0.00103, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8066, Train Loss:0.56882, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8067, Train Loss:0.02555, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8068, Train Loss:0.05776, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8069, Train Loss:0.00175, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8070, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8071, Train Loss:0.00001, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8072, Train Loss:0.00384, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8073, Train Loss:0.00216, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8074, Train Loss:0.00212, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8075, Train Loss:0.24375, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8076, Train Loss:0.00113, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8077, Train Loss:0.09658, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8078, Train Loss:0.08078, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8079, Train Loss:0.02092, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8080, Train Loss:0.00065, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8081, Train Loss:0.08577, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8082, Train Loss:0.12523, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8083, Train Loss:0.26991, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8084, Train Loss:0.13895, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8085, Train Loss:0.02315, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8086, Train Loss:0.00017, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8087, Train Loss:0.05952, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8088, Train Loss:0.00029, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8089, Train Loss:0.02084, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8090, Train Loss:0.00171, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8091, Train Loss:0.32668, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8092, Train Loss:0.10378, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8093, Train Loss:0.00229, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8094, Train Loss:0.00031, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8095, Train Loss:0.16743, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8096, Train Loss:0.22681, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8097, Train Loss:0.00473, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8098, Train Loss:0.00138, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8099, Train Loss:0.00506, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8100, Train Loss:0.00000, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8101, Train Loss:0.13078, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8102, Train Loss:0.03884, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8103, Train Loss:0.00321, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8104, Train Loss:0.00010, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8105, Train Loss:0.00476, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8106, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8107, Train Loss:0.00003, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8108, Train Loss:0.15438, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8109, Train Loss:0.03721, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8110, Train Loss:0.05515, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8111, Train Loss:0.00004, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8112, Train Loss:0.00001, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8113, Train Loss:0.45726, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8114, Train Loss:0.14321, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8115, Train Loss:0.00000, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8116, Train Loss:0.11866, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8117, Train Loss:0.11266, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8118, Train Loss:0.00127, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8119, Train Loss:0.06256, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8120, Train Loss:0.00255, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8121, Train Loss:0.13858, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8122, Train Loss:0.50714, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8123, Train Loss:0.00115, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8124, Train Loss:0.19843, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8125, Train Loss:0.41498, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8126, Train Loss:0.35789, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8127, Train Loss:0.93225, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8128, Train Loss:0.01356, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8129, Train Loss:0.40639, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8130, Train Loss:0.43510, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8131, Train Loss:0.05725, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8132, Train Loss:0.37682, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8133, Train Loss:0.31412, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8134, Train Loss:0.31752, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8135, Train Loss:0.08484, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8136, Train Loss:0.40816, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8137, Train Loss:0.04525, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8138, Train Loss:0.10059, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8139, Train Loss:0.00502, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8140, Train Loss:0.03971, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8141, Train Loss:0.16731, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8142, Train Loss:0.01183, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8143, Train Loss:0.17009, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8144, Train Loss:0.04329, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8145, Train Loss:0.15125, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8146, Train Loss:0.12321, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8147, Train Loss:0.01672, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8148, Train Loss:0.03264, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8149, Train Loss:0.03275, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8150, Train Loss:0.40989, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8151, Train Loss:0.04804, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8152, Train Loss:0.10103, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8153, Train Loss:0.18707, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8154, Train Loss:0.51589, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8155, Train Loss:0.57628, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8156, Train Loss:0.16927, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8157, Train Loss:0.00004, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8158, Train Loss:1.63506, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8159, Train Loss:0.03984, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8160, Train Loss:0.01392, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8161, Train Loss:0.05977, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8162, Train Loss:0.37527, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8163, Train Loss:0.57855, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8164, Train Loss:1.86297, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8165, Train Loss:0.00006, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8166, Train Loss:0.11744, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8167, Train Loss:0.15867, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8168, Train Loss:0.10584, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8169, Train Loss:0.00000, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8170, Train Loss:0.92012, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8171, Train Loss:0.54817, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8172, Train Loss:0.00109, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8173, Train Loss:0.61962, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8174, Train Loss:0.23182, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8175, Train Loss:0.17625, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8176, Train Loss:0.00019, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8177, Train Loss:0.27840, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8178, Train Loss:0.12290, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8179, Train Loss:0.06088, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8180, Train Loss:0.23470, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8181, Train Loss:0.11128, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8182, Train Loss:0.08916, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8183, Train Loss:0.68192, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8184, Train Loss:0.00838, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8185, Train Loss:0.86706, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8186, Train Loss:0.02608, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8187, Train Loss:0.02189, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8188, Train Loss:0.23232, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8189, Train Loss:0.47237, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8190, Train Loss:0.18447, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8191, Train Loss:0.10900, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8192, Train Loss:0.34199, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8193, Train Loss:0.11288, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8194, Train Loss:0.00059, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8195, Train Loss:0.02460, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8196, Train Loss:0.00764, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8197, Train Loss:0.00018, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8198, Train Loss:0.20535, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8199, Train Loss:0.13504, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8200, Train Loss:0.18249, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8201, Train Loss:0.01562, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8202, Train Loss:0.10752, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8203, Train Loss:0.00001, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8204, Train Loss:0.00002, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8205, Train Loss:0.67016, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8206, Train Loss:2.02412, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8207, Train Loss:0.23264, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8208, Train Loss:0.00001, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8209, Train Loss:0.07896, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8210, Train Loss:0.13330, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8211, Train Loss:0.02385, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8212, Train Loss:0.03035, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8213, Train Loss:0.01656, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8214, Train Loss:0.28957, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8215, Train Loss:0.24273, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8216, Train Loss:0.21875, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8217, Train Loss:0.01350, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8218, Train Loss:0.00435, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8219, Train Loss:0.10484, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8220, Train Loss:0.13607, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8221, Train Loss:0.42216, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8222, Train Loss:0.07383, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8223, Train Loss:0.25226, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8224, Train Loss:0.24161, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8225, Train Loss:0.13785, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8226, Train Loss:0.00284, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8227, Train Loss:0.00111, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8228, Train Loss:0.26258, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8229, Train Loss:0.71723, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8230, Train Loss:0.01175, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8231, Train Loss:0.40663, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8232, Train Loss:1.55415, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8233, Train Loss:0.14361, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8234, Train Loss:0.13346, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8235, Train Loss:0.32914, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8236, Train Loss:0.12644, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8237, Train Loss:0.24696, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8238, Train Loss:0.66113, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8239, Train Loss:0.11076, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8240, Train Loss:0.15875, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8241, Train Loss:0.05965, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8242, Train Loss:0.00029, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8243, Train Loss:0.00187, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8244, Train Loss:0.17180, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8245, Train Loss:0.01683, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8246, Train Loss:0.23633, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8247, Train Loss:0.01846, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8248, Train Loss:0.22353, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8249, Train Loss:0.27128, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8250, Train Loss:0.14868, Dev Loss:0.14913\n",
      "Epoch:[29/100], step:8251, Train Loss:0.00038, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8252, Train Loss:0.09464, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8253, Train Loss:0.02340, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8254, Train Loss:0.00007, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8255, Train Loss:0.01191, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8256, Train Loss:0.20114, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8257, Train Loss:0.00873, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8258, Train Loss:0.74467, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8259, Train Loss:0.15561, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8260, Train Loss:0.00105, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8261, Train Loss:0.09101, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8262, Train Loss:0.00002, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8263, Train Loss:0.23357, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8264, Train Loss:0.13159, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8265, Train Loss:0.33465, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8266, Train Loss:0.00047, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8267, Train Loss:0.00023, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8268, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8269, Train Loss:0.17939, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8270, Train Loss:0.43172, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8271, Train Loss:0.83748, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8272, Train Loss:0.54693, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8273, Train Loss:0.00074, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8274, Train Loss:0.13749, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8275, Train Loss:0.10986, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8276, Train Loss:0.39756, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8277, Train Loss:0.03581, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8278, Train Loss:0.00634, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8279, Train Loss:0.01093, Dev Loss:0.12932\n",
      "Epoch:[29/100], step:8280, Train Loss:0.25984, Dev Loss:0.12932\n",
      "Start Epoch: 30, Steps: 17\n",
      "Epoch:[30/100], step:8281, Train Loss:0.00002, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8282, Train Loss:0.03263, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8283, Train Loss:0.16629, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8284, Train Loss:0.09123, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8285, Train Loss:0.00018, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8286, Train Loss:0.00460, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8287, Train Loss:0.04728, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8288, Train Loss:0.10935, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8289, Train Loss:0.41482, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8290, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8291, Train Loss:0.14407, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8292, Train Loss:0.74152, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8293, Train Loss:0.09265, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8294, Train Loss:0.11219, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8295, Train Loss:0.13011, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8296, Train Loss:0.00585, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8297, Train Loss:0.05003, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8298, Train Loss:0.17117, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8299, Train Loss:0.09932, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8300, Train Loss:0.06010, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8301, Train Loss:0.08388, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8302, Train Loss:0.00417, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8303, Train Loss:0.23661, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8304, Train Loss:0.20289, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8305, Train Loss:0.00284, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8306, Train Loss:0.71902, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8307, Train Loss:0.62728, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8308, Train Loss:0.01680, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8309, Train Loss:0.00015, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8310, Train Loss:0.03270, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8311, Train Loss:0.02420, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8312, Train Loss:0.10781, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8313, Train Loss:0.09780, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8314, Train Loss:0.11867, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8315, Train Loss:0.22430, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8316, Train Loss:0.23506, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8317, Train Loss:0.01702, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8318, Train Loss:0.25989, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8319, Train Loss:0.16411, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8320, Train Loss:0.00081, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8321, Train Loss:0.00040, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8322, Train Loss:0.02538, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8323, Train Loss:0.00867, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8324, Train Loss:0.47452, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8325, Train Loss:0.00044, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8326, Train Loss:0.00001, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8327, Train Loss:0.00156, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8328, Train Loss:0.00287, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8329, Train Loss:0.01000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8330, Train Loss:0.00175, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8331, Train Loss:0.17189, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8332, Train Loss:0.12661, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8333, Train Loss:0.00882, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8334, Train Loss:0.00909, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8335, Train Loss:0.90865, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8336, Train Loss:0.00001, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8337, Train Loss:0.00402, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8338, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8339, Train Loss:0.02245, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8340, Train Loss:0.09331, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8341, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8342, Train Loss:0.03000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8343, Train Loss:0.06117, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8344, Train Loss:0.89520, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8345, Train Loss:0.22459, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8346, Train Loss:0.01591, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8347, Train Loss:0.09247, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8348, Train Loss:0.13095, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8349, Train Loss:0.17603, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8350, Train Loss:0.00034, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8351, Train Loss:0.18412, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8352, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8353, Train Loss:0.39841, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8354, Train Loss:0.08646, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8355, Train Loss:0.29133, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8356, Train Loss:0.00411, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8357, Train Loss:0.00032, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8358, Train Loss:0.18220, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8359, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8360, Train Loss:0.00087, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8361, Train Loss:0.00021, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8362, Train Loss:0.13005, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8363, Train Loss:0.00367, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8364, Train Loss:0.02193, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8365, Train Loss:0.19958, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8366, Train Loss:0.06602, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8367, Train Loss:0.94948, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8368, Train Loss:0.07893, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8369, Train Loss:0.00888, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8370, Train Loss:0.27086, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8371, Train Loss:0.00001, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8372, Train Loss:0.01347, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8373, Train Loss:0.28904, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8374, Train Loss:0.00277, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8375, Train Loss:0.01993, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8376, Train Loss:0.00161, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8377, Train Loss:0.00001, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8378, Train Loss:0.53657, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8379, Train Loss:0.05102, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8380, Train Loss:0.04008, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8381, Train Loss:0.04708, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8382, Train Loss:0.11032, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8383, Train Loss:0.00007, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8384, Train Loss:0.04495, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8385, Train Loss:0.51587, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8386, Train Loss:0.00030, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8387, Train Loss:1.22021, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8388, Train Loss:0.00814, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8389, Train Loss:0.02211, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8390, Train Loss:0.00022, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8391, Train Loss:0.00003, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8392, Train Loss:0.01337, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8393, Train Loss:0.02065, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8394, Train Loss:0.13055, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8395, Train Loss:0.00299, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8396, Train Loss:0.00237, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8397, Train Loss:0.03215, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8398, Train Loss:0.00446, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8399, Train Loss:0.03203, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8400, Train Loss:0.02113, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8401, Train Loss:0.00005, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8402, Train Loss:0.00445, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8403, Train Loss:0.00101, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8404, Train Loss:0.03785, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8405, Train Loss:0.47080, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8406, Train Loss:0.10720, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8407, Train Loss:0.06367, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8408, Train Loss:0.25440, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8409, Train Loss:0.15149, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8410, Train Loss:0.24146, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8411, Train Loss:0.35182, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8412, Train Loss:0.34821, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8413, Train Loss:0.13302, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8414, Train Loss:0.28258, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8415, Train Loss:0.09252, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8416, Train Loss:0.10304, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8417, Train Loss:0.01467, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8418, Train Loss:0.35331, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8419, Train Loss:0.16340, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8420, Train Loss:0.04220, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8421, Train Loss:0.07573, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8422, Train Loss:0.47957, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8423, Train Loss:0.24195, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8424, Train Loss:0.00759, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8425, Train Loss:0.57289, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8426, Train Loss:0.06217, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8427, Train Loss:0.43420, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8428, Train Loss:0.21008, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8429, Train Loss:0.08366, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8430, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8431, Train Loss:0.00098, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8432, Train Loss:0.43194, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8433, Train Loss:0.20867, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8434, Train Loss:0.09141, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8435, Train Loss:0.00641, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8436, Train Loss:0.16264, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8437, Train Loss:0.15010, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8438, Train Loss:0.15268, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8439, Train Loss:0.47663, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8440, Train Loss:0.37454, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8441, Train Loss:0.11848, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8442, Train Loss:0.19611, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8443, Train Loss:0.00007, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8444, Train Loss:0.21756, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8445, Train Loss:0.03384, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8446, Train Loss:0.02707, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8447, Train Loss:0.54280, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8448, Train Loss:0.20823, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8449, Train Loss:0.49616, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8450, Train Loss:0.32316, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8451, Train Loss:0.00016, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8452, Train Loss:0.12297, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8453, Train Loss:0.02057, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8454, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8455, Train Loss:0.10665, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8456, Train Loss:0.12581, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8457, Train Loss:0.02540, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8458, Train Loss:0.02707, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8459, Train Loss:0.00069, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8460, Train Loss:0.51031, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8461, Train Loss:0.01351, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8462, Train Loss:0.29476, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8463, Train Loss:0.46813, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8464, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8465, Train Loss:0.38273, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8466, Train Loss:0.01912, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8467, Train Loss:0.36725, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8468, Train Loss:0.00397, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8469, Train Loss:0.00000, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8470, Train Loss:0.18601, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8471, Train Loss:0.63946, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8472, Train Loss:0.02794, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8473, Train Loss:0.00123, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8474, Train Loss:0.00020, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8475, Train Loss:0.10459, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8476, Train Loss:0.17314, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8477, Train Loss:0.27839, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8478, Train Loss:0.04736, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8479, Train Loss:0.00220, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8480, Train Loss:0.15875, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8481, Train Loss:0.00209, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8482, Train Loss:0.71497, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8483, Train Loss:1.06307, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8484, Train Loss:0.03725, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8485, Train Loss:0.92543, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8486, Train Loss:0.05367, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8487, Train Loss:0.14738, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8488, Train Loss:0.24121, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8489, Train Loss:0.20197, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8490, Train Loss:0.01110, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8491, Train Loss:0.40570, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8492, Train Loss:0.01592, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8493, Train Loss:0.00011, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8494, Train Loss:0.18961, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8495, Train Loss:0.25105, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8496, Train Loss:0.23355, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8497, Train Loss:0.90238, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8498, Train Loss:0.07501, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8499, Train Loss:0.01557, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8500, Train Loss:0.00992, Dev Loss:0.12932\n",
      "Epoch:[30/100], step:8501, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8502, Train Loss:0.36545, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8503, Train Loss:0.26988, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8504, Train Loss:0.10103, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8505, Train Loss:0.00107, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8506, Train Loss:0.03963, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8507, Train Loss:0.00376, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8508, Train Loss:0.32366, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8509, Train Loss:0.28513, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8510, Train Loss:0.08781, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8511, Train Loss:0.32689, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8512, Train Loss:0.22537, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8513, Train Loss:0.12972, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8514, Train Loss:0.05379, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8515, Train Loss:0.06893, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8516, Train Loss:0.16569, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8517, Train Loss:0.08891, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8518, Train Loss:0.03647, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8519, Train Loss:0.02721, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8520, Train Loss:0.11685, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8521, Train Loss:0.03986, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8522, Train Loss:0.01016, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8523, Train Loss:0.05137, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8524, Train Loss:0.00018, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8525, Train Loss:0.00143, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8526, Train Loss:0.69498, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8527, Train Loss:0.32737, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8528, Train Loss:0.05117, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8529, Train Loss:0.14847, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8530, Train Loss:0.18001, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8531, Train Loss:0.08791, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8532, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8533, Train Loss:0.00133, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8534, Train Loss:0.24157, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8535, Train Loss:0.03934, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8536, Train Loss:0.24160, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8537, Train Loss:0.15171, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8538, Train Loss:0.12394, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8539, Train Loss:0.65266, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8540, Train Loss:0.16516, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8541, Train Loss:0.41679, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8542, Train Loss:0.00003, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8543, Train Loss:0.18814, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8544, Train Loss:0.00040, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8545, Train Loss:0.02509, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8546, Train Loss:0.10559, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8547, Train Loss:0.46317, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8548, Train Loss:0.14842, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8549, Train Loss:0.06616, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8550, Train Loss:0.29576, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8551, Train Loss:0.05494, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8552, Train Loss:0.08924, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8553, Train Loss:0.12983, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8554, Train Loss:0.06449, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8555, Train Loss:0.12339, Dev Loss:0.34953\n",
      "Epoch:[30/100], step:8556, Train Loss:0.44333, Dev Loss:0.34953\n",
      "Start Epoch: 31, Steps: 17\n",
      "Epoch:[31/100], step:8557, Train Loss:0.12931, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8558, Train Loss:0.23668, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8559, Train Loss:0.00609, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8560, Train Loss:0.00394, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8561, Train Loss:0.09845, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8562, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8563, Train Loss:0.15813, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8564, Train Loss:0.03791, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8565, Train Loss:0.00830, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8566, Train Loss:0.10760, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8567, Train Loss:0.00025, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8568, Train Loss:0.00005, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8569, Train Loss:0.00013, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8570, Train Loss:0.37687, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8571, Train Loss:0.00001, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8572, Train Loss:0.28545, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8573, Train Loss:0.03465, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8574, Train Loss:0.00107, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8575, Train Loss:0.00373, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8576, Train Loss:0.00211, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8577, Train Loss:0.06872, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8578, Train Loss:0.01327, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8579, Train Loss:0.07619, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8580, Train Loss:0.03824, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8581, Train Loss:0.44893, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8582, Train Loss:0.00023, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8583, Train Loss:0.00518, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8584, Train Loss:0.15172, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8585, Train Loss:0.23417, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8586, Train Loss:0.00036, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8587, Train Loss:0.19446, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8588, Train Loss:0.24962, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8589, Train Loss:0.00964, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8590, Train Loss:0.00031, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8591, Train Loss:0.04132, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8592, Train Loss:0.03043, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8593, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8594, Train Loss:0.00225, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8595, Train Loss:0.00110, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8596, Train Loss:0.31964, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8597, Train Loss:0.00343, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8598, Train Loss:0.17123, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8599, Train Loss:0.02860, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8600, Train Loss:0.09739, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8601, Train Loss:0.01080, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8602, Train Loss:0.17017, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8603, Train Loss:0.00004, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8604, Train Loss:0.10665, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8605, Train Loss:0.03633, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8606, Train Loss:0.23379, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8607, Train Loss:0.05180, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8608, Train Loss:0.21419, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8609, Train Loss:0.05007, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8610, Train Loss:0.02715, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8611, Train Loss:0.11801, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8612, Train Loss:0.13264, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8613, Train Loss:0.25705, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8614, Train Loss:0.00610, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8615, Train Loss:0.00095, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8616, Train Loss:0.00284, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8617, Train Loss:0.18243, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8618, Train Loss:0.19075, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8619, Train Loss:0.17082, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8620, Train Loss:0.11711, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8621, Train Loss:0.00001, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8622, Train Loss:0.88543, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8623, Train Loss:0.00221, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8624, Train Loss:0.00040, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8625, Train Loss:0.00003, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8626, Train Loss:1.40599, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8627, Train Loss:0.05676, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8628, Train Loss:0.03911, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8629, Train Loss:0.12490, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8630, Train Loss:0.52733, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8631, Train Loss:0.02647, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8632, Train Loss:0.68638, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8633, Train Loss:0.00014, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8634, Train Loss:0.00107, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8635, Train Loss:0.10343, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8636, Train Loss:0.00006, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8637, Train Loss:0.61338, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8638, Train Loss:0.14338, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8639, Train Loss:0.16756, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8640, Train Loss:0.01607, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8641, Train Loss:0.17339, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8642, Train Loss:0.00790, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8643, Train Loss:0.00616, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8644, Train Loss:0.02834, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8645, Train Loss:0.00009, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8646, Train Loss:0.10085, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8647, Train Loss:0.26345, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8648, Train Loss:0.01882, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8649, Train Loss:0.26633, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8650, Train Loss:0.00345, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8651, Train Loss:0.21031, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8652, Train Loss:0.00083, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8653, Train Loss:0.41116, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8654, Train Loss:0.00075, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8655, Train Loss:0.00614, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8656, Train Loss:0.40046, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8657, Train Loss:0.00006, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8658, Train Loss:0.12313, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8659, Train Loss:0.03706, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8660, Train Loss:0.00135, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8661, Train Loss:0.19802, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8662, Train Loss:0.01992, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8663, Train Loss:0.00497, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8664, Train Loss:0.14978, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8665, Train Loss:0.36235, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8666, Train Loss:0.00629, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8667, Train Loss:0.11455, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8668, Train Loss:0.00416, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8669, Train Loss:0.00155, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8670, Train Loss:0.10613, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8671, Train Loss:0.20428, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8672, Train Loss:0.01538, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8673, Train Loss:0.04056, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8674, Train Loss:0.60294, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8675, Train Loss:1.00096, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8676, Train Loss:0.01371, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8677, Train Loss:0.07648, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8678, Train Loss:0.05639, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8679, Train Loss:0.08720, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8680, Train Loss:0.18653, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8681, Train Loss:0.00181, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8682, Train Loss:0.00418, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8683, Train Loss:0.15332, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8684, Train Loss:0.03272, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8685, Train Loss:0.03431, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8686, Train Loss:0.00008, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8687, Train Loss:0.17502, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8688, Train Loss:0.21517, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8689, Train Loss:0.00216, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8690, Train Loss:0.00237, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8691, Train Loss:0.00156, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8692, Train Loss:0.04056, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8693, Train Loss:0.06169, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8694, Train Loss:0.25118, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8695, Train Loss:0.00021, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8696, Train Loss:0.02342, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8697, Train Loss:0.10809, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8698, Train Loss:0.36690, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8699, Train Loss:0.88637, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8700, Train Loss:0.42617, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8701, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8702, Train Loss:0.01802, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8703, Train Loss:0.14519, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8704, Train Loss:0.22240, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8705, Train Loss:0.36279, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8706, Train Loss:0.02017, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8707, Train Loss:0.44191, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8708, Train Loss:0.05248, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8709, Train Loss:0.12850, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8710, Train Loss:0.00046, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8711, Train Loss:0.50298, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8712, Train Loss:0.00271, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8713, Train Loss:0.28592, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8714, Train Loss:0.09516, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8715, Train Loss:0.00097, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8716, Train Loss:0.26029, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8717, Train Loss:0.04303, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8718, Train Loss:0.12485, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8719, Train Loss:0.02170, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8720, Train Loss:0.02017, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8721, Train Loss:0.07353, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8722, Train Loss:0.11283, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8723, Train Loss:0.02078, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8724, Train Loss:0.00040, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8725, Train Loss:0.02305, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8726, Train Loss:0.02565, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8727, Train Loss:0.19054, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8728, Train Loss:0.00115, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8729, Train Loss:0.00230, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8730, Train Loss:0.00936, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8731, Train Loss:0.07574, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8732, Train Loss:0.10855, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8733, Train Loss:0.10484, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8734, Train Loss:0.00025, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8735, Train Loss:0.06357, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8736, Train Loss:0.00250, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8737, Train Loss:0.01894, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8738, Train Loss:0.19929, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8739, Train Loss:0.11850, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8740, Train Loss:0.47816, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8741, Train Loss:0.00000, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8742, Train Loss:0.10690, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8743, Train Loss:0.00007, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8744, Train Loss:0.00091, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8745, Train Loss:0.00029, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8746, Train Loss:0.20086, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8747, Train Loss:0.00042, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8748, Train Loss:0.12243, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8749, Train Loss:0.10838, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8750, Train Loss:0.00095, Dev Loss:0.34953\n",
      "Epoch:[31/100], step:8751, Train Loss:0.18496, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8752, Train Loss:0.08535, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8753, Train Loss:0.34506, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8754, Train Loss:0.19347, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8755, Train Loss:0.13829, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8756, Train Loss:0.00334, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8757, Train Loss:1.57096, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8758, Train Loss:0.00974, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8759, Train Loss:0.00072, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8760, Train Loss:0.00016, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8761, Train Loss:0.41700, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8762, Train Loss:0.12168, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8763, Train Loss:0.02375, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8764, Train Loss:0.21134, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8765, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8766, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8767, Train Loss:0.11698, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8768, Train Loss:0.01273, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8769, Train Loss:0.09694, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8770, Train Loss:0.13362, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8771, Train Loss:0.05540, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8772, Train Loss:0.31068, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8773, Train Loss:0.57408, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8774, Train Loss:0.21214, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8775, Train Loss:0.14831, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8776, Train Loss:0.77093, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8777, Train Loss:0.00299, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8778, Train Loss:0.31728, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8779, Train Loss:0.21124, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8780, Train Loss:0.00057, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8781, Train Loss:0.12690, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8782, Train Loss:0.10825, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8783, Train Loss:0.27814, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8784, Train Loss:0.19345, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8785, Train Loss:0.33486, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8786, Train Loss:0.87814, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8787, Train Loss:0.35658, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8788, Train Loss:0.09912, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8789, Train Loss:0.03846, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8790, Train Loss:0.03410, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8791, Train Loss:0.09593, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8792, Train Loss:0.22983, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8793, Train Loss:0.06158, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8794, Train Loss:0.09481, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8795, Train Loss:0.01737, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8796, Train Loss:0.53028, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8797, Train Loss:0.01378, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8798, Train Loss:0.10131, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8799, Train Loss:0.25627, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8800, Train Loss:0.02350, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8801, Train Loss:0.00142, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8802, Train Loss:0.23410, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8803, Train Loss:0.00012, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8804, Train Loss:0.35973, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8805, Train Loss:0.04078, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8806, Train Loss:0.15090, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8807, Train Loss:0.39493, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8808, Train Loss:0.06134, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8809, Train Loss:0.06882, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8810, Train Loss:0.14806, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8811, Train Loss:0.06679, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8812, Train Loss:0.04353, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8813, Train Loss:0.07344, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8814, Train Loss:0.01796, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8815, Train Loss:0.00043, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8816, Train Loss:0.44660, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8817, Train Loss:0.04028, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8818, Train Loss:0.06420, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8819, Train Loss:0.38241, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8820, Train Loss:0.00006, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8821, Train Loss:0.00282, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8822, Train Loss:0.27049, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8823, Train Loss:0.01787, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8824, Train Loss:0.01167, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8825, Train Loss:0.03875, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8826, Train Loss:0.20423, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8827, Train Loss:0.03881, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8828, Train Loss:0.13231, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8829, Train Loss:0.08482, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8830, Train Loss:0.08289, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8831, Train Loss:0.87609, Dev Loss:0.16388\n",
      "Epoch:[31/100], step:8832, Train Loss:0.28499, Dev Loss:0.16388\n",
      "Start Epoch: 32, Steps: 17\n",
      "Epoch:[32/100], step:8833, Train Loss:0.07868, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8834, Train Loss:0.06911, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8835, Train Loss:0.04157, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8836, Train Loss:0.00027, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8837, Train Loss:0.06178, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8838, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8839, Train Loss:0.80485, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8840, Train Loss:0.01915, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8841, Train Loss:0.00147, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8842, Train Loss:0.00251, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8843, Train Loss:0.02837, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8844, Train Loss:0.04574, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8845, Train Loss:0.00079, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8846, Train Loss:0.00554, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8847, Train Loss:0.27501, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8848, Train Loss:0.00469, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8849, Train Loss:0.00001, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8850, Train Loss:0.00024, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8851, Train Loss:0.00016, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8852, Train Loss:0.09993, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8853, Train Loss:0.12679, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8854, Train Loss:0.00565, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8855, Train Loss:0.10993, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8856, Train Loss:0.81916, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8857, Train Loss:0.09414, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8858, Train Loss:0.00599, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8859, Train Loss:0.00250, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8860, Train Loss:0.00271, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8861, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8862, Train Loss:0.19295, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8863, Train Loss:0.00679, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8864, Train Loss:0.29701, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8865, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8866, Train Loss:0.16000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8867, Train Loss:0.45397, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8868, Train Loss:0.01259, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8869, Train Loss:0.00163, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8870, Train Loss:0.16860, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8871, Train Loss:0.04158, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8872, Train Loss:1.19475, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8873, Train Loss:0.00002, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8874, Train Loss:0.16999, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8875, Train Loss:0.34212, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8876, Train Loss:0.01118, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8877, Train Loss:0.11007, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8878, Train Loss:0.00019, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8879, Train Loss:0.00018, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8880, Train Loss:0.00190, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8881, Train Loss:0.00540, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8882, Train Loss:0.00182, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8883, Train Loss:0.04209, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8884, Train Loss:0.00114, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8885, Train Loss:0.10859, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8886, Train Loss:0.00012, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8887, Train Loss:0.01606, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8888, Train Loss:0.02409, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8889, Train Loss:0.09102, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8890, Train Loss:0.00032, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8891, Train Loss:0.26603, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8892, Train Loss:0.00075, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8893, Train Loss:0.08053, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8894, Train Loss:0.00011, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8895, Train Loss:0.01046, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8896, Train Loss:0.00244, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8897, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8898, Train Loss:0.04236, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8899, Train Loss:0.12011, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8900, Train Loss:0.03436, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8901, Train Loss:0.05386, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8902, Train Loss:0.00001, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8903, Train Loss:0.21857, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8904, Train Loss:0.00020, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8905, Train Loss:0.00535, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8906, Train Loss:0.25259, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8907, Train Loss:0.00833, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8908, Train Loss:0.78163, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8909, Train Loss:0.20772, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8910, Train Loss:0.03554, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8911, Train Loss:0.00450, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8912, Train Loss:0.00024, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8913, Train Loss:0.05525, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8914, Train Loss:0.08732, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8915, Train Loss:0.00001, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8916, Train Loss:0.04839, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8917, Train Loss:0.00657, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8918, Train Loss:0.24878, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8919, Train Loss:0.04338, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8920, Train Loss:0.00009, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8921, Train Loss:0.13672, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8922, Train Loss:0.08587, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8923, Train Loss:0.02604, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8924, Train Loss:0.02189, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8925, Train Loss:0.03663, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8926, Train Loss:0.29006, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8927, Train Loss:0.29414, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8928, Train Loss:0.02581, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8929, Train Loss:0.10730, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8930, Train Loss:0.00006, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8931, Train Loss:0.04425, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8932, Train Loss:0.00043, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8933, Train Loss:0.03549, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8934, Train Loss:0.00979, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8935, Train Loss:0.10244, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8936, Train Loss:0.22179, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8937, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8938, Train Loss:0.02204, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8939, Train Loss:0.10397, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8940, Train Loss:0.00004, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8941, Train Loss:0.01179, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8942, Train Loss:0.00826, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8943, Train Loss:0.00026, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8944, Train Loss:0.00375, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8945, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8946, Train Loss:0.01106, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8947, Train Loss:0.00038, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8948, Train Loss:0.00266, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8949, Train Loss:0.01474, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8950, Train Loss:0.00314, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8951, Train Loss:0.00087, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8952, Train Loss:0.16644, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8953, Train Loss:0.04367, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8954, Train Loss:0.00938, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8955, Train Loss:0.07273, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8956, Train Loss:0.00192, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8957, Train Loss:0.07185, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8958, Train Loss:0.00002, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8959, Train Loss:0.03820, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8960, Train Loss:0.00430, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8961, Train Loss:0.00093, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8962, Train Loss:0.00098, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8963, Train Loss:0.02622, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8964, Train Loss:0.10335, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8965, Train Loss:0.00941, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8966, Train Loss:0.01129, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8967, Train Loss:0.04880, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8968, Train Loss:0.00001, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8969, Train Loss:0.01116, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8970, Train Loss:0.15903, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8971, Train Loss:0.00093, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8972, Train Loss:0.00148, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8973, Train Loss:0.00032, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8974, Train Loss:0.00276, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8975, Train Loss:0.00018, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8976, Train Loss:0.40386, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8977, Train Loss:0.21428, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8978, Train Loss:0.18744, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8979, Train Loss:0.00028, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8980, Train Loss:0.01141, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8981, Train Loss:0.02323, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8982, Train Loss:0.05820, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8983, Train Loss:0.01355, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8984, Train Loss:0.00622, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8985, Train Loss:0.00848, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8986, Train Loss:0.13133, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8987, Train Loss:0.16995, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8988, Train Loss:0.00212, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8989, Train Loss:0.00022, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8990, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8991, Train Loss:0.07108, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8992, Train Loss:0.09652, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8993, Train Loss:0.00012, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8994, Train Loss:0.00269, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8995, Train Loss:0.01237, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8996, Train Loss:0.06744, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8997, Train Loss:0.00542, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8998, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:8999, Train Loss:0.00000, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:9000, Train Loss:0.04905, Dev Loss:0.16388\n",
      "Epoch:[32/100], step:9001, Train Loss:0.44136, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9002, Train Loss:0.00004, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9003, Train Loss:0.26972, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9004, Train Loss:0.00059, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9005, Train Loss:0.00705, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9006, Train Loss:0.03655, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9007, Train Loss:0.13399, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9008, Train Loss:0.04829, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9009, Train Loss:0.24894, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9010, Train Loss:0.00048, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9011, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9012, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9013, Train Loss:0.08604, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9014, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9015, Train Loss:0.02991, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9016, Train Loss:0.00136, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9017, Train Loss:0.00003, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9018, Train Loss:0.00130, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9019, Train Loss:0.00008, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9020, Train Loss:0.83444, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9021, Train Loss:0.00033, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9022, Train Loss:0.09829, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9023, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9024, Train Loss:0.10492, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9025, Train Loss:0.91792, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9026, Train Loss:0.53457, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9027, Train Loss:0.06222, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9028, Train Loss:0.06701, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9029, Train Loss:0.28430, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9030, Train Loss:0.00221, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9031, Train Loss:0.04362, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9032, Train Loss:0.00029, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9033, Train Loss:0.11820, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9034, Train Loss:0.00083, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9035, Train Loss:0.00078, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9036, Train Loss:0.00022, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9037, Train Loss:0.00026, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9038, Train Loss:0.28050, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9039, Train Loss:0.03231, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9040, Train Loss:0.01108, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9041, Train Loss:0.00039, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9042, Train Loss:0.06107, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9043, Train Loss:0.04117, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9044, Train Loss:0.00646, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9045, Train Loss:0.24029, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9046, Train Loss:0.00005, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9047, Train Loss:0.07985, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9048, Train Loss:0.00011, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9049, Train Loss:0.02277, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9050, Train Loss:0.12046, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9051, Train Loss:0.21926, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9052, Train Loss:0.53233, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9053, Train Loss:0.23456, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9054, Train Loss:0.00320, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9055, Train Loss:0.11217, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9056, Train Loss:0.00235, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9057, Train Loss:0.00005, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9058, Train Loss:0.00549, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9059, Train Loss:0.01588, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9060, Train Loss:0.11895, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9061, Train Loss:0.33512, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9062, Train Loss:0.00202, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9063, Train Loss:0.13091, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9064, Train Loss:0.05846, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9065, Train Loss:0.26847, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9066, Train Loss:0.00005, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9067, Train Loss:0.03027, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9068, Train Loss:0.33205, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9069, Train Loss:0.07695, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9070, Train Loss:0.01681, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9071, Train Loss:0.01256, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9072, Train Loss:0.00117, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9073, Train Loss:0.00070, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9074, Train Loss:0.05169, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9075, Train Loss:0.00479, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9076, Train Loss:0.00051, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9077, Train Loss:0.08644, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9078, Train Loss:0.00059, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9079, Train Loss:0.00230, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9080, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9081, Train Loss:0.09084, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9082, Train Loss:0.00141, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9083, Train Loss:0.01939, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9084, Train Loss:0.09889, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9085, Train Loss:0.46577, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9086, Train Loss:0.40817, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9087, Train Loss:0.17124, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9088, Train Loss:0.00241, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9089, Train Loss:0.00671, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9090, Train Loss:0.00001, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9091, Train Loss:0.26841, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9092, Train Loss:0.00028, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9093, Train Loss:0.10834, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9094, Train Loss:0.00019, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9095, Train Loss:0.02615, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9096, Train Loss:0.34190, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9097, Train Loss:0.02972, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9098, Train Loss:0.13899, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9099, Train Loss:0.31587, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9100, Train Loss:0.01644, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9101, Train Loss:0.00007, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9102, Train Loss:0.07044, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9103, Train Loss:0.00421, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9104, Train Loss:0.25463, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9105, Train Loss:0.00021, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9106, Train Loss:0.00287, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9107, Train Loss:0.19076, Dev Loss:0.12954\n",
      "Epoch:[32/100], step:9108, Train Loss:0.10543, Dev Loss:0.12954\n",
      "Start Epoch: 33, Steps: 17\n",
      "Epoch:[33/100], step:9109, Train Loss:0.00286, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9110, Train Loss:0.21625, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9111, Train Loss:0.00004, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9112, Train Loss:0.00011, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9113, Train Loss:0.00087, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9114, Train Loss:0.00005, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9115, Train Loss:0.06507, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9116, Train Loss:0.17561, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9117, Train Loss:0.04747, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9118, Train Loss:0.00270, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9119, Train Loss:0.09407, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9120, Train Loss:0.00650, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9121, Train Loss:0.23139, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9122, Train Loss:0.00009, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9123, Train Loss:0.01577, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9124, Train Loss:0.00082, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9125, Train Loss:0.00001, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9126, Train Loss:0.00016, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9127, Train Loss:0.00145, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9128, Train Loss:0.10850, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9129, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9130, Train Loss:0.00547, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9131, Train Loss:0.79122, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9132, Train Loss:0.00028, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9133, Train Loss:0.02859, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9134, Train Loss:0.02014, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9135, Train Loss:0.44894, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9136, Train Loss:0.01761, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9137, Train Loss:0.22442, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9138, Train Loss:0.00977, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9139, Train Loss:0.14967, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9140, Train Loss:0.05242, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9141, Train Loss:0.04650, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9142, Train Loss:0.03970, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9143, Train Loss:0.09454, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9144, Train Loss:0.58461, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9145, Train Loss:0.00578, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9146, Train Loss:0.04779, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9147, Train Loss:0.14005, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9148, Train Loss:0.00341, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9149, Train Loss:0.11729, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9150, Train Loss:0.00004, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9151, Train Loss:0.00024, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9152, Train Loss:0.00006, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9153, Train Loss:0.47794, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9154, Train Loss:0.26399, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9155, Train Loss:0.28422, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9156, Train Loss:0.28360, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9157, Train Loss:0.27735, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9158, Train Loss:0.69792, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9159, Train Loss:0.00080, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9160, Train Loss:0.04328, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9161, Train Loss:0.00049, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9162, Train Loss:0.41930, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9163, Train Loss:0.00168, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9164, Train Loss:0.26596, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9165, Train Loss:0.24723, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9166, Train Loss:0.18661, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9167, Train Loss:0.31618, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9168, Train Loss:0.01186, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9169, Train Loss:0.03211, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9170, Train Loss:0.02514, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9171, Train Loss:0.58733, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9172, Train Loss:0.00098, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9173, Train Loss:0.00844, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9174, Train Loss:0.05566, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9175, Train Loss:0.06802, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9176, Train Loss:0.00024, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9177, Train Loss:0.33588, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9178, Train Loss:0.55834, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9179, Train Loss:0.00084, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9180, Train Loss:0.00981, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9181, Train Loss:0.27750, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9182, Train Loss:0.07950, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9183, Train Loss:0.08524, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9184, Train Loss:0.00318, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9185, Train Loss:0.01355, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9186, Train Loss:0.25240, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9187, Train Loss:0.02012, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9188, Train Loss:0.00000, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9189, Train Loss:0.01490, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9190, Train Loss:0.00059, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9191, Train Loss:0.00312, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9192, Train Loss:0.11621, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9193, Train Loss:0.00187, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9194, Train Loss:0.16602, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9195, Train Loss:0.11802, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9196, Train Loss:0.48933, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9197, Train Loss:0.08916, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9198, Train Loss:0.06429, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9199, Train Loss:0.05800, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9200, Train Loss:0.04277, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9201, Train Loss:0.02469, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9202, Train Loss:0.00002, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9203, Train Loss:0.22524, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9204, Train Loss:0.72196, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9205, Train Loss:0.00302, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9206, Train Loss:0.90121, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9207, Train Loss:0.00829, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9208, Train Loss:0.00022, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9209, Train Loss:0.00032, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9210, Train Loss:0.45762, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9211, Train Loss:0.59651, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9212, Train Loss:0.34514, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9213, Train Loss:0.02199, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9214, Train Loss:0.03375, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9215, Train Loss:0.27262, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9216, Train Loss:0.24321, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9217, Train Loss:0.35854, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9218, Train Loss:0.00006, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9219, Train Loss:0.00341, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9220, Train Loss:0.25511, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9221, Train Loss:0.05436, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9222, Train Loss:0.00046, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9223, Train Loss:0.03091, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9224, Train Loss:0.33806, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9225, Train Loss:0.08087, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9226, Train Loss:0.29021, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9227, Train Loss:0.20028, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9228, Train Loss:0.00165, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9229, Train Loss:0.17403, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9230, Train Loss:0.13493, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9231, Train Loss:0.00630, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9232, Train Loss:0.01170, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9233, Train Loss:0.09395, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9234, Train Loss:0.00111, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9235, Train Loss:0.08210, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9236, Train Loss:0.11598, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9237, Train Loss:0.00037, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9238, Train Loss:0.73927, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9239, Train Loss:0.09623, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9240, Train Loss:0.00115, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9241, Train Loss:0.01506, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9242, Train Loss:0.02280, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9243, Train Loss:0.34927, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9244, Train Loss:0.00002, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9245, Train Loss:0.00002, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9246, Train Loss:0.00039, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9247, Train Loss:0.00344, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9248, Train Loss:0.07554, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9249, Train Loss:0.06373, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9250, Train Loss:0.08390, Dev Loss:0.12954\n",
      "Epoch:[33/100], step:9251, Train Loss:0.11294, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9252, Train Loss:0.11099, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9253, Train Loss:0.00612, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9254, Train Loss:0.00092, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9255, Train Loss:0.04004, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9256, Train Loss:0.00933, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9257, Train Loss:0.00001, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9258, Train Loss:0.03140, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9259, Train Loss:0.67268, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9260, Train Loss:0.00132, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9261, Train Loss:0.05111, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9262, Train Loss:0.17187, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9263, Train Loss:0.00988, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9264, Train Loss:0.13996, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9265, Train Loss:0.14115, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9266, Train Loss:0.00533, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9267, Train Loss:0.00062, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9268, Train Loss:0.00006, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9269, Train Loss:0.00115, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9270, Train Loss:0.00789, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9271, Train Loss:0.00044, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9272, Train Loss:0.00003, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9273, Train Loss:0.10334, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9274, Train Loss:0.00244, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9275, Train Loss:0.08538, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9276, Train Loss:0.05044, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9277, Train Loss:0.08802, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9278, Train Loss:0.00059, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9279, Train Loss:0.00056, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9280, Train Loss:0.19133, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9281, Train Loss:0.08819, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9282, Train Loss:0.15488, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9283, Train Loss:0.01012, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9284, Train Loss:0.00133, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9285, Train Loss:0.00013, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9286, Train Loss:0.11531, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9287, Train Loss:0.01447, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9288, Train Loss:0.01438, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9289, Train Loss:0.00055, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9290, Train Loss:0.10437, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9291, Train Loss:0.00014, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9292, Train Loss:0.15777, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9293, Train Loss:0.00523, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9294, Train Loss:0.32633, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9295, Train Loss:0.09791, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9296, Train Loss:0.01326, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9297, Train Loss:0.00001, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9298, Train Loss:0.07916, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9299, Train Loss:0.00268, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9300, Train Loss:0.00082, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9301, Train Loss:0.03904, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9302, Train Loss:0.01545, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9303, Train Loss:0.04045, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9304, Train Loss:0.05626, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9305, Train Loss:0.00055, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9306, Train Loss:0.19793, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9307, Train Loss:0.00009, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9308, Train Loss:0.09589, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9309, Train Loss:0.00001, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9310, Train Loss:0.00196, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9311, Train Loss:0.00651, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9312, Train Loss:0.06777, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9313, Train Loss:0.05984, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9314, Train Loss:0.03109, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9315, Train Loss:0.00109, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9316, Train Loss:0.05248, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9317, Train Loss:0.21898, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9318, Train Loss:0.00045, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9319, Train Loss:0.00177, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9320, Train Loss:0.00002, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9321, Train Loss:0.01267, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9322, Train Loss:0.00025, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9323, Train Loss:0.06893, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9324, Train Loss:0.00287, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9325, Train Loss:0.00089, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9326, Train Loss:0.00015, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9327, Train Loss:0.71434, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9328, Train Loss:0.08588, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9329, Train Loss:0.04101, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9330, Train Loss:0.00004, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9331, Train Loss:0.16950, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9332, Train Loss:0.00049, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9333, Train Loss:0.11320, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9334, Train Loss:0.02721, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9335, Train Loss:0.00277, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9336, Train Loss:0.18397, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9337, Train Loss:0.07676, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9338, Train Loss:0.02964, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9339, Train Loss:0.03583, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9340, Train Loss:0.84533, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9341, Train Loss:0.01059, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9342, Train Loss:0.00114, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9343, Train Loss:0.00030, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9344, Train Loss:0.00150, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9345, Train Loss:0.20952, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9346, Train Loss:0.00233, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9347, Train Loss:0.29815, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9348, Train Loss:0.18765, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9349, Train Loss:0.00004, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9350, Train Loss:0.00021, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9351, Train Loss:0.02199, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9352, Train Loss:0.01219, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9353, Train Loss:0.11783, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9354, Train Loss:0.00010, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9355, Train Loss:0.00062, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9356, Train Loss:0.10682, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9357, Train Loss:0.13803, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9358, Train Loss:0.08085, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9359, Train Loss:0.09458, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9360, Train Loss:0.34656, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9361, Train Loss:0.08346, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9362, Train Loss:0.06666, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9363, Train Loss:0.18469, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9364, Train Loss:0.00073, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9365, Train Loss:0.14583, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9366, Train Loss:0.00773, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9367, Train Loss:0.03536, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9368, Train Loss:0.00252, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9369, Train Loss:0.00481, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9370, Train Loss:0.05736, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9371, Train Loss:0.04296, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9372, Train Loss:0.07111, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9373, Train Loss:0.01511, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9374, Train Loss:0.02377, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9375, Train Loss:0.06534, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9376, Train Loss:0.20631, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9377, Train Loss:0.16706, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9378, Train Loss:0.61817, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9379, Train Loss:0.00034, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9380, Train Loss:0.00093, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9381, Train Loss:0.28534, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9382, Train Loss:0.11476, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9383, Train Loss:0.09076, Dev Loss:0.15236\n",
      "Epoch:[33/100], step:9384, Train Loss:0.53018, Dev Loss:0.15236\n",
      "Start Epoch: 34, Steps: 17\n",
      "Epoch:[34/100], step:9385, Train Loss:0.00003, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9386, Train Loss:0.17678, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9387, Train Loss:0.05397, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9388, Train Loss:0.06234, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9389, Train Loss:0.02913, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9390, Train Loss:0.00044, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9391, Train Loss:0.16866, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9392, Train Loss:0.09737, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9393, Train Loss:0.00024, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9394, Train Loss:0.35071, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9395, Train Loss:0.26730, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9396, Train Loss:0.15843, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9397, Train Loss:0.05240, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9398, Train Loss:0.00986, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9399, Train Loss:0.03139, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9400, Train Loss:0.13607, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9401, Train Loss:0.09567, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9402, Train Loss:0.07303, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9403, Train Loss:0.16313, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9404, Train Loss:0.00220, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9405, Train Loss:0.00200, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9406, Train Loss:0.45202, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9407, Train Loss:0.28379, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9408, Train Loss:0.00682, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9409, Train Loss:0.62198, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9410, Train Loss:0.00000, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9411, Train Loss:0.13951, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9412, Train Loss:0.02620, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9413, Train Loss:0.00150, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9414, Train Loss:0.00088, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9415, Train Loss:0.01975, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9416, Train Loss:0.10034, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9417, Train Loss:0.03187, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9418, Train Loss:0.27511, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9419, Train Loss:0.07289, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9420, Train Loss:0.88998, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9421, Train Loss:0.11332, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9422, Train Loss:0.07907, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9423, Train Loss:0.70708, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9424, Train Loss:0.22092, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9425, Train Loss:0.00008, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9426, Train Loss:0.94874, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9427, Train Loss:0.06268, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9428, Train Loss:0.17210, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9429, Train Loss:0.05524, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9430, Train Loss:0.31339, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9431, Train Loss:0.01377, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9432, Train Loss:0.08035, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9433, Train Loss:0.02466, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9434, Train Loss:0.00142, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9435, Train Loss:0.00002, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9436, Train Loss:0.00678, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9437, Train Loss:0.19184, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9438, Train Loss:0.04751, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9439, Train Loss:0.02481, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9440, Train Loss:0.04768, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9441, Train Loss:0.05890, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9442, Train Loss:0.02815, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9443, Train Loss:0.12202, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9444, Train Loss:0.05112, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9445, Train Loss:0.12119, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9446, Train Loss:0.00295, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9447, Train Loss:0.00265, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9448, Train Loss:0.39769, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9449, Train Loss:0.00351, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9450, Train Loss:0.11709, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9451, Train Loss:0.06742, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9452, Train Loss:0.00044, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9453, Train Loss:0.00280, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9454, Train Loss:0.00001, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9455, Train Loss:0.04872, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9456, Train Loss:0.00180, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9457, Train Loss:0.03075, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9458, Train Loss:0.01481, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9459, Train Loss:0.00222, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9460, Train Loss:0.03685, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9461, Train Loss:0.25073, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9462, Train Loss:0.18017, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9463, Train Loss:0.00000, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9464, Train Loss:0.12133, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9465, Train Loss:0.00012, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9466, Train Loss:0.00002, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9467, Train Loss:0.09082, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9468, Train Loss:0.03752, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9469, Train Loss:0.00049, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9470, Train Loss:0.13831, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9471, Train Loss:0.03724, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9472, Train Loss:0.15020, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9473, Train Loss:0.00061, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9474, Train Loss:0.00174, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9475, Train Loss:0.39364, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9476, Train Loss:0.34508, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9477, Train Loss:0.00076, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9478, Train Loss:0.00575, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9479, Train Loss:0.00005, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9480, Train Loss:0.00000, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9481, Train Loss:0.00000, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9482, Train Loss:0.00261, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9483, Train Loss:0.12351, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9484, Train Loss:0.08917, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9485, Train Loss:0.00048, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9486, Train Loss:0.29592, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9487, Train Loss:0.19147, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9488, Train Loss:0.33552, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9489, Train Loss:0.03350, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9490, Train Loss:0.00003, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9491, Train Loss:0.00000, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9492, Train Loss:0.26839, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9493, Train Loss:0.03889, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9494, Train Loss:0.20279, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9495, Train Loss:0.15980, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9496, Train Loss:0.01516, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9497, Train Loss:0.62607, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9498, Train Loss:0.08873, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9499, Train Loss:0.22711, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9500, Train Loss:0.11932, Dev Loss:0.15236\n",
      "Epoch:[34/100], step:9501, Train Loss:0.00380, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9502, Train Loss:0.21279, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9503, Train Loss:0.00852, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9504, Train Loss:0.39448, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9505, Train Loss:0.16056, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9506, Train Loss:0.00001, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9507, Train Loss:0.00184, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9508, Train Loss:0.04603, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9509, Train Loss:0.00670, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9510, Train Loss:0.16960, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9511, Train Loss:0.04652, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9512, Train Loss:0.36584, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9513, Train Loss:0.00104, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9514, Train Loss:0.11802, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9515, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9516, Train Loss:0.04910, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9517, Train Loss:0.51995, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9518, Train Loss:0.31274, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9519, Train Loss:0.38327, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9520, Train Loss:0.02462, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9521, Train Loss:0.03845, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9522, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9523, Train Loss:0.22568, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9524, Train Loss:0.00303, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9525, Train Loss:0.20346, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9526, Train Loss:0.00192, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9527, Train Loss:0.10845, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9528, Train Loss:0.03883, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9529, Train Loss:0.00620, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9530, Train Loss:0.35590, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9531, Train Loss:0.02682, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9532, Train Loss:0.77826, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9533, Train Loss:0.00002, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9534, Train Loss:0.00102, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9535, Train Loss:0.04121, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9536, Train Loss:0.00019, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9537, Train Loss:0.06374, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9538, Train Loss:0.25364, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9539, Train Loss:0.06839, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9540, Train Loss:0.00221, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9541, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9542, Train Loss:0.09533, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9543, Train Loss:0.01708, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9544, Train Loss:0.00482, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9545, Train Loss:0.50312, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9546, Train Loss:0.02822, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9547, Train Loss:0.43644, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9548, Train Loss:0.01016, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9549, Train Loss:0.00337, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9550, Train Loss:0.30303, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9551, Train Loss:1.12213, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9552, Train Loss:0.39962, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9553, Train Loss:0.11198, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9554, Train Loss:0.19627, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9555, Train Loss:0.13682, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9556, Train Loss:0.00854, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9557, Train Loss:0.20530, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9558, Train Loss:0.46508, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9559, Train Loss:0.09879, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9560, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9561, Train Loss:0.00036, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9562, Train Loss:0.09609, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9563, Train Loss:0.09918, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9564, Train Loss:0.00032, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9565, Train Loss:0.11683, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9566, Train Loss:0.00150, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9567, Train Loss:0.07607, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9568, Train Loss:0.00024, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9569, Train Loss:0.42001, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9570, Train Loss:0.03694, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9571, Train Loss:0.00031, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9572, Train Loss:0.12791, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9573, Train Loss:0.18980, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9574, Train Loss:0.00584, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9575, Train Loss:0.04029, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9576, Train Loss:0.03566, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9577, Train Loss:0.40446, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9578, Train Loss:0.06711, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9579, Train Loss:0.13320, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9580, Train Loss:0.00002, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9581, Train Loss:0.00197, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9582, Train Loss:0.70974, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9583, Train Loss:0.19621, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9584, Train Loss:0.00010, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9585, Train Loss:0.00136, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9586, Train Loss:0.16859, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9587, Train Loss:0.00976, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9588, Train Loss:0.04319, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9589, Train Loss:0.00020, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9590, Train Loss:0.15997, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9591, Train Loss:0.11384, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9592, Train Loss:0.12061, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9593, Train Loss:0.04050, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9594, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9595, Train Loss:0.03924, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9596, Train Loss:0.00037, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9597, Train Loss:0.00089, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9598, Train Loss:0.00142, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9599, Train Loss:0.35832, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9600, Train Loss:0.07602, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9601, Train Loss:0.00004, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9602, Train Loss:0.65145, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9603, Train Loss:0.10641, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9604, Train Loss:0.01885, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9605, Train Loss:0.03943, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9606, Train Loss:0.00726, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9607, Train Loss:0.06418, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9608, Train Loss:0.08445, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9609, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9610, Train Loss:0.05328, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9611, Train Loss:0.03814, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9612, Train Loss:0.00427, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9613, Train Loss:0.26222, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9614, Train Loss:0.09278, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9615, Train Loss:0.00174, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9616, Train Loss:0.00074, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9617, Train Loss:0.00384, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9618, Train Loss:0.00043, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9619, Train Loss:0.11620, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9620, Train Loss:0.11480, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9621, Train Loss:0.08737, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9622, Train Loss:0.00301, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9623, Train Loss:0.02296, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9624, Train Loss:0.00129, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9625, Train Loss:0.09759, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9626, Train Loss:0.10626, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9627, Train Loss:0.20365, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9628, Train Loss:0.03147, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9629, Train Loss:0.01670, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9630, Train Loss:0.00231, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9631, Train Loss:0.06434, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9632, Train Loss:0.48365, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9633, Train Loss:0.00172, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9634, Train Loss:0.01592, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9635, Train Loss:0.00017, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9636, Train Loss:0.03026, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9637, Train Loss:0.00001, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9638, Train Loss:0.00025, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9639, Train Loss:0.15407, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9640, Train Loss:0.08480, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9641, Train Loss:0.06791, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9642, Train Loss:0.00001, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9643, Train Loss:0.02457, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9644, Train Loss:0.07445, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9645, Train Loss:0.09319, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9646, Train Loss:0.41385, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9647, Train Loss:0.13253, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9648, Train Loss:0.00065, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9649, Train Loss:0.00049, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9650, Train Loss:0.00047, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9651, Train Loss:0.00030, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9652, Train Loss:0.70029, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9653, Train Loss:0.01147, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9654, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9655, Train Loss:0.07593, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9656, Train Loss:0.00006, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9657, Train Loss:0.00318, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9658, Train Loss:0.00001, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9659, Train Loss:0.02724, Dev Loss:0.12351\n",
      "Epoch:[34/100], step:9660, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Start Epoch: 35, Steps: 17\n",
      "Epoch:[35/100], step:9661, Train Loss:0.00002, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9662, Train Loss:0.02814, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9663, Train Loss:0.07219, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9664, Train Loss:0.00006, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9665, Train Loss:0.07480, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9666, Train Loss:0.07665, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9667, Train Loss:0.29390, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9668, Train Loss:0.04195, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9669, Train Loss:0.04946, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9670, Train Loss:0.00002, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9671, Train Loss:0.56872, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9672, Train Loss:0.05753, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9673, Train Loss:0.21850, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9674, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9675, Train Loss:0.00215, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9676, Train Loss:0.01730, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9677, Train Loss:0.00022, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9678, Train Loss:0.10372, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9679, Train Loss:0.00017, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9680, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9681, Train Loss:0.00113, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9682, Train Loss:0.00180, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9683, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9684, Train Loss:0.06855, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9685, Train Loss:0.11524, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9686, Train Loss:0.54972, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9687, Train Loss:0.10848, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9688, Train Loss:0.19352, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9689, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9690, Train Loss:0.01570, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9691, Train Loss:0.70414, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9692, Train Loss:0.00004, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9693, Train Loss:0.01664, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9694, Train Loss:0.00002, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9695, Train Loss:0.20060, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9696, Train Loss:0.01803, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9697, Train Loss:0.01394, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9698, Train Loss:0.13213, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9699, Train Loss:0.01542, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9700, Train Loss:0.00218, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9701, Train Loss:0.00314, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9702, Train Loss:0.26749, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9703, Train Loss:0.08635, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9704, Train Loss:0.00212, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9705, Train Loss:0.24276, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9706, Train Loss:0.30587, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9707, Train Loss:0.00528, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9708, Train Loss:0.00757, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9709, Train Loss:0.02739, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9710, Train Loss:0.00005, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9711, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9712, Train Loss:0.16231, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9713, Train Loss:0.25587, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9714, Train Loss:0.05040, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9715, Train Loss:0.00125, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9716, Train Loss:0.08580, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9717, Train Loss:0.08648, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9718, Train Loss:0.10422, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9719, Train Loss:0.18915, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9720, Train Loss:0.56965, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9721, Train Loss:0.05899, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9722, Train Loss:0.11320, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9723, Train Loss:0.17044, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9724, Train Loss:0.01892, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9725, Train Loss:0.05756, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9726, Train Loss:0.44444, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9727, Train Loss:0.11978, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9728, Train Loss:0.07964, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9729, Train Loss:0.00178, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9730, Train Loss:0.00227, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9731, Train Loss:0.18679, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9732, Train Loss:0.04272, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9733, Train Loss:0.00027, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9734, Train Loss:0.04968, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9735, Train Loss:0.08693, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9736, Train Loss:0.02107, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9737, Train Loss:0.33821, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9738, Train Loss:0.04255, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9739, Train Loss:0.22567, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9740, Train Loss:0.07260, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9741, Train Loss:0.00206, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9742, Train Loss:0.19595, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9743, Train Loss:0.09835, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9744, Train Loss:0.00271, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9745, Train Loss:0.00000, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9746, Train Loss:0.01920, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9747, Train Loss:0.14738, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9748, Train Loss:0.09466, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9749, Train Loss:0.00599, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9750, Train Loss:0.00170, Dev Loss:0.12351\n",
      "Epoch:[35/100], step:9751, Train Loss:0.00580, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9752, Train Loss:0.00071, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9753, Train Loss:0.04890, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9754, Train Loss:0.02938, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9755, Train Loss:0.09101, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9756, Train Loss:0.42112, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9757, Train Loss:0.03046, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9758, Train Loss:0.00404, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9759, Train Loss:0.00073, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9760, Train Loss:0.00093, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9761, Train Loss:0.12893, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9762, Train Loss:0.13730, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9763, Train Loss:0.06674, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9764, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9765, Train Loss:0.50392, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9766, Train Loss:0.00098, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9767, Train Loss:1.17558, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9768, Train Loss:0.00057, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9769, Train Loss:0.25194, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9770, Train Loss:0.34310, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9771, Train Loss:0.38760, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9772, Train Loss:0.02049, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9773, Train Loss:0.03342, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9774, Train Loss:1.33329, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9775, Train Loss:0.06206, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9776, Train Loss:0.18821, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9777, Train Loss:0.16453, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9778, Train Loss:0.06248, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9779, Train Loss:0.02552, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9780, Train Loss:0.09413, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9781, Train Loss:0.00766, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9782, Train Loss:0.12379, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9783, Train Loss:0.00003, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9784, Train Loss:0.08641, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9785, Train Loss:0.03361, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9786, Train Loss:0.11792, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9787, Train Loss:0.01590, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9788, Train Loss:0.18162, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9789, Train Loss:0.28180, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9790, Train Loss:0.10211, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9791, Train Loss:0.06004, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9792, Train Loss:0.00178, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9793, Train Loss:0.01228, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9794, Train Loss:0.00140, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9795, Train Loss:0.07290, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9796, Train Loss:0.15759, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9797, Train Loss:0.00010, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9798, Train Loss:0.01994, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9799, Train Loss:0.00321, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9800, Train Loss:0.07087, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9801, Train Loss:0.15057, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9802, Train Loss:0.01612, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9803, Train Loss:0.09626, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9804, Train Loss:0.00164, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9805, Train Loss:0.00256, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9806, Train Loss:0.00461, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9807, Train Loss:0.19542, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9808, Train Loss:0.00713, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9809, Train Loss:0.04075, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9810, Train Loss:0.00036, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9811, Train Loss:0.14381, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9812, Train Loss:0.00167, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9813, Train Loss:0.10903, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9814, Train Loss:0.00411, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9815, Train Loss:0.11650, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9816, Train Loss:0.00375, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9817, Train Loss:0.11394, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9818, Train Loss:0.55132, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9819, Train Loss:0.00069, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9820, Train Loss:0.01697, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9821, Train Loss:0.11726, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9822, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9823, Train Loss:0.17844, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9824, Train Loss:0.00374, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9825, Train Loss:0.00631, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9826, Train Loss:0.00948, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9827, Train Loss:0.08336, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9828, Train Loss:0.00374, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9829, Train Loss:0.00006, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9830, Train Loss:0.00017, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9831, Train Loss:0.07623, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9832, Train Loss:0.08512, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9833, Train Loss:0.00861, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9834, Train Loss:0.37362, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9835, Train Loss:0.00202, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9836, Train Loss:0.12548, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9837, Train Loss:0.00023, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9838, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9839, Train Loss:0.00299, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9840, Train Loss:0.02232, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9841, Train Loss:0.02186, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9842, Train Loss:0.00397, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9843, Train Loss:0.00014, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9844, Train Loss:0.00002, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9845, Train Loss:0.15936, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9846, Train Loss:0.05618, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9847, Train Loss:0.08116, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9848, Train Loss:0.00053, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9849, Train Loss:0.03409, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9850, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9851, Train Loss:0.13715, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9852, Train Loss:0.09023, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9853, Train Loss:0.00002, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9854, Train Loss:0.25111, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9855, Train Loss:0.41792, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9856, Train Loss:0.00382, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9857, Train Loss:1.35388, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9858, Train Loss:0.00155, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9859, Train Loss:0.03909, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9860, Train Loss:0.02311, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9861, Train Loss:0.04652, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9862, Train Loss:0.01749, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9863, Train Loss:0.00006, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9864, Train Loss:0.09966, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9865, Train Loss:1.91871, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9866, Train Loss:0.38494, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9867, Train Loss:0.00287, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9868, Train Loss:0.00365, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9869, Train Loss:0.02108, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9870, Train Loss:0.00062, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9871, Train Loss:0.55891, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9872, Train Loss:0.05886, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9873, Train Loss:0.23085, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9874, Train Loss:0.68094, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9875, Train Loss:0.08448, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9876, Train Loss:0.04822, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9877, Train Loss:0.03105, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9878, Train Loss:0.00157, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9879, Train Loss:0.03214, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9880, Train Loss:0.14822, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9881, Train Loss:0.19147, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9882, Train Loss:0.11823, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9883, Train Loss:0.54484, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9884, Train Loss:0.00064, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9885, Train Loss:0.04447, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9886, Train Loss:0.00049, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9887, Train Loss:0.32344, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9888, Train Loss:0.03583, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9889, Train Loss:0.00093, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9890, Train Loss:0.28465, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9891, Train Loss:0.02960, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9892, Train Loss:0.02212, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9893, Train Loss:0.00181, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9894, Train Loss:0.02819, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9895, Train Loss:0.03324, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9896, Train Loss:0.00357, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9897, Train Loss:0.00970, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9898, Train Loss:0.24082, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9899, Train Loss:0.20736, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9900, Train Loss:0.00016, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9901, Train Loss:0.04613, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9902, Train Loss:0.03115, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9903, Train Loss:0.00217, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9904, Train Loss:0.00016, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9905, Train Loss:0.04505, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9906, Train Loss:0.07691, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9907, Train Loss:0.04940, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9908, Train Loss:0.00011, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9909, Train Loss:0.03342, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9910, Train Loss:0.00003, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9911, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9912, Train Loss:0.00001, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9913, Train Loss:0.40741, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9914, Train Loss:0.04712, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9915, Train Loss:0.00096, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9916, Train Loss:0.05256, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9917, Train Loss:0.15819, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9918, Train Loss:0.57916, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9919, Train Loss:0.00878, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9920, Train Loss:0.18340, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9921, Train Loss:0.03889, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9922, Train Loss:0.05786, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9923, Train Loss:0.06337, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9924, Train Loss:0.00017, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9925, Train Loss:0.03129, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9926, Train Loss:0.04626, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9927, Train Loss:0.00011, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9928, Train Loss:0.11932, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9929, Train Loss:0.06407, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9930, Train Loss:0.01536, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9931, Train Loss:0.09532, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9932, Train Loss:0.11274, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9933, Train Loss:0.41999, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9934, Train Loss:0.23298, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9935, Train Loss:0.14864, Dev Loss:0.14159\n",
      "Epoch:[35/100], step:9936, Train Loss:0.92698, Dev Loss:0.14159\n",
      "Start Epoch: 36, Steps: 17\n",
      "Epoch:[36/100], step:9937, Train Loss:0.18262, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9938, Train Loss:0.10809, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9939, Train Loss:0.00018, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9940, Train Loss:0.20347, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9941, Train Loss:0.00273, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9942, Train Loss:0.00016, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9943, Train Loss:0.04187, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9944, Train Loss:0.15205, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9945, Train Loss:0.26006, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9946, Train Loss:0.00016, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9947, Train Loss:0.01967, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9948, Train Loss:0.04834, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9949, Train Loss:0.05437, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9950, Train Loss:0.00387, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9951, Train Loss:0.12591, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9952, Train Loss:0.01460, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9953, Train Loss:0.09321, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9954, Train Loss:0.33501, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9955, Train Loss:0.04075, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9956, Train Loss:0.00004, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9957, Train Loss:0.22494, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9958, Train Loss:0.08371, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9959, Train Loss:0.55708, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9960, Train Loss:0.06949, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9961, Train Loss:0.07806, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9962, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9963, Train Loss:0.00016, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9964, Train Loss:0.15695, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9965, Train Loss:0.05190, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9966, Train Loss:0.52146, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9967, Train Loss:0.02197, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9968, Train Loss:0.06896, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9969, Train Loss:0.16121, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9970, Train Loss:0.24532, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9971, Train Loss:0.00001, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9972, Train Loss:0.00006, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9973, Train Loss:0.31139, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9974, Train Loss:0.11497, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9975, Train Loss:0.03835, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9976, Train Loss:0.03161, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9977, Train Loss:0.00190, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9978, Train Loss:0.00005, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9979, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9980, Train Loss:0.00014, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9981, Train Loss:0.48148, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9982, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9983, Train Loss:0.02397, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9984, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9985, Train Loss:0.00041, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9986, Train Loss:0.12098, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9987, Train Loss:0.00875, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9988, Train Loss:0.23543, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9989, Train Loss:0.00101, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9990, Train Loss:0.11565, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9991, Train Loss:0.00002, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9992, Train Loss:0.00000, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9993, Train Loss:0.06632, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9994, Train Loss:0.00001, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9995, Train Loss:0.02194, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9996, Train Loss:0.01206, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9997, Train Loss:0.03854, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9998, Train Loss:0.55920, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:9999, Train Loss:0.01031, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:10000, Train Loss:0.51877, Dev Loss:0.14159\n",
      "Epoch:[36/100], step:10001, Train Loss:0.19800, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10002, Train Loss:0.00005, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10003, Train Loss:0.03280, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10004, Train Loss:0.00016, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10005, Train Loss:0.51815, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10006, Train Loss:0.00346, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10007, Train Loss:0.00755, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10008, Train Loss:0.00005, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10009, Train Loss:0.00243, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10010, Train Loss:0.79512, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10011, Train Loss:0.17712, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10012, Train Loss:0.13846, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10013, Train Loss:0.01789, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10014, Train Loss:0.39268, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10015, Train Loss:0.02134, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10016, Train Loss:0.08960, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10017, Train Loss:0.11016, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10018, Train Loss:0.08420, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10019, Train Loss:0.00001, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10020, Train Loss:0.06690, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10021, Train Loss:0.00472, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10022, Train Loss:0.11158, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10023, Train Loss:0.22916, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10024, Train Loss:0.00253, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10025, Train Loss:0.08496, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10026, Train Loss:0.00232, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10027, Train Loss:0.03701, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10028, Train Loss:0.00007, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10029, Train Loss:0.07129, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10030, Train Loss:0.00199, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10031, Train Loss:0.55563, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10032, Train Loss:0.01252, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10033, Train Loss:0.00641, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10034, Train Loss:0.24889, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10035, Train Loss:0.51504, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10036, Train Loss:0.55753, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10037, Train Loss:0.10274, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10038, Train Loss:0.00084, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10039, Train Loss:1.12459, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10040, Train Loss:0.00342, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10041, Train Loss:0.29156, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10042, Train Loss:0.12532, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10043, Train Loss:0.08065, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10044, Train Loss:0.08217, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10045, Train Loss:0.00095, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10046, Train Loss:0.26851, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10047, Train Loss:0.24596, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10048, Train Loss:0.07308, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10049, Train Loss:0.05171, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10050, Train Loss:0.07513, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10051, Train Loss:0.06991, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10052, Train Loss:0.39841, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10053, Train Loss:0.39397, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10054, Train Loss:0.00328, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10055, Train Loss:0.28574, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10056, Train Loss:0.00120, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10057, Train Loss:0.00492, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10058, Train Loss:0.10699, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10059, Train Loss:0.15800, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10060, Train Loss:0.00066, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10061, Train Loss:0.27208, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10062, Train Loss:0.12079, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10063, Train Loss:0.01165, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10064, Train Loss:0.00034, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10065, Train Loss:0.00088, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10066, Train Loss:0.11128, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10067, Train Loss:0.03579, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10068, Train Loss:0.00000, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10069, Train Loss:0.00362, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10070, Train Loss:0.00493, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10071, Train Loss:0.00000, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10072, Train Loss:0.00832, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10073, Train Loss:0.23903, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10074, Train Loss:0.00001, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10075, Train Loss:0.31121, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10076, Train Loss:0.00171, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10077, Train Loss:0.15942, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10078, Train Loss:0.06271, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10079, Train Loss:0.05410, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10080, Train Loss:0.00013, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10081, Train Loss:0.16814, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10082, Train Loss:0.05638, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10083, Train Loss:0.08567, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10084, Train Loss:0.04554, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10085, Train Loss:0.02011, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10086, Train Loss:0.00001, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10087, Train Loss:0.00319, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10088, Train Loss:0.04223, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10089, Train Loss:0.04444, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10090, Train Loss:0.00068, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10091, Train Loss:0.44714, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10092, Train Loss:0.02241, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10093, Train Loss:0.00000, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10094, Train Loss:0.29496, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10095, Train Loss:0.37028, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10096, Train Loss:0.00357, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10097, Train Loss:0.03517, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10098, Train Loss:0.01181, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10099, Train Loss:0.40566, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10100, Train Loss:0.00327, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10101, Train Loss:0.00060, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10102, Train Loss:0.00563, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10103, Train Loss:0.21532, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10104, Train Loss:0.07668, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10105, Train Loss:0.00000, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10106, Train Loss:0.00086, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10107, Train Loss:0.17434, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10108, Train Loss:0.11236, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10109, Train Loss:0.02384, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10110, Train Loss:0.84471, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10111, Train Loss:0.00124, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10112, Train Loss:0.00273, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10113, Train Loss:0.00676, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10114, Train Loss:0.14974, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10115, Train Loss:0.00025, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10116, Train Loss:0.00012, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10117, Train Loss:0.03188, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10118, Train Loss:0.03384, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10119, Train Loss:0.01278, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10120, Train Loss:0.20678, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10121, Train Loss:0.64019, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10122, Train Loss:0.14695, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10123, Train Loss:0.08025, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10124, Train Loss:0.01896, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10125, Train Loss:0.02223, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10126, Train Loss:0.05816, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10127, Train Loss:0.18960, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10128, Train Loss:0.04858, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10129, Train Loss:0.19910, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10130, Train Loss:0.03282, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10131, Train Loss:0.00041, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10132, Train Loss:0.03378, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10133, Train Loss:0.00035, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10134, Train Loss:0.00028, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10135, Train Loss:0.11977, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10136, Train Loss:0.12614, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10137, Train Loss:0.08236, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10138, Train Loss:0.10241, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10139, Train Loss:0.05544, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10140, Train Loss:0.33561, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10141, Train Loss:0.00219, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10142, Train Loss:0.22213, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10143, Train Loss:0.17584, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10144, Train Loss:0.00004, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10145, Train Loss:0.13405, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10146, Train Loss:0.00014, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10147, Train Loss:0.00407, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10148, Train Loss:0.00537, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10149, Train Loss:0.00056, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10150, Train Loss:0.27593, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10151, Train Loss:0.11832, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10152, Train Loss:0.05310, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10153, Train Loss:1.18500, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10154, Train Loss:0.16795, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10155, Train Loss:0.11178, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10156, Train Loss:0.73468, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10157, Train Loss:0.35191, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10158, Train Loss:0.74201, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10159, Train Loss:0.57556, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10160, Train Loss:0.21776, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10161, Train Loss:0.00780, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10162, Train Loss:0.07824, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10163, Train Loss:0.03001, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10164, Train Loss:0.13272, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10165, Train Loss:0.03256, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10166, Train Loss:0.35277, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10167, Train Loss:0.36101, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10168, Train Loss:0.07313, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10169, Train Loss:0.12749, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10170, Train Loss:0.11766, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10171, Train Loss:0.11831, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10172, Train Loss:0.11744, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10173, Train Loss:0.16946, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10174, Train Loss:0.17291, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10175, Train Loss:0.00414, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10176, Train Loss:0.03384, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10177, Train Loss:0.25100, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10178, Train Loss:0.00081, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10179, Train Loss:0.10490, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10180, Train Loss:0.07078, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10181, Train Loss:0.02417, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10182, Train Loss:0.12949, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10183, Train Loss:0.08946, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10184, Train Loss:0.45379, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10185, Train Loss:0.09898, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10186, Train Loss:0.00445, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10187, Train Loss:0.00054, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10188, Train Loss:0.17147, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10189, Train Loss:0.00002, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10190, Train Loss:0.00307, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10191, Train Loss:0.00018, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10192, Train Loss:0.00374, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10193, Train Loss:0.41776, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10194, Train Loss:0.00052, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10195, Train Loss:0.00003, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10196, Train Loss:0.04462, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10197, Train Loss:0.13096, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10198, Train Loss:0.08090, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10199, Train Loss:0.23164, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10200, Train Loss:0.03639, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10201, Train Loss:0.27869, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10202, Train Loss:0.01322, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10203, Train Loss:0.00741, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10204, Train Loss:0.06577, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10205, Train Loss:0.23066, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10206, Train Loss:0.98532, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10207, Train Loss:0.08106, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10208, Train Loss:0.00001, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10209, Train Loss:0.00004, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10210, Train Loss:0.01276, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10211, Train Loss:0.04529, Dev Loss:0.09075\n",
      "Epoch:[36/100], step:10212, Train Loss:0.16931, Dev Loss:0.09075\n",
      "Start Epoch: 37, Steps: 17\n",
      "Epoch:[37/100], step:10213, Train Loss:0.00014, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10214, Train Loss:0.00038, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10215, Train Loss:0.01811, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10216, Train Loss:0.04517, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10217, Train Loss:0.00018, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10218, Train Loss:0.66806, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10219, Train Loss:0.00373, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10220, Train Loss:0.00025, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10221, Train Loss:0.00103, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10222, Train Loss:0.01670, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10223, Train Loss:0.69964, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10224, Train Loss:0.00043, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10225, Train Loss:0.29633, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10226, Train Loss:0.81128, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10227, Train Loss:0.00025, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10228, Train Loss:0.01087, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10229, Train Loss:0.00047, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10230, Train Loss:0.00002, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10231, Train Loss:0.64386, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10232, Train Loss:0.05259, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10233, Train Loss:1.39796, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10234, Train Loss:0.11163, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10235, Train Loss:0.00185, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10236, Train Loss:0.63137, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10237, Train Loss:0.11251, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10238, Train Loss:0.00290, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10239, Train Loss:0.04265, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10240, Train Loss:0.08288, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10241, Train Loss:0.08756, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10242, Train Loss:0.01022, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10243, Train Loss:0.18985, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10244, Train Loss:0.03674, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10245, Train Loss:0.00046, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10246, Train Loss:0.04174, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10247, Train Loss:0.41834, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10248, Train Loss:0.90668, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10249, Train Loss:0.07240, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10250, Train Loss:0.00474, Dev Loss:0.09075\n",
      "Epoch:[37/100], step:10251, Train Loss:0.20762, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10252, Train Loss:0.07634, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10253, Train Loss:0.07631, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10254, Train Loss:0.17868, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10255, Train Loss:0.61687, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10256, Train Loss:0.21309, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10257, Train Loss:0.00761, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10258, Train Loss:0.33141, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10259, Train Loss:0.20683, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10260, Train Loss:0.00447, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10261, Train Loss:0.16197, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10262, Train Loss:0.03978, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10263, Train Loss:0.00498, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10264, Train Loss:0.01398, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10265, Train Loss:0.05810, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10266, Train Loss:0.25921, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10267, Train Loss:0.01724, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10268, Train Loss:0.00004, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10269, Train Loss:0.24142, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10270, Train Loss:0.00013, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10271, Train Loss:0.00856, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10272, Train Loss:0.17773, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10273, Train Loss:0.00458, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10274, Train Loss:0.06133, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10275, Train Loss:0.22022, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10276, Train Loss:0.01076, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10277, Train Loss:0.00020, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10278, Train Loss:0.81146, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10279, Train Loss:0.07123, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10280, Train Loss:0.00506, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10281, Train Loss:0.03077, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10282, Train Loss:0.00704, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10283, Train Loss:0.61974, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10284, Train Loss:0.05346, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10285, Train Loss:0.24463, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10286, Train Loss:0.00857, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10287, Train Loss:0.00248, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10288, Train Loss:0.00412, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10289, Train Loss:0.04241, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10290, Train Loss:0.42701, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10291, Train Loss:0.34119, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10292, Train Loss:0.00077, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10293, Train Loss:0.05464, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10294, Train Loss:0.04477, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10295, Train Loss:0.02373, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10296, Train Loss:1.52481, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10297, Train Loss:0.45299, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10298, Train Loss:0.04857, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10299, Train Loss:0.05409, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10300, Train Loss:0.05297, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10301, Train Loss:0.01662, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10302, Train Loss:0.22407, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10303, Train Loss:0.57022, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10304, Train Loss:0.01051, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10305, Train Loss:0.12993, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10306, Train Loss:0.28043, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10307, Train Loss:0.00136, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10308, Train Loss:0.13499, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10309, Train Loss:0.09167, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10310, Train Loss:0.00066, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10311, Train Loss:0.03785, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10312, Train Loss:0.00317, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10313, Train Loss:0.33663, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10314, Train Loss:0.01210, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10315, Train Loss:0.00237, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10316, Train Loss:0.00340, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10317, Train Loss:0.35114, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10318, Train Loss:0.00016, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10319, Train Loss:0.09429, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10320, Train Loss:0.54973, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10321, Train Loss:0.00005, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10322, Train Loss:0.00060, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10323, Train Loss:0.04847, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10324, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10325, Train Loss:0.07317, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10326, Train Loss:0.00220, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10327, Train Loss:0.11760, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10328, Train Loss:0.02421, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10329, Train Loss:0.44653, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10330, Train Loss:0.00549, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10331, Train Loss:0.16941, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10332, Train Loss:0.28563, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10333, Train Loss:0.00943, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10334, Train Loss:0.00159, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10335, Train Loss:0.10290, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10336, Train Loss:0.01171, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10337, Train Loss:0.03613, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10338, Train Loss:0.25687, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10339, Train Loss:0.86969, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10340, Train Loss:0.05854, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10341, Train Loss:0.07023, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10342, Train Loss:0.82214, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10343, Train Loss:0.02080, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10344, Train Loss:0.01939, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10345, Train Loss:0.03990, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10346, Train Loss:0.00963, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10347, Train Loss:0.14105, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10348, Train Loss:0.03074, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10349, Train Loss:0.07820, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10350, Train Loss:0.47646, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10351, Train Loss:0.05550, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10352, Train Loss:0.41083, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10353, Train Loss:0.00011, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10354, Train Loss:0.17419, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10355, Train Loss:0.18432, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10356, Train Loss:0.06581, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10357, Train Loss:0.00923, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10358, Train Loss:0.23865, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10359, Train Loss:0.08901, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10360, Train Loss:0.00834, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10361, Train Loss:0.14798, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10362, Train Loss:0.00247, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10363, Train Loss:0.44641, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10364, Train Loss:0.00471, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10365, Train Loss:0.05178, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10366, Train Loss:0.08750, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10367, Train Loss:0.01703, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10368, Train Loss:0.13235, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10369, Train Loss:0.00130, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10370, Train Loss:0.13194, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10371, Train Loss:0.06150, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10372, Train Loss:0.27738, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10373, Train Loss:0.13908, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10374, Train Loss:0.11139, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10375, Train Loss:0.01922, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10376, Train Loss:0.08822, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10377, Train Loss:0.06230, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10378, Train Loss:0.34061, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10379, Train Loss:0.00634, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10380, Train Loss:0.06136, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10381, Train Loss:0.18106, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10382, Train Loss:0.10281, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10383, Train Loss:0.08697, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10384, Train Loss:0.19372, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10385, Train Loss:0.03306, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10386, Train Loss:0.39279, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10387, Train Loss:0.02522, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10388, Train Loss:0.05028, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10389, Train Loss:0.48256, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10390, Train Loss:0.13329, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10391, Train Loss:0.13740, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10392, Train Loss:0.00151, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10393, Train Loss:0.15161, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10394, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10395, Train Loss:0.00355, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10396, Train Loss:0.00004, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10397, Train Loss:0.02219, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10398, Train Loss:0.06565, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10399, Train Loss:0.00002, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10400, Train Loss:0.04197, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10401, Train Loss:0.38015, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10402, Train Loss:0.03312, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10403, Train Loss:0.09888, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10404, Train Loss:0.23921, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10405, Train Loss:0.38048, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10406, Train Loss:0.01232, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10407, Train Loss:0.00333, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10408, Train Loss:0.12306, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10409, Train Loss:0.00004, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10410, Train Loss:0.04157, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10411, Train Loss:0.07665, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10412, Train Loss:0.04844, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10413, Train Loss:0.09464, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10414, Train Loss:0.17308, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10415, Train Loss:0.19085, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10416, Train Loss:0.01320, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10417, Train Loss:0.04047, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10418, Train Loss:0.00490, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10419, Train Loss:0.01707, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10420, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10421, Train Loss:0.00058, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10422, Train Loss:0.36301, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10423, Train Loss:0.00049, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10424, Train Loss:0.00428, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10425, Train Loss:0.00033, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10426, Train Loss:0.00310, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10427, Train Loss:0.05429, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10428, Train Loss:0.01629, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10429, Train Loss:0.04540, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10430, Train Loss:0.37534, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10431, Train Loss:0.13136, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10432, Train Loss:0.06038, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10433, Train Loss:0.05125, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10434, Train Loss:0.00027, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10435, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10436, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10437, Train Loss:0.00220, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10438, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10439, Train Loss:0.78108, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10440, Train Loss:0.00000, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10441, Train Loss:0.27604, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10442, Train Loss:0.00679, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10443, Train Loss:0.00001, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10444, Train Loss:0.00058, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10445, Train Loss:0.56500, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10446, Train Loss:0.01386, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10447, Train Loss:0.12141, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10448, Train Loss:0.00178, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10449, Train Loss:0.12167, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10450, Train Loss:0.00132, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10451, Train Loss:0.56976, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10452, Train Loss:0.14323, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10453, Train Loss:0.04412, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10454, Train Loss:0.00026, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10455, Train Loss:0.01349, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10456, Train Loss:0.43863, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10457, Train Loss:0.45406, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10458, Train Loss:0.05487, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10459, Train Loss:0.05956, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10460, Train Loss:0.09547, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10461, Train Loss:0.00225, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10462, Train Loss:0.55214, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10463, Train Loss:0.51055, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10464, Train Loss:0.03579, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10465, Train Loss:0.11858, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10466, Train Loss:0.00069, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10467, Train Loss:0.01950, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10468, Train Loss:0.00014, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10469, Train Loss:0.10772, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10470, Train Loss:0.20651, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10471, Train Loss:0.14366, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10472, Train Loss:0.22261, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10473, Train Loss:0.37237, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10474, Train Loss:0.05539, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10475, Train Loss:0.09097, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10476, Train Loss:0.39100, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10477, Train Loss:0.01084, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10478, Train Loss:0.08080, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10479, Train Loss:0.00237, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10480, Train Loss:0.41837, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10481, Train Loss:0.04544, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10482, Train Loss:0.21069, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10483, Train Loss:0.53041, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10484, Train Loss:0.00730, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10485, Train Loss:0.36517, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10486, Train Loss:0.46663, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10487, Train Loss:0.16390, Dev Loss:0.16509\n",
      "Epoch:[37/100], step:10488, Train Loss:0.84288, Dev Loss:0.16509\n",
      "Start Epoch: 38, Steps: 17\n",
      "Epoch:[38/100], step:10489, Train Loss:0.09779, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10490, Train Loss:0.16065, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10491, Train Loss:0.01336, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10492, Train Loss:0.02072, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10493, Train Loss:0.39031, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10494, Train Loss:0.00059, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10495, Train Loss:0.03304, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10496, Train Loss:0.00182, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10497, Train Loss:0.02427, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10498, Train Loss:0.00626, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10499, Train Loss:0.27762, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10500, Train Loss:0.38796, Dev Loss:0.16509\n",
      "Epoch:[38/100], step:10501, Train Loss:0.00018, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10502, Train Loss:0.18849, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10503, Train Loss:0.30710, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10504, Train Loss:0.05893, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10505, Train Loss:0.01958, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10506, Train Loss:0.16966, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10507, Train Loss:0.07931, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10508, Train Loss:0.16137, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10509, Train Loss:0.29899, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10510, Train Loss:0.02467, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10511, Train Loss:0.00002, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10512, Train Loss:0.39319, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10513, Train Loss:0.02507, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10514, Train Loss:0.00647, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10515, Train Loss:0.09516, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10516, Train Loss:0.34554, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10517, Train Loss:0.00631, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10518, Train Loss:0.08971, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10519, Train Loss:0.00323, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10520, Train Loss:0.09585, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10521, Train Loss:0.28284, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10522, Train Loss:0.01688, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10523, Train Loss:0.01053, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10524, Train Loss:0.05200, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10525, Train Loss:0.00731, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10526, Train Loss:0.04297, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10527, Train Loss:0.00058, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10528, Train Loss:0.00042, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10529, Train Loss:0.00005, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10530, Train Loss:0.07131, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10531, Train Loss:0.08465, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10532, Train Loss:0.00085, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10533, Train Loss:0.07835, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10534, Train Loss:0.00036, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10535, Train Loss:0.19448, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10536, Train Loss:0.62081, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10537, Train Loss:0.06443, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10538, Train Loss:0.00917, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10539, Train Loss:0.89893, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10540, Train Loss:0.34811, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10541, Train Loss:0.21123, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10542, Train Loss:0.03882, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10543, Train Loss:0.08106, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10544, Train Loss:0.48798, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10545, Train Loss:0.00075, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10546, Train Loss:0.00003, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10547, Train Loss:0.00265, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10548, Train Loss:0.24149, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10549, Train Loss:0.02524, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10550, Train Loss:0.00303, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10551, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10552, Train Loss:0.00200, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10553, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10554, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10555, Train Loss:0.00189, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10556, Train Loss:0.05150, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10557, Train Loss:0.05916, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10558, Train Loss:0.30774, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10559, Train Loss:0.00309, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10560, Train Loss:0.00303, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10561, Train Loss:0.00013, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10562, Train Loss:0.01507, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10563, Train Loss:0.00195, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10564, Train Loss:0.00083, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10565, Train Loss:0.09993, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10566, Train Loss:0.00025, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10567, Train Loss:0.00186, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10568, Train Loss:2.69339, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10569, Train Loss:0.07180, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10570, Train Loss:0.09923, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10571, Train Loss:0.00097, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10572, Train Loss:0.18942, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10573, Train Loss:0.56854, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10574, Train Loss:0.00673, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10575, Train Loss:0.09781, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10576, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10577, Train Loss:0.08785, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10578, Train Loss:0.04183, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10579, Train Loss:0.00117, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10580, Train Loss:0.04365, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10581, Train Loss:0.67563, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10582, Train Loss:0.09148, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10583, Train Loss:0.03231, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10584, Train Loss:0.02741, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10585, Train Loss:0.00002, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10586, Train Loss:0.00377, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10587, Train Loss:0.04982, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10588, Train Loss:0.00131, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10589, Train Loss:0.00776, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10590, Train Loss:0.03193, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10591, Train Loss:0.03941, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10592, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10593, Train Loss:0.01168, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10594, Train Loss:0.00012, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10595, Train Loss:0.00064, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10596, Train Loss:0.51833, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10597, Train Loss:0.00005, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10598, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10599, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10600, Train Loss:0.00004, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10601, Train Loss:0.09859, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10602, Train Loss:0.27080, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10603, Train Loss:0.00701, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10604, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10605, Train Loss:0.00004, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10606, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10607, Train Loss:0.11787, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10608, Train Loss:0.12747, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10609, Train Loss:0.01069, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10610, Train Loss:0.00010, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10611, Train Loss:0.00854, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10612, Train Loss:0.00095, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10613, Train Loss:0.00462, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10614, Train Loss:0.01532, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10615, Train Loss:0.00380, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10616, Train Loss:0.00186, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10617, Train Loss:0.00546, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10618, Train Loss:0.00045, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10619, Train Loss:0.26536, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10620, Train Loss:0.04050, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10621, Train Loss:0.27877, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10622, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10623, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10624, Train Loss:0.49839, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10625, Train Loss:0.00251, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10626, Train Loss:0.39725, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10627, Train Loss:1.09290, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10628, Train Loss:0.47991, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10629, Train Loss:0.18113, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10630, Train Loss:0.14077, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10631, Train Loss:0.14886, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10632, Train Loss:0.00089, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10633, Train Loss:0.24055, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10634, Train Loss:0.09982, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10635, Train Loss:0.36017, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10636, Train Loss:0.36061, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10637, Train Loss:0.00730, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10638, Train Loss:0.47383, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10639, Train Loss:0.30285, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10640, Train Loss:0.32026, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10641, Train Loss:0.25810, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10642, Train Loss:0.48102, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10643, Train Loss:0.01976, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10644, Train Loss:0.23692, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10645, Train Loss:0.03333, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10646, Train Loss:0.52844, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10647, Train Loss:0.20495, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10648, Train Loss:0.22908, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10649, Train Loss:0.02833, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10650, Train Loss:0.05117, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10651, Train Loss:0.21860, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10652, Train Loss:0.39540, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10653, Train Loss:0.13290, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10654, Train Loss:0.00129, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10655, Train Loss:0.00531, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10656, Train Loss:0.14623, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10657, Train Loss:0.23136, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10658, Train Loss:0.10721, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10659, Train Loss:0.01803, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10660, Train Loss:0.18932, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10661, Train Loss:0.09475, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10662, Train Loss:0.00339, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10663, Train Loss:0.11282, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10664, Train Loss:0.30723, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10665, Train Loss:0.00328, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10666, Train Loss:0.20400, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10667, Train Loss:0.00009, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10668, Train Loss:0.08775, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10669, Train Loss:0.00009, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10670, Train Loss:0.52089, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10671, Train Loss:0.37563, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10672, Train Loss:0.29274, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10673, Train Loss:0.00231, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10674, Train Loss:0.05603, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10675, Train Loss:0.76898, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10676, Train Loss:0.00005, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10677, Train Loss:0.08247, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10678, Train Loss:0.00012, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10679, Train Loss:0.45579, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10680, Train Loss:0.32232, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10681, Train Loss:0.08746, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10682, Train Loss:0.03614, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10683, Train Loss:0.13413, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10684, Train Loss:0.13086, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10685, Train Loss:0.02610, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10686, Train Loss:0.00740, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10687, Train Loss:0.08770, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10688, Train Loss:0.00106, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10689, Train Loss:0.02522, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10690, Train Loss:0.08020, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10691, Train Loss:0.03013, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10692, Train Loss:0.18449, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10693, Train Loss:0.23567, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10694, Train Loss:0.16997, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10695, Train Loss:0.04604, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10696, Train Loss:0.00021, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10697, Train Loss:0.00919, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10698, Train Loss:0.00014, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10699, Train Loss:0.11665, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10700, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10701, Train Loss:0.12699, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10702, Train Loss:0.12742, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10703, Train Loss:0.00059, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10704, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10705, Train Loss:0.00615, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10706, Train Loss:0.04402, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10707, Train Loss:0.02087, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10708, Train Loss:0.22168, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10709, Train Loss:0.07129, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10710, Train Loss:0.39705, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10711, Train Loss:0.00143, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10712, Train Loss:0.01257, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10713, Train Loss:0.02935, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10714, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10715, Train Loss:0.01980, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10716, Train Loss:0.05933, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10717, Train Loss:0.00283, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10718, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10719, Train Loss:0.03472, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10720, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10721, Train Loss:0.00697, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10722, Train Loss:0.01472, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10723, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10724, Train Loss:0.44148, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10725, Train Loss:0.00007, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10726, Train Loss:0.00060, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10727, Train Loss:0.00047, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10728, Train Loss:0.02229, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10729, Train Loss:0.00023, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10730, Train Loss:0.15501, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10731, Train Loss:0.00001, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10732, Train Loss:0.00255, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10733, Train Loss:0.00837, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10734, Train Loss:0.00197, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10735, Train Loss:0.13647, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10736, Train Loss:0.00085, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10737, Train Loss:0.00000, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10738, Train Loss:0.00008, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10739, Train Loss:0.31831, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10740, Train Loss:0.00005, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10741, Train Loss:0.01142, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10742, Train Loss:0.32231, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10743, Train Loss:0.00760, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10744, Train Loss:0.26112, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10745, Train Loss:0.05654, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10746, Train Loss:0.08466, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10747, Train Loss:0.67221, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10748, Train Loss:0.00015, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10749, Train Loss:0.00104, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10750, Train Loss:0.02400, Dev Loss:0.09942\n",
      "Epoch:[38/100], step:10751, Train Loss:0.00016, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10752, Train Loss:0.00081, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10753, Train Loss:0.28371, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10754, Train Loss:0.00932, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10755, Train Loss:0.69355, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10756, Train Loss:0.03912, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10757, Train Loss:0.34942, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10758, Train Loss:0.10076, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10759, Train Loss:0.00704, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10760, Train Loss:0.01084, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10761, Train Loss:0.01410, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10762, Train Loss:0.00440, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10763, Train Loss:0.00002, Dev Loss:0.11993\n",
      "Epoch:[38/100], step:10764, Train Loss:0.02345, Dev Loss:0.11993\n",
      "Start Epoch: 39, Steps: 17\n",
      "Epoch:[39/100], step:10765, Train Loss:0.04775, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10766, Train Loss:0.00148, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10767, Train Loss:0.00107, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10768, Train Loss:0.00693, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10769, Train Loss:0.05122, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10770, Train Loss:0.27719, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10771, Train Loss:0.22366, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10772, Train Loss:0.01742, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10773, Train Loss:0.43810, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10774, Train Loss:0.00051, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10775, Train Loss:0.08292, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10776, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10777, Train Loss:0.00208, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10778, Train Loss:0.07837, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10779, Train Loss:0.00004, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10780, Train Loss:0.00247, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10781, Train Loss:0.00719, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10782, Train Loss:0.00070, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10783, Train Loss:0.00003, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10784, Train Loss:0.01576, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10785, Train Loss:0.00630, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10786, Train Loss:0.10009, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10787, Train Loss:0.71682, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10788, Train Loss:0.00122, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10789, Train Loss:0.00315, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10790, Train Loss:0.08210, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10791, Train Loss:0.18611, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10792, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10793, Train Loss:0.05069, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10794, Train Loss:0.00677, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10795, Train Loss:0.07854, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10796, Train Loss:0.00052, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10797, Train Loss:0.04896, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10798, Train Loss:0.00005, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10799, Train Loss:0.59104, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10800, Train Loss:0.01947, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10801, Train Loss:0.00010, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10802, Train Loss:0.00025, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10803, Train Loss:0.00258, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10804, Train Loss:0.02040, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10805, Train Loss:0.00005, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10806, Train Loss:0.02926, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10807, Train Loss:0.09101, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10808, Train Loss:0.11349, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10809, Train Loss:0.16637, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10810, Train Loss:0.00098, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10811, Train Loss:0.00528, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10812, Train Loss:0.07119, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10813, Train Loss:0.01639, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10814, Train Loss:0.00021, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10815, Train Loss:0.22754, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10816, Train Loss:0.01076, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10817, Train Loss:0.98449, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10818, Train Loss:1.12669, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10819, Train Loss:0.05558, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10820, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10821, Train Loss:0.44349, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10822, Train Loss:0.00017, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10823, Train Loss:0.57281, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10824, Train Loss:0.10616, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10825, Train Loss:0.00049, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10826, Train Loss:0.00265, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10827, Train Loss:0.00004, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10828, Train Loss:0.11652, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10829, Train Loss:0.00021, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10830, Train Loss:0.00066, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10831, Train Loss:0.00007, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10832, Train Loss:0.00005, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10833, Train Loss:0.00189, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10834, Train Loss:0.01517, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10835, Train Loss:0.00006, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10836, Train Loss:0.00037, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10837, Train Loss:0.28336, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10838, Train Loss:0.20417, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10839, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10840, Train Loss:0.07463, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10841, Train Loss:0.00302, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10842, Train Loss:0.21097, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10843, Train Loss:0.01194, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10844, Train Loss:0.07548, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10845, Train Loss:0.08348, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10846, Train Loss:0.00006, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10847, Train Loss:0.03975, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10848, Train Loss:0.00015, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10849, Train Loss:0.00004, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10850, Train Loss:0.07052, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10851, Train Loss:0.15980, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10852, Train Loss:0.00059, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10853, Train Loss:0.00002, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10854, Train Loss:0.11374, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10855, Train Loss:0.00028, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10856, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10857, Train Loss:0.00121, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10858, Train Loss:0.10438, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10859, Train Loss:0.49067, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10860, Train Loss:0.65880, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10861, Train Loss:0.05085, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10862, Train Loss:0.01101, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10863, Train Loss:0.04188, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10864, Train Loss:0.14054, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10865, Train Loss:0.21225, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10866, Train Loss:0.12399, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10867, Train Loss:0.35878, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10868, Train Loss:0.06051, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10869, Train Loss:0.01717, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10870, Train Loss:0.09984, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10871, Train Loss:0.00750, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10872, Train Loss:0.06171, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10873, Train Loss:0.01376, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10874, Train Loss:0.75200, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10875, Train Loss:0.10677, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10876, Train Loss:0.33853, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10877, Train Loss:0.07665, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10878, Train Loss:0.06468, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10879, Train Loss:0.01638, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10880, Train Loss:0.02024, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10881, Train Loss:0.00352, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10882, Train Loss:0.00040, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10883, Train Loss:0.00256, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10884, Train Loss:0.01576, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10885, Train Loss:0.00781, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10886, Train Loss:0.00037, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10887, Train Loss:0.05069, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10888, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10889, Train Loss:0.05494, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10890, Train Loss:0.34184, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10891, Train Loss:0.06089, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10892, Train Loss:0.00058, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10893, Train Loss:0.09202, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10894, Train Loss:0.00057, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10895, Train Loss:0.00005, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10896, Train Loss:0.20903, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10897, Train Loss:0.01846, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10898, Train Loss:0.10803, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10899, Train Loss:0.24700, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10900, Train Loss:0.00013, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10901, Train Loss:0.51640, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10902, Train Loss:0.00085, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10903, Train Loss:0.00020, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10904, Train Loss:0.01021, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10905, Train Loss:0.16357, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10906, Train Loss:0.31807, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10907, Train Loss:0.00002, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10908, Train Loss:0.00589, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10909, Train Loss:0.28931, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10910, Train Loss:0.00011, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10911, Train Loss:0.09006, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10912, Train Loss:0.14350, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10913, Train Loss:0.04217, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10914, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10915, Train Loss:0.13242, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10916, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10917, Train Loss:0.42947, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10918, Train Loss:0.00851, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10919, Train Loss:0.58856, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10920, Train Loss:0.46027, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10921, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10922, Train Loss:0.00853, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10923, Train Loss:0.24145, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10924, Train Loss:0.01796, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10925, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10926, Train Loss:0.37172, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10927, Train Loss:0.17297, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10928, Train Loss:0.00013, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10929, Train Loss:0.57608, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10930, Train Loss:0.17427, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10931, Train Loss:0.00005, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10932, Train Loss:0.03432, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10933, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10934, Train Loss:0.05282, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10935, Train Loss:0.05277, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10936, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10937, Train Loss:0.09525, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10938, Train Loss:0.01749, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10939, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10940, Train Loss:0.00922, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10941, Train Loss:0.02274, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10942, Train Loss:0.30942, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10943, Train Loss:0.00119, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10944, Train Loss:0.00216, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10945, Train Loss:0.09948, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10946, Train Loss:0.00307, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10947, Train Loss:0.00689, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10948, Train Loss:0.00022, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10949, Train Loss:0.00041, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10950, Train Loss:0.34131, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10951, Train Loss:0.11068, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10952, Train Loss:0.00826, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10953, Train Loss:0.00262, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10954, Train Loss:0.08469, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10955, Train Loss:0.05553, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10956, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10957, Train Loss:0.13874, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10958, Train Loss:0.06269, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10959, Train Loss:0.00224, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10960, Train Loss:0.00565, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10961, Train Loss:0.05563, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10962, Train Loss:0.03875, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10963, Train Loss:0.02267, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10964, Train Loss:0.12790, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10965, Train Loss:0.33262, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10966, Train Loss:0.00028, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10967, Train Loss:0.00152, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10968, Train Loss:0.05412, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10969, Train Loss:0.02140, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10970, Train Loss:0.00034, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10971, Train Loss:0.26768, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10972, Train Loss:0.10779, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10973, Train Loss:0.06680, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10974, Train Loss:0.11764, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10975, Train Loss:0.00000, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10976, Train Loss:0.57729, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10977, Train Loss:0.00081, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10978, Train Loss:0.07939, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10979, Train Loss:0.09473, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10980, Train Loss:0.32724, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10981, Train Loss:0.13902, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10982, Train Loss:0.10641, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10983, Train Loss:0.22686, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10984, Train Loss:0.05040, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10985, Train Loss:0.00094, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10986, Train Loss:0.09825, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10987, Train Loss:0.00643, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10988, Train Loss:0.09578, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10989, Train Loss:0.15061, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10990, Train Loss:0.00031, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10991, Train Loss:0.69295, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10992, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10993, Train Loss:0.05528, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10994, Train Loss:0.00001, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10995, Train Loss:0.10899, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10996, Train Loss:0.50348, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10997, Train Loss:0.08925, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10998, Train Loss:0.00010, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:10999, Train Loss:0.00007, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:11000, Train Loss:0.05827, Dev Loss:0.11993\n",
      "Epoch:[39/100], step:11001, Train Loss:0.09408, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11002, Train Loss:0.12369, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11003, Train Loss:0.00013, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11004, Train Loss:0.34756, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11005, Train Loss:0.00434, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11006, Train Loss:0.28023, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11007, Train Loss:0.00918, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11008, Train Loss:0.00217, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11009, Train Loss:0.22731, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11010, Train Loss:0.00013, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11011, Train Loss:0.00656, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11012, Train Loss:0.07996, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11013, Train Loss:0.00034, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11014, Train Loss:0.05771, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11015, Train Loss:0.07105, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11016, Train Loss:0.17864, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11017, Train Loss:0.55507, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11018, Train Loss:0.00379, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11019, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11020, Train Loss:0.04952, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11021, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11022, Train Loss:0.42371, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11023, Train Loss:0.17578, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11024, Train Loss:0.00007, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11025, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11026, Train Loss:0.00027, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11027, Train Loss:0.10094, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11028, Train Loss:0.24647, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11029, Train Loss:0.02135, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11030, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11031, Train Loss:0.16812, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11032, Train Loss:0.00062, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11033, Train Loss:0.72751, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11034, Train Loss:0.00915, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11035, Train Loss:0.42723, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11036, Train Loss:0.00805, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11037, Train Loss:0.00733, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11038, Train Loss:0.01320, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11039, Train Loss:0.07225, Dev Loss:0.09319\n",
      "Epoch:[39/100], step:11040, Train Loss:0.12567, Dev Loss:0.09319\n",
      "Start Epoch: 40, Steps: 17\n",
      "Epoch:[40/100], step:11041, Train Loss:0.15297, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11042, Train Loss:0.11797, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11043, Train Loss:0.00642, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11044, Train Loss:0.19048, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11045, Train Loss:0.09315, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11046, Train Loss:0.00004, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11047, Train Loss:0.00006, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11048, Train Loss:0.10756, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11049, Train Loss:0.00347, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11050, Train Loss:0.01170, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11051, Train Loss:0.47293, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11052, Train Loss:0.00027, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11053, Train Loss:0.00782, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11054, Train Loss:0.00003, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11055, Train Loss:0.16199, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11056, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11057, Train Loss:0.33233, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11058, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11059, Train Loss:0.05609, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11060, Train Loss:0.00031, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11061, Train Loss:0.00003, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11062, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11063, Train Loss:0.00336, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11064, Train Loss:0.06950, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11065, Train Loss:0.00381, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11066, Train Loss:0.04517, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11067, Train Loss:0.04598, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11068, Train Loss:0.00343, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11069, Train Loss:0.00030, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11070, Train Loss:2.83563, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11071, Train Loss:0.00697, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11072, Train Loss:0.00024, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11073, Train Loss:0.20082, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11074, Train Loss:0.01168, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11075, Train Loss:0.05822, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11076, Train Loss:0.00024, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11077, Train Loss:0.12756, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11078, Train Loss:0.26570, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11079, Train Loss:0.15218, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11080, Train Loss:0.13535, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11081, Train Loss:1.25283, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11082, Train Loss:0.21102, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11083, Train Loss:0.01054, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11084, Train Loss:0.00394, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11085, Train Loss:0.25049, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11086, Train Loss:0.21331, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11087, Train Loss:0.23786, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11088, Train Loss:0.22255, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11089, Train Loss:0.08351, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11090, Train Loss:0.03882, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11091, Train Loss:0.13057, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11092, Train Loss:0.00356, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11093, Train Loss:0.14586, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11094, Train Loss:0.09974, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11095, Train Loss:0.07848, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11096, Train Loss:0.13611, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11097, Train Loss:0.38300, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11098, Train Loss:0.35065, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11099, Train Loss:0.00444, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11100, Train Loss:0.05242, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11101, Train Loss:0.40915, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11102, Train Loss:0.00091, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11103, Train Loss:0.07041, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11104, Train Loss:0.11274, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11105, Train Loss:0.00044, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11106, Train Loss:0.09926, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11107, Train Loss:0.00330, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11108, Train Loss:0.04613, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11109, Train Loss:0.06865, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11110, Train Loss:0.00486, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11111, Train Loss:0.14218, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11112, Train Loss:0.05058, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11113, Train Loss:0.09477, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11114, Train Loss:0.00316, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11115, Train Loss:0.16864, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11116, Train Loss:0.00002, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11117, Train Loss:0.05901, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11118, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11119, Train Loss:0.07596, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11120, Train Loss:0.41866, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11121, Train Loss:0.32576, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11122, Train Loss:0.89488, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11123, Train Loss:0.12469, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11124, Train Loss:0.00049, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11125, Train Loss:0.05829, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11126, Train Loss:0.01805, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11127, Train Loss:0.00004, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11128, Train Loss:0.10220, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11129, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11130, Train Loss:0.62551, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11131, Train Loss:0.03926, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11132, Train Loss:0.53481, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11133, Train Loss:0.21524, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11134, Train Loss:0.06282, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11135, Train Loss:0.52825, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11136, Train Loss:0.04748, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11137, Train Loss:0.00725, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11138, Train Loss:0.07315, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11139, Train Loss:0.03230, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11140, Train Loss:0.04232, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11141, Train Loss:0.94285, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11142, Train Loss:0.65125, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11143, Train Loss:0.00143, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11144, Train Loss:0.15651, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11145, Train Loss:0.01321, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11146, Train Loss:0.05104, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11147, Train Loss:0.38794, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11148, Train Loss:0.05072, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11149, Train Loss:0.09433, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11150, Train Loss:0.02201, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11151, Train Loss:0.21001, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11152, Train Loss:0.24673, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11153, Train Loss:0.11579, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11154, Train Loss:0.12099, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11155, Train Loss:0.10313, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11156, Train Loss:0.02742, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11157, Train Loss:0.17013, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11158, Train Loss:0.84783, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11159, Train Loss:0.04360, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11160, Train Loss:0.07662, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11161, Train Loss:0.09828, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11162, Train Loss:0.09240, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11163, Train Loss:0.31055, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11164, Train Loss:1.30277, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11165, Train Loss:0.12256, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11166, Train Loss:0.00092, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11167, Train Loss:0.35477, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11168, Train Loss:0.00170, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11169, Train Loss:0.00612, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11170, Train Loss:0.04959, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11171, Train Loss:0.00229, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11172, Train Loss:0.25102, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11173, Train Loss:0.47281, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11174, Train Loss:0.64207, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11175, Train Loss:0.51157, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11176, Train Loss:0.03146, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11177, Train Loss:0.05721, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11178, Train Loss:0.14536, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11179, Train Loss:0.09188, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11180, Train Loss:0.22904, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11181, Train Loss:0.09191, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11182, Train Loss:0.36416, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11183, Train Loss:0.27435, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11184, Train Loss:0.19186, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11185, Train Loss:0.96455, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11186, Train Loss:0.02011, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11187, Train Loss:0.59759, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11188, Train Loss:0.03319, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11189, Train Loss:0.22751, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11190, Train Loss:0.69568, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11191, Train Loss:0.00595, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11192, Train Loss:0.49572, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11193, Train Loss:0.03849, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11194, Train Loss:0.11945, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11195, Train Loss:0.04056, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11196, Train Loss:0.00025, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11197, Train Loss:0.04649, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11198, Train Loss:0.49809, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11199, Train Loss:0.06880, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11200, Train Loss:0.53823, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11201, Train Loss:0.43826, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11202, Train Loss:0.02088, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11203, Train Loss:0.03367, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11204, Train Loss:0.05489, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11205, Train Loss:0.30670, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11206, Train Loss:0.05885, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11207, Train Loss:0.10377, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11208, Train Loss:0.03271, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11209, Train Loss:0.00148, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11210, Train Loss:0.03096, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11211, Train Loss:0.24380, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11212, Train Loss:0.00010, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11213, Train Loss:0.70412, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11214, Train Loss:0.03794, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11215, Train Loss:0.01078, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11216, Train Loss:0.01770, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11217, Train Loss:0.07521, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11218, Train Loss:0.42790, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11219, Train Loss:0.18850, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11220, Train Loss:0.28429, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11221, Train Loss:0.08793, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11222, Train Loss:0.23118, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11223, Train Loss:0.16154, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11224, Train Loss:0.00000, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11225, Train Loss:0.03926, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11226, Train Loss:0.06943, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11227, Train Loss:0.07454, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11228, Train Loss:0.05640, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11229, Train Loss:0.00064, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11230, Train Loss:0.00032, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11231, Train Loss:0.16617, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11232, Train Loss:0.10292, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11233, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11234, Train Loss:0.00954, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11235, Train Loss:0.00620, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11236, Train Loss:0.10184, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11237, Train Loss:0.02142, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11238, Train Loss:0.10567, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11239, Train Loss:0.06034, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11240, Train Loss:0.00051, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11241, Train Loss:0.02527, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11242, Train Loss:0.19143, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11243, Train Loss:0.00003, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11244, Train Loss:0.00259, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11245, Train Loss:0.00001, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11246, Train Loss:0.23827, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11247, Train Loss:0.33221, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11248, Train Loss:0.07015, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11249, Train Loss:0.29568, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11250, Train Loss:0.16175, Dev Loss:0.09319\n",
      "Epoch:[40/100], step:11251, Train Loss:0.01969, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11252, Train Loss:0.01277, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11253, Train Loss:0.05575, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11254, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11255, Train Loss:0.00038, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11256, Train Loss:0.00854, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11257, Train Loss:0.50479, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11258, Train Loss:0.25077, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11259, Train Loss:0.00004, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11260, Train Loss:0.00804, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11261, Train Loss:0.33966, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11262, Train Loss:0.00693, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11263, Train Loss:0.00262, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11264, Train Loss:0.21115, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11265, Train Loss:0.00011, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11266, Train Loss:0.07985, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11267, Train Loss:0.32137, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11268, Train Loss:0.15371, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11269, Train Loss:0.03168, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11270, Train Loss:0.05000, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11271, Train Loss:0.08863, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11272, Train Loss:0.00001, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11273, Train Loss:0.11118, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11274, Train Loss:0.00002, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11275, Train Loss:0.02717, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11276, Train Loss:0.48732, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11277, Train Loss:0.58539, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11278, Train Loss:0.00415, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11279, Train Loss:0.00416, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11280, Train Loss:0.07615, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11281, Train Loss:0.00941, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11282, Train Loss:0.01507, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11283, Train Loss:0.09179, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11284, Train Loss:0.23250, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11285, Train Loss:0.08673, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11286, Train Loss:0.05717, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11287, Train Loss:0.00831, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11288, Train Loss:0.34412, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11289, Train Loss:0.03423, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11290, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11291, Train Loss:0.00421, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11292, Train Loss:0.05055, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11293, Train Loss:0.16398, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11294, Train Loss:0.08897, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11295, Train Loss:0.06165, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11296, Train Loss:0.31501, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11297, Train Loss:0.16095, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11298, Train Loss:0.01559, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11299, Train Loss:0.00009, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11300, Train Loss:0.00468, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11301, Train Loss:0.06550, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11302, Train Loss:0.00239, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11303, Train Loss:0.05967, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11304, Train Loss:0.16358, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11305, Train Loss:0.00090, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11306, Train Loss:0.21346, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11307, Train Loss:0.16250, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11308, Train Loss:0.00126, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11309, Train Loss:0.03991, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11310, Train Loss:0.00302, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11311, Train Loss:0.02459, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11312, Train Loss:0.01491, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11313, Train Loss:0.03898, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11314, Train Loss:0.51991, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11315, Train Loss:0.00035, Dev Loss:0.10644\n",
      "Epoch:[40/100], step:11316, Train Loss:0.00006, Dev Loss:0.10644\n",
      "Start Epoch: 41, Steps: 17\n",
      "Epoch:[41/100], step:11317, Train Loss:0.22725, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11318, Train Loss:0.00026, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11319, Train Loss:0.00055, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11320, Train Loss:0.14645, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11321, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11322, Train Loss:0.48136, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11323, Train Loss:0.00375, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11324, Train Loss:0.07440, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11325, Train Loss:0.09722, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11326, Train Loss:0.22022, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11327, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11328, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11329, Train Loss:0.00013, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11330, Train Loss:0.41595, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11331, Train Loss:0.02747, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11332, Train Loss:0.05640, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11333, Train Loss:0.01453, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11334, Train Loss:0.07875, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11335, Train Loss:0.05985, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11336, Train Loss:0.13453, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11337, Train Loss:0.00017, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11338, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11339, Train Loss:0.03177, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11340, Train Loss:0.06955, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11341, Train Loss:0.02205, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11342, Train Loss:0.01385, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11343, Train Loss:0.16183, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11344, Train Loss:0.01286, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11345, Train Loss:0.01135, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11346, Train Loss:0.38175, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11347, Train Loss:0.00155, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11348, Train Loss:0.01781, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11349, Train Loss:0.00070, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11350, Train Loss:0.03494, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11351, Train Loss:0.14351, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11352, Train Loss:0.00015, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11353, Train Loss:0.00053, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11354, Train Loss:0.18269, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11355, Train Loss:0.26002, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11356, Train Loss:0.00120, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11357, Train Loss:0.06394, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11358, Train Loss:0.00297, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11359, Train Loss:0.09169, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11360, Train Loss:0.00039, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11361, Train Loss:0.06501, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11362, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11363, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11364, Train Loss:0.00015, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11365, Train Loss:0.00025, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11366, Train Loss:0.14274, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11367, Train Loss:0.00023, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11368, Train Loss:0.13075, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11369, Train Loss:0.01040, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11370, Train Loss:0.01802, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11371, Train Loss:0.00958, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11372, Train Loss:0.00351, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11373, Train Loss:0.07214, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11374, Train Loss:0.28550, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11375, Train Loss:0.00013, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11376, Train Loss:0.00065, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11377, Train Loss:0.00012, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11378, Train Loss:0.08240, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11379, Train Loss:0.10982, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11380, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11381, Train Loss:0.03477, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11382, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11383, Train Loss:0.23769, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11384, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11385, Train Loss:0.12942, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11386, Train Loss:0.00204, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11387, Train Loss:0.00008, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11388, Train Loss:0.01443, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11389, Train Loss:0.00073, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11390, Train Loss:0.15653, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11391, Train Loss:0.02166, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11392, Train Loss:0.00006, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11393, Train Loss:0.01062, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11394, Train Loss:0.00005, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11395, Train Loss:0.00187, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11396, Train Loss:0.00002, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11397, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11398, Train Loss:0.00003, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11399, Train Loss:0.04395, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11400, Train Loss:0.18740, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11401, Train Loss:0.08021, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11402, Train Loss:0.11387, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11403, Train Loss:0.00003, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11404, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11405, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11406, Train Loss:0.00120, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11407, Train Loss:0.00011, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11408, Train Loss:0.07944, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11409, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11410, Train Loss:0.02114, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11411, Train Loss:0.10703, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11412, Train Loss:0.00050, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11413, Train Loss:0.00237, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11414, Train Loss:0.04907, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11415, Train Loss:0.00001, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11416, Train Loss:0.01988, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11417, Train Loss:0.03427, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11418, Train Loss:0.02228, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11419, Train Loss:0.07579, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11420, Train Loss:0.32485, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11421, Train Loss:0.17136, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11422, Train Loss:0.00002, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11423, Train Loss:0.00004, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11424, Train Loss:0.07573, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11425, Train Loss:0.10857, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11426, Train Loss:0.17278, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11427, Train Loss:0.11691, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11428, Train Loss:0.00141, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11429, Train Loss:0.10775, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11430, Train Loss:0.00021, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11431, Train Loss:0.00924, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11432, Train Loss:0.00183, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11433, Train Loss:0.00055, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11434, Train Loss:0.00813, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11435, Train Loss:0.32773, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11436, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11437, Train Loss:0.00093, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11438, Train Loss:0.00094, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11439, Train Loss:0.02912, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11440, Train Loss:0.01329, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11441, Train Loss:0.00074, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11442, Train Loss:0.09754, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11443, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11444, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11445, Train Loss:0.29683, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11446, Train Loss:0.11833, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11447, Train Loss:0.09002, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11448, Train Loss:0.22733, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11449, Train Loss:0.00870, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11450, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11451, Train Loss:0.43023, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11452, Train Loss:0.00002, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11453, Train Loss:0.20550, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11454, Train Loss:0.00373, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11455, Train Loss:0.12925, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11456, Train Loss:0.29343, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11457, Train Loss:0.00006, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11458, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11459, Train Loss:0.00052, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11460, Train Loss:0.00571, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11461, Train Loss:0.00887, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11462, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11463, Train Loss:0.03364, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11464, Train Loss:0.01138, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11465, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11466, Train Loss:0.09246, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11467, Train Loss:0.10047, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11468, Train Loss:0.00155, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11469, Train Loss:0.01625, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11470, Train Loss:0.01684, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11471, Train Loss:0.27956, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11472, Train Loss:0.00061, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11473, Train Loss:0.00934, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11474, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11475, Train Loss:0.06514, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11476, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11477, Train Loss:0.02432, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11478, Train Loss:0.00003, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11479, Train Loss:0.18899, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11480, Train Loss:0.00017, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11481, Train Loss:0.01069, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11482, Train Loss:0.10624, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11483, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11484, Train Loss:0.00816, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11485, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11486, Train Loss:0.00714, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11487, Train Loss:0.01751, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11488, Train Loss:0.21500, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11489, Train Loss:0.05131, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11490, Train Loss:0.11349, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11491, Train Loss:0.00473, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11492, Train Loss:0.18484, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11493, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11494, Train Loss:0.00242, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11495, Train Loss:0.00189, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11496, Train Loss:0.00000, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11497, Train Loss:0.03043, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11498, Train Loss:0.02204, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11499, Train Loss:0.59241, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11500, Train Loss:0.01615, Dev Loss:0.10644\n",
      "Epoch:[41/100], step:11501, Train Loss:0.32444, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11502, Train Loss:0.06145, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11503, Train Loss:0.08901, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11504, Train Loss:0.15849, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11505, Train Loss:0.37975, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11506, Train Loss:0.61957, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11507, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11508, Train Loss:0.22241, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11509, Train Loss:0.85204, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11510, Train Loss:0.02650, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11511, Train Loss:0.00430, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11512, Train Loss:0.42950, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11513, Train Loss:0.71987, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11514, Train Loss:0.18229, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11515, Train Loss:0.00419, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11516, Train Loss:0.00783, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11517, Train Loss:0.03055, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11518, Train Loss:0.03505, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11519, Train Loss:0.26245, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11520, Train Loss:0.13631, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11521, Train Loss:0.06180, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11522, Train Loss:0.58510, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11523, Train Loss:0.08663, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11524, Train Loss:0.00476, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11525, Train Loss:0.00321, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11526, Train Loss:0.78724, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11527, Train Loss:0.00015, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11528, Train Loss:0.13693, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11529, Train Loss:0.00036, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11530, Train Loss:0.00086, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11531, Train Loss:0.00858, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11532, Train Loss:0.00007, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11533, Train Loss:0.00000, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11534, Train Loss:0.21251, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11535, Train Loss:0.00258, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11536, Train Loss:0.28086, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11537, Train Loss:0.62344, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11538, Train Loss:0.00065, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11539, Train Loss:0.16197, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11540, Train Loss:0.00104, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11541, Train Loss:0.25599, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11542, Train Loss:0.08315, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11543, Train Loss:0.00004, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11544, Train Loss:0.17556, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11545, Train Loss:0.00816, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11546, Train Loss:0.03069, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11547, Train Loss:0.46223, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11548, Train Loss:0.00417, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11549, Train Loss:0.55470, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11550, Train Loss:0.00019, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11551, Train Loss:0.01932, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11552, Train Loss:0.00832, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11553, Train Loss:0.10258, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11554, Train Loss:0.07843, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11555, Train Loss:0.08122, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11556, Train Loss:0.10328, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11557, Train Loss:0.44163, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11558, Train Loss:0.49047, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11559, Train Loss:0.00094, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11560, Train Loss:0.87872, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11561, Train Loss:0.22692, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11562, Train Loss:0.00060, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11563, Train Loss:0.01174, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11564, Train Loss:0.08538, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11565, Train Loss:0.00000, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11566, Train Loss:1.63709, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11567, Train Loss:0.00010, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11568, Train Loss:0.00572, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11569, Train Loss:0.09859, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11570, Train Loss:0.05820, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11571, Train Loss:0.19766, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11572, Train Loss:0.19819, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11573, Train Loss:0.03359, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11574, Train Loss:0.08839, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11575, Train Loss:0.00176, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11576, Train Loss:0.55236, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11577, Train Loss:0.11321, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11578, Train Loss:0.05443, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11579, Train Loss:0.11127, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11580, Train Loss:0.06704, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11581, Train Loss:0.11428, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11582, Train Loss:0.09159, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11583, Train Loss:0.08101, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11584, Train Loss:0.00207, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11585, Train Loss:0.00467, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11586, Train Loss:0.08324, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11587, Train Loss:0.38711, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11588, Train Loss:0.04852, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11589, Train Loss:0.35696, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11590, Train Loss:0.46286, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11591, Train Loss:0.01384, Dev Loss:0.79268\n",
      "Epoch:[41/100], step:11592, Train Loss:0.00376, Dev Loss:0.79268\n",
      "Start Epoch: 42, Steps: 17\n",
      "Epoch:[42/100], step:11593, Train Loss:0.07986, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11594, Train Loss:0.63627, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11595, Train Loss:0.00154, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11596, Train Loss:0.01681, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11597, Train Loss:0.53716, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11598, Train Loss:0.30320, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11599, Train Loss:0.26064, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11600, Train Loss:0.16805, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11601, Train Loss:0.00720, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11602, Train Loss:0.00051, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11603, Train Loss:0.00004, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11604, Train Loss:0.00836, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11605, Train Loss:0.02529, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11606, Train Loss:0.00085, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11607, Train Loss:0.00040, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11608, Train Loss:0.02807, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11609, Train Loss:0.03941, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11610, Train Loss:0.04536, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11611, Train Loss:0.00921, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11612, Train Loss:0.00008, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11613, Train Loss:0.22431, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11614, Train Loss:0.00622, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11615, Train Loss:0.13892, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11616, Train Loss:0.11526, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11617, Train Loss:0.01425, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11618, Train Loss:0.00424, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11619, Train Loss:0.00439, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11620, Train Loss:0.02120, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11621, Train Loss:0.02040, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11622, Train Loss:0.00765, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11623, Train Loss:0.07505, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11624, Train Loss:0.00768, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11625, Train Loss:0.05500, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11626, Train Loss:0.00007, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11627, Train Loss:0.43836, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11628, Train Loss:0.01279, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11629, Train Loss:0.00132, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11630, Train Loss:0.02505, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11631, Train Loss:0.00704, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11632, Train Loss:0.01564, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11633, Train Loss:0.06856, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11634, Train Loss:0.01935, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11635, Train Loss:0.00400, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11636, Train Loss:0.29626, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11637, Train Loss:0.03950, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11638, Train Loss:0.00007, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11639, Train Loss:0.19473, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11640, Train Loss:0.02483, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11641, Train Loss:0.00121, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11642, Train Loss:0.34404, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11643, Train Loss:0.06188, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11644, Train Loss:0.27737, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11645, Train Loss:0.03846, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11646, Train Loss:0.25054, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11647, Train Loss:0.11408, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11648, Train Loss:0.36336, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11649, Train Loss:0.20415, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11650, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11651, Train Loss:0.18404, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11652, Train Loss:0.08129, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11653, Train Loss:0.00651, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11654, Train Loss:0.01255, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11655, Train Loss:0.01773, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11656, Train Loss:0.00618, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11657, Train Loss:0.14588, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11658, Train Loss:0.32295, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11659, Train Loss:0.13334, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11660, Train Loss:0.03959, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11661, Train Loss:0.08437, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11662, Train Loss:0.06577, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11663, Train Loss:0.12697, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11664, Train Loss:0.03896, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11665, Train Loss:0.00273, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11666, Train Loss:0.10058, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11667, Train Loss:0.02514, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11668, Train Loss:0.24090, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11669, Train Loss:0.22254, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11670, Train Loss:0.15941, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11671, Train Loss:0.00003, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11672, Train Loss:0.20904, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11673, Train Loss:0.24552, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11674, Train Loss:0.04829, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11675, Train Loss:0.35016, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11676, Train Loss:0.01267, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11677, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11678, Train Loss:0.04992, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11679, Train Loss:0.03535, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11680, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11681, Train Loss:0.02960, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11682, Train Loss:0.00014, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11683, Train Loss:0.00131, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11684, Train Loss:0.00054, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11685, Train Loss:0.77909, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11686, Train Loss:0.00207, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11687, Train Loss:0.05133, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11688, Train Loss:0.00304, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11689, Train Loss:0.10357, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11690, Train Loss:0.12630, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11691, Train Loss:0.10804, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11692, Train Loss:0.00031, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11693, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11694, Train Loss:0.01825, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11695, Train Loss:0.52552, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11696, Train Loss:0.00272, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11697, Train Loss:0.00014, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11698, Train Loss:0.08652, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11699, Train Loss:0.03313, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11700, Train Loss:0.00101, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11701, Train Loss:0.00121, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11702, Train Loss:0.03493, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11703, Train Loss:0.16366, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11704, Train Loss:0.00115, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11705, Train Loss:0.10962, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11706, Train Loss:0.00073, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11707, Train Loss:0.01649, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11708, Train Loss:0.09913, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11709, Train Loss:0.00924, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11710, Train Loss:0.00053, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11711, Train Loss:0.00022, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11712, Train Loss:0.16376, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11713, Train Loss:0.00007, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11714, Train Loss:0.06350, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11715, Train Loss:0.04833, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11716, Train Loss:0.00635, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11717, Train Loss:0.06974, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11718, Train Loss:0.00171, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11719, Train Loss:0.35043, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11720, Train Loss:0.09882, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11721, Train Loss:0.11619, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11722, Train Loss:0.00009, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11723, Train Loss:0.01951, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11724, Train Loss:0.00004, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11725, Train Loss:0.11743, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11726, Train Loss:0.71885, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11727, Train Loss:0.00300, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11728, Train Loss:0.51046, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11729, Train Loss:0.00018, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11730, Train Loss:0.21098, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11731, Train Loss:0.00880, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11732, Train Loss:0.26579, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11733, Train Loss:0.26997, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11734, Train Loss:0.38182, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11735, Train Loss:0.13858, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11736, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11737, Train Loss:0.00011, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11738, Train Loss:0.48173, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11739, Train Loss:0.33453, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11740, Train Loss:0.00166, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11741, Train Loss:0.00056, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11742, Train Loss:0.00070, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11743, Train Loss:0.09210, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11744, Train Loss:0.05281, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11745, Train Loss:0.11326, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11746, Train Loss:0.00001, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11747, Train Loss:0.08688, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11748, Train Loss:0.07146, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11749, Train Loss:0.13279, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11750, Train Loss:0.14594, Dev Loss:0.79268\n",
      "Epoch:[42/100], step:11751, Train Loss:0.24850, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11752, Train Loss:0.01200, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11753, Train Loss:0.21971, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11754, Train Loss:0.04429, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11755, Train Loss:0.14910, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11756, Train Loss:0.03243, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11757, Train Loss:0.14255, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11758, Train Loss:0.01258, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11759, Train Loss:0.09493, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11760, Train Loss:0.00056, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11761, Train Loss:0.00021, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11762, Train Loss:0.31593, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11763, Train Loss:0.20500, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11764, Train Loss:0.03939, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11765, Train Loss:0.00030, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11766, Train Loss:0.00069, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11767, Train Loss:0.69309, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11768, Train Loss:0.05392, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11769, Train Loss:0.45210, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11770, Train Loss:0.10130, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11771, Train Loss:0.12249, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11772, Train Loss:0.02044, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11773, Train Loss:0.00485, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11774, Train Loss:0.08178, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11775, Train Loss:0.00080, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11776, Train Loss:0.01665, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11777, Train Loss:0.00013, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11778, Train Loss:0.04561, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11779, Train Loss:0.17376, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11780, Train Loss:0.00328, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11781, Train Loss:0.00021, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11782, Train Loss:0.07700, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11783, Train Loss:0.10543, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11784, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11785, Train Loss:0.03573, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11786, Train Loss:0.16331, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11787, Train Loss:0.03006, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11788, Train Loss:0.03709, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11789, Train Loss:0.00043, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11790, Train Loss:0.00160, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11791, Train Loss:0.09167, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11792, Train Loss:0.02824, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11793, Train Loss:0.00124, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11794, Train Loss:0.00860, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11795, Train Loss:0.02145, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11796, Train Loss:0.00019, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11797, Train Loss:0.17984, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11798, Train Loss:0.20861, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11799, Train Loss:0.00016, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11800, Train Loss:0.18614, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11801, Train Loss:0.20012, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11802, Train Loss:0.00297, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11803, Train Loss:0.00520, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11804, Train Loss:0.04423, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11805, Train Loss:0.00013, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11806, Train Loss:0.00004, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11807, Train Loss:0.12812, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11808, Train Loss:0.41783, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11809, Train Loss:0.09285, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11810, Train Loss:0.01748, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11811, Train Loss:0.01963, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11812, Train Loss:0.02749, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11813, Train Loss:0.08296, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11814, Train Loss:0.00487, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11815, Train Loss:0.00029, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11816, Train Loss:0.01287, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11817, Train Loss:0.33185, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11818, Train Loss:0.00499, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11819, Train Loss:0.00030, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11820, Train Loss:0.05548, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11821, Train Loss:0.13672, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11822, Train Loss:0.17328, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11823, Train Loss:0.07639, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11824, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11825, Train Loss:0.00664, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11826, Train Loss:0.00003, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11827, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11828, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11829, Train Loss:0.42145, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11830, Train Loss:0.00068, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11831, Train Loss:0.01091, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11832, Train Loss:0.04275, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11833, Train Loss:0.26598, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11834, Train Loss:0.11766, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11835, Train Loss:0.17044, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11836, Train Loss:0.00481, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11837, Train Loss:0.08371, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11838, Train Loss:0.00086, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11839, Train Loss:0.00003, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11840, Train Loss:0.00106, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11841, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11842, Train Loss:0.03132, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11843, Train Loss:0.01806, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11844, Train Loss:0.07508, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11845, Train Loss:0.00298, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11846, Train Loss:0.00558, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11847, Train Loss:0.09740, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11848, Train Loss:0.00072, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11849, Train Loss:0.00020, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11850, Train Loss:0.00260, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11851, Train Loss:0.00061, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11852, Train Loss:0.14438, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11853, Train Loss:0.03008, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11854, Train Loss:0.19938, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11855, Train Loss:0.00005, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11856, Train Loss:0.00019, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11857, Train Loss:0.00137, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11858, Train Loss:0.14779, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11859, Train Loss:0.00284, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11860, Train Loss:0.04470, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11861, Train Loss:0.04766, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11862, Train Loss:0.00336, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11863, Train Loss:0.08640, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11864, Train Loss:0.02655, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11865, Train Loss:0.21502, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11866, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11867, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[42/100], step:11868, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Start Epoch: 43, Steps: 17\n",
      "Epoch:[43/100], step:11869, Train Loss:0.04018, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11870, Train Loss:0.00004, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11871, Train Loss:0.03506, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11872, Train Loss:0.17247, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11873, Train Loss:0.00031, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11874, Train Loss:0.10223, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11875, Train Loss:0.10414, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11876, Train Loss:0.01682, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11877, Train Loss:0.22455, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11878, Train Loss:0.04359, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11879, Train Loss:0.06102, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11880, Train Loss:0.10475, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11881, Train Loss:0.08097, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11882, Train Loss:0.08833, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11883, Train Loss:0.00085, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11884, Train Loss:0.00912, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11885, Train Loss:0.00005, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11886, Train Loss:0.04943, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11887, Train Loss:0.00850, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11888, Train Loss:0.02799, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11889, Train Loss:0.19362, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11890, Train Loss:0.05516, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11891, Train Loss:0.17168, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11892, Train Loss:0.00169, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11893, Train Loss:0.02108, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11894, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11895, Train Loss:0.50065, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11896, Train Loss:0.00013, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11897, Train Loss:0.00004, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11898, Train Loss:0.01413, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11899, Train Loss:0.00002, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11900, Train Loss:0.00007, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11901, Train Loss:0.04928, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11902, Train Loss:0.00209, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11903, Train Loss:0.00726, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11904, Train Loss:0.03379, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11905, Train Loss:0.00003, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11906, Train Loss:0.08415, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11907, Train Loss:0.00208, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11908, Train Loss:0.00007, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11909, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11910, Train Loss:0.00002, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11911, Train Loss:0.00023, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11912, Train Loss:0.00658, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11913, Train Loss:0.00355, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11914, Train Loss:0.04109, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11915, Train Loss:0.12385, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11916, Train Loss:0.00074, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11917, Train Loss:0.13144, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11918, Train Loss:0.00124, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11919, Train Loss:0.07130, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11920, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11921, Train Loss:0.07051, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11922, Train Loss:0.00767, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11923, Train Loss:0.00014, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11924, Train Loss:0.05348, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11925, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11926, Train Loss:0.00011, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11927, Train Loss:0.17930, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11928, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11929, Train Loss:0.03354, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11930, Train Loss:0.00008, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11931, Train Loss:0.02852, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11932, Train Loss:0.00092, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11933, Train Loss:0.03337, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11934, Train Loss:0.00017, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11935, Train Loss:0.16890, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11936, Train Loss:0.00417, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11937, Train Loss:0.03993, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11938, Train Loss:0.00175, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11939, Train Loss:0.09075, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11940, Train Loss:0.00032, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11941, Train Loss:0.03068, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11942, Train Loss:0.06947, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11943, Train Loss:0.03756, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11944, Train Loss:0.58528, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11945, Train Loss:0.00144, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11946, Train Loss:0.00416, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11947, Train Loss:0.00012, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11948, Train Loss:0.00027, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11949, Train Loss:0.01651, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11950, Train Loss:0.02892, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11951, Train Loss:0.05880, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11952, Train Loss:0.00012, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11953, Train Loss:0.09215, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11954, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11955, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11956, Train Loss:0.05401, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11957, Train Loss:0.03797, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11958, Train Loss:0.00038, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11959, Train Loss:0.00312, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11960, Train Loss:0.01844, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11961, Train Loss:0.00265, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11962, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11963, Train Loss:0.00052, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11964, Train Loss:0.00341, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11965, Train Loss:0.02047, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11966, Train Loss:0.08374, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11967, Train Loss:0.04673, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11968, Train Loss:0.00070, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11969, Train Loss:0.09922, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11970, Train Loss:0.09339, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11971, Train Loss:0.03744, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11972, Train Loss:0.00001, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11973, Train Loss:0.01768, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11974, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11975, Train Loss:0.00065, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11976, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11977, Train Loss:0.24881, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11978, Train Loss:0.00027, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11979, Train Loss:0.00004, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11980, Train Loss:0.23500, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11981, Train Loss:0.06899, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11982, Train Loss:0.07597, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11983, Train Loss:0.00003, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11984, Train Loss:0.15778, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11985, Train Loss:0.00429, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11986, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11987, Train Loss:0.36287, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11988, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11989, Train Loss:0.41651, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11990, Train Loss:0.07330, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11991, Train Loss:0.13998, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11992, Train Loss:0.00867, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11993, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11994, Train Loss:0.01969, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11995, Train Loss:0.71745, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11996, Train Loss:0.10704, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11997, Train Loss:0.03658, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11998, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:11999, Train Loss:0.00000, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:12000, Train Loss:0.09270, Dev Loss:0.11475\n",
      "Epoch:[43/100], step:12001, Train Loss:0.04226, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12002, Train Loss:0.06029, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12003, Train Loss:0.00078, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12004, Train Loss:0.05093, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12005, Train Loss:0.00001, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12006, Train Loss:0.41505, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12007, Train Loss:0.19124, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12008, Train Loss:0.01063, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12009, Train Loss:0.27246, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12010, Train Loss:0.69357, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12011, Train Loss:0.00001, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12012, Train Loss:0.71050, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12013, Train Loss:0.00493, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12014, Train Loss:0.50922, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12015, Train Loss:0.27159, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12016, Train Loss:0.21935, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12017, Train Loss:0.20108, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12018, Train Loss:0.03356, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12019, Train Loss:0.00695, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12020, Train Loss:0.17169, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12021, Train Loss:0.96310, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12022, Train Loss:0.22889, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12023, Train Loss:0.00205, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12024, Train Loss:0.26271, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12025, Train Loss:0.19018, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12026, Train Loss:0.12944, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12027, Train Loss:0.72829, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12028, Train Loss:0.01827, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12029, Train Loss:0.27458, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12030, Train Loss:0.04641, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12031, Train Loss:0.12686, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12032, Train Loss:0.00080, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12033, Train Loss:0.16986, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12034, Train Loss:0.03241, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12035, Train Loss:0.05026, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12036, Train Loss:0.03218, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12037, Train Loss:0.07911, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12038, Train Loss:0.06560, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12039, Train Loss:0.00400, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12040, Train Loss:0.22420, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12041, Train Loss:0.03734, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12042, Train Loss:0.00399, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12043, Train Loss:0.94197, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12044, Train Loss:0.11727, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12045, Train Loss:0.16812, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12046, Train Loss:0.00436, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12047, Train Loss:0.01689, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12048, Train Loss:0.00467, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12049, Train Loss:0.18811, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12050, Train Loss:0.03774, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12051, Train Loss:0.00561, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12052, Train Loss:0.17737, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12053, Train Loss:0.20352, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12054, Train Loss:0.18457, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12055, Train Loss:0.00063, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12056, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12057, Train Loss:0.04908, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12058, Train Loss:0.08244, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12059, Train Loss:0.10581, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12060, Train Loss:0.00007, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12061, Train Loss:0.00006, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12062, Train Loss:0.00009, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12063, Train Loss:0.01015, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12064, Train Loss:0.13653, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12065, Train Loss:0.20271, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12066, Train Loss:0.51218, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12067, Train Loss:0.08743, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12068, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12069, Train Loss:0.16192, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12070, Train Loss:0.05842, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12071, Train Loss:0.25083, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12072, Train Loss:0.13522, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12073, Train Loss:0.08014, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12074, Train Loss:0.14886, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12075, Train Loss:0.00213, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12076, Train Loss:0.02834, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12077, Train Loss:0.00236, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12078, Train Loss:0.00002, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12079, Train Loss:0.04241, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12080, Train Loss:0.02275, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12081, Train Loss:0.00081, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12082, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12083, Train Loss:0.24577, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12084, Train Loss:0.21365, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12085, Train Loss:0.00001, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12086, Train Loss:0.00143, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12087, Train Loss:0.14980, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12088, Train Loss:0.21604, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12089, Train Loss:0.21653, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12090, Train Loss:0.00034, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12091, Train Loss:0.00004, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12092, Train Loss:0.00011, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12093, Train Loss:0.00038, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12094, Train Loss:0.00330, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12095, Train Loss:0.00076, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12096, Train Loss:0.00085, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12097, Train Loss:0.01157, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12098, Train Loss:0.08322, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12099, Train Loss:0.13673, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12100, Train Loss:0.02633, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12101, Train Loss:0.00049, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12102, Train Loss:0.00098, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12103, Train Loss:0.00005, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12104, Train Loss:0.00027, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12105, Train Loss:0.35196, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12106, Train Loss:0.04494, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12107, Train Loss:0.08086, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12108, Train Loss:0.01895, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12109, Train Loss:0.04736, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12110, Train Loss:0.36104, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12111, Train Loss:0.08324, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12112, Train Loss:0.05764, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12113, Train Loss:0.00057, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12114, Train Loss:0.31610, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12115, Train Loss:0.04250, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12116, Train Loss:0.06630, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12117, Train Loss:0.00007, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12118, Train Loss:0.00083, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12119, Train Loss:0.00007, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12120, Train Loss:0.00002, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12121, Train Loss:0.18062, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12122, Train Loss:0.00029, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12123, Train Loss:0.00102, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12124, Train Loss:0.00016, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12125, Train Loss:0.22548, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12126, Train Loss:0.45790, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12127, Train Loss:0.00241, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12128, Train Loss:1.31130, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12129, Train Loss:0.20086, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12130, Train Loss:0.00206, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12131, Train Loss:0.11397, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12132, Train Loss:0.00254, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12133, Train Loss:0.32042, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12134, Train Loss:0.68830, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12135, Train Loss:0.40164, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12136, Train Loss:0.38680, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12137, Train Loss:0.39196, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12138, Train Loss:0.07154, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12139, Train Loss:0.17213, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12140, Train Loss:0.51165, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12141, Train Loss:0.38285, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12142, Train Loss:0.05273, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12143, Train Loss:0.12858, Dev Loss:0.22790\n",
      "Epoch:[43/100], step:12144, Train Loss:0.08591, Dev Loss:0.22790\n",
      "Start Epoch: 44, Steps: 17\n",
      "Epoch:[44/100], step:12145, Train Loss:0.06273, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12146, Train Loss:0.54101, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12147, Train Loss:0.02315, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12148, Train Loss:0.13520, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12149, Train Loss:0.15203, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12150, Train Loss:0.30697, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12151, Train Loss:0.10065, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12152, Train Loss:0.22185, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12153, Train Loss:0.68447, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12154, Train Loss:0.00065, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12155, Train Loss:0.02572, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12156, Train Loss:0.23318, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12157, Train Loss:0.04543, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12158, Train Loss:0.19558, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12159, Train Loss:0.00763, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12160, Train Loss:0.05828, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12161, Train Loss:0.24174, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12162, Train Loss:0.00207, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12163, Train Loss:0.03397, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12164, Train Loss:0.21052, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12165, Train Loss:0.01184, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12166, Train Loss:0.12491, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12167, Train Loss:0.11974, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12168, Train Loss:0.00552, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12169, Train Loss:0.00014, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12170, Train Loss:0.10025, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12171, Train Loss:0.02378, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12172, Train Loss:0.00035, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12173, Train Loss:0.03062, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12174, Train Loss:0.33006, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12175, Train Loss:0.00236, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12176, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12177, Train Loss:0.00004, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12178, Train Loss:0.00088, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12179, Train Loss:0.26372, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12180, Train Loss:0.11379, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12181, Train Loss:0.00067, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12182, Train Loss:0.00008, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12183, Train Loss:0.00046, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12184, Train Loss:0.00018, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12185, Train Loss:0.00001, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12186, Train Loss:0.00654, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12187, Train Loss:0.00135, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12188, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12189, Train Loss:1.25145, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12190, Train Loss:0.39880, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12191, Train Loss:0.71103, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12192, Train Loss:0.25522, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12193, Train Loss:0.01671, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12194, Train Loss:0.00009, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12195, Train Loss:0.29274, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12196, Train Loss:0.08146, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12197, Train Loss:0.30463, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12198, Train Loss:1.12401, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12199, Train Loss:0.03122, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12200, Train Loss:0.08701, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12201, Train Loss:0.00308, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12202, Train Loss:0.09147, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12203, Train Loss:0.24313, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12204, Train Loss:0.09184, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12205, Train Loss:0.21345, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12206, Train Loss:0.46328, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12207, Train Loss:0.17274, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12208, Train Loss:0.19993, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12209, Train Loss:0.17420, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12210, Train Loss:0.06106, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12211, Train Loss:0.24163, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12212, Train Loss:0.49815, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12213, Train Loss:0.03481, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12214, Train Loss:0.13997, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12215, Train Loss:0.20816, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12216, Train Loss:0.00392, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12217, Train Loss:0.15920, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12218, Train Loss:0.09551, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12219, Train Loss:0.27235, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12220, Train Loss:0.28949, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12221, Train Loss:0.29018, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12222, Train Loss:0.80888, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12223, Train Loss:0.00431, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12224, Train Loss:0.17712, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12225, Train Loss:0.04484, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12226, Train Loss:0.09026, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12227, Train Loss:0.08599, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12228, Train Loss:0.03957, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12229, Train Loss:0.00087, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12230, Train Loss:0.06061, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12231, Train Loss:0.00055, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12232, Train Loss:0.45324, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12233, Train Loss:0.18099, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12234, Train Loss:0.00104, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12235, Train Loss:0.00342, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12236, Train Loss:0.05239, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12237, Train Loss:0.03993, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12238, Train Loss:0.04846, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12239, Train Loss:0.04915, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12240, Train Loss:0.89695, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12241, Train Loss:0.12069, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12242, Train Loss:0.00506, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12243, Train Loss:0.03239, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12244, Train Loss:0.19128, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12245, Train Loss:0.00000, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12246, Train Loss:0.00120, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12247, Train Loss:0.37238, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12248, Train Loss:0.42624, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12249, Train Loss:0.00001, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12250, Train Loss:0.49684, Dev Loss:0.22790\n",
      "Epoch:[44/100], step:12251, Train Loss:0.24711, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12252, Train Loss:0.00365, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12253, Train Loss:0.00083, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12254, Train Loss:0.50683, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12255, Train Loss:0.00004, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12256, Train Loss:0.05872, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12257, Train Loss:0.05766, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12258, Train Loss:0.00015, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12259, Train Loss:0.03277, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12260, Train Loss:0.29421, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12261, Train Loss:0.00080, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12262, Train Loss:0.01030, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12263, Train Loss:0.73519, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12264, Train Loss:0.00110, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12265, Train Loss:0.04615, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12266, Train Loss:0.19242, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12267, Train Loss:0.12020, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12268, Train Loss:0.11178, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12269, Train Loss:0.15691, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12270, Train Loss:0.06921, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12271, Train Loss:0.00187, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12272, Train Loss:0.00272, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12273, Train Loss:0.00455, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12274, Train Loss:0.02169, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12275, Train Loss:0.02446, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12276, Train Loss:0.00236, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12277, Train Loss:0.00472, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12278, Train Loss:0.11847, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12279, Train Loss:0.00443, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12280, Train Loss:0.01729, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12281, Train Loss:0.00330, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12282, Train Loss:0.14841, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12283, Train Loss:0.53940, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12284, Train Loss:0.15756, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12285, Train Loss:0.00049, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12286, Train Loss:0.06996, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12287, Train Loss:0.20532, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12288, Train Loss:0.01155, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12289, Train Loss:0.03032, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12290, Train Loss:0.13263, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12291, Train Loss:0.17253, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12292, Train Loss:0.01454, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12293, Train Loss:0.00012, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12294, Train Loss:0.02014, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12295, Train Loss:0.04077, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12296, Train Loss:0.22264, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12297, Train Loss:0.11713, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12298, Train Loss:0.04486, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12299, Train Loss:0.00085, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12300, Train Loss:0.00138, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12301, Train Loss:0.00061, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12302, Train Loss:0.26652, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12303, Train Loss:0.00400, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12304, Train Loss:0.00002, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12305, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12306, Train Loss:0.23122, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12307, Train Loss:0.23974, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12308, Train Loss:0.39227, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12309, Train Loss:0.00600, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12310, Train Loss:0.00014, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12311, Train Loss:0.16431, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12312, Train Loss:0.00195, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12313, Train Loss:0.00005, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12314, Train Loss:0.15016, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12315, Train Loss:0.14712, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12316, Train Loss:0.15983, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12317, Train Loss:0.00003, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12318, Train Loss:0.00349, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12319, Train Loss:0.07814, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12320, Train Loss:0.02292, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12321, Train Loss:0.00964, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12322, Train Loss:0.00618, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12323, Train Loss:0.01166, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12324, Train Loss:0.20358, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12325, Train Loss:0.00094, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12326, Train Loss:0.07063, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12327, Train Loss:0.59789, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12328, Train Loss:0.00143, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12329, Train Loss:0.00770, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12330, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12331, Train Loss:0.00002, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12332, Train Loss:0.36297, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12333, Train Loss:0.18284, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12334, Train Loss:0.14358, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12335, Train Loss:0.08988, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12336, Train Loss:0.08290, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12337, Train Loss:0.14686, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12338, Train Loss:0.25830, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12339, Train Loss:0.29696, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12340, Train Loss:0.00003, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12341, Train Loss:0.16435, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12342, Train Loss:0.09765, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12343, Train Loss:0.01286, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12344, Train Loss:0.00005, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12345, Train Loss:0.22659, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12346, Train Loss:0.00004, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12347, Train Loss:0.40413, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12348, Train Loss:0.00591, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12349, Train Loss:0.01742, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12350, Train Loss:0.00110, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12351, Train Loss:0.20180, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12352, Train Loss:0.00754, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12353, Train Loss:0.10124, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12354, Train Loss:0.00095, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12355, Train Loss:0.45004, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12356, Train Loss:0.00005, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12357, Train Loss:0.00002, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12358, Train Loss:0.00149, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12359, Train Loss:0.00002, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12360, Train Loss:0.00113, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12361, Train Loss:0.03846, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12362, Train Loss:0.01171, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12363, Train Loss:0.00353, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12364, Train Loss:0.00003, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12365, Train Loss:0.09715, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12366, Train Loss:0.00046, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12367, Train Loss:0.00003, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12368, Train Loss:0.23717, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12369, Train Loss:0.00022, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12370, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12371, Train Loss:0.07365, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12372, Train Loss:0.01967, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12373, Train Loss:0.04288, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12374, Train Loss:0.00613, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12375, Train Loss:0.00200, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12376, Train Loss:0.03806, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12377, Train Loss:0.15668, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12378, Train Loss:0.00653, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12379, Train Loss:0.00344, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12380, Train Loss:0.02329, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12381, Train Loss:0.13597, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12382, Train Loss:0.88475, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12383, Train Loss:0.00323, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12384, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12385, Train Loss:0.74505, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12386, Train Loss:0.05361, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12387, Train Loss:0.01326, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12388, Train Loss:0.00953, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12389, Train Loss:0.02669, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12390, Train Loss:0.00057, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12391, Train Loss:0.10654, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12392, Train Loss:0.05118, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12393, Train Loss:0.03277, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12394, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12395, Train Loss:0.00752, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12396, Train Loss:0.00014, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12397, Train Loss:0.18172, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12398, Train Loss:0.06908, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12399, Train Loss:0.03215, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12400, Train Loss:0.00125, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12401, Train Loss:0.23745, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12402, Train Loss:0.00060, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12403, Train Loss:0.18804, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12404, Train Loss:0.00906, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12405, Train Loss:0.04847, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12406, Train Loss:0.00129, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12407, Train Loss:0.06365, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12408, Train Loss:0.02118, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12409, Train Loss:0.33013, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12410, Train Loss:0.00003, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12411, Train Loss:0.25097, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12412, Train Loss:0.00020, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12413, Train Loss:0.08793, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12414, Train Loss:0.01330, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12415, Train Loss:0.21739, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12416, Train Loss:0.12916, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12417, Train Loss:0.00636, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12418, Train Loss:0.00198, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12419, Train Loss:0.02498, Dev Loss:0.12785\n",
      "Epoch:[44/100], step:12420, Train Loss:0.00033, Dev Loss:0.12785\n",
      "Start Epoch: 45, Steps: 17\n",
      "Epoch:[45/100], step:12421, Train Loss:0.21118, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12422, Train Loss:0.01653, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12423, Train Loss:0.02615, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12424, Train Loss:0.00057, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12425, Train Loss:0.01997, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12426, Train Loss:0.00042, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12427, Train Loss:0.00016, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12428, Train Loss:0.06478, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12429, Train Loss:0.18168, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12430, Train Loss:0.18652, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12431, Train Loss:0.00012, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12432, Train Loss:0.00006, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12433, Train Loss:0.00181, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12434, Train Loss:0.31898, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12435, Train Loss:0.00145, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12436, Train Loss:0.00708, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12437, Train Loss:0.01019, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12438, Train Loss:0.20619, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12439, Train Loss:0.04472, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12440, Train Loss:0.00151, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12441, Train Loss:0.03194, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12442, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12443, Train Loss:0.00637, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12444, Train Loss:0.27859, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12445, Train Loss:0.01697, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12446, Train Loss:0.00283, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12447, Train Loss:0.38176, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12448, Train Loss:0.06909, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12449, Train Loss:0.71017, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12450, Train Loss:0.00779, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12451, Train Loss:0.00027, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12452, Train Loss:0.00000, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12453, Train Loss:0.00054, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12454, Train Loss:0.00001, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12455, Train Loss:0.36060, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12456, Train Loss:0.07438, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12457, Train Loss:0.00000, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12458, Train Loss:0.01209, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12459, Train Loss:0.00496, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12460, Train Loss:0.00524, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12461, Train Loss:0.17237, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12462, Train Loss:0.00014, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12463, Train Loss:0.01479, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12464, Train Loss:0.01828, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12465, Train Loss:0.05844, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12466, Train Loss:0.01711, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12467, Train Loss:0.00846, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12468, Train Loss:0.00002, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12469, Train Loss:0.11727, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12470, Train Loss:0.14554, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12471, Train Loss:0.07239, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12472, Train Loss:0.12545, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12473, Train Loss:0.11864, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12474, Train Loss:0.12804, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12475, Train Loss:0.00008, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12476, Train Loss:0.14721, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12477, Train Loss:0.00026, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12478, Train Loss:0.00121, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12479, Train Loss:0.05940, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12480, Train Loss:0.01148, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12481, Train Loss:0.39784, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12482, Train Loss:0.00034, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12483, Train Loss:0.00016, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12484, Train Loss:0.00246, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12485, Train Loss:0.02263, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12486, Train Loss:0.01471, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12487, Train Loss:0.11237, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12488, Train Loss:0.05116, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12489, Train Loss:0.02738, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12490, Train Loss:0.10249, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12491, Train Loss:0.00006, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12492, Train Loss:0.11478, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12493, Train Loss:0.28945, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12494, Train Loss:0.08459, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12495, Train Loss:0.01853, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12496, Train Loss:0.16841, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12497, Train Loss:0.00004, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12498, Train Loss:0.00011, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12499, Train Loss:0.02980, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12500, Train Loss:0.00642, Dev Loss:0.12785\n",
      "Epoch:[45/100], step:12501, Train Loss:0.07794, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12502, Train Loss:0.28915, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12503, Train Loss:0.00639, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12504, Train Loss:0.00140, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12505, Train Loss:0.12450, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12506, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12507, Train Loss:0.06353, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12508, Train Loss:0.17382, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12509, Train Loss:0.18816, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12510, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12511, Train Loss:0.00006, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12512, Train Loss:0.64848, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12513, Train Loss:0.06989, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12514, Train Loss:0.02168, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12515, Train Loss:0.00002, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12516, Train Loss:0.01328, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12517, Train Loss:0.00096, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12518, Train Loss:0.00293, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12519, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12520, Train Loss:0.00102, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12521, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12522, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12523, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12524, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12525, Train Loss:0.28918, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12526, Train Loss:0.00328, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12527, Train Loss:0.19410, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12528, Train Loss:0.01784, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12529, Train Loss:0.02101, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12530, Train Loss:0.00953, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12531, Train Loss:0.21971, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12532, Train Loss:0.01279, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12533, Train Loss:0.02994, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12534, Train Loss:0.54786, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12535, Train Loss:0.31448, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12536, Train Loss:0.00003, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12537, Train Loss:0.33253, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12538, Train Loss:0.71149, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12539, Train Loss:0.08726, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12540, Train Loss:0.00059, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12541, Train Loss:0.16779, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12542, Train Loss:0.00004, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12543, Train Loss:0.19568, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12544, Train Loss:0.17262, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12545, Train Loss:0.44569, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12546, Train Loss:0.00003, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12547, Train Loss:0.12115, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12548, Train Loss:0.00391, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12549, Train Loss:0.00041, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12550, Train Loss:0.01413, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12551, Train Loss:0.14184, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12552, Train Loss:0.04908, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12553, Train Loss:0.86854, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12554, Train Loss:1.24203, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12555, Train Loss:0.00016, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12556, Train Loss:0.03630, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12557, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12558, Train Loss:0.07780, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12559, Train Loss:0.04979, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12560, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12561, Train Loss:0.00002, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12562, Train Loss:0.07779, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12563, Train Loss:0.37090, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12564, Train Loss:0.06230, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12565, Train Loss:0.00442, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12566, Train Loss:0.01172, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12567, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12568, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12569, Train Loss:0.00246, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12570, Train Loss:0.35710, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12571, Train Loss:0.03576, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12572, Train Loss:0.24564, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12573, Train Loss:0.30748, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12574, Train Loss:0.02413, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12575, Train Loss:0.28223, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12576, Train Loss:0.00004, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12577, Train Loss:0.45454, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12578, Train Loss:0.00101, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12579, Train Loss:0.05264, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12580, Train Loss:0.20485, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12581, Train Loss:0.00654, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12582, Train Loss:0.00007, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12583, Train Loss:0.03195, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12584, Train Loss:0.00496, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12585, Train Loss:0.20795, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12586, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12587, Train Loss:0.33445, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12588, Train Loss:0.18249, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12589, Train Loss:0.37781, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12590, Train Loss:0.07820, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12591, Train Loss:0.12459, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12592, Train Loss:0.01320, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12593, Train Loss:0.08053, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12594, Train Loss:0.23512, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12595, Train Loss:0.00370, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12596, Train Loss:0.00235, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12597, Train Loss:0.00002, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12598, Train Loss:0.05598, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12599, Train Loss:0.07536, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12600, Train Loss:0.35982, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12601, Train Loss:0.22813, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12602, Train Loss:0.04286, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12603, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12604, Train Loss:0.03481, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12605, Train Loss:1.04774, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12606, Train Loss:0.00034, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12607, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12608, Train Loss:0.12991, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12609, Train Loss:0.03124, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12610, Train Loss:0.03713, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12611, Train Loss:0.00004, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12612, Train Loss:0.20013, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12613, Train Loss:0.00026, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12614, Train Loss:0.00112, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12615, Train Loss:0.08377, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12616, Train Loss:0.61043, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12617, Train Loss:0.14920, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12618, Train Loss:0.08633, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12619, Train Loss:0.01491, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12620, Train Loss:0.08721, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12621, Train Loss:0.67506, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12622, Train Loss:0.00098, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12623, Train Loss:0.00191, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12624, Train Loss:0.66356, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12625, Train Loss:0.06845, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12626, Train Loss:0.00073, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12627, Train Loss:0.11634, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12628, Train Loss:0.30147, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12629, Train Loss:0.00153, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12630, Train Loss:0.00139, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12631, Train Loss:0.03405, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12632, Train Loss:0.07152, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12633, Train Loss:0.13400, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12634, Train Loss:0.21086, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12635, Train Loss:0.00814, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12636, Train Loss:0.18928, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12637, Train Loss:0.39514, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12638, Train Loss:0.01101, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12639, Train Loss:0.00015, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12640, Train Loss:0.01452, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12641, Train Loss:0.19944, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12642, Train Loss:0.00002, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12643, Train Loss:0.13203, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12644, Train Loss:0.01747, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12645, Train Loss:0.08052, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12646, Train Loss:1.35050, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12647, Train Loss:0.09534, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12648, Train Loss:0.17680, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12649, Train Loss:0.04578, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12650, Train Loss:0.39467, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12651, Train Loss:0.00041, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12652, Train Loss:0.61230, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12653, Train Loss:0.08731, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12654, Train Loss:0.08246, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12655, Train Loss:0.08007, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12656, Train Loss:0.09127, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12657, Train Loss:0.18831, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12658, Train Loss:0.08500, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12659, Train Loss:0.05395, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12660, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12661, Train Loss:0.00934, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12662, Train Loss:0.15599, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12663, Train Loss:0.03572, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12664, Train Loss:0.11016, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12665, Train Loss:0.49400, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12666, Train Loss:0.16260, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12667, Train Loss:0.09479, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12668, Train Loss:0.10708, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12669, Train Loss:0.06305, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12670, Train Loss:0.11645, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12671, Train Loss:0.01957, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12672, Train Loss:0.00810, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12673, Train Loss:0.30499, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12674, Train Loss:0.00101, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12675, Train Loss:0.19194, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12676, Train Loss:0.00062, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12677, Train Loss:0.01998, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12678, Train Loss:0.00158, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12679, Train Loss:0.24748, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12680, Train Loss:0.35412, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12681, Train Loss:0.07012, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12682, Train Loss:0.08494, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12683, Train Loss:0.00108, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12684, Train Loss:0.17086, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12685, Train Loss:0.09875, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12686, Train Loss:0.00117, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12687, Train Loss:0.01569, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12688, Train Loss:0.03658, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12689, Train Loss:1.15666, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12690, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12691, Train Loss:0.00087, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12692, Train Loss:0.05963, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12693, Train Loss:0.10204, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12694, Train Loss:0.00043, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12695, Train Loss:0.03548, Dev Loss:0.12885\n",
      "Epoch:[45/100], step:12696, Train Loss:0.06574, Dev Loss:0.12885\n",
      "Start Epoch: 46, Steps: 17\n",
      "Epoch:[46/100], step:12697, Train Loss:0.00044, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12698, Train Loss:0.00555, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12699, Train Loss:0.10718, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12700, Train Loss:1.02775, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12701, Train Loss:0.06713, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12702, Train Loss:0.15673, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12703, Train Loss:0.00021, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12704, Train Loss:0.02151, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12705, Train Loss:0.00523, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12706, Train Loss:0.14839, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12707, Train Loss:0.00450, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12708, Train Loss:0.03501, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12709, Train Loss:0.00007, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12710, Train Loss:0.00328, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12711, Train Loss:0.00040, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12712, Train Loss:0.08129, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12713, Train Loss:0.00986, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12714, Train Loss:0.00006, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12715, Train Loss:0.04622, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12716, Train Loss:0.00935, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12717, Train Loss:0.17945, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12718, Train Loss:0.05229, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12719, Train Loss:0.00021, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12720, Train Loss:0.02942, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12721, Train Loss:0.25057, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12722, Train Loss:0.11319, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12723, Train Loss:0.00603, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12724, Train Loss:0.15365, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12725, Train Loss:0.16616, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12726, Train Loss:0.08308, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12727, Train Loss:0.17129, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12728, Train Loss:0.06965, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12729, Train Loss:0.00008, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12730, Train Loss:0.01051, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12731, Train Loss:0.12823, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12732, Train Loss:0.17758, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12733, Train Loss:0.00001, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12734, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12735, Train Loss:0.00116, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12736, Train Loss:0.60092, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12737, Train Loss:0.00000, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12738, Train Loss:0.00059, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12739, Train Loss:0.57772, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12740, Train Loss:0.03156, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12741, Train Loss:0.00207, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12742, Train Loss:0.00041, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12743, Train Loss:0.03174, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12744, Train Loss:0.04207, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12745, Train Loss:0.07363, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12746, Train Loss:0.00397, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12747, Train Loss:0.00553, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12748, Train Loss:0.11804, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12749, Train Loss:0.00082, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12750, Train Loss:0.04310, Dev Loss:0.12885\n",
      "Epoch:[46/100], step:12751, Train Loss:0.01285, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12752, Train Loss:0.08019, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12753, Train Loss:0.00407, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12754, Train Loss:0.06084, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12755, Train Loss:0.03417, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12756, Train Loss:0.17979, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12757, Train Loss:0.00431, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12758, Train Loss:0.00026, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12759, Train Loss:0.32659, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12760, Train Loss:0.00021, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12761, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12762, Train Loss:0.01385, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12763, Train Loss:0.01398, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12764, Train Loss:0.08508, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12765, Train Loss:0.00154, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12766, Train Loss:0.31280, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12767, Train Loss:0.01006, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12768, Train Loss:0.16781, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12769, Train Loss:0.14089, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12770, Train Loss:0.00233, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12771, Train Loss:0.00023, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12772, Train Loss:0.00143, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12773, Train Loss:0.03538, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12774, Train Loss:0.00036, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12775, Train Loss:0.06581, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12776, Train Loss:0.01490, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12777, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12778, Train Loss:0.05072, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12779, Train Loss:0.09463, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12780, Train Loss:0.17847, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12781, Train Loss:0.00050, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12782, Train Loss:0.04426, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12783, Train Loss:0.06108, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12784, Train Loss:0.15913, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12785, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12786, Train Loss:0.00023, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12787, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12788, Train Loss:0.17357, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12789, Train Loss:0.07459, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12790, Train Loss:0.03571, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12791, Train Loss:0.01783, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12792, Train Loss:0.01164, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12793, Train Loss:0.00768, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12794, Train Loss:0.00026, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12795, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12796, Train Loss:0.00025, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12797, Train Loss:0.01753, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12798, Train Loss:0.00116, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12799, Train Loss:0.23422, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12800, Train Loss:0.00045, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12801, Train Loss:0.22386, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12802, Train Loss:0.02686, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12803, Train Loss:0.40443, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12804, Train Loss:0.10007, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12805, Train Loss:0.15636, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12806, Train Loss:0.01813, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12807, Train Loss:0.00754, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12808, Train Loss:0.26096, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12809, Train Loss:0.00020, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12810, Train Loss:0.03324, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12811, Train Loss:0.00018, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12812, Train Loss:0.00608, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12813, Train Loss:0.09658, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12814, Train Loss:0.10785, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12815, Train Loss:0.11006, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12816, Train Loss:0.19193, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12817, Train Loss:0.00031, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12818, Train Loss:0.01070, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12819, Train Loss:0.00172, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12820, Train Loss:0.08027, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12821, Train Loss:0.00006, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12822, Train Loss:0.00028, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12823, Train Loss:0.03125, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12824, Train Loss:0.53939, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12825, Train Loss:0.26766, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12826, Train Loss:0.01136, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12827, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12828, Train Loss:0.00627, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12829, Train Loss:0.00669, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12830, Train Loss:0.00131, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12831, Train Loss:0.00343, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12832, Train Loss:0.07544, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12833, Train Loss:0.00002, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12834, Train Loss:0.18128, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12835, Train Loss:0.06667, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12836, Train Loss:0.06614, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12837, Train Loss:0.01294, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12838, Train Loss:0.12961, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12839, Train Loss:0.23213, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12840, Train Loss:0.25752, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12841, Train Loss:0.01512, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12842, Train Loss:0.00634, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12843, Train Loss:0.00003, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12844, Train Loss:0.03636, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12845, Train Loss:0.00034, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12846, Train Loss:0.04319, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12847, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12848, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12849, Train Loss:0.09730, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12850, Train Loss:0.11786, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12851, Train Loss:0.25450, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12852, Train Loss:0.02985, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12853, Train Loss:0.01551, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12854, Train Loss:0.10221, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12855, Train Loss:0.00010, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12856, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12857, Train Loss:0.45567, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12858, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12859, Train Loss:0.00068, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12860, Train Loss:0.00053, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12861, Train Loss:0.00265, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12862, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12863, Train Loss:0.57172, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12864, Train Loss:0.00013, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12865, Train Loss:0.34096, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12866, Train Loss:0.05890, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12867, Train Loss:0.00027, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12868, Train Loss:0.39513, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12869, Train Loss:0.06925, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12870, Train Loss:0.00031, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12871, Train Loss:0.00914, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12872, Train Loss:0.10502, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12873, Train Loss:0.00450, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12874, Train Loss:0.05155, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12875, Train Loss:0.03411, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12876, Train Loss:0.00020, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12877, Train Loss:0.18822, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12878, Train Loss:0.00002, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12879, Train Loss:0.07086, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12880, Train Loss:0.03898, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12881, Train Loss:0.03452, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12882, Train Loss:0.00004, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12883, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12884, Train Loss:0.00069, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12885, Train Loss:0.14318, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12886, Train Loss:0.00011, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12887, Train Loss:0.06227, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12888, Train Loss:0.03008, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12889, Train Loss:0.06644, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12890, Train Loss:0.00999, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12891, Train Loss:0.16662, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12892, Train Loss:0.24782, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12893, Train Loss:0.09897, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12894, Train Loss:0.01644, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12895, Train Loss:0.11074, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12896, Train Loss:0.00027, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12897, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12898, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12899, Train Loss:0.00134, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12900, Train Loss:0.00036, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12901, Train Loss:0.01720, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12902, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12903, Train Loss:0.03724, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12904, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12905, Train Loss:0.23350, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12906, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12907, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12908, Train Loss:0.20830, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12909, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12910, Train Loss:0.01420, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12911, Train Loss:0.00934, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12912, Train Loss:0.00012, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12913, Train Loss:0.00995, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12914, Train Loss:0.00329, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12915, Train Loss:0.44582, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12916, Train Loss:0.12792, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12917, Train Loss:0.12182, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12918, Train Loss:0.02408, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12919, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12920, Train Loss:0.01240, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12921, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12922, Train Loss:0.04442, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12923, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12924, Train Loss:0.00283, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12925, Train Loss:0.00289, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12926, Train Loss:0.00005, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12927, Train Loss:0.06665, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12928, Train Loss:0.12586, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12929, Train Loss:0.03691, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12930, Train Loss:0.00006, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12931, Train Loss:0.00110, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12932, Train Loss:0.05642, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12933, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12934, Train Loss:0.00140, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12935, Train Loss:0.00009, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12936, Train Loss:0.00036, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12937, Train Loss:0.01064, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12938, Train Loss:0.29931, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12939, Train Loss:0.00002, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12940, Train Loss:0.00205, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12941, Train Loss:0.27018, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12942, Train Loss:0.23974, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12943, Train Loss:0.10476, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12944, Train Loss:0.10130, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12945, Train Loss:0.21363, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12946, Train Loss:0.00122, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12947, Train Loss:0.00116, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12948, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12949, Train Loss:0.15640, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12950, Train Loss:0.11226, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12951, Train Loss:0.49594, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12952, Train Loss:0.00008, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12953, Train Loss:0.00377, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12954, Train Loss:0.00052, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12955, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12956, Train Loss:0.00014, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12957, Train Loss:0.20398, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12958, Train Loss:0.00072, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12959, Train Loss:0.01203, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12960, Train Loss:0.34773, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12961, Train Loss:0.00015, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12962, Train Loss:0.18547, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12963, Train Loss:0.00992, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12964, Train Loss:0.44562, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12965, Train Loss:0.00392, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12966, Train Loss:0.01189, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12967, Train Loss:0.02718, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12968, Train Loss:0.00009, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12969, Train Loss:0.05308, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12970, Train Loss:0.01517, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12971, Train Loss:0.07319, Dev Loss:0.14477\n",
      "Epoch:[46/100], step:12972, Train Loss:0.00002, Dev Loss:0.14477\n",
      "Start Epoch: 47, Steps: 17\n",
      "Epoch:[47/100], step:12973, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12974, Train Loss:0.00043, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12975, Train Loss:0.00086, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12976, Train Loss:0.00072, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12977, Train Loss:0.00001, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12978, Train Loss:0.01575, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12979, Train Loss:0.00994, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12980, Train Loss:0.01557, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12981, Train Loss:0.44227, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12982, Train Loss:0.04718, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12983, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12984, Train Loss:0.09906, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12985, Train Loss:0.09753, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12986, Train Loss:0.00432, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12987, Train Loss:0.00000, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12988, Train Loss:0.01433, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12989, Train Loss:0.15113, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12990, Train Loss:0.04963, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12991, Train Loss:0.77491, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12992, Train Loss:0.09385, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12993, Train Loss:0.04027, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12994, Train Loss:0.00045, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12995, Train Loss:0.00518, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12996, Train Loss:0.00526, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12997, Train Loss:0.23044, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12998, Train Loss:0.13544, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:12999, Train Loss:0.00036, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:13000, Train Loss:0.00032, Dev Loss:0.14477\n",
      "Epoch:[47/100], step:13001, Train Loss:0.08048, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13002, Train Loss:0.00684, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13003, Train Loss:0.00015, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13004, Train Loss:0.58676, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13005, Train Loss:0.00012, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13006, Train Loss:0.07247, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13007, Train Loss:0.00329, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13008, Train Loss:0.65688, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13009, Train Loss:0.02984, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13010, Train Loss:0.00021, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13011, Train Loss:0.00043, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13012, Train Loss:0.09707, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13013, Train Loss:0.00898, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13014, Train Loss:0.06239, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13015, Train Loss:0.06408, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13016, Train Loss:0.00972, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13017, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13018, Train Loss:0.01621, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13019, Train Loss:0.12297, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13020, Train Loss:0.01205, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13021, Train Loss:0.07158, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13022, Train Loss:0.05650, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13023, Train Loss:0.55694, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13024, Train Loss:0.08733, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13025, Train Loss:0.07051, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13026, Train Loss:0.07598, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13027, Train Loss:0.00005, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13028, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13029, Train Loss:0.16558, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13030, Train Loss:0.11926, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13031, Train Loss:0.29830, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13032, Train Loss:0.04002, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13033, Train Loss:0.01060, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13034, Train Loss:0.00585, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13035, Train Loss:0.00012, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13036, Train Loss:0.40818, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13037, Train Loss:0.02628, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13038, Train Loss:0.03650, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13039, Train Loss:0.10820, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13040, Train Loss:0.00419, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13041, Train Loss:0.00350, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13042, Train Loss:0.12251, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13043, Train Loss:0.19021, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13044, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13045, Train Loss:0.00367, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13046, Train Loss:0.00136, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13047, Train Loss:0.00128, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13048, Train Loss:0.00177, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13049, Train Loss:0.00020, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13050, Train Loss:0.09740, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13051, Train Loss:0.04111, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13052, Train Loss:0.18756, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13053, Train Loss:0.01511, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13054, Train Loss:0.16224, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13055, Train Loss:0.05672, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13056, Train Loss:0.00635, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13057, Train Loss:0.00002, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13058, Train Loss:0.00009, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13059, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13060, Train Loss:0.00821, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13061, Train Loss:0.01122, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13062, Train Loss:0.18073, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13063, Train Loss:0.04258, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13064, Train Loss:0.00016, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13065, Train Loss:0.00767, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13066, Train Loss:0.01543, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13067, Train Loss:0.00827, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13068, Train Loss:0.00010, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13069, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13070, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13071, Train Loss:0.02160, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13072, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13073, Train Loss:0.03869, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13074, Train Loss:0.10059, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13075, Train Loss:0.01737, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13076, Train Loss:0.00006, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13077, Train Loss:0.01809, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13078, Train Loss:1.61943, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13079, Train Loss:0.07516, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13080, Train Loss:0.00015, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13081, Train Loss:0.00058, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13082, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13083, Train Loss:0.00072, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13084, Train Loss:0.06653, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13085, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13086, Train Loss:0.00091, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13087, Train Loss:0.10380, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13088, Train Loss:0.01312, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13089, Train Loss:0.68370, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13090, Train Loss:0.12633, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13091, Train Loss:0.08389, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13092, Train Loss:0.09018, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13093, Train Loss:1.24988, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13094, Train Loss:0.04937, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13095, Train Loss:0.00018, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13096, Train Loss:0.01374, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13097, Train Loss:0.09278, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13098, Train Loss:0.02951, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13099, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13100, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13101, Train Loss:0.07783, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13102, Train Loss:0.13641, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13103, Train Loss:0.00011, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13104, Train Loss:0.08844, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13105, Train Loss:1.61786, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13106, Train Loss:0.00041, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13107, Train Loss:0.06462, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13108, Train Loss:0.08849, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13109, Train Loss:0.17779, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13110, Train Loss:0.06455, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13111, Train Loss:0.00204, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13112, Train Loss:0.05871, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13113, Train Loss:0.00833, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13114, Train Loss:0.06949, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13115, Train Loss:0.08946, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13116, Train Loss:0.03434, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13117, Train Loss:0.05583, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13118, Train Loss:0.03595, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13119, Train Loss:0.01463, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13120, Train Loss:0.02685, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13121, Train Loss:0.30199, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13122, Train Loss:0.18392, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13123, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13124, Train Loss:0.13020, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13125, Train Loss:0.00281, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13126, Train Loss:0.23393, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13127, Train Loss:0.17650, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13128, Train Loss:0.00215, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13129, Train Loss:0.00287, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13130, Train Loss:0.04293, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13131, Train Loss:0.09180, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13132, Train Loss:0.01321, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13133, Train Loss:0.13636, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13134, Train Loss:0.00516, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13135, Train Loss:0.28212, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13136, Train Loss:0.04830, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13137, Train Loss:0.03817, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13138, Train Loss:0.00582, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13139, Train Loss:0.01204, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13140, Train Loss:0.00055, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13141, Train Loss:0.00006, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13142, Train Loss:0.11408, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13143, Train Loss:0.01337, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13144, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13145, Train Loss:0.02382, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13146, Train Loss:0.03048, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13147, Train Loss:0.00099, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13148, Train Loss:0.00084, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13149, Train Loss:0.00013, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13150, Train Loss:0.00280, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13151, Train Loss:0.11766, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13152, Train Loss:0.00148, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13153, Train Loss:0.00383, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13154, Train Loss:0.03661, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13155, Train Loss:0.00023, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13156, Train Loss:0.24976, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13157, Train Loss:0.64441, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13158, Train Loss:0.13400, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13159, Train Loss:0.00080, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13160, Train Loss:0.02487, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13161, Train Loss:0.07274, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13162, Train Loss:0.52125, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13163, Train Loss:0.00138, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13164, Train Loss:0.03117, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13165, Train Loss:0.04928, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13166, Train Loss:0.00417, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13167, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13168, Train Loss:0.00943, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13169, Train Loss:0.00052, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13170, Train Loss:0.00082, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13171, Train Loss:0.09778, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13172, Train Loss:0.04429, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13173, Train Loss:0.73106, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13174, Train Loss:0.14255, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13175, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13176, Train Loss:0.05914, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13177, Train Loss:0.10121, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13178, Train Loss:0.03186, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13179, Train Loss:0.12744, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13180, Train Loss:0.00753, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13181, Train Loss:0.00755, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13182, Train Loss:0.08476, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13183, Train Loss:0.00197, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13184, Train Loss:0.00024, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13185, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13186, Train Loss:0.01936, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13187, Train Loss:0.00641, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13188, Train Loss:0.00025, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13189, Train Loss:0.25504, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13190, Train Loss:1.13359, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13191, Train Loss:0.00053, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13192, Train Loss:0.24345, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13193, Train Loss:0.01834, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13194, Train Loss:0.00000, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13195, Train Loss:0.00093, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13196, Train Loss:0.84791, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13197, Train Loss:0.08837, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13198, Train Loss:0.75492, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13199, Train Loss:0.95420, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13200, Train Loss:0.09516, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13201, Train Loss:0.10139, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13202, Train Loss:0.03650, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13203, Train Loss:0.16851, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13204, Train Loss:0.31834, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13205, Train Loss:0.00065, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13206, Train Loss:0.00925, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13207, Train Loss:0.21591, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13208, Train Loss:0.19285, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13209, Train Loss:0.27653, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13210, Train Loss:0.15263, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13211, Train Loss:0.05102, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13212, Train Loss:0.14900, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13213, Train Loss:0.00001, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13214, Train Loss:0.28057, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13215, Train Loss:0.65618, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13216, Train Loss:0.00101, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13217, Train Loss:0.63512, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13218, Train Loss:0.42764, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13219, Train Loss:0.13784, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13220, Train Loss:0.01954, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13221, Train Loss:0.00202, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13222, Train Loss:0.16371, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13223, Train Loss:0.00030, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13224, Train Loss:0.27754, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13225, Train Loss:0.29808, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13226, Train Loss:0.18595, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13227, Train Loss:0.32426, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13228, Train Loss:0.34164, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13229, Train Loss:0.10168, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13230, Train Loss:0.19117, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13231, Train Loss:0.47328, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13232, Train Loss:0.14604, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13233, Train Loss:0.09021, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13234, Train Loss:0.04945, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13235, Train Loss:0.50422, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13236, Train Loss:0.16943, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13237, Train Loss:0.07814, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13238, Train Loss:0.06430, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13239, Train Loss:0.03694, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13240, Train Loss:0.00245, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13241, Train Loss:0.20270, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13242, Train Loss:0.04227, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13243, Train Loss:0.10690, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13244, Train Loss:0.00111, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13245, Train Loss:0.14519, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13246, Train Loss:0.00130, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13247, Train Loss:0.68705, Dev Loss:0.15249\n",
      "Epoch:[47/100], step:13248, Train Loss:0.01828, Dev Loss:0.15249\n",
      "Start Epoch: 48, Steps: 17\n",
      "Epoch:[48/100], step:13249, Train Loss:0.10242, Dev Loss:0.15249\n",
      "Epoch:[48/100], step:13250, Train Loss:0.10601, Dev Loss:0.15249\n",
      "Epoch:[48/100], step:13251, Train Loss:0.15089, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13252, Train Loss:0.00026, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13253, Train Loss:0.04466, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13254, Train Loss:0.15136, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13255, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13256, Train Loss:0.00478, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13257, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13258, Train Loss:0.41188, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13259, Train Loss:0.88505, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13260, Train Loss:0.00253, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13261, Train Loss:0.00222, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13262, Train Loss:0.02617, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13263, Train Loss:0.00302, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13264, Train Loss:0.10287, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13265, Train Loss:0.08879, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13266, Train Loss:0.00237, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13267, Train Loss:0.01487, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13268, Train Loss:0.05870, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13269, Train Loss:0.00243, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13270, Train Loss:0.27159, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13271, Train Loss:0.00035, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13272, Train Loss:0.01529, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13273, Train Loss:0.14415, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13274, Train Loss:0.05708, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13275, Train Loss:0.04692, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13276, Train Loss:0.39618, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13277, Train Loss:0.03112, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13278, Train Loss:0.03318, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13279, Train Loss:0.00031, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13280, Train Loss:0.00007, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13281, Train Loss:0.03283, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13282, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13283, Train Loss:0.08681, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13284, Train Loss:0.14373, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13285, Train Loss:0.04141, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13286, Train Loss:0.04105, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13287, Train Loss:0.03555, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13288, Train Loss:0.00006, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13289, Train Loss:0.57250, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13290, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13291, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13292, Train Loss:0.07712, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13293, Train Loss:0.03029, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13294, Train Loss:0.11400, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13295, Train Loss:0.32762, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13296, Train Loss:0.03432, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13297, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13298, Train Loss:0.00847, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13299, Train Loss:0.14934, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13300, Train Loss:0.03485, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13301, Train Loss:0.00003, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13302, Train Loss:0.25689, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13303, Train Loss:0.04588, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13304, Train Loss:0.23150, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13305, Train Loss:0.00044, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13306, Train Loss:0.00012, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13307, Train Loss:0.00848, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13308, Train Loss:0.00022, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13309, Train Loss:0.11614, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13310, Train Loss:0.00273, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13311, Train Loss:0.01890, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13312, Train Loss:0.12873, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13313, Train Loss:0.12777, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13314, Train Loss:0.52794, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13315, Train Loss:0.05882, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13316, Train Loss:0.04266, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13317, Train Loss:0.00002, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13318, Train Loss:0.31218, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13319, Train Loss:0.00003, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13320, Train Loss:0.00003, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13321, Train Loss:0.00105, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13322, Train Loss:0.00023, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13323, Train Loss:0.00007, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13324, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13325, Train Loss:0.10358, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13326, Train Loss:0.20592, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13327, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13328, Train Loss:0.00013, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13329, Train Loss:0.01058, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13330, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13331, Train Loss:0.13979, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13332, Train Loss:0.63602, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13333, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13334, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13335, Train Loss:0.25848, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13336, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13337, Train Loss:0.01818, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13338, Train Loss:0.00003, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13339, Train Loss:0.00023, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13340, Train Loss:0.03842, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13341, Train Loss:0.14946, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13342, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13343, Train Loss:0.02855, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13344, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13345, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13346, Train Loss:0.00672, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13347, Train Loss:0.47515, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13348, Train Loss:0.13457, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13349, Train Loss:0.81749, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13350, Train Loss:0.07195, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13351, Train Loss:0.29537, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13352, Train Loss:0.14366, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13353, Train Loss:0.67988, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13354, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13355, Train Loss:0.00148, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13356, Train Loss:0.17162, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13357, Train Loss:0.01888, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13358, Train Loss:0.09011, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13359, Train Loss:0.15844, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13360, Train Loss:0.00967, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13361, Train Loss:0.05343, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13362, Train Loss:0.00158, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13363, Train Loss:0.00966, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13364, Train Loss:0.18994, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13365, Train Loss:0.00244, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13366, Train Loss:0.00569, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13367, Train Loss:0.08045, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13368, Train Loss:0.01143, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13369, Train Loss:0.00003, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13370, Train Loss:0.00983, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13371, Train Loss:0.00111, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13372, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13373, Train Loss:0.05649, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13374, Train Loss:0.11123, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13375, Train Loss:0.00685, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13376, Train Loss:0.11560, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13377, Train Loss:0.03718, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13378, Train Loss:0.00460, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13379, Train Loss:0.00112, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13380, Train Loss:0.14530, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13381, Train Loss:0.00257, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13382, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13383, Train Loss:0.64317, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13384, Train Loss:0.15815, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13385, Train Loss:0.00781, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13386, Train Loss:0.22140, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13387, Train Loss:0.00077, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13388, Train Loss:0.14608, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13389, Train Loss:0.22097, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13390, Train Loss:0.89729, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13391, Train Loss:0.00112, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13392, Train Loss:0.00469, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13393, Train Loss:0.00035, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13394, Train Loss:0.59468, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13395, Train Loss:0.81094, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13396, Train Loss:0.00182, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13397, Train Loss:0.01068, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13398, Train Loss:0.59109, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13399, Train Loss:0.02125, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13400, Train Loss:0.21592, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13401, Train Loss:0.09758, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13402, Train Loss:0.21694, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13403, Train Loss:0.00864, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13404, Train Loss:0.06721, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13405, Train Loss:0.06960, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13406, Train Loss:0.00180, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13407, Train Loss:0.10048, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13408, Train Loss:0.00021, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13409, Train Loss:0.08844, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13410, Train Loss:0.21316, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13411, Train Loss:0.00001, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13412, Train Loss:0.43684, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13413, Train Loss:0.09667, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13414, Train Loss:0.02048, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13415, Train Loss:0.26173, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13416, Train Loss:0.10764, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13417, Train Loss:0.28920, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13418, Train Loss:0.00040, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13419, Train Loss:0.08677, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13420, Train Loss:0.28597, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13421, Train Loss:0.01128, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13422, Train Loss:0.04845, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13423, Train Loss:0.00068, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13424, Train Loss:0.00027, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13425, Train Loss:0.05979, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13426, Train Loss:0.33786, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13427, Train Loss:0.15751, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13428, Train Loss:0.42494, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13429, Train Loss:0.26975, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13430, Train Loss:0.08802, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13431, Train Loss:0.13878, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13432, Train Loss:0.00137, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13433, Train Loss:0.00220, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13434, Train Loss:0.10978, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13435, Train Loss:0.00089, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13436, Train Loss:0.01400, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13437, Train Loss:0.00040, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13438, Train Loss:0.00232, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13439, Train Loss:0.07481, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13440, Train Loss:0.00041, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13441, Train Loss:0.27678, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13442, Train Loss:0.00918, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13443, Train Loss:0.00814, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13444, Train Loss:0.09471, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13445, Train Loss:0.19669, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13446, Train Loss:0.00129, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13447, Train Loss:0.11576, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13448, Train Loss:0.05820, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13449, Train Loss:0.11681, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13450, Train Loss:0.08414, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13451, Train Loss:0.01248, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13452, Train Loss:0.00043, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13453, Train Loss:0.17215, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13454, Train Loss:0.16342, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13455, Train Loss:1.13753, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13456, Train Loss:0.06608, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13457, Train Loss:0.00004, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13458, Train Loss:0.00006, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13459, Train Loss:0.11587, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13460, Train Loss:0.01862, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13461, Train Loss:0.09222, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13462, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13463, Train Loss:2.24789, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13464, Train Loss:0.00064, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13465, Train Loss:0.03574, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13466, Train Loss:0.02448, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13467, Train Loss:0.00851, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13468, Train Loss:0.00354, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13469, Train Loss:0.03207, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13470, Train Loss:0.03448, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13471, Train Loss:0.00066, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13472, Train Loss:0.01165, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13473, Train Loss:0.87299, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13474, Train Loss:0.39891, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13475, Train Loss:0.19959, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13476, Train Loss:0.25658, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13477, Train Loss:0.13035, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13478, Train Loss:0.18335, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13479, Train Loss:0.00529, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13480, Train Loss:0.00222, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13481, Train Loss:0.00009, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13482, Train Loss:0.32695, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13483, Train Loss:0.01916, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13484, Train Loss:0.22104, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13485, Train Loss:0.08617, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13486, Train Loss:0.03700, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13487, Train Loss:0.47242, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13488, Train Loss:0.05496, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13489, Train Loss:0.20075, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13490, Train Loss:0.03335, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13491, Train Loss:0.12990, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13492, Train Loss:0.17363, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13493, Train Loss:0.11457, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13494, Train Loss:0.09779, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13495, Train Loss:0.29649, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13496, Train Loss:0.03040, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13497, Train Loss:0.87239, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13498, Train Loss:0.02778, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13499, Train Loss:0.35450, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13500, Train Loss:0.00000, Dev Loss:0.14836\n",
      "Epoch:[48/100], step:13501, Train Loss:0.00020, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13502, Train Loss:0.05690, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13503, Train Loss:0.19380, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13504, Train Loss:0.00780, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13505, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13506, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13507, Train Loss:0.46036, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13508, Train Loss:0.07252, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13509, Train Loss:0.53596, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13510, Train Loss:0.25207, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13511, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13512, Train Loss:0.15339, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13513, Train Loss:0.07920, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13514, Train Loss:0.00314, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13515, Train Loss:0.00076, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13516, Train Loss:0.00039, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13517, Train Loss:0.09113, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13518, Train Loss:0.00444, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13519, Train Loss:0.07324, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13520, Train Loss:0.15118, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13521, Train Loss:0.03944, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13522, Train Loss:0.14078, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13523, Train Loss:0.05833, Dev Loss:0.15877\n",
      "Epoch:[48/100], step:13524, Train Loss:0.06225, Dev Loss:0.15877\n",
      "Start Epoch: 49, Steps: 17\n",
      "Epoch:[49/100], step:13525, Train Loss:0.05137, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13526, Train Loss:0.10773, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13527, Train Loss:0.05340, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13528, Train Loss:0.02198, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13529, Train Loss:0.16506, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13530, Train Loss:0.33550, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13531, Train Loss:0.07837, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13532, Train Loss:0.00125, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13533, Train Loss:0.61398, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13534, Train Loss:0.04763, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13535, Train Loss:0.03697, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13536, Train Loss:0.00104, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13537, Train Loss:0.23283, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13538, Train Loss:0.00025, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13539, Train Loss:0.03768, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13540, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13541, Train Loss:0.00003, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13542, Train Loss:0.07052, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13543, Train Loss:0.00032, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13544, Train Loss:0.21140, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13545, Train Loss:0.05887, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13546, Train Loss:0.03936, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13547, Train Loss:0.09364, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13548, Train Loss:2.07675, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13549, Train Loss:0.00485, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13550, Train Loss:0.06000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13551, Train Loss:0.06088, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13552, Train Loss:0.00488, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13553, Train Loss:0.00040, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13554, Train Loss:0.00882, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13555, Train Loss:0.01922, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13556, Train Loss:0.64923, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13557, Train Loss:0.26255, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13558, Train Loss:1.56413, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13559, Train Loss:0.00728, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13560, Train Loss:0.07319, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13561, Train Loss:0.73740, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13562, Train Loss:0.20228, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13563, Train Loss:0.00469, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13564, Train Loss:1.36706, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13565, Train Loss:0.00029, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13566, Train Loss:0.00506, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13567, Train Loss:0.12309, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13568, Train Loss:0.00640, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13569, Train Loss:0.09812, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13570, Train Loss:0.19443, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13571, Train Loss:0.00393, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13572, Train Loss:0.01039, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13573, Train Loss:0.21962, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13574, Train Loss:0.00013, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13575, Train Loss:0.19159, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13576, Train Loss:0.28812, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13577, Train Loss:0.10147, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13578, Train Loss:0.21550, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13579, Train Loss:0.11006, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13580, Train Loss:0.11815, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13581, Train Loss:0.70729, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13582, Train Loss:0.09628, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13583, Train Loss:0.20171, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13584, Train Loss:0.13842, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13585, Train Loss:0.01101, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13586, Train Loss:0.04695, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13587, Train Loss:0.00640, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13588, Train Loss:0.07103, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13589, Train Loss:1.49587, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13590, Train Loss:0.25557, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13591, Train Loss:0.06630, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13592, Train Loss:0.01516, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13593, Train Loss:0.15856, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13594, Train Loss:0.00006, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13595, Train Loss:0.01028, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13596, Train Loss:0.06000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13597, Train Loss:0.26165, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13598, Train Loss:0.00032, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13599, Train Loss:0.01625, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13600, Train Loss:0.02007, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13601, Train Loss:0.33724, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13602, Train Loss:0.29161, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13603, Train Loss:0.01604, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13604, Train Loss:0.34018, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13605, Train Loss:0.10550, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13606, Train Loss:0.00016, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13607, Train Loss:0.25158, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13608, Train Loss:0.21145, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13609, Train Loss:0.11262, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13610, Train Loss:0.01916, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13611, Train Loss:0.35900, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13612, Train Loss:0.00323, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13613, Train Loss:0.20002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13614, Train Loss:0.04634, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13615, Train Loss:0.32015, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13616, Train Loss:0.00039, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13617, Train Loss:0.03658, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13618, Train Loss:0.00255, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13619, Train Loss:0.06650, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13620, Train Loss:0.04030, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13621, Train Loss:0.00014, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13622, Train Loss:0.00061, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13623, Train Loss:0.01639, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13624, Train Loss:0.02666, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13625, Train Loss:0.10738, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13626, Train Loss:0.00004, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13627, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13628, Train Loss:0.04306, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13629, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13630, Train Loss:0.00020, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13631, Train Loss:0.00016, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13632, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13633, Train Loss:0.19101, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13634, Train Loss:0.03354, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13635, Train Loss:0.00002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13636, Train Loss:0.01039, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13637, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13638, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13639, Train Loss:0.00305, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13640, Train Loss:0.03619, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13641, Train Loss:0.13178, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13642, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13643, Train Loss:0.27383, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13644, Train Loss:0.00011, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13645, Train Loss:0.00580, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13646, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13647, Train Loss:0.02896, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13648, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13649, Train Loss:0.00055, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13650, Train Loss:0.00392, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13651, Train Loss:0.00338, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13652, Train Loss:0.32582, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13653, Train Loss:0.03230, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13654, Train Loss:0.26352, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13655, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13656, Train Loss:0.00002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13657, Train Loss:0.48847, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13658, Train Loss:0.11299, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13659, Train Loss:0.00331, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13660, Train Loss:0.00123, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13661, Train Loss:0.00002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13662, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13663, Train Loss:0.00005, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13664, Train Loss:0.55365, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13665, Train Loss:0.04672, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13666, Train Loss:0.58593, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13667, Train Loss:0.00159, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13668, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13669, Train Loss:0.06455, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13670, Train Loss:0.04136, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13671, Train Loss:0.35316, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13672, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13673, Train Loss:0.23018, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13674, Train Loss:0.00191, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13675, Train Loss:0.00343, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13676, Train Loss:0.71545, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13677, Train Loss:0.28908, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13678, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13679, Train Loss:0.60514, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13680, Train Loss:0.50161, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13681, Train Loss:0.08825, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13682, Train Loss:0.33622, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13683, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13684, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13685, Train Loss:0.00039, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13686, Train Loss:0.14899, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13687, Train Loss:0.00006, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13688, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13689, Train Loss:0.00060, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13690, Train Loss:0.09730, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13691, Train Loss:0.06667, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13692, Train Loss:0.00006, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13693, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13694, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13695, Train Loss:0.00033, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13696, Train Loss:0.00021, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13697, Train Loss:0.00013, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13698, Train Loss:0.35027, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13699, Train Loss:0.04740, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13700, Train Loss:0.00298, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13701, Train Loss:0.31597, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13702, Train Loss:0.19260, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13703, Train Loss:0.00460, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13704, Train Loss:0.14537, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13705, Train Loss:0.19429, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13706, Train Loss:0.25530, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13707, Train Loss:0.01341, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13708, Train Loss:0.00383, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13709, Train Loss:0.25130, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13710, Train Loss:0.58236, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13711, Train Loss:0.01765, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13712, Train Loss:0.00004, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13713, Train Loss:0.00001, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13714, Train Loss:0.35547, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13715, Train Loss:0.00041, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13716, Train Loss:0.08114, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13717, Train Loss:0.00002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13718, Train Loss:0.01244, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13719, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13720, Train Loss:0.09005, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13721, Train Loss:0.32477, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13722, Train Loss:0.08227, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13723, Train Loss:0.00367, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13724, Train Loss:0.00000, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13725, Train Loss:0.51782, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13726, Train Loss:0.04036, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13727, Train Loss:0.00003, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13728, Train Loss:0.07002, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13729, Train Loss:0.00441, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13730, Train Loss:0.08594, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13731, Train Loss:0.72162, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13732, Train Loss:0.01433, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13733, Train Loss:0.03389, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13734, Train Loss:0.00809, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13735, Train Loss:0.22902, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13736, Train Loss:0.02295, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13737, Train Loss:0.00006, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13738, Train Loss:0.13598, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13739, Train Loss:0.34290, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13740, Train Loss:0.00022, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13741, Train Loss:0.16161, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13742, Train Loss:0.01312, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13743, Train Loss:0.00500, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13744, Train Loss:0.00068, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13745, Train Loss:0.06929, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13746, Train Loss:0.25582, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13747, Train Loss:0.02136, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13748, Train Loss:0.04320, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13749, Train Loss:0.12666, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13750, Train Loss:0.00661, Dev Loss:0.15877\n",
      "Epoch:[49/100], step:13751, Train Loss:0.05387, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13752, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13753, Train Loss:0.00076, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13754, Train Loss:0.00028, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13755, Train Loss:0.00200, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13756, Train Loss:0.00003, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13757, Train Loss:0.00148, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13758, Train Loss:0.01625, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13759, Train Loss:0.10227, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13760, Train Loss:0.00132, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13761, Train Loss:0.00009, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13762, Train Loss:0.00186, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13763, Train Loss:0.07721, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13764, Train Loss:0.01263, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13765, Train Loss:0.02423, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13766, Train Loss:0.01428, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13767, Train Loss:0.02736, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13768, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13769, Train Loss:0.06302, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13770, Train Loss:0.07292, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13771, Train Loss:0.00270, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13772, Train Loss:0.02023, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13773, Train Loss:0.45189, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13774, Train Loss:0.65931, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13775, Train Loss:0.03313, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13776, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13777, Train Loss:0.53519, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13778, Train Loss:0.05455, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13779, Train Loss:0.23845, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13780, Train Loss:0.00025, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13781, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13782, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13783, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13784, Train Loss:0.03329, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13785, Train Loss:0.00034, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13786, Train Loss:0.00468, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13787, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13788, Train Loss:0.00044, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13789, Train Loss:0.11311, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13790, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13791, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13792, Train Loss:0.00214, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13793, Train Loss:0.48980, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13794, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13795, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13796, Train Loss:0.23771, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13797, Train Loss:0.00115, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13798, Train Loss:0.00057, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13799, Train Loss:0.50291, Dev Loss:0.23724\n",
      "Epoch:[49/100], step:13800, Train Loss:0.06666, Dev Loss:0.23724\n",
      "Start Epoch: 50, Steps: 17\n",
      "Epoch:[50/100], step:13801, Train Loss:0.11828, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13802, Train Loss:0.33498, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13803, Train Loss:0.05864, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13804, Train Loss:0.51248, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13805, Train Loss:0.00004, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13806, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13807, Train Loss:0.02836, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13808, Train Loss:0.04753, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13809, Train Loss:0.26449, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13810, Train Loss:0.26330, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13811, Train Loss:0.00006, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13812, Train Loss:0.01719, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13813, Train Loss:0.00104, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13814, Train Loss:0.00192, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13815, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13816, Train Loss:0.00085, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13817, Train Loss:0.06329, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13818, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13819, Train Loss:0.08351, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13820, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13821, Train Loss:0.02171, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13822, Train Loss:0.42637, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13823, Train Loss:0.00004, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13824, Train Loss:0.00295, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13825, Train Loss:0.01425, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13826, Train Loss:0.01986, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13827, Train Loss:0.28667, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13828, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13829, Train Loss:0.10499, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13830, Train Loss:0.03339, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13831, Train Loss:0.14273, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13832, Train Loss:0.00374, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13833, Train Loss:0.11278, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13834, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13835, Train Loss:0.00011, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13836, Train Loss:0.00015, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13837, Train Loss:0.07643, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13838, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13839, Train Loss:0.00080, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13840, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13841, Train Loss:0.00003, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13842, Train Loss:0.08367, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13843, Train Loss:0.04328, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13844, Train Loss:0.10975, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13845, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13846, Train Loss:0.09280, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13847, Train Loss:0.00021, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13848, Train Loss:0.02139, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13849, Train Loss:0.09657, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13850, Train Loss:0.03582, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13851, Train Loss:0.20944, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13852, Train Loss:0.21406, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13853, Train Loss:0.00042, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13854, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13855, Train Loss:0.15952, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13856, Train Loss:0.20766, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13857, Train Loss:0.94152, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13858, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13859, Train Loss:0.00045, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13860, Train Loss:0.05097, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13861, Train Loss:0.00040, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13862, Train Loss:0.00987, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13863, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13864, Train Loss:0.13860, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13865, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13866, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13867, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13868, Train Loss:0.00234, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13869, Train Loss:0.02604, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13870, Train Loss:0.28474, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13871, Train Loss:0.29160, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13872, Train Loss:1.56434, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13873, Train Loss:0.08852, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13874, Train Loss:0.00195, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13875, Train Loss:0.00704, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13876, Train Loss:0.10646, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13877, Train Loss:0.01174, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13878, Train Loss:0.01266, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13879, Train Loss:0.14256, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13880, Train Loss:0.00346, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13881, Train Loss:0.00026, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13882, Train Loss:0.95786, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13883, Train Loss:0.76133, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13884, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13885, Train Loss:0.03987, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13886, Train Loss:0.37434, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13887, Train Loss:0.02070, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13888, Train Loss:0.01341, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13889, Train Loss:0.00256, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13890, Train Loss:1.19220, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13891, Train Loss:0.19226, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13892, Train Loss:0.20935, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13893, Train Loss:0.00320, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13894, Train Loss:0.05466, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13895, Train Loss:0.16378, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13896, Train Loss:0.03488, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13897, Train Loss:0.00208, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13898, Train Loss:0.07441, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13899, Train Loss:0.20700, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13900, Train Loss:0.00384, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13901, Train Loss:0.03836, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13902, Train Loss:0.57545, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13903, Train Loss:0.04244, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13904, Train Loss:0.18660, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13905, Train Loss:0.08255, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13906, Train Loss:0.08314, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13907, Train Loss:0.27450, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13908, Train Loss:0.10146, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13909, Train Loss:0.00843, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13910, Train Loss:0.10123, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13911, Train Loss:0.08640, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13912, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13913, Train Loss:0.23605, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13914, Train Loss:0.06962, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13915, Train Loss:0.23010, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13916, Train Loss:0.01189, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13917, Train Loss:0.00008, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13918, Train Loss:0.00326, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13919, Train Loss:0.35076, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13920, Train Loss:0.51337, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13921, Train Loss:0.02356, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13922, Train Loss:1.06523, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13923, Train Loss:0.16565, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13924, Train Loss:0.03965, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13925, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13926, Train Loss:0.00263, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13927, Train Loss:0.14743, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13928, Train Loss:0.03119, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13929, Train Loss:0.03907, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13930, Train Loss:0.12157, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13931, Train Loss:0.17951, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13932, Train Loss:0.25869, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13933, Train Loss:0.00489, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13934, Train Loss:0.23815, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13935, Train Loss:0.03456, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13936, Train Loss:0.49652, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13937, Train Loss:0.04912, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13938, Train Loss:0.09230, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13939, Train Loss:0.20766, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13940, Train Loss:0.06946, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13941, Train Loss:0.56695, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13942, Train Loss:0.00060, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13943, Train Loss:0.54678, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13944, Train Loss:0.82622, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13945, Train Loss:0.06770, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13946, Train Loss:0.00239, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13947, Train Loss:0.37697, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13948, Train Loss:0.01690, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13949, Train Loss:0.02258, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13950, Train Loss:0.00061, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13951, Train Loss:0.00086, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13952, Train Loss:0.01496, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13953, Train Loss:0.00541, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13954, Train Loss:0.00006, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13955, Train Loss:0.00250, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13956, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13957, Train Loss:0.05899, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13958, Train Loss:0.00021, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13959, Train Loss:0.11368, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13960, Train Loss:1.04933, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13961, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13962, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13963, Train Loss:0.09609, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13964, Train Loss:0.06015, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13965, Train Loss:0.01320, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13966, Train Loss:0.00015, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13967, Train Loss:0.00003, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13968, Train Loss:0.01882, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13969, Train Loss:0.07815, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13970, Train Loss:0.00107, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13971, Train Loss:0.12041, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13972, Train Loss:0.00110, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13973, Train Loss:0.00281, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13974, Train Loss:0.01064, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13975, Train Loss:0.02378, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13976, Train Loss:0.11102, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13977, Train Loss:0.00053, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13978, Train Loss:0.09466, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13979, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13980, Train Loss:0.00002, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13981, Train Loss:0.00217, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13982, Train Loss:0.01273, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13983, Train Loss:0.51696, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13984, Train Loss:0.04875, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13985, Train Loss:0.00001, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13986, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13987, Train Loss:0.15484, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13988, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13989, Train Loss:0.00016, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13990, Train Loss:0.61210, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13991, Train Loss:0.00010, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13992, Train Loss:0.00035, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13993, Train Loss:0.00434, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13994, Train Loss:0.11611, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13995, Train Loss:0.00000, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13996, Train Loss:0.81259, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13997, Train Loss:0.07458, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13998, Train Loss:0.20813, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:13999, Train Loss:0.02630, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:14000, Train Loss:0.02089, Dev Loss:0.23724\n",
      "Epoch:[50/100], step:14001, Train Loss:0.03610, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14002, Train Loss:0.00004, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14003, Train Loss:0.00008, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14004, Train Loss:0.50041, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14005, Train Loss:0.05988, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14006, Train Loss:0.04320, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14007, Train Loss:0.05784, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14008, Train Loss:0.51433, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14009, Train Loss:0.00280, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14010, Train Loss:0.07463, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14011, Train Loss:0.05807, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14012, Train Loss:0.06131, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14013, Train Loss:0.03554, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14014, Train Loss:0.00646, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14015, Train Loss:0.00288, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14016, Train Loss:0.00052, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14017, Train Loss:0.04045, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14018, Train Loss:0.17195, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14019, Train Loss:0.07211, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14020, Train Loss:0.00759, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14021, Train Loss:0.05069, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14022, Train Loss:0.00079, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14023, Train Loss:0.00009, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14024, Train Loss:0.01607, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14025, Train Loss:0.00016, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14026, Train Loss:0.00032, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14027, Train Loss:0.01485, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14028, Train Loss:0.00009, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14029, Train Loss:0.00180, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14030, Train Loss:0.05531, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14031, Train Loss:0.00047, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14032, Train Loss:0.16756, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14033, Train Loss:0.11529, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14034, Train Loss:0.00035, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14035, Train Loss:0.00017, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14036, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14037, Train Loss:0.00040, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14038, Train Loss:0.00723, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14039, Train Loss:0.00430, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14040, Train Loss:0.00017, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14041, Train Loss:0.00528, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14042, Train Loss:0.12985, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14043, Train Loss:0.00013, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14044, Train Loss:0.31150, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14045, Train Loss:0.00003, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14046, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14047, Train Loss:0.00013, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14048, Train Loss:0.03744, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14049, Train Loss:0.41805, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14050, Train Loss:0.02827, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14051, Train Loss:0.00237, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14052, Train Loss:0.38220, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14053, Train Loss:0.02489, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14054, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14055, Train Loss:0.00003, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14056, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14057, Train Loss:0.60970, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14058, Train Loss:0.02857, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14059, Train Loss:0.00003, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14060, Train Loss:0.02046, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14061, Train Loss:0.00010, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14062, Train Loss:0.00019, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14063, Train Loss:0.04796, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14064, Train Loss:0.30387, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14065, Train Loss:0.03809, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14066, Train Loss:0.00716, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14067, Train Loss:0.00315, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14068, Train Loss:0.05571, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14069, Train Loss:0.52407, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14070, Train Loss:0.02927, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14071, Train Loss:0.10365, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14072, Train Loss:0.06456, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14073, Train Loss:0.13705, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14074, Train Loss:0.00353, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14075, Train Loss:0.01795, Dev Loss:0.24836\n",
      "Epoch:[50/100], step:14076, Train Loss:0.06530, Dev Loss:0.24836\n",
      "Start Epoch: 51, Steps: 17\n",
      "Epoch:[51/100], step:14077, Train Loss:0.02625, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14078, Train Loss:0.13583, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14079, Train Loss:0.01277, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14080, Train Loss:0.00142, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14081, Train Loss:0.00355, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14082, Train Loss:0.17246, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14083, Train Loss:0.00881, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14084, Train Loss:0.01618, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14085, Train Loss:0.10367, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14086, Train Loss:0.19676, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14087, Train Loss:0.00778, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14088, Train Loss:0.00027, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14089, Train Loss:0.03620, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14090, Train Loss:0.00075, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14091, Train Loss:0.08872, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14092, Train Loss:0.00018, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14093, Train Loss:0.00012, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14094, Train Loss:0.00194, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14095, Train Loss:0.00008, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14096, Train Loss:0.03748, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14097, Train Loss:0.24557, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14098, Train Loss:0.13544, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14099, Train Loss:0.00180, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14100, Train Loss:0.00242, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14101, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14102, Train Loss:0.23015, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14103, Train Loss:0.00015, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14104, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14105, Train Loss:0.01368, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14106, Train Loss:0.00035, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14107, Train Loss:0.17567, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14108, Train Loss:0.02087, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14109, Train Loss:0.00010, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14110, Train Loss:0.06828, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14111, Train Loss:0.00036, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14112, Train Loss:0.00016, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14113, Train Loss:0.31339, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14114, Train Loss:0.00573, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14115, Train Loss:0.04024, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14116, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14117, Train Loss:0.00208, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14118, Train Loss:0.00021, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14119, Train Loss:0.08158, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14120, Train Loss:0.01127, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14121, Train Loss:0.00001, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14122, Train Loss:0.00018, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14123, Train Loss:0.05708, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14124, Train Loss:0.00060, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14125, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14126, Train Loss:0.00125, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14127, Train Loss:0.00105, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14128, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14129, Train Loss:0.00010, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14130, Train Loss:0.01177, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14131, Train Loss:0.04026, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14132, Train Loss:0.14613, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14133, Train Loss:0.08738, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14134, Train Loss:0.05330, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14135, Train Loss:0.00271, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14136, Train Loss:0.41450, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14137, Train Loss:0.00018, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14138, Train Loss:0.01225, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14139, Train Loss:0.34550, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14140, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14141, Train Loss:0.01514, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14142, Train Loss:0.00379, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14143, Train Loss:0.00011, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14144, Train Loss:0.00003, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14145, Train Loss:0.03569, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14146, Train Loss:0.00151, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14147, Train Loss:0.21819, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14148, Train Loss:0.02449, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14149, Train Loss:0.00336, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14150, Train Loss:0.00541, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14151, Train Loss:0.08114, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14152, Train Loss:0.00044, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14153, Train Loss:0.26410, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14154, Train Loss:0.00337, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14155, Train Loss:0.14448, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14156, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14157, Train Loss:0.00001, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14158, Train Loss:0.14319, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14159, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14160, Train Loss:0.00404, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14161, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14162, Train Loss:0.21610, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14163, Train Loss:0.00060, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14164, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14165, Train Loss:0.37797, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14166, Train Loss:0.22103, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14167, Train Loss:0.53545, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14168, Train Loss:0.09642, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14169, Train Loss:0.00015, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14170, Train Loss:0.10029, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14171, Train Loss:0.00046, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14172, Train Loss:0.00053, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14173, Train Loss:0.17463, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14174, Train Loss:0.06107, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14175, Train Loss:0.05061, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14176, Train Loss:0.17668, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14177, Train Loss:0.00711, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14178, Train Loss:0.00072, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14179, Train Loss:0.01313, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14180, Train Loss:0.00613, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14181, Train Loss:0.00059, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14182, Train Loss:0.40172, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14183, Train Loss:0.00155, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14184, Train Loss:0.14989, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14185, Train Loss:0.00798, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14186, Train Loss:0.01891, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14187, Train Loss:0.28944, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14188, Train Loss:0.22897, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14189, Train Loss:0.01183, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14190, Train Loss:0.08032, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14191, Train Loss:0.12402, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14192, Train Loss:0.01028, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14193, Train Loss:0.06632, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14194, Train Loss:0.01485, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14195, Train Loss:0.00034, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14196, Train Loss:0.00137, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14197, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14198, Train Loss:0.33342, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14199, Train Loss:0.13854, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14200, Train Loss:0.08922, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14201, Train Loss:0.02641, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14202, Train Loss:0.00724, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14203, Train Loss:0.00826, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14204, Train Loss:0.38105, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14205, Train Loss:0.44113, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14206, Train Loss:0.02245, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14207, Train Loss:0.00001, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14208, Train Loss:0.04717, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14209, Train Loss:0.07254, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14210, Train Loss:0.06912, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14211, Train Loss:0.13199, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14212, Train Loss:0.01070, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14213, Train Loss:0.07376, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14214, Train Loss:0.00014, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14215, Train Loss:0.11141, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14216, Train Loss:0.13904, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14217, Train Loss:0.14870, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14218, Train Loss:0.08382, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14219, Train Loss:0.04498, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14220, Train Loss:0.00017, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14221, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14222, Train Loss:0.30312, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14223, Train Loss:0.16146, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14224, Train Loss:0.00341, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14225, Train Loss:0.00697, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14226, Train Loss:0.00184, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14227, Train Loss:0.00114, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14228, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14229, Train Loss:0.13857, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14230, Train Loss:0.00631, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14231, Train Loss:0.42745, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14232, Train Loss:0.00001, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14233, Train Loss:0.32482, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14234, Train Loss:0.00132, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14235, Train Loss:0.00768, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14236, Train Loss:0.00017, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14237, Train Loss:0.22181, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14238, Train Loss:0.01240, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14239, Train Loss:0.11655, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14240, Train Loss:0.15725, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14241, Train Loss:0.00487, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14242, Train Loss:0.00199, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14243, Train Loss:0.12867, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14244, Train Loss:0.00000, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14245, Train Loss:0.05368, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14246, Train Loss:0.39420, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14247, Train Loss:0.30220, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14248, Train Loss:0.20603, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14249, Train Loss:0.03335, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14250, Train Loss:0.00001, Dev Loss:0.24836\n",
      "Epoch:[51/100], step:14251, Train Loss:0.07821, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14252, Train Loss:1.23005, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14253, Train Loss:0.19116, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14254, Train Loss:0.00125, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14255, Train Loss:0.95825, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14256, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14257, Train Loss:0.04911, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14258, Train Loss:0.00002, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14259, Train Loss:0.15102, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14260, Train Loss:0.00605, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14261, Train Loss:0.18134, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14262, Train Loss:0.11979, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14263, Train Loss:0.05450, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14264, Train Loss:0.27826, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14265, Train Loss:0.90502, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14266, Train Loss:0.00022, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14267, Train Loss:0.06493, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14268, Train Loss:0.00008, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14269, Train Loss:0.05128, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14270, Train Loss:0.00022, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14271, Train Loss:0.08107, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14272, Train Loss:0.04277, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14273, Train Loss:0.25477, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14274, Train Loss:0.01489, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14275, Train Loss:0.00570, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14276, Train Loss:0.05835, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14277, Train Loss:0.19650, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14278, Train Loss:0.36274, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14279, Train Loss:0.00221, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14280, Train Loss:0.15791, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14281, Train Loss:0.00098, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14282, Train Loss:0.22496, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14283, Train Loss:0.14573, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14284, Train Loss:0.07292, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14285, Train Loss:0.00152, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14286, Train Loss:0.11312, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14287, Train Loss:0.00009, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14288, Train Loss:0.00466, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14289, Train Loss:0.00003, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14290, Train Loss:0.00172, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14291, Train Loss:0.00123, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14292, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14293, Train Loss:0.04310, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14294, Train Loss:0.10968, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14295, Train Loss:0.35551, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14296, Train Loss:0.00152, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14297, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14298, Train Loss:0.02346, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14299, Train Loss:0.00013, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14300, Train Loss:0.31653, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14301, Train Loss:0.22380, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14302, Train Loss:0.00016, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14303, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14304, Train Loss:0.00015, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14305, Train Loss:0.05335, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14306, Train Loss:0.13862, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14307, Train Loss:0.08344, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14308, Train Loss:0.15794, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14309, Train Loss:0.27297, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14310, Train Loss:0.01164, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14311, Train Loss:0.00002, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14312, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14313, Train Loss:0.00718, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14314, Train Loss:0.00011, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14315, Train Loss:0.07987, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14316, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14317, Train Loss:0.10243, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14318, Train Loss:0.00039, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14319, Train Loss:0.26189, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14320, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14321, Train Loss:0.00010, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14322, Train Loss:0.00016, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14323, Train Loss:0.00008, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14324, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14325, Train Loss:0.04808, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14326, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14327, Train Loss:0.15107, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14328, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14329, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14330, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14331, Train Loss:0.09768, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14332, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14333, Train Loss:0.15979, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14334, Train Loss:0.04862, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14335, Train Loss:0.09006, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14336, Train Loss:0.00035, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14337, Train Loss:0.00016, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14338, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14339, Train Loss:0.31966, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14340, Train Loss:0.00134, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14341, Train Loss:0.00118, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14342, Train Loss:0.00002, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14343, Train Loss:0.00576, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14344, Train Loss:0.95157, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14345, Train Loss:0.10279, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14346, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14347, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14348, Train Loss:0.21578, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14349, Train Loss:0.02068, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14350, Train Loss:0.28502, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14351, Train Loss:0.00013, Dev Loss:0.14558\n",
      "Epoch:[51/100], step:14352, Train Loss:0.28872, Dev Loss:0.14558\n",
      "Start Epoch: 52, Steps: 17\n",
      "Epoch:[52/100], step:14353, Train Loss:0.15540, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14354, Train Loss:0.01950, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14355, Train Loss:0.28809, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14356, Train Loss:0.00821, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14357, Train Loss:0.00003, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14358, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14359, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14360, Train Loss:0.01502, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14361, Train Loss:0.00028, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14362, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14363, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14364, Train Loss:0.12627, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14365, Train Loss:0.25876, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14366, Train Loss:0.05552, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14367, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14368, Train Loss:0.03177, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14369, Train Loss:0.00333, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14370, Train Loss:0.01092, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14371, Train Loss:0.02190, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14372, Train Loss:0.07608, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14373, Train Loss:0.00002, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14374, Train Loss:0.00083, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14375, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14376, Train Loss:0.00419, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14377, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14378, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14379, Train Loss:0.22165, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14380, Train Loss:0.00111, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14381, Train Loss:0.76338, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14382, Train Loss:0.04561, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14383, Train Loss:1.44500, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14384, Train Loss:0.00030, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14385, Train Loss:0.00243, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14386, Train Loss:0.08883, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14387, Train Loss:0.00031, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14388, Train Loss:0.30892, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14389, Train Loss:0.00017, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14390, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14391, Train Loss:0.17634, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14392, Train Loss:0.00038, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14393, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14394, Train Loss:0.00105, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14395, Train Loss:0.13953, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14396, Train Loss:0.01254, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14397, Train Loss:0.10724, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14398, Train Loss:0.03737, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14399, Train Loss:0.12616, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14400, Train Loss:0.10304, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14401, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14402, Train Loss:0.23476, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14403, Train Loss:0.11123, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14404, Train Loss:0.02344, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14405, Train Loss:0.23691, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14406, Train Loss:0.02477, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14407, Train Loss:0.00436, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14408, Train Loss:0.01863, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14409, Train Loss:0.01719, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14410, Train Loss:0.09980, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14411, Train Loss:0.00312, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14412, Train Loss:0.00177, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14413, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14414, Train Loss:0.00175, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14415, Train Loss:0.08822, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14416, Train Loss:0.65396, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14417, Train Loss:0.06697, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14418, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14419, Train Loss:0.13330, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14420, Train Loss:0.04559, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14421, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14422, Train Loss:0.07803, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14423, Train Loss:0.00011, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14424, Train Loss:0.29160, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14425, Train Loss:0.36962, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14426, Train Loss:0.00496, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14427, Train Loss:0.66108, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14428, Train Loss:0.21812, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14429, Train Loss:0.00006, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14430, Train Loss:0.02418, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14431, Train Loss:0.00038, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14432, Train Loss:0.04736, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14433, Train Loss:0.00058, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14434, Train Loss:0.88317, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14435, Train Loss:0.00520, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14436, Train Loss:0.00006, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14437, Train Loss:0.00430, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14438, Train Loss:0.00168, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14439, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14440, Train Loss:0.10284, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14441, Train Loss:0.19393, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14442, Train Loss:0.00003, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14443, Train Loss:0.01053, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14444, Train Loss:0.27611, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14445, Train Loss:0.07032, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14446, Train Loss:0.02474, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14447, Train Loss:0.00803, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14448, Train Loss:0.41664, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14449, Train Loss:0.55826, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14450, Train Loss:0.01429, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14451, Train Loss:0.04018, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14452, Train Loss:0.17185, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14453, Train Loss:0.00009, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14454, Train Loss:0.00013, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14455, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14456, Train Loss:0.00547, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14457, Train Loss:0.00272, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14458, Train Loss:0.00015, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14459, Train Loss:0.06462, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14460, Train Loss:0.03363, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14461, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14462, Train Loss:0.00066, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14463, Train Loss:0.02834, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14464, Train Loss:0.13857, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14465, Train Loss:0.00363, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14466, Train Loss:0.02901, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14467, Train Loss:0.74923, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14468, Train Loss:0.05969, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14469, Train Loss:0.01895, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14470, Train Loss:0.21882, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14471, Train Loss:0.07828, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14472, Train Loss:0.00000, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14473, Train Loss:0.01004, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14474, Train Loss:0.23640, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14475, Train Loss:0.07350, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14476, Train Loss:0.48131, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14477, Train Loss:0.65211, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14478, Train Loss:0.09333, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14479, Train Loss:0.54851, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14480, Train Loss:0.00674, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14481, Train Loss:0.00431, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14482, Train Loss:0.00003, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14483, Train Loss:0.00044, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14484, Train Loss:0.00964, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14485, Train Loss:0.00061, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14486, Train Loss:0.00040, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14487, Train Loss:0.00008, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14488, Train Loss:0.00534, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14489, Train Loss:0.83413, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14490, Train Loss:0.09198, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14491, Train Loss:0.00051, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14492, Train Loss:0.27237, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14493, Train Loss:0.16572, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14494, Train Loss:0.00023, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14495, Train Loss:0.04868, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14496, Train Loss:0.03694, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14497, Train Loss:0.03505, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14498, Train Loss:0.12510, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14499, Train Loss:0.24759, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14500, Train Loss:0.00001, Dev Loss:0.14558\n",
      "Epoch:[52/100], step:14501, Train Loss:0.01377, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14502, Train Loss:0.08463, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14503, Train Loss:0.12421, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14504, Train Loss:0.07847, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14505, Train Loss:0.10647, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14506, Train Loss:0.00084, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14507, Train Loss:0.00012, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14508, Train Loss:0.03135, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14509, Train Loss:0.00006, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14510, Train Loss:0.19907, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14511, Train Loss:0.63356, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14512, Train Loss:0.00570, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14513, Train Loss:0.10507, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14514, Train Loss:0.18197, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14515, Train Loss:0.00054, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14516, Train Loss:0.84382, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14517, Train Loss:0.02341, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14518, Train Loss:0.15623, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14519, Train Loss:0.08962, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14520, Train Loss:0.10092, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14521, Train Loss:0.08035, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14522, Train Loss:0.66204, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14523, Train Loss:0.14505, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14524, Train Loss:0.00045, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14525, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14526, Train Loss:0.08638, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14527, Train Loss:0.02878, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14528, Train Loss:0.00005, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14529, Train Loss:0.31301, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14530, Train Loss:0.25908, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14531, Train Loss:0.17261, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14532, Train Loss:0.64532, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14533, Train Loss:0.88315, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14534, Train Loss:0.18339, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14535, Train Loss:0.04660, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14536, Train Loss:0.00008, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14537, Train Loss:0.08374, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14538, Train Loss:0.04219, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14539, Train Loss:0.00156, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14540, Train Loss:0.18856, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14541, Train Loss:0.03758, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14542, Train Loss:0.00087, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14543, Train Loss:0.44310, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14544, Train Loss:0.02793, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14545, Train Loss:0.00445, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14546, Train Loss:0.01916, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14547, Train Loss:0.13296, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14548, Train Loss:0.07167, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14549, Train Loss:0.40991, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14550, Train Loss:0.00092, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14551, Train Loss:0.00140, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14552, Train Loss:0.01987, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14553, Train Loss:0.04924, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14554, Train Loss:0.00019, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14555, Train Loss:0.05317, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14556, Train Loss:0.08023, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14557, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14558, Train Loss:0.29896, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14559, Train Loss:0.03000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14560, Train Loss:0.00980, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14561, Train Loss:0.32828, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14562, Train Loss:0.02679, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14563, Train Loss:0.22613, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14564, Train Loss:0.00870, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14565, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14566, Train Loss:0.00002, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14567, Train Loss:0.95314, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14568, Train Loss:0.00073, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14569, Train Loss:0.00113, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14570, Train Loss:0.07511, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14571, Train Loss:0.01687, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14572, Train Loss:0.04144, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14573, Train Loss:0.12000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14574, Train Loss:0.21375, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14575, Train Loss:0.38745, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14576, Train Loss:0.01808, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14577, Train Loss:0.00400, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14578, Train Loss:0.03407, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14579, Train Loss:0.22426, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14580, Train Loss:0.04502, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14581, Train Loss:0.02771, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14582, Train Loss:0.69420, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14583, Train Loss:0.02360, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14584, Train Loss:0.00017, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14585, Train Loss:0.17984, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14586, Train Loss:0.23700, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14587, Train Loss:0.00144, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14588, Train Loss:0.83449, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14589, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14590, Train Loss:0.00920, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14591, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14592, Train Loss:0.02559, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14593, Train Loss:0.73604, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14594, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14595, Train Loss:0.01673, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14596, Train Loss:0.05627, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14597, Train Loss:0.19648, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14598, Train Loss:0.05229, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14599, Train Loss:0.15347, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14600, Train Loss:0.16190, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14601, Train Loss:0.24712, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14602, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14603, Train Loss:0.00025, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14604, Train Loss:0.00003, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14605, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14606, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14607, Train Loss:0.00043, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14608, Train Loss:0.00087, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14609, Train Loss:0.00002, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14610, Train Loss:0.02760, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14611, Train Loss:0.00024, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14612, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14613, Train Loss:0.21472, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14614, Train Loss:0.24406, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14615, Train Loss:0.53079, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14616, Train Loss:0.00046, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14617, Train Loss:0.18047, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14618, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14619, Train Loss:0.00269, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14620, Train Loss:0.06835, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14621, Train Loss:0.02748, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14622, Train Loss:0.00008, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14623, Train Loss:0.13214, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14624, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14625, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14626, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14627, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[52/100], step:14628, Train Loss:0.05658, Dev Loss:0.10994\n",
      "Start Epoch: 53, Steps: 17\n",
      "Epoch:[53/100], step:14629, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14630, Train Loss:0.02472, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14631, Train Loss:0.33645, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14632, Train Loss:0.00121, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14633, Train Loss:0.83407, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14634, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14635, Train Loss:0.00004, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14636, Train Loss:0.01336, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14637, Train Loss:0.65566, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14638, Train Loss:1.19190, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14639, Train Loss:0.01416, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14640, Train Loss:0.00344, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14641, Train Loss:0.16931, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14642, Train Loss:0.00003, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14643, Train Loss:0.05885, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14644, Train Loss:0.23484, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14645, Train Loss:0.01741, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14646, Train Loss:0.12629, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14647, Train Loss:0.20715, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14648, Train Loss:0.01127, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14649, Train Loss:0.23525, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14650, Train Loss:0.15180, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14651, Train Loss:0.14156, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14652, Train Loss:0.15849, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14653, Train Loss:0.00013, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14654, Train Loss:0.08214, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14655, Train Loss:0.01614, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14656, Train Loss:0.29210, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14657, Train Loss:0.03084, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14658, Train Loss:0.09562, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14659, Train Loss:0.08684, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14660, Train Loss:0.00013, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14661, Train Loss:0.00359, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14662, Train Loss:0.08783, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14663, Train Loss:0.00004, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14664, Train Loss:0.36970, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14665, Train Loss:0.00230, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14666, Train Loss:0.01251, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14667, Train Loss:0.01212, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14668, Train Loss:0.28362, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14669, Train Loss:0.09915, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14670, Train Loss:0.04904, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14671, Train Loss:0.34392, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14672, Train Loss:0.05097, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14673, Train Loss:0.01543, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14674, Train Loss:0.19729, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14675, Train Loss:0.09251, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14676, Train Loss:0.04140, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14677, Train Loss:0.00043, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14678, Train Loss:0.11060, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14679, Train Loss:0.00043, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14680, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14681, Train Loss:0.01989, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14682, Train Loss:0.28192, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14683, Train Loss:0.00736, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14684, Train Loss:0.03747, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14685, Train Loss:0.79960, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14686, Train Loss:0.00208, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14687, Train Loss:0.06175, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14688, Train Loss:0.17645, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14689, Train Loss:0.01318, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14690, Train Loss:0.00082, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14691, Train Loss:0.06703, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14692, Train Loss:0.00105, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14693, Train Loss:0.01809, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14694, Train Loss:0.77207, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14695, Train Loss:0.02712, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14696, Train Loss:0.00009, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14697, Train Loss:0.49707, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14698, Train Loss:0.03448, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14699, Train Loss:0.00427, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14700, Train Loss:0.01130, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14701, Train Loss:0.14295, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14702, Train Loss:0.00051, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14703, Train Loss:0.00164, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14704, Train Loss:0.00192, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14705, Train Loss:0.05582, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14706, Train Loss:0.01116, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14707, Train Loss:0.71916, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14708, Train Loss:0.00514, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14709, Train Loss:0.08306, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14710, Train Loss:0.00158, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14711, Train Loss:0.01080, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14712, Train Loss:0.00002, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14713, Train Loss:0.00274, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14714, Train Loss:0.00003, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14715, Train Loss:0.62995, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14716, Train Loss:0.00313, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14717, Train Loss:0.13452, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14718, Train Loss:0.14554, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14719, Train Loss:0.03815, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14720, Train Loss:0.02602, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14721, Train Loss:0.13455, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14722, Train Loss:0.00848, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14723, Train Loss:0.00064, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14724, Train Loss:0.41726, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14725, Train Loss:0.16129, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14726, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14727, Train Loss:0.00464, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14728, Train Loss:0.06098, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14729, Train Loss:0.00267, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14730, Train Loss:0.00011, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14731, Train Loss:0.01486, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14732, Train Loss:0.04874, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14733, Train Loss:0.00961, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14734, Train Loss:0.03253, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14735, Train Loss:0.06061, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14736, Train Loss:0.00108, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14737, Train Loss:0.00011, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14738, Train Loss:0.00013, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14739, Train Loss:0.05087, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14740, Train Loss:0.00005, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14741, Train Loss:0.00001, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14742, Train Loss:0.00035, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14743, Train Loss:0.03747, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14744, Train Loss:0.02729, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14745, Train Loss:0.00717, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14746, Train Loss:0.00400, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14747, Train Loss:0.00000, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14748, Train Loss:0.12377, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14749, Train Loss:0.02174, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14750, Train Loss:0.00008, Dev Loss:0.10994\n",
      "Epoch:[53/100], step:14751, Train Loss:0.13464, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14752, Train Loss:0.00030, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14753, Train Loss:0.01972, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14754, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14755, Train Loss:0.07188, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14756, Train Loss:0.05561, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14757, Train Loss:0.07533, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14758, Train Loss:0.00617, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14759, Train Loss:0.00113, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14760, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14761, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14762, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14763, Train Loss:0.02276, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14764, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14765, Train Loss:0.00961, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14766, Train Loss:0.00006, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14767, Train Loss:0.35814, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14768, Train Loss:0.00227, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14769, Train Loss:0.00854, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14770, Train Loss:0.08000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14771, Train Loss:0.08806, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14772, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14773, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14774, Train Loss:0.00006, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14775, Train Loss:0.00026, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14776, Train Loss:0.01752, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14777, Train Loss:0.02111, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14778, Train Loss:0.00825, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14779, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14780, Train Loss:0.11895, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14781, Train Loss:0.00236, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14782, Train Loss:0.00367, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14783, Train Loss:0.00008, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14784, Train Loss:0.03232, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14785, Train Loss:0.15637, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14786, Train Loss:0.00012, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14787, Train Loss:0.21078, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14788, Train Loss:0.03770, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14789, Train Loss:0.01841, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14790, Train Loss:0.05764, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14791, Train Loss:0.00004, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14792, Train Loss:0.01414, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14793, Train Loss:0.02134, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14794, Train Loss:0.00032, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14795, Train Loss:0.00243, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14796, Train Loss:0.14871, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14797, Train Loss:0.00219, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14798, Train Loss:0.16593, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14799, Train Loss:0.00254, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14800, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14801, Train Loss:0.00527, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14802, Train Loss:0.00082, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14803, Train Loss:0.00111, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14804, Train Loss:0.06001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14805, Train Loss:0.00125, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14806, Train Loss:0.00020, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14807, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14808, Train Loss:0.00852, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14809, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14810, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14811, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14812, Train Loss:0.00019, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14813, Train Loss:0.09215, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14814, Train Loss:0.00008, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14815, Train Loss:0.00313, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14816, Train Loss:0.00026, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14817, Train Loss:0.00003, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14818, Train Loss:0.00713, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14819, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14820, Train Loss:0.67759, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14821, Train Loss:0.00036, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14822, Train Loss:0.00157, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14823, Train Loss:0.00003, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14824, Train Loss:0.00003, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14825, Train Loss:0.00223, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14826, Train Loss:0.00004, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14827, Train Loss:0.04410, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14828, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14829, Train Loss:0.00875, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14830, Train Loss:0.00058, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14831, Train Loss:0.09150, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14832, Train Loss:0.00177, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14833, Train Loss:0.08041, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14834, Train Loss:0.06083, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14835, Train Loss:0.04855, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14836, Train Loss:0.00057, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14837, Train Loss:0.04493, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14838, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14839, Train Loss:0.07333, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14840, Train Loss:0.13093, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14841, Train Loss:0.00044, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14842, Train Loss:0.00052, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14843, Train Loss:0.23409, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14844, Train Loss:0.21931, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14845, Train Loss:0.05207, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14846, Train Loss:0.00124, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14847, Train Loss:0.04308, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14848, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14849, Train Loss:0.00218, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14850, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14851, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14852, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14853, Train Loss:0.09747, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14854, Train Loss:0.18889, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14855, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14856, Train Loss:0.00007, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14857, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14858, Train Loss:0.21859, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14859, Train Loss:0.18112, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14860, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14861, Train Loss:0.05129, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14862, Train Loss:0.00985, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14863, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14864, Train Loss:0.02127, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14865, Train Loss:1.07720, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14866, Train Loss:0.10289, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14867, Train Loss:0.25096, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14868, Train Loss:0.21872, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14869, Train Loss:1.05040, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14870, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14871, Train Loss:0.23771, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14872, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14873, Train Loss:0.05968, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14874, Train Loss:0.00023, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14875, Train Loss:0.00006, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14876, Train Loss:0.00361, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14877, Train Loss:0.03709, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14878, Train Loss:0.00329, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14879, Train Loss:0.03055, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14880, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14881, Train Loss:1.27988, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14882, Train Loss:0.24358, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14883, Train Loss:0.24388, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14884, Train Loss:0.36337, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14885, Train Loss:0.00002, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14886, Train Loss:0.08875, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14887, Train Loss:0.09166, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14888, Train Loss:0.07605, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14889, Train Loss:0.01136, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14890, Train Loss:0.58616, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14891, Train Loss:0.18590, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14892, Train Loss:0.27209, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14893, Train Loss:0.02609, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14894, Train Loss:0.00015, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14895, Train Loss:0.00318, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14896, Train Loss:0.00008, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14897, Train Loss:0.08727, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14898, Train Loss:0.14249, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14899, Train Loss:0.12657, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14900, Train Loss:0.32630, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14901, Train Loss:0.00752, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14902, Train Loss:0.12892, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14903, Train Loss:0.19537, Dev Loss:0.12952\n",
      "Epoch:[53/100], step:14904, Train Loss:0.03739, Dev Loss:0.12952\n",
      "Start Epoch: 54, Steps: 17\n",
      "Epoch:[54/100], step:14905, Train Loss:0.18512, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14906, Train Loss:0.75406, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14907, Train Loss:0.22720, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14908, Train Loss:0.00005, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14909, Train Loss:0.61978, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14910, Train Loss:0.00281, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14911, Train Loss:0.00118, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14912, Train Loss:0.04144, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14913, Train Loss:0.01869, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14914, Train Loss:0.00158, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14915, Train Loss:0.00201, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14916, Train Loss:0.31389, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14917, Train Loss:0.00707, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14918, Train Loss:0.00055, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14919, Train Loss:0.08682, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14920, Train Loss:0.03560, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14921, Train Loss:0.04293, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14922, Train Loss:0.00003, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14923, Train Loss:0.03306, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14924, Train Loss:0.51029, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14925, Train Loss:0.69934, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14926, Train Loss:0.00891, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14927, Train Loss:0.00006, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14928, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14929, Train Loss:0.00351, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14930, Train Loss:0.01136, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14931, Train Loss:0.15330, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14932, Train Loss:0.00436, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14933, Train Loss:0.19610, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14934, Train Loss:0.01573, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14935, Train Loss:0.14296, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14936, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14937, Train Loss:0.00031, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14938, Train Loss:0.00015, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14939, Train Loss:0.09041, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14940, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14941, Train Loss:0.01160, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14942, Train Loss:0.00029, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14943, Train Loss:0.02151, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14944, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14945, Train Loss:0.06203, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14946, Train Loss:0.12709, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14947, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14948, Train Loss:0.29906, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14949, Train Loss:0.00440, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14950, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14951, Train Loss:0.38199, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14952, Train Loss:0.00437, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14953, Train Loss:0.00001, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14954, Train Loss:0.00002, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14955, Train Loss:0.00095, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14956, Train Loss:0.63337, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14957, Train Loss:0.00276, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14958, Train Loss:0.00002, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14959, Train Loss:0.78724, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14960, Train Loss:0.24134, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14961, Train Loss:0.00022, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14962, Train Loss:0.00000, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14963, Train Loss:0.06376, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14964, Train Loss:0.13221, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14965, Train Loss:0.03818, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14966, Train Loss:0.26927, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14967, Train Loss:0.12551, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14968, Train Loss:0.00707, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14969, Train Loss:0.08440, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14970, Train Loss:0.00011, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14971, Train Loss:0.00016, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14972, Train Loss:0.06525, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14973, Train Loss:0.00295, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14974, Train Loss:0.01647, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14975, Train Loss:0.00023, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14976, Train Loss:0.00213, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14977, Train Loss:0.07550, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14978, Train Loss:0.79647, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14979, Train Loss:0.09137, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14980, Train Loss:0.00037, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14981, Train Loss:0.41187, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14982, Train Loss:0.00248, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14983, Train Loss:0.04183, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14984, Train Loss:0.02358, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14985, Train Loss:0.19194, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14986, Train Loss:0.17163, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14987, Train Loss:0.24365, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14988, Train Loss:0.08738, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14989, Train Loss:0.03639, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14990, Train Loss:0.55144, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14991, Train Loss:0.18203, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14992, Train Loss:0.00433, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14993, Train Loss:0.02801, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14994, Train Loss:0.16214, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14995, Train Loss:0.04147, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14996, Train Loss:1.09559, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14997, Train Loss:0.23269, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14998, Train Loss:1.51005, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:14999, Train Loss:0.03863, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:15000, Train Loss:0.18333, Dev Loss:0.12952\n",
      "Epoch:[54/100], step:15001, Train Loss:0.35717, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15002, Train Loss:0.16929, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15003, Train Loss:0.11829, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15004, Train Loss:0.18072, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15005, Train Loss:0.17355, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15006, Train Loss:0.17366, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15007, Train Loss:0.11962, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15008, Train Loss:0.00345, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15009, Train Loss:0.00022, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15010, Train Loss:0.19937, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15011, Train Loss:0.01344, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15012, Train Loss:0.00054, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15013, Train Loss:0.03285, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15014, Train Loss:0.09131, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15015, Train Loss:0.11081, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15016, Train Loss:0.26821, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15017, Train Loss:0.00025, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15018, Train Loss:0.07155, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15019, Train Loss:0.14281, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15020, Train Loss:0.36504, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15021, Train Loss:0.00114, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15022, Train Loss:0.17413, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15023, Train Loss:0.60038, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15024, Train Loss:0.00181, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15025, Train Loss:0.09653, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15026, Train Loss:0.11078, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15027, Train Loss:0.00033, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15028, Train Loss:0.39581, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15029, Train Loss:0.20068, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15030, Train Loss:0.44745, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15031, Train Loss:0.19409, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15032, Train Loss:0.02663, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15033, Train Loss:0.02379, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15034, Train Loss:0.00187, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15035, Train Loss:0.09108, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15036, Train Loss:0.16494, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15037, Train Loss:0.82779, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15038, Train Loss:0.01643, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15039, Train Loss:0.79597, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15040, Train Loss:0.31794, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15041, Train Loss:25.15828, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15042, Train Loss:0.44725, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15043, Train Loss:0.02021, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15044, Train Loss:0.26317, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15045, Train Loss:0.11996, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15046, Train Loss:0.28628, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15047, Train Loss:0.41142, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15048, Train Loss:0.42262, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15049, Train Loss:0.27588, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15050, Train Loss:0.26133, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15051, Train Loss:1.03356, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15052, Train Loss:1.23468, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15053, Train Loss:1.05807, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15054, Train Loss:0.38541, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15055, Train Loss:0.47156, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15056, Train Loss:0.27370, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15057, Train Loss:1.09760, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15058, Train Loss:1.01021, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15059, Train Loss:1.25498, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15060, Train Loss:0.15907, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15061, Train Loss:1.26470, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15062, Train Loss:0.27904, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15063, Train Loss:0.23938, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15064, Train Loss:0.03022, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15065, Train Loss:1.16497, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15066, Train Loss:1.09390, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15067, Train Loss:0.59720, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15068, Train Loss:2.31469, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15069, Train Loss:1.38629, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15070, Train Loss:0.76924, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15071, Train Loss:0.33243, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15072, Train Loss:0.24118, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15073, Train Loss:0.20805, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15074, Train Loss:0.59680, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15075, Train Loss:0.56344, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15076, Train Loss:0.16352, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15077, Train Loss:1.35572, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15078, Train Loss:0.31040, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15079, Train Loss:0.76647, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15080, Train Loss:0.00176, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15081, Train Loss:0.46673, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15082, Train Loss:0.11886, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15083, Train Loss:0.17444, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15084, Train Loss:0.14882, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15085, Train Loss:0.83924, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15086, Train Loss:0.82885, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15087, Train Loss:0.52203, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15088, Train Loss:0.25859, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15089, Train Loss:0.34847, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15090, Train Loss:0.28476, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15091, Train Loss:0.00012, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15092, Train Loss:0.59045, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15093, Train Loss:0.10878, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15094, Train Loss:0.49894, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15095, Train Loss:0.71515, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15096, Train Loss:0.30704, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15097, Train Loss:1.34835, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15098, Train Loss:0.37436, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15099, Train Loss:0.13052, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15100, Train Loss:0.22853, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15101, Train Loss:0.15243, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15102, Train Loss:0.55710, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15103, Train Loss:0.46107, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15104, Train Loss:0.29775, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15105, Train Loss:0.41776, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15106, Train Loss:0.98933, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15107, Train Loss:0.63193, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15108, Train Loss:0.38958, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15109, Train Loss:0.18157, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15110, Train Loss:0.20039, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15111, Train Loss:0.50672, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15112, Train Loss:0.28025, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15113, Train Loss:0.23835, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15114, Train Loss:0.31395, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15115, Train Loss:0.33947, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15116, Train Loss:0.05447, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15117, Train Loss:0.13875, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15118, Train Loss:0.01434, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15119, Train Loss:0.00107, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15120, Train Loss:0.02029, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15121, Train Loss:0.00070, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15122, Train Loss:0.01750, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15123, Train Loss:0.09991, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15124, Train Loss:0.29856, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15125, Train Loss:0.12252, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15126, Train Loss:0.10126, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15127, Train Loss:0.00391, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15128, Train Loss:0.11277, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15129, Train Loss:0.07060, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15130, Train Loss:0.12129, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15131, Train Loss:0.00077, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15132, Train Loss:0.02462, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15133, Train Loss:0.01004, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15134, Train Loss:1.09546, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15135, Train Loss:0.00000, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15136, Train Loss:0.13916, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15137, Train Loss:0.49280, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15138, Train Loss:0.01098, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15139, Train Loss:0.06089, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15140, Train Loss:0.22442, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15141, Train Loss:0.59911, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15142, Train Loss:0.49854, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15143, Train Loss:0.05991, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15144, Train Loss:0.24459, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15145, Train Loss:0.15198, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15146, Train Loss:0.32934, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15147, Train Loss:0.06120, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15148, Train Loss:0.06137, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15149, Train Loss:0.16014, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15150, Train Loss:0.27686, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15151, Train Loss:0.01849, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15152, Train Loss:0.05022, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15153, Train Loss:0.14196, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15154, Train Loss:0.08734, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15155, Train Loss:0.22027, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15156, Train Loss:0.18739, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15157, Train Loss:0.00531, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15158, Train Loss:0.10236, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15159, Train Loss:1.93479, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15160, Train Loss:0.28495, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15161, Train Loss:0.01672, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15162, Train Loss:0.00768, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15163, Train Loss:0.00020, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15164, Train Loss:0.08428, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15165, Train Loss:0.24521, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15166, Train Loss:0.00045, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15167, Train Loss:0.02300, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15168, Train Loss:0.31143, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15169, Train Loss:0.00532, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15170, Train Loss:0.00080, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15171, Train Loss:0.00023, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15172, Train Loss:0.00001, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15173, Train Loss:0.00011, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15174, Train Loss:0.08207, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15175, Train Loss:0.14854, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15176, Train Loss:0.07517, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15177, Train Loss:0.23823, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15178, Train Loss:0.06000, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15179, Train Loss:0.00181, Dev Loss:0.22826\n",
      "Epoch:[54/100], step:15180, Train Loss:0.00037, Dev Loss:0.22826\n",
      "Start Epoch: 55, Steps: 17\n",
      "Epoch:[55/100], step:15181, Train Loss:0.03334, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15182, Train Loss:2.08616, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15183, Train Loss:0.11048, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15184, Train Loss:0.16158, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15185, Train Loss:0.06136, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15186, Train Loss:0.15984, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15187, Train Loss:0.36333, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15188, Train Loss:0.00076, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15189, Train Loss:0.05716, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15190, Train Loss:0.10713, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15191, Train Loss:0.00263, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15192, Train Loss:0.48411, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15193, Train Loss:0.12980, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15194, Train Loss:0.02751, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15195, Train Loss:0.42190, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15196, Train Loss:0.09226, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15197, Train Loss:0.15237, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15198, Train Loss:0.03718, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15199, Train Loss:0.00084, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15200, Train Loss:0.12321, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15201, Train Loss:0.01859, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15202, Train Loss:0.03377, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15203, Train Loss:0.00090, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15204, Train Loss:0.07916, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15205, Train Loss:0.02373, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15206, Train Loss:0.00140, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15207, Train Loss:0.03468, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15208, Train Loss:0.05208, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15209, Train Loss:0.21187, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15210, Train Loss:0.60211, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15211, Train Loss:0.08256, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15212, Train Loss:0.07805, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15213, Train Loss:0.07059, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15214, Train Loss:0.02042, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15215, Train Loss:0.10010, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15216, Train Loss:0.00007, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15217, Train Loss:0.18429, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15218, Train Loss:0.00804, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15219, Train Loss:0.23356, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15220, Train Loss:0.06206, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15221, Train Loss:0.08430, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15222, Train Loss:0.00000, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15223, Train Loss:0.14968, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15224, Train Loss:0.05694, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15225, Train Loss:0.02169, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15226, Train Loss:0.01181, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15227, Train Loss:0.29468, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15228, Train Loss:0.00152, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15229, Train Loss:0.21465, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15230, Train Loss:0.31083, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15231, Train Loss:0.00004, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15232, Train Loss:0.00001, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15233, Train Loss:0.53789, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15234, Train Loss:0.25491, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15235, Train Loss:0.18116, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15236, Train Loss:0.01355, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15237, Train Loss:0.55757, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15238, Train Loss:0.70623, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15239, Train Loss:0.08069, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15240, Train Loss:0.19004, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15241, Train Loss:0.51230, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15242, Train Loss:0.01490, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15243, Train Loss:0.03812, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15244, Train Loss:0.04465, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15245, Train Loss:0.05639, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15246, Train Loss:0.02439, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15247, Train Loss:0.07133, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15248, Train Loss:0.08541, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15249, Train Loss:0.01985, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15250, Train Loss:0.00926, Dev Loss:0.22826\n",
      "Epoch:[55/100], step:15251, Train Loss:0.01019, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15252, Train Loss:0.37047, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15253, Train Loss:0.00079, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15254, Train Loss:0.15884, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15255, Train Loss:0.16195, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15256, Train Loss:0.09267, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15257, Train Loss:0.22641, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15258, Train Loss:0.23143, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15259, Train Loss:0.09717, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15260, Train Loss:0.14133, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15261, Train Loss:0.26052, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15262, Train Loss:0.38205, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15263, Train Loss:0.04448, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15264, Train Loss:0.05602, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15265, Train Loss:0.00582, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15266, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15267, Train Loss:0.10658, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15268, Train Loss:0.08832, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15269, Train Loss:0.02709, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15270, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15271, Train Loss:0.01278, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15272, Train Loss:0.10067, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15273, Train Loss:0.03721, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15274, Train Loss:0.05034, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15275, Train Loss:0.02836, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15276, Train Loss:0.16326, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15277, Train Loss:0.13298, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15278, Train Loss:0.15114, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15279, Train Loss:0.14831, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15280, Train Loss:0.00083, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15281, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15282, Train Loss:0.06272, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15283, Train Loss:0.00189, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15284, Train Loss:0.00512, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15285, Train Loss:0.00002, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15286, Train Loss:0.00111, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15287, Train Loss:0.00374, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15288, Train Loss:0.11716, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15289, Train Loss:0.00183, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15290, Train Loss:0.00094, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15291, Train Loss:0.00203, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15292, Train Loss:0.03657, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15293, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15294, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15295, Train Loss:0.00510, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15296, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15297, Train Loss:0.06032, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15298, Train Loss:0.00016, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15299, Train Loss:0.00064, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15300, Train Loss:0.00151, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15301, Train Loss:0.02952, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15302, Train Loss:0.00316, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15303, Train Loss:0.00115, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15304, Train Loss:0.00004, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15305, Train Loss:0.26083, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15306, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15307, Train Loss:0.00027, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15308, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15309, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15310, Train Loss:0.03523, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15311, Train Loss:0.05329, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15312, Train Loss:0.00003, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15313, Train Loss:0.16199, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15314, Train Loss:0.05613, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15315, Train Loss:0.11285, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15316, Train Loss:0.00063, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15317, Train Loss:0.13399, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15318, Train Loss:0.07632, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15319, Train Loss:0.01045, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15320, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15321, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15322, Train Loss:0.15659, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15323, Train Loss:0.00002, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15324, Train Loss:0.12185, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15325, Train Loss:0.06313, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15326, Train Loss:0.00045, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15327, Train Loss:0.21878, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15328, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15329, Train Loss:0.03096, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15330, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15331, Train Loss:0.00700, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15332, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15333, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15334, Train Loss:0.16645, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15335, Train Loss:0.10903, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15336, Train Loss:0.00529, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15337, Train Loss:0.00004, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15338, Train Loss:0.11354, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15339, Train Loss:0.22541, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15340, Train Loss:0.23627, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15341, Train Loss:0.16374, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15342, Train Loss:0.02009, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15343, Train Loss:0.00013, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15344, Train Loss:0.02095, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15345, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15346, Train Loss:0.85785, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15347, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15348, Train Loss:0.00021, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15349, Train Loss:0.05966, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15350, Train Loss:0.00795, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15351, Train Loss:0.27239, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15352, Train Loss:0.01241, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15353, Train Loss:0.00123, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15354, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15355, Train Loss:0.41488, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15356, Train Loss:0.00002, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15357, Train Loss:0.09965, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15358, Train Loss:0.01648, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15359, Train Loss:0.00036, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15360, Train Loss:0.00007, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15361, Train Loss:0.12990, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15362, Train Loss:0.16461, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15363, Train Loss:0.19565, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15364, Train Loss:0.03890, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15365, Train Loss:0.06331, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15366, Train Loss:0.00005, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15367, Train Loss:0.00138, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15368, Train Loss:0.36220, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15369, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15370, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15371, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15372, Train Loss:0.00513, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15373, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15374, Train Loss:0.11140, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15375, Train Loss:0.52704, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15376, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15377, Train Loss:0.06173, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15378, Train Loss:0.02470, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15379, Train Loss:0.34692, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15380, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15381, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15382, Train Loss:0.03396, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15383, Train Loss:0.00585, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15384, Train Loss:0.04007, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15385, Train Loss:0.07233, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15386, Train Loss:0.00977, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15387, Train Loss:0.49886, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15388, Train Loss:0.17397, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15389, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15390, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15391, Train Loss:0.00007, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15392, Train Loss:0.00956, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15393, Train Loss:0.00076, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15394, Train Loss:0.03359, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15395, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15396, Train Loss:0.59154, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15397, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15398, Train Loss:0.22151, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15399, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15400, Train Loss:0.05463, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15401, Train Loss:1.30138, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15402, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15403, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15404, Train Loss:0.00028, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15405, Train Loss:0.00252, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15406, Train Loss:0.10848, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15407, Train Loss:0.02951, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15408, Train Loss:0.01820, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15409, Train Loss:0.50123, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15410, Train Loss:0.16169, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15411, Train Loss:0.00057, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15412, Train Loss:0.30998, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15413, Train Loss:0.23184, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15414, Train Loss:0.37826, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15415, Train Loss:1.11575, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15416, Train Loss:0.48349, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15417, Train Loss:0.00063, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15418, Train Loss:0.44797, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15419, Train Loss:0.00632, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15420, Train Loss:0.00007, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15421, Train Loss:0.09926, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15422, Train Loss:0.00669, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15423, Train Loss:0.06478, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15424, Train Loss:0.00545, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15425, Train Loss:0.06764, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15426, Train Loss:0.04690, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15427, Train Loss:0.00275, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15428, Train Loss:0.39677, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15429, Train Loss:0.04133, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15430, Train Loss:0.34084, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15431, Train Loss:0.00278, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15432, Train Loss:0.00259, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15433, Train Loss:0.25858, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15434, Train Loss:0.01818, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15435, Train Loss:0.12914, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15436, Train Loss:0.05452, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15437, Train Loss:0.39651, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15438, Train Loss:0.20349, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15439, Train Loss:0.21929, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15440, Train Loss:0.02205, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15441, Train Loss:0.17581, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15442, Train Loss:0.00221, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15443, Train Loss:0.00703, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15444, Train Loss:0.00010, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15445, Train Loss:0.01179, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15446, Train Loss:0.28956, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15447, Train Loss:0.04785, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15448, Train Loss:0.05686, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15449, Train Loss:0.10576, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15450, Train Loss:0.31179, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15451, Train Loss:0.37516, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15452, Train Loss:0.00077, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15453, Train Loss:0.01621, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15454, Train Loss:0.03124, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15455, Train Loss:0.21008, Dev Loss:0.15304\n",
      "Epoch:[55/100], step:15456, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Start Epoch: 56, Steps: 17\n",
      "Epoch:[56/100], step:15457, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15458, Train Loss:0.00180, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15459, Train Loss:0.16793, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15460, Train Loss:0.21296, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15461, Train Loss:0.00663, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15462, Train Loss:0.12429, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15463, Train Loss:0.02377, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15464, Train Loss:0.00472, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15465, Train Loss:0.14088, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15466, Train Loss:0.00015, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15467, Train Loss:0.00290, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15468, Train Loss:0.00687, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15469, Train Loss:0.00005, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15470, Train Loss:0.00039, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15471, Train Loss:0.07594, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15472, Train Loss:0.01972, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15473, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15474, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15475, Train Loss:0.13591, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15476, Train Loss:0.33460, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15477, Train Loss:0.08515, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15478, Train Loss:0.04363, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15479, Train Loss:0.00081, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15480, Train Loss:0.22886, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15481, Train Loss:0.15783, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15482, Train Loss:0.01285, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15483, Train Loss:0.30054, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15484, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15485, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15486, Train Loss:0.24359, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15487, Train Loss:0.00001, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15488, Train Loss:0.16162, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15489, Train Loss:0.00007, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15490, Train Loss:0.00215, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15491, Train Loss:0.34441, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15492, Train Loss:0.12204, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15493, Train Loss:0.44332, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15494, Train Loss:0.00190, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15495, Train Loss:0.00389, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15496, Train Loss:0.06131, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15497, Train Loss:0.01075, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15498, Train Loss:0.00000, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15499, Train Loss:0.00002, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15500, Train Loss:0.13316, Dev Loss:0.15304\n",
      "Epoch:[56/100], step:15501, Train Loss:0.00053, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15502, Train Loss:0.00014, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15503, Train Loss:0.07944, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15504, Train Loss:0.16596, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15505, Train Loss:0.00467, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15506, Train Loss:0.00068, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15507, Train Loss:0.05429, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15508, Train Loss:0.18052, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15509, Train Loss:0.02994, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15510, Train Loss:0.07195, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15511, Train Loss:0.25485, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15512, Train Loss:0.00014, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15513, Train Loss:0.22627, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15514, Train Loss:0.00008, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15515, Train Loss:0.00010, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15516, Train Loss:0.00325, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15517, Train Loss:0.00059, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15518, Train Loss:0.03436, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15519, Train Loss:0.09827, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15520, Train Loss:0.00781, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15521, Train Loss:0.02856, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15522, Train Loss:0.00054, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15523, Train Loss:0.74811, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15524, Train Loss:0.26866, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15525, Train Loss:0.07427, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15526, Train Loss:0.14396, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15527, Train Loss:0.05893, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15528, Train Loss:0.00002, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15529, Train Loss:0.00057, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15530, Train Loss:0.02855, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15531, Train Loss:0.00524, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15532, Train Loss:0.00010, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15533, Train Loss:0.02372, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15534, Train Loss:0.01752, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15535, Train Loss:0.00256, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15536, Train Loss:0.00748, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15537, Train Loss:0.14744, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15538, Train Loss:0.00046, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15539, Train Loss:0.00490, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15540, Train Loss:0.25355, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15541, Train Loss:0.00114, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15542, Train Loss:0.01677, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15543, Train Loss:0.00016, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15544, Train Loss:0.00003, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15545, Train Loss:0.00438, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15546, Train Loss:0.09764, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15547, Train Loss:0.00001, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15548, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15549, Train Loss:0.00377, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15550, Train Loss:0.00001, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15551, Train Loss:0.00475, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15552, Train Loss:0.07756, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15553, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15554, Train Loss:0.00277, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15555, Train Loss:0.00012, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15556, Train Loss:0.01095, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15557, Train Loss:0.79570, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15558, Train Loss:0.00010, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15559, Train Loss:0.19165, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15560, Train Loss:0.00204, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15561, Train Loss:0.37883, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15562, Train Loss:0.15906, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15563, Train Loss:0.00674, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15564, Train Loss:0.10528, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15565, Train Loss:0.36533, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15566, Train Loss:0.64811, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15567, Train Loss:0.27568, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15568, Train Loss:0.07524, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15569, Train Loss:0.10005, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15570, Train Loss:0.00242, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15571, Train Loss:0.44010, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15572, Train Loss:0.23384, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15573, Train Loss:0.27134, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15574, Train Loss:0.15781, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15575, Train Loss:1.60872, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15576, Train Loss:0.00097, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15577, Train Loss:0.00001, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15578, Train Loss:0.68465, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15579, Train Loss:0.28542, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15580, Train Loss:0.17150, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15581, Train Loss:0.21844, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15582, Train Loss:0.19511, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15583, Train Loss:0.08200, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15584, Train Loss:0.15871, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15585, Train Loss:0.02032, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15586, Train Loss:0.15022, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15587, Train Loss:0.31481, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15588, Train Loss:0.12155, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15589, Train Loss:0.14543, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15590, Train Loss:0.18451, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15591, Train Loss:0.56364, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15592, Train Loss:0.15792, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15593, Train Loss:0.12878, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15594, Train Loss:0.09678, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15595, Train Loss:0.01149, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15596, Train Loss:0.07549, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15597, Train Loss:0.26774, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15598, Train Loss:0.34192, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15599, Train Loss:0.07719, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15600, Train Loss:0.00051, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15601, Train Loss:0.00012, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15602, Train Loss:0.34482, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15603, Train Loss:0.03682, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15604, Train Loss:0.08380, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15605, Train Loss:0.24815, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15606, Train Loss:0.18236, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15607, Train Loss:0.00028, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15608, Train Loss:0.13875, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15609, Train Loss:0.16118, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15610, Train Loss:0.00255, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15611, Train Loss:0.07684, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15612, Train Loss:0.03392, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15613, Train Loss:0.04927, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15614, Train Loss:0.01410, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15615, Train Loss:0.10112, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15616, Train Loss:0.00199, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15617, Train Loss:0.05944, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15618, Train Loss:0.00003, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15619, Train Loss:0.03610, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15620, Train Loss:0.42996, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15621, Train Loss:0.12047, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15622, Train Loss:0.31878, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15623, Train Loss:0.00350, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15624, Train Loss:0.01030, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15625, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15626, Train Loss:0.00123, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15627, Train Loss:0.27401, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15628, Train Loss:0.14942, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15629, Train Loss:0.00045, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15630, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15631, Train Loss:0.29286, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15632, Train Loss:0.00026, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15633, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15634, Train Loss:0.36468, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15635, Train Loss:0.19393, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15636, Train Loss:0.26685, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15637, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15638, Train Loss:0.18740, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15639, Train Loss:0.00086, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15640, Train Loss:0.00005, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15641, Train Loss:0.17502, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15642, Train Loss:0.00004, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15643, Train Loss:0.21427, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15644, Train Loss:0.09497, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15645, Train Loss:0.00001, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15646, Train Loss:0.00101, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15647, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15648, Train Loss:0.20803, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15649, Train Loss:0.00099, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15650, Train Loss:0.16406, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15651, Train Loss:0.00016, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15652, Train Loss:0.01609, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15653, Train Loss:0.09258, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15654, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15655, Train Loss:0.21592, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15656, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15657, Train Loss:0.00493, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15658, Train Loss:0.23735, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15659, Train Loss:0.27187, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15660, Train Loss:0.01870, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15661, Train Loss:0.05408, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15662, Train Loss:0.02399, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15663, Train Loss:0.00573, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15664, Train Loss:0.00039, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15665, Train Loss:0.06298, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15666, Train Loss:0.00685, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15667, Train Loss:0.47386, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15668, Train Loss:0.00569, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15669, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15670, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15671, Train Loss:0.02458, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15672, Train Loss:0.03121, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15673, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15674, Train Loss:0.00472, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15675, Train Loss:0.00011, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15676, Train Loss:0.05993, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15677, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15678, Train Loss:0.14348, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15679, Train Loss:0.01053, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15680, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15681, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15682, Train Loss:0.08044, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15683, Train Loss:0.01709, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15684, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15685, Train Loss:0.02418, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15686, Train Loss:0.14741, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15687, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15688, Train Loss:0.04344, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15689, Train Loss:0.17915, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15690, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15691, Train Loss:0.00004, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15692, Train Loss:0.55441, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15693, Train Loss:0.02455, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15694, Train Loss:0.00003, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15695, Train Loss:0.24239, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15696, Train Loss:0.53081, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15697, Train Loss:0.01047, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15698, Train Loss:0.00408, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15699, Train Loss:0.02684, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15700, Train Loss:0.00634, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15701, Train Loss:0.00001, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15702, Train Loss:0.02488, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15703, Train Loss:0.22378, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15704, Train Loss:0.11999, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15705, Train Loss:0.00532, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15706, Train Loss:0.00105, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15707, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15708, Train Loss:0.25486, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15709, Train Loss:0.08186, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15710, Train Loss:0.18412, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15711, Train Loss:0.06947, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15712, Train Loss:0.16771, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15713, Train Loss:0.00089, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15714, Train Loss:0.20377, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15715, Train Loss:0.00410, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15716, Train Loss:0.01432, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15717, Train Loss:0.13634, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15718, Train Loss:0.00957, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15719, Train Loss:0.01088, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15720, Train Loss:0.07861, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15721, Train Loss:0.07568, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15722, Train Loss:0.09373, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15723, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15724, Train Loss:0.01522, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15725, Train Loss:0.04372, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15726, Train Loss:0.02905, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15727, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15728, Train Loss:0.29495, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15729, Train Loss:0.04303, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15730, Train Loss:0.00015, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15731, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[56/100], step:15732, Train Loss:0.03026, Dev Loss:0.09648\n",
      "Start Epoch: 57, Steps: 17\n",
      "Epoch:[57/100], step:15733, Train Loss:0.00729, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15734, Train Loss:0.00089, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15735, Train Loss:0.09275, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15736, Train Loss:0.00108, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15737, Train Loss:0.07200, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15738, Train Loss:0.07053, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15739, Train Loss:0.00280, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15740, Train Loss:0.00387, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15741, Train Loss:0.05017, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15742, Train Loss:0.08805, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15743, Train Loss:0.00284, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15744, Train Loss:0.18795, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15745, Train Loss:0.00189, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15746, Train Loss:0.06717, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15747, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15748, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15749, Train Loss:0.00169, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15750, Train Loss:0.00000, Dev Loss:0.09648\n",
      "Epoch:[57/100], step:15751, Train Loss:0.00377, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15752, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15753, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15754, Train Loss:0.07652, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15755, Train Loss:0.22593, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15756, Train Loss:0.00177, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15757, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15758, Train Loss:0.00487, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15759, Train Loss:0.10518, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15760, Train Loss:0.02501, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15761, Train Loss:0.21516, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15762, Train Loss:0.00150, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15763, Train Loss:0.10459, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15764, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15765, Train Loss:0.10941, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15766, Train Loss:0.00186, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15767, Train Loss:0.00001, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15768, Train Loss:0.00061, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15769, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15770, Train Loss:0.00076, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15771, Train Loss:0.00015, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15772, Train Loss:0.21596, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15773, Train Loss:0.08080, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15774, Train Loss:0.00149, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15775, Train Loss:0.00420, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15776, Train Loss:0.00007, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15777, Train Loss:0.07778, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15778, Train Loss:0.16526, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15779, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15780, Train Loss:0.00209, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15781, Train Loss:0.07121, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15782, Train Loss:0.04262, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15783, Train Loss:0.03561, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15784, Train Loss:0.05733, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15785, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15786, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15787, Train Loss:0.17799, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15788, Train Loss:0.04421, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15789, Train Loss:0.00100, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15790, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15791, Train Loss:0.13690, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15792, Train Loss:0.04344, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15793, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15794, Train Loss:0.00001, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15795, Train Loss:0.00003, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15796, Train Loss:0.01160, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15797, Train Loss:0.12724, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15798, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15799, Train Loss:0.12229, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15800, Train Loss:0.00198, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15801, Train Loss:0.73467, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15802, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15803, Train Loss:0.00990, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15804, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15805, Train Loss:0.03255, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15806, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15807, Train Loss:0.01458, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15808, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15809, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15810, Train Loss:0.04701, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15811, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15812, Train Loss:0.00036, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15813, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15814, Train Loss:0.00143, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15815, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15816, Train Loss:0.13822, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15817, Train Loss:0.00225, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15818, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15819, Train Loss:0.15746, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15820, Train Loss:0.00236, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15821, Train Loss:0.15066, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15822, Train Loss:0.07120, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15823, Train Loss:0.00110, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15824, Train Loss:0.00001, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15825, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15826, Train Loss:0.16082, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15827, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15828, Train Loss:0.01455, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15829, Train Loss:0.00026, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15830, Train Loss:0.02305, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15831, Train Loss:0.00017, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15832, Train Loss:0.01620, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15833, Train Loss:0.05364, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15834, Train Loss:0.00050, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15835, Train Loss:0.00226, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15836, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15837, Train Loss:0.05218, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15838, Train Loss:0.13489, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15839, Train Loss:0.00003, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15840, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15841, Train Loss:0.42604, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15842, Train Loss:0.05718, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15843, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15844, Train Loss:0.03523, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15845, Train Loss:0.43346, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15846, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15847, Train Loss:0.00966, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15848, Train Loss:0.00027, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15849, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15850, Train Loss:0.00001, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15851, Train Loss:0.02514, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15852, Train Loss:0.04128, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15853, Train Loss:0.31638, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15854, Train Loss:0.23674, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15855, Train Loss:0.24795, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15856, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15857, Train Loss:0.01084, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15858, Train Loss:0.00084, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15859, Train Loss:0.00739, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15860, Train Loss:0.09869, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15861, Train Loss:0.08153, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15862, Train Loss:0.18474, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15863, Train Loss:0.22162, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15864, Train Loss:0.01894, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15865, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15866, Train Loss:0.29365, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15867, Train Loss:0.40371, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15868, Train Loss:0.00825, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15869, Train Loss:0.00006, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15870, Train Loss:0.00317, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15871, Train Loss:0.00541, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15872, Train Loss:0.00338, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15873, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15874, Train Loss:0.00346, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15875, Train Loss:0.02934, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15876, Train Loss:0.09704, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15877, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15878, Train Loss:0.21868, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15879, Train Loss:0.00015, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15880, Train Loss:0.16498, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15881, Train Loss:0.00110, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15882, Train Loss:0.18122, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15883, Train Loss:0.01507, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15884, Train Loss:0.00010, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15885, Train Loss:0.00493, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15886, Train Loss:0.00003, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15887, Train Loss:0.17867, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15888, Train Loss:0.01461, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15889, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15890, Train Loss:0.00011, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15891, Train Loss:0.00928, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15892, Train Loss:0.02738, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15893, Train Loss:0.68286, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15894, Train Loss:0.00138, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15895, Train Loss:0.10303, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15896, Train Loss:0.00904, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15897, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15898, Train Loss:0.01796, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15899, Train Loss:0.15954, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15900, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15901, Train Loss:0.00009, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15902, Train Loss:0.12765, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15903, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15904, Train Loss:0.09127, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15905, Train Loss:0.21720, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15906, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15907, Train Loss:0.11105, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15908, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15909, Train Loss:0.34725, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15910, Train Loss:0.10734, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15911, Train Loss:0.00003, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15912, Train Loss:0.00019, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15913, Train Loss:0.02463, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15914, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15915, Train Loss:0.76343, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15916, Train Loss:0.10747, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15917, Train Loss:0.01118, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15918, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15919, Train Loss:0.00259, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15920, Train Loss:0.00001, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15921, Train Loss:0.17081, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15922, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15923, Train Loss:0.25371, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15924, Train Loss:0.47994, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15925, Train Loss:0.00133, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15926, Train Loss:0.05982, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15927, Train Loss:0.00514, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15928, Train Loss:0.00091, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15929, Train Loss:0.46436, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15930, Train Loss:0.21032, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15931, Train Loss:0.74490, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15932, Train Loss:0.00019, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15933, Train Loss:0.00461, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15934, Train Loss:0.00358, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15935, Train Loss:0.05160, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15936, Train Loss:0.06173, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15937, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15938, Train Loss:0.02465, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15939, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15940, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15941, Train Loss:0.01219, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15942, Train Loss:0.04576, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15943, Train Loss:0.00009, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15944, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15945, Train Loss:0.12244, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15946, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15947, Train Loss:0.16695, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15948, Train Loss:0.00033, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15949, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15950, Train Loss:0.00007, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15951, Train Loss:0.20335, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15952, Train Loss:0.00074, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15953, Train Loss:0.08996, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15954, Train Loss:0.10832, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15955, Train Loss:0.24472, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15956, Train Loss:0.04579, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15957, Train Loss:0.00341, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15958, Train Loss:0.06837, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15959, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15960, Train Loss:0.01749, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15961, Train Loss:0.94366, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15962, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15963, Train Loss:0.00028, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15964, Train Loss:0.00005, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15965, Train Loss:0.15006, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15966, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15967, Train Loss:0.00971, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15968, Train Loss:0.00012, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15969, Train Loss:0.19050, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15970, Train Loss:0.23324, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15971, Train Loss:0.39302, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15972, Train Loss:3.85334, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15973, Train Loss:0.02168, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15974, Train Loss:0.00000, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15975, Train Loss:0.04099, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15976, Train Loss:0.00242, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15977, Train Loss:0.09681, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15978, Train Loss:0.00279, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15979, Train Loss:0.15971, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15980, Train Loss:0.00259, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15981, Train Loss:0.29051, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15982, Train Loss:0.08712, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15983, Train Loss:0.03025, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15984, Train Loss:0.00079, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15985, Train Loss:0.71422, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15986, Train Loss:1.23955, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15987, Train Loss:0.19466, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15988, Train Loss:0.15098, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15989, Train Loss:0.02505, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15990, Train Loss:0.01468, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15991, Train Loss:0.01497, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15992, Train Loss:0.06433, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15993, Train Loss:0.18477, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15994, Train Loss:0.00002, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15995, Train Loss:0.12617, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15996, Train Loss:1.60861, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15997, Train Loss:0.18262, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15998, Train Loss:0.09489, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:15999, Train Loss:0.18157, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:16000, Train Loss:0.04053, Dev Loss:0.13087\n",
      "Epoch:[57/100], step:16001, Train Loss:0.09653, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16002, Train Loss:0.04766, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16003, Train Loss:0.26319, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16004, Train Loss:0.26365, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16005, Train Loss:0.05183, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16006, Train Loss:0.00219, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16007, Train Loss:0.27379, Dev Loss:0.15713\n",
      "Epoch:[57/100], step:16008, Train Loss:0.16110, Dev Loss:0.15713\n",
      "Start Epoch: 58, Steps: 17\n",
      "Epoch:[58/100], step:16009, Train Loss:0.19770, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16010, Train Loss:0.01243, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16011, Train Loss:0.10899, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16012, Train Loss:0.10599, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16013, Train Loss:0.01920, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16014, Train Loss:0.11869, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16015, Train Loss:0.13996, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16016, Train Loss:0.05875, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16017, Train Loss:0.26804, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16018, Train Loss:0.00747, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16019, Train Loss:0.22319, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16020, Train Loss:0.14329, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16021, Train Loss:0.12109, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16022, Train Loss:0.02825, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16023, Train Loss:0.09762, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16024, Train Loss:0.00002, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16025, Train Loss:0.00571, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16026, Train Loss:0.05114, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16027, Train Loss:0.24475, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16028, Train Loss:0.16143, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16029, Train Loss:0.00140, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16030, Train Loss:0.01426, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16031, Train Loss:0.16153, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16032, Train Loss:0.00402, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16033, Train Loss:0.00313, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16034, Train Loss:0.13860, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16035, Train Loss:0.12052, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16036, Train Loss:0.00014, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16037, Train Loss:0.00142, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16038, Train Loss:0.03921, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16039, Train Loss:0.00428, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16040, Train Loss:0.01414, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16041, Train Loss:0.00043, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16042, Train Loss:0.00920, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16043, Train Loss:0.00181, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16044, Train Loss:0.00119, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16045, Train Loss:0.00109, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16046, Train Loss:0.00004, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16047, Train Loss:0.01453, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16048, Train Loss:0.01873, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16049, Train Loss:0.00077, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16050, Train Loss:0.04573, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16051, Train Loss:0.00337, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16052, Train Loss:0.00125, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16053, Train Loss:0.21568, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16054, Train Loss:0.33644, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16055, Train Loss:0.06836, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16056, Train Loss:0.00466, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16057, Train Loss:0.13815, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16058, Train Loss:0.07396, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16059, Train Loss:0.04375, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16060, Train Loss:0.01408, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16061, Train Loss:0.13361, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16062, Train Loss:0.23949, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16063, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16064, Train Loss:0.02375, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16065, Train Loss:0.00376, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16066, Train Loss:0.08662, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16067, Train Loss:0.01860, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16068, Train Loss:0.00003, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16069, Train Loss:0.00001, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16070, Train Loss:0.13328, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16071, Train Loss:0.21161, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16072, Train Loss:0.21707, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16073, Train Loss:0.00030, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16074, Train Loss:0.00202, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16075, Train Loss:0.61602, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16076, Train Loss:0.21529, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16077, Train Loss:0.02644, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16078, Train Loss:0.13118, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16079, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16080, Train Loss:0.00164, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16081, Train Loss:0.03518, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16082, Train Loss:0.01064, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16083, Train Loss:0.00046, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16084, Train Loss:0.37892, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16085, Train Loss:0.02065, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16086, Train Loss:0.15120, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16087, Train Loss:0.00274, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16088, Train Loss:0.12019, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16089, Train Loss:0.01756, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16090, Train Loss:0.31930, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16091, Train Loss:0.00160, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16092, Train Loss:0.11389, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16093, Train Loss:0.06247, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16094, Train Loss:0.00046, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16095, Train Loss:0.00103, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16096, Train Loss:0.09466, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16097, Train Loss:0.03709, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16098, Train Loss:0.07837, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16099, Train Loss:0.00444, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16100, Train Loss:0.11794, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16101, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16102, Train Loss:0.01414, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16103, Train Loss:0.33078, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16104, Train Loss:0.00105, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16105, Train Loss:0.07946, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16106, Train Loss:0.00094, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16107, Train Loss:0.00841, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16108, Train Loss:0.01725, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16109, Train Loss:0.00350, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16110, Train Loss:0.00006, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16111, Train Loss:0.00069, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16112, Train Loss:0.11241, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16113, Train Loss:0.01597, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16114, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16115, Train Loss:0.01124, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16116, Train Loss:0.00048, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16117, Train Loss:0.03783, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16118, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16119, Train Loss:0.06414, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16120, Train Loss:0.01810, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16121, Train Loss:0.00084, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16122, Train Loss:0.10070, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16123, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16124, Train Loss:0.36728, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16125, Train Loss:0.01030, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16126, Train Loss:0.02466, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16127, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16128, Train Loss:0.00116, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16129, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16130, Train Loss:0.00030, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16131, Train Loss:0.00044, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16132, Train Loss:0.00003, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16133, Train Loss:0.22432, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16134, Train Loss:0.02154, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16135, Train Loss:0.06202, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16136, Train Loss:0.14368, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16137, Train Loss:0.01495, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16138, Train Loss:0.00010, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16139, Train Loss:0.25022, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16140, Train Loss:0.00305, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16141, Train Loss:0.00067, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16142, Train Loss:0.07305, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16143, Train Loss:0.00402, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16144, Train Loss:0.09558, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16145, Train Loss:0.23295, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16146, Train Loss:0.01600, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16147, Train Loss:0.19202, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16148, Train Loss:0.05035, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16149, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16150, Train Loss:0.09926, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16151, Train Loss:0.09004, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16152, Train Loss:0.00380, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16153, Train Loss:0.00001, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16154, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16155, Train Loss:0.00009, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16156, Train Loss:0.00016, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16157, Train Loss:0.00923, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16158, Train Loss:0.00870, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16159, Train Loss:0.11197, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16160, Train Loss:0.00001, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16161, Train Loss:0.07077, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16162, Train Loss:0.02533, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16163, Train Loss:0.00012, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16164, Train Loss:0.01028, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16165, Train Loss:0.00140, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16166, Train Loss:0.00021, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16167, Train Loss:0.47902, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16168, Train Loss:0.00231, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16169, Train Loss:0.00241, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16170, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16171, Train Loss:0.00511, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16172, Train Loss:0.00066, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16173, Train Loss:0.22621, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16174, Train Loss:0.11653, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16175, Train Loss:0.00131, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16176, Train Loss:0.00068, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16177, Train Loss:0.70340, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16178, Train Loss:0.73110, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16179, Train Loss:0.03247, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16180, Train Loss:0.00184, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16181, Train Loss:0.11757, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16182, Train Loss:0.04428, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16183, Train Loss:0.29414, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16184, Train Loss:0.06559, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16185, Train Loss:0.00698, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16186, Train Loss:0.00001, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16187, Train Loss:0.24274, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16188, Train Loss:0.09832, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16189, Train Loss:0.00775, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16190, Train Loss:0.58883, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16191, Train Loss:0.16307, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16192, Train Loss:0.07713, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16193, Train Loss:0.00004, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16194, Train Loss:0.10596, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16195, Train Loss:0.00270, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16196, Train Loss:0.00011, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16197, Train Loss:0.00925, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16198, Train Loss:0.06071, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16199, Train Loss:0.07426, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16200, Train Loss:0.01041, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16201, Train Loss:0.40187, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16202, Train Loss:0.07747, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16203, Train Loss:0.02427, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16204, Train Loss:0.04458, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16205, Train Loss:0.16784, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16206, Train Loss:0.09893, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16207, Train Loss:0.03393, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16208, Train Loss:0.00063, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16209, Train Loss:0.13185, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16210, Train Loss:0.02095, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16211, Train Loss:0.19503, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16212, Train Loss:0.00096, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16213, Train Loss:0.02406, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16214, Train Loss:0.01161, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16215, Train Loss:0.00853, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16216, Train Loss:0.08849, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16217, Train Loss:0.00001, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16218, Train Loss:0.09699, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16219, Train Loss:0.25092, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16220, Train Loss:0.00340, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16221, Train Loss:0.71773, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16222, Train Loss:0.00034, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16223, Train Loss:0.00318, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16224, Train Loss:0.00045, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16225, Train Loss:0.00152, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16226, Train Loss:0.00045, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16227, Train Loss:0.14422, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16228, Train Loss:0.09271, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16229, Train Loss:0.00026, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16230, Train Loss:0.01443, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16231, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16232, Train Loss:0.01446, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16233, Train Loss:0.30274, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16234, Train Loss:0.00066, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16235, Train Loss:0.00025, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16236, Train Loss:0.34288, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16237, Train Loss:0.00004, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16238, Train Loss:0.00092, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16239, Train Loss:0.00063, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16240, Train Loss:0.02223, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16241, Train Loss:0.51204, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16242, Train Loss:0.22956, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16243, Train Loss:0.00061, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16244, Train Loss:0.00037, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16245, Train Loss:0.00004, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16246, Train Loss:0.00000, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16247, Train Loss:0.00070, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16248, Train Loss:0.00339, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16249, Train Loss:0.00452, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16250, Train Loss:0.00017, Dev Loss:0.15713\n",
      "Epoch:[58/100], step:16251, Train Loss:0.11177, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16252, Train Loss:0.19653, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16253, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16254, Train Loss:0.00125, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16255, Train Loss:0.00723, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16256, Train Loss:0.11548, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16257, Train Loss:0.08540, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16258, Train Loss:0.01406, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16259, Train Loss:0.21966, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16260, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16261, Train Loss:0.00093, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16262, Train Loss:0.00036, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16263, Train Loss:0.00368, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16264, Train Loss:0.00176, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16265, Train Loss:0.00024, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16266, Train Loss:0.13785, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16267, Train Loss:0.12545, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16268, Train Loss:0.00081, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16269, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16270, Train Loss:0.06131, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16271, Train Loss:0.26063, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16272, Train Loss:0.08454, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16273, Train Loss:0.00006, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16274, Train Loss:0.01051, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16275, Train Loss:0.00627, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16276, Train Loss:0.00749, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16277, Train Loss:0.00012, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16278, Train Loss:0.00182, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16279, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16280, Train Loss:0.00119, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16281, Train Loss:0.00193, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16282, Train Loss:0.00095, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16283, Train Loss:0.28466, Dev Loss:0.08778\n",
      "Epoch:[58/100], step:16284, Train Loss:0.04867, Dev Loss:0.08778\n",
      "Start Epoch: 59, Steps: 17\n",
      "Epoch:[59/100], step:16285, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16286, Train Loss:0.18125, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16287, Train Loss:0.04197, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16288, Train Loss:0.00060, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16289, Train Loss:0.61565, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16290, Train Loss:0.66154, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16291, Train Loss:0.00027, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16292, Train Loss:0.00007, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16293, Train Loss:0.36822, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16294, Train Loss:0.00420, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16295, Train Loss:0.00077, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16296, Train Loss:0.26089, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16297, Train Loss:0.00045, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16298, Train Loss:0.03589, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16299, Train Loss:0.62350, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16300, Train Loss:0.00011, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16301, Train Loss:0.03237, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16302, Train Loss:0.00137, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16303, Train Loss:0.00445, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16304, Train Loss:0.10879, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16305, Train Loss:0.05324, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16306, Train Loss:0.05784, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16307, Train Loss:0.00003, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16308, Train Loss:0.10669, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16309, Train Loss:0.00141, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16310, Train Loss:0.00302, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16311, Train Loss:0.02034, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16312, Train Loss:0.00093, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16313, Train Loss:0.00009, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16314, Train Loss:0.13076, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16315, Train Loss:0.06105, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16316, Train Loss:0.19702, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16317, Train Loss:0.09354, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16318, Train Loss:0.03031, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16319, Train Loss:0.00837, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16320, Train Loss:0.00647, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16321, Train Loss:0.00058, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16322, Train Loss:0.08584, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16323, Train Loss:0.04229, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16324, Train Loss:0.04499, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16325, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16326, Train Loss:0.03322, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16327, Train Loss:0.32903, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16328, Train Loss:0.00017, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16329, Train Loss:0.00057, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16330, Train Loss:0.00063, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16331, Train Loss:0.31423, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16332, Train Loss:0.19506, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16333, Train Loss:0.15819, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16334, Train Loss:0.06444, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16335, Train Loss:0.00428, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16336, Train Loss:0.14588, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16337, Train Loss:0.07022, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16338, Train Loss:0.02922, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16339, Train Loss:0.23244, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16340, Train Loss:0.10567, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16341, Train Loss:0.06245, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16342, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16343, Train Loss:0.16521, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16344, Train Loss:0.00891, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16345, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16346, Train Loss:0.00592, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16347, Train Loss:0.00021, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16348, Train Loss:0.34351, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16349, Train Loss:0.50332, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16350, Train Loss:0.02701, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16351, Train Loss:0.13507, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16352, Train Loss:0.22940, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16353, Train Loss:0.17541, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16354, Train Loss:0.00535, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16355, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16356, Train Loss:0.00039, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16357, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16358, Train Loss:0.01333, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16359, Train Loss:0.01896, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16360, Train Loss:0.09432, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16361, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16362, Train Loss:0.00029, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16363, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16364, Train Loss:0.00035, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16365, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16366, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16367, Train Loss:0.00048, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16368, Train Loss:0.01514, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16369, Train Loss:0.04783, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16370, Train Loss:0.02503, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16371, Train Loss:0.00436, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16372, Train Loss:0.17237, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16373, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16374, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16375, Train Loss:0.04375, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16376, Train Loss:0.05212, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16377, Train Loss:0.55371, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16378, Train Loss:0.07365, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16379, Train Loss:0.00007, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16380, Train Loss:0.00855, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16381, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16382, Train Loss:0.68188, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16383, Train Loss:0.00003, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16384, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16385, Train Loss:0.07463, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16386, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16387, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16388, Train Loss:0.26225, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16389, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16390, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16391, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16392, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16393, Train Loss:0.03726, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16394, Train Loss:0.02664, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16395, Train Loss:0.01621, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16396, Train Loss:0.00912, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16397, Train Loss:0.28747, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16398, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16399, Train Loss:0.00015, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16400, Train Loss:0.00028, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16401, Train Loss:0.00954, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16402, Train Loss:0.00008, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16403, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16404, Train Loss:2.09857, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16405, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16406, Train Loss:0.00049, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16407, Train Loss:0.00003, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16408, Train Loss:0.02105, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16409, Train Loss:0.51348, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16410, Train Loss:0.39088, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16411, Train Loss:0.28629, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16412, Train Loss:0.00901, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16413, Train Loss:0.04501, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16414, Train Loss:0.00011, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16415, Train Loss:0.01488, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16416, Train Loss:0.01895, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16417, Train Loss:0.00187, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16418, Train Loss:0.00002, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16419, Train Loss:0.15274, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16420, Train Loss:0.41544, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16421, Train Loss:0.03795, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16422, Train Loss:0.00001, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16423, Train Loss:0.13890, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16424, Train Loss:0.09528, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16425, Train Loss:0.15560, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16426, Train Loss:0.02443, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16427, Train Loss:0.00022, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16428, Train Loss:0.00201, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16429, Train Loss:0.00031, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16430, Train Loss:0.13617, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16431, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16432, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16433, Train Loss:0.01961, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16434, Train Loss:0.54772, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16435, Train Loss:0.08522, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16436, Train Loss:0.23744, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16437, Train Loss:0.00131, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16438, Train Loss:0.10997, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16439, Train Loss:0.12403, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16440, Train Loss:0.00299, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16441, Train Loss:0.13301, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16442, Train Loss:0.00013, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16443, Train Loss:0.05955, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16444, Train Loss:0.19044, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16445, Train Loss:0.00151, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16446, Train Loss:0.18099, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16447, Train Loss:0.00110, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16448, Train Loss:0.00276, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16449, Train Loss:0.15770, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16450, Train Loss:0.00016, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16451, Train Loss:0.44889, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16452, Train Loss:0.05796, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16453, Train Loss:0.02487, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16454, Train Loss:0.02135, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16455, Train Loss:0.00555, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16456, Train Loss:0.04958, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16457, Train Loss:0.07832, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16458, Train Loss:0.00238, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16459, Train Loss:0.51838, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16460, Train Loss:0.00054, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16461, Train Loss:0.02625, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16462, Train Loss:0.77674, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16463, Train Loss:0.03484, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16464, Train Loss:0.00269, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16465, Train Loss:0.00140, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16466, Train Loss:0.04630, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16467, Train Loss:0.00021, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16468, Train Loss:0.00074, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16469, Train Loss:0.27100, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16470, Train Loss:0.00016, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16471, Train Loss:0.39673, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16472, Train Loss:0.01583, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16473, Train Loss:0.00007, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16474, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16475, Train Loss:0.19605, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16476, Train Loss:0.00107, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16477, Train Loss:0.02651, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16478, Train Loss:0.02767, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16479, Train Loss:0.01600, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16480, Train Loss:0.29318, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16481, Train Loss:0.02029, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16482, Train Loss:0.47829, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16483, Train Loss:0.07319, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16484, Train Loss:0.08539, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16485, Train Loss:0.00033, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16486, Train Loss:0.00390, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16487, Train Loss:0.00377, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16488, Train Loss:0.05790, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16489, Train Loss:0.08105, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16490, Train Loss:0.00010, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16491, Train Loss:0.00000, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16492, Train Loss:0.11516, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16493, Train Loss:0.00089, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16494, Train Loss:2.57541, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16495, Train Loss:0.00323, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16496, Train Loss:0.25894, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16497, Train Loss:0.01293, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16498, Train Loss:0.19211, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16499, Train Loss:0.01699, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16500, Train Loss:0.00016, Dev Loss:0.08778\n",
      "Epoch:[59/100], step:16501, Train Loss:0.00354, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16502, Train Loss:0.10025, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16503, Train Loss:0.03804, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16504, Train Loss:0.00815, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16505, Train Loss:0.47097, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16506, Train Loss:0.03082, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16507, Train Loss:0.00033, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16508, Train Loss:0.00002, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16509, Train Loss:0.14081, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16510, Train Loss:0.01115, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16511, Train Loss:0.16023, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16512, Train Loss:0.10673, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16513, Train Loss:0.02763, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16514, Train Loss:0.14162, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16515, Train Loss:0.22569, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16516, Train Loss:0.12978, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16517, Train Loss:0.00804, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16518, Train Loss:0.13839, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16519, Train Loss:0.13177, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16520, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16521, Train Loss:0.09331, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16522, Train Loss:0.02978, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16523, Train Loss:0.04829, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16524, Train Loss:0.38179, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16525, Train Loss:1.16113, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16526, Train Loss:0.20874, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16527, Train Loss:0.03995, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16528, Train Loss:0.16611, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16529, Train Loss:0.00013, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16530, Train Loss:0.00021, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16531, Train Loss:0.00042, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16532, Train Loss:0.08457, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16533, Train Loss:0.05764, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16534, Train Loss:0.00064, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16535, Train Loss:0.00206, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16536, Train Loss:0.00070, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16537, Train Loss:0.00027, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16538, Train Loss:0.00092, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16539, Train Loss:0.03177, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16540, Train Loss:0.14289, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16541, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16542, Train Loss:0.00423, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16543, Train Loss:0.34470, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16544, Train Loss:0.56374, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16545, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16546, Train Loss:0.00763, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16547, Train Loss:0.25250, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16548, Train Loss:0.29798, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16549, Train Loss:0.02493, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16550, Train Loss:0.19588, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16551, Train Loss:0.00009, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16552, Train Loss:0.10412, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16553, Train Loss:0.00003, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16554, Train Loss:0.14400, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16555, Train Loss:0.14265, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16556, Train Loss:0.04983, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16557, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16558, Train Loss:0.03749, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16559, Train Loss:0.10176, Dev Loss:0.14492\n",
      "Epoch:[59/100], step:16560, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Start Epoch: 60, Steps: 17\n",
      "Epoch:[60/100], step:16561, Train Loss:0.09365, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16562, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16563, Train Loss:0.06594, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16564, Train Loss:0.17447, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16565, Train Loss:0.00546, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16566, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16567, Train Loss:0.15063, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16568, Train Loss:0.00054, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16569, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16570, Train Loss:0.00010, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16571, Train Loss:0.00503, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16572, Train Loss:0.23622, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16573, Train Loss:0.01228, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16574, Train Loss:0.00095, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16575, Train Loss:0.00096, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16576, Train Loss:0.00012, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16577, Train Loss:0.01512, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16578, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16579, Train Loss:0.01389, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16580, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16581, Train Loss:0.00174, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16582, Train Loss:0.00250, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16583, Train Loss:0.01770, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16584, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16585, Train Loss:0.00434, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16586, Train Loss:0.01148, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16587, Train Loss:0.32844, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16588, Train Loss:0.03190, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16589, Train Loss:0.00086, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16590, Train Loss:0.05241, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16591, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16592, Train Loss:0.13943, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16593, Train Loss:0.12116, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16594, Train Loss:0.00074, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16595, Train Loss:0.02125, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16596, Train Loss:0.04014, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16597, Train Loss:0.16522, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16598, Train Loss:0.00007, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16599, Train Loss:0.00095, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16600, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16601, Train Loss:0.04888, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16602, Train Loss:0.02076, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16603, Train Loss:0.00006, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16604, Train Loss:0.04378, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16605, Train Loss:0.00115, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16606, Train Loss:0.06471, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16607, Train Loss:0.00299, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16608, Train Loss:0.00043, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16609, Train Loss:0.00004, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16610, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16611, Train Loss:0.11659, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16612, Train Loss:0.25894, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16613, Train Loss:0.01945, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16614, Train Loss:0.01509, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16615, Train Loss:0.08824, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16616, Train Loss:0.00008, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16617, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16618, Train Loss:0.00026, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16619, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16620, Train Loss:0.02049, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16621, Train Loss:0.00004, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16622, Train Loss:0.00005, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16623, Train Loss:0.12121, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16624, Train Loss:0.00011, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16625, Train Loss:0.00006, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16626, Train Loss:0.00044, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16627, Train Loss:0.00920, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16628, Train Loss:0.01015, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16629, Train Loss:0.23326, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16630, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16631, Train Loss:0.93767, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16632, Train Loss:0.26750, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16633, Train Loss:0.00042, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16634, Train Loss:0.00014, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16635, Train Loss:0.15392, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16636, Train Loss:0.00242, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16637, Train Loss:0.00650, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16638, Train Loss:0.00008, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16639, Train Loss:0.00017, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16640, Train Loss:0.10544, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16641, Train Loss:0.04037, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16642, Train Loss:0.00070, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16643, Train Loss:0.29381, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16644, Train Loss:0.41564, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16645, Train Loss:0.00039, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16646, Train Loss:0.05857, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16647, Train Loss:0.02463, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16648, Train Loss:0.07073, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16649, Train Loss:0.14028, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16650, Train Loss:0.00554, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16651, Train Loss:0.00342, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16652, Train Loss:0.16981, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16653, Train Loss:0.16024, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16654, Train Loss:0.27236, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16655, Train Loss:0.17668, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16656, Train Loss:0.25020, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16657, Train Loss:0.00992, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16658, Train Loss:0.00905, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16659, Train Loss:0.10866, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16660, Train Loss:0.04677, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16661, Train Loss:0.00409, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16662, Train Loss:0.01043, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16663, Train Loss:0.14018, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16664, Train Loss:0.05387, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16665, Train Loss:0.09980, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16666, Train Loss:0.11750, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16667, Train Loss:0.11833, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16668, Train Loss:0.00874, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16669, Train Loss:0.00006, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16670, Train Loss:0.00202, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16671, Train Loss:0.01854, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16672, Train Loss:0.14185, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16673, Train Loss:0.00409, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16674, Train Loss:0.06274, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16675, Train Loss:0.45697, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16676, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16677, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16678, Train Loss:0.00022, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16679, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16680, Train Loss:0.19044, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16681, Train Loss:0.00014, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16682, Train Loss:0.05661, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16683, Train Loss:0.01127, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16684, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16685, Train Loss:0.01803, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16686, Train Loss:0.00041, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16687, Train Loss:0.00533, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16688, Train Loss:0.00189, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16689, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16690, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16691, Train Loss:0.07102, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16692, Train Loss:0.01609, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16693, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16694, Train Loss:0.00016, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16695, Train Loss:0.00728, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16696, Train Loss:0.44502, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16697, Train Loss:0.00030, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16698, Train Loss:0.01822, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16699, Train Loss:0.14828, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16700, Train Loss:0.00030, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16701, Train Loss:0.92437, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16702, Train Loss:0.28064, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16703, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16704, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16705, Train Loss:0.15372, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16706, Train Loss:0.02419, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16707, Train Loss:0.00360, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16708, Train Loss:0.00040, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16709, Train Loss:0.25155, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16710, Train Loss:0.00005, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16711, Train Loss:0.00014, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16712, Train Loss:0.00406, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16713, Train Loss:0.00062, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16714, Train Loss:0.37882, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16715, Train Loss:0.00208, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16716, Train Loss:0.35407, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16717, Train Loss:0.00001, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16718, Train Loss:0.70326, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16719, Train Loss:0.02231, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16720, Train Loss:0.00054, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16721, Train Loss:0.03581, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16722, Train Loss:0.01678, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16723, Train Loss:0.02450, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16724, Train Loss:0.00003, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16725, Train Loss:0.04524, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16726, Train Loss:0.08540, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16727, Train Loss:0.00114, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16728, Train Loss:0.05787, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16729, Train Loss:0.13557, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16730, Train Loss:0.24830, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16731, Train Loss:0.00026, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16732, Train Loss:0.34732, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16733, Train Loss:0.29859, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16734, Train Loss:0.19603, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16735, Train Loss:0.12726, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16736, Train Loss:0.42794, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16737, Train Loss:0.17471, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16738, Train Loss:0.01621, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16739, Train Loss:0.22637, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16740, Train Loss:0.00000, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16741, Train Loss:0.06197, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16742, Train Loss:0.17413, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16743, Train Loss:0.09426, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16744, Train Loss:0.14592, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16745, Train Loss:0.03572, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16746, Train Loss:0.22957, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16747, Train Loss:0.00342, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16748, Train Loss:0.14164, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16749, Train Loss:0.07023, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16750, Train Loss:0.05696, Dev Loss:0.14492\n",
      "Epoch:[60/100], step:16751, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16752, Train Loss:0.00107, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16753, Train Loss:0.05162, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16754, Train Loss:0.01894, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16755, Train Loss:0.17054, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16756, Train Loss:0.00129, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16757, Train Loss:0.03254, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16758, Train Loss:0.00214, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16759, Train Loss:0.18096, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16760, Train Loss:0.11406, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16761, Train Loss:0.00030, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16762, Train Loss:0.00098, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16763, Train Loss:0.00018, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16764, Train Loss:0.00768, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16765, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16766, Train Loss:0.00936, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16767, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16768, Train Loss:0.09658, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16769, Train Loss:0.02163, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16770, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16771, Train Loss:0.00346, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16772, Train Loss:0.13040, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16773, Train Loss:0.01690, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16774, Train Loss:0.00018, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16775, Train Loss:0.00016, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16776, Train Loss:0.04647, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16777, Train Loss:0.00003, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16778, Train Loss:0.00004, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16779, Train Loss:0.02137, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16780, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16781, Train Loss:0.09376, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16782, Train Loss:0.93513, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16783, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16784, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16785, Train Loss:0.01184, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16786, Train Loss:0.31736, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16787, Train Loss:0.01658, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16788, Train Loss:0.12486, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16789, Train Loss:0.20370, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16790, Train Loss:0.01690, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16791, Train Loss:0.00048, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16792, Train Loss:0.00022, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16793, Train Loss:0.00014, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16794, Train Loss:0.32102, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16795, Train Loss:0.06331, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16796, Train Loss:0.00137, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16797, Train Loss:0.19526, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16798, Train Loss:0.00014, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16799, Train Loss:0.03388, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16800, Train Loss:0.05327, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16801, Train Loss:0.00790, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16802, Train Loss:0.00012, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16803, Train Loss:0.02814, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16804, Train Loss:0.00019, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16805, Train Loss:0.16534, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16806, Train Loss:0.00252, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16807, Train Loss:0.00589, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16808, Train Loss:0.00120, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16809, Train Loss:0.00638, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16810, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16811, Train Loss:0.00032, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16812, Train Loss:0.08205, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16813, Train Loss:0.01563, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16814, Train Loss:0.38356, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16815, Train Loss:0.00228, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16816, Train Loss:0.02038, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16817, Train Loss:0.14527, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16818, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16819, Train Loss:0.01405, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16820, Train Loss:0.01696, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16821, Train Loss:0.00222, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16822, Train Loss:0.03834, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16823, Train Loss:0.00279, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16824, Train Loss:0.01051, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16825, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16826, Train Loss:0.07085, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16827, Train Loss:0.00141, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16828, Train Loss:0.01382, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16829, Train Loss:0.24887, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16830, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16831, Train Loss:0.20740, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16832, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16833, Train Loss:2.36720, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16834, Train Loss:0.02172, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16835, Train Loss:0.00632, Dev Loss:0.06241\n",
      "Epoch:[60/100], step:16836, Train Loss:0.00185, Dev Loss:0.06241\n",
      "Start Epoch: 61, Steps: 17\n",
      "Epoch:[61/100], step:16837, Train Loss:0.20920, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16838, Train Loss:0.00085, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16839, Train Loss:0.13017, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16840, Train Loss:0.05675, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16841, Train Loss:0.45400, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16842, Train Loss:0.01421, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16843, Train Loss:0.01488, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16844, Train Loss:0.00524, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16845, Train Loss:0.04829, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16846, Train Loss:0.00328, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16847, Train Loss:0.00490, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16848, Train Loss:0.00273, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16849, Train Loss:0.09185, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16850, Train Loss:0.01758, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16851, Train Loss:0.21113, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16852, Train Loss:0.16073, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16853, Train Loss:0.02768, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16854, Train Loss:0.00006, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16855, Train Loss:0.00090, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16856, Train Loss:0.00455, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16857, Train Loss:0.00088, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16858, Train Loss:0.08261, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16859, Train Loss:0.02955, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16860, Train Loss:0.12753, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16861, Train Loss:0.09577, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16862, Train Loss:0.00038, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16863, Train Loss:0.00058, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16864, Train Loss:0.04020, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16865, Train Loss:0.00587, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16866, Train Loss:0.02016, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16867, Train Loss:0.00493, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16868, Train Loss:0.00029, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16869, Train Loss:0.12918, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16870, Train Loss:0.00439, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16871, Train Loss:0.00001, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16872, Train Loss:0.00017, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16873, Train Loss:0.33221, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16874, Train Loss:0.02212, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16875, Train Loss:0.00019, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16876, Train Loss:0.00134, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16877, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16878, Train Loss:0.06394, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16879, Train Loss:0.00078, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16880, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16881, Train Loss:0.03809, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16882, Train Loss:0.05236, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16883, Train Loss:0.02200, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16884, Train Loss:0.01388, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16885, Train Loss:0.01880, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16886, Train Loss:0.31134, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16887, Train Loss:0.00007, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16888, Train Loss:0.00394, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16889, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16890, Train Loss:0.22120, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16891, Train Loss:0.00017, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16892, Train Loss:0.10457, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16893, Train Loss:0.00060, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16894, Train Loss:0.05582, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16895, Train Loss:0.03008, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16896, Train Loss:0.02194, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16897, Train Loss:0.31838, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16898, Train Loss:0.00004, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16899, Train Loss:0.14654, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16900, Train Loss:0.00446, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16901, Train Loss:0.06524, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16902, Train Loss:0.00006, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16903, Train Loss:0.76495, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16904, Train Loss:0.01171, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16905, Train Loss:0.00003, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16906, Train Loss:0.00082, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16907, Train Loss:0.00005, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16908, Train Loss:0.00008, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16909, Train Loss:0.06172, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16910, Train Loss:0.03005, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16911, Train Loss:0.00003, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16912, Train Loss:0.00118, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16913, Train Loss:0.00007, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16914, Train Loss:0.15093, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16915, Train Loss:0.04639, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16916, Train Loss:0.31259, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16917, Train Loss:0.05920, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16918, Train Loss:0.42631, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16919, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16920, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16921, Train Loss:0.00019, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16922, Train Loss:0.00096, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16923, Train Loss:0.09684, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16924, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16925, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16926, Train Loss:0.00922, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16927, Train Loss:0.14192, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16928, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16929, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16930, Train Loss:0.11545, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16931, Train Loss:0.00094, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16932, Train Loss:0.00044, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16933, Train Loss:0.01750, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16934, Train Loss:0.03589, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16935, Train Loss:0.18686, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16936, Train Loss:0.06203, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16937, Train Loss:0.19314, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16938, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16939, Train Loss:0.00567, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16940, Train Loss:0.00861, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16941, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16942, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16943, Train Loss:0.13349, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16944, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16945, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16946, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16947, Train Loss:0.23333, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16948, Train Loss:0.02098, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16949, Train Loss:0.17740, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16950, Train Loss:0.00661, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16951, Train Loss:0.00056, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16952, Train Loss:0.22940, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16953, Train Loss:0.24734, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16954, Train Loss:0.01838, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16955, Train Loss:0.00003, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16956, Train Loss:0.00007, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16957, Train Loss:0.04356, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16958, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16959, Train Loss:0.10428, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16960, Train Loss:0.00004, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16961, Train Loss:0.00004, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16962, Train Loss:0.00333, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16963, Train Loss:0.04853, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16964, Train Loss:0.05724, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16965, Train Loss:0.02189, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16966, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16967, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16968, Train Loss:0.07728, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16969, Train Loss:0.02399, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16970, Train Loss:0.00850, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16971, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16972, Train Loss:0.01422, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16973, Train Loss:0.00659, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16974, Train Loss:0.09791, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16975, Train Loss:0.00948, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16976, Train Loss:0.00746, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16977, Train Loss:0.00163, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16978, Train Loss:0.00156, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16979, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16980, Train Loss:0.00496, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16981, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16982, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16983, Train Loss:0.26887, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16984, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16985, Train Loss:0.00461, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16986, Train Loss:0.00090, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16987, Train Loss:0.49330, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16988, Train Loss:0.03190, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16989, Train Loss:0.09182, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16990, Train Loss:0.43130, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16991, Train Loss:0.72769, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16992, Train Loss:0.19409, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16993, Train Loss:0.00002, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16994, Train Loss:0.00030, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16995, Train Loss:0.00046, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16996, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16997, Train Loss:0.00336, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16998, Train Loss:0.00024, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:16999, Train Loss:0.00000, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:17000, Train Loss:0.41601, Dev Loss:0.06241\n",
      "Epoch:[61/100], step:17001, Train Loss:0.00036, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17002, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17003, Train Loss:0.00021, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17004, Train Loss:0.00048, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17005, Train Loss:0.01570, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17006, Train Loss:0.23201, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17007, Train Loss:0.02216, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17008, Train Loss:0.00049, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17009, Train Loss:0.00336, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17010, Train Loss:0.01351, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17011, Train Loss:0.02055, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17012, Train Loss:0.04044, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17013, Train Loss:0.47921, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17014, Train Loss:0.03513, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17015, Train Loss:0.01607, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17016, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17017, Train Loss:0.16187, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17018, Train Loss:0.06637, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17019, Train Loss:0.00007, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17020, Train Loss:0.02610, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17021, Train Loss:0.00768, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17022, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17023, Train Loss:0.03273, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17024, Train Loss:0.13716, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17025, Train Loss:0.00003, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17026, Train Loss:0.01679, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17027, Train Loss:0.02437, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17028, Train Loss:0.04128, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17029, Train Loss:0.00018, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17030, Train Loss:0.00015, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17031, Train Loss:0.00046, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17032, Train Loss:0.04755, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17033, Train Loss:0.02472, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17034, Train Loss:0.09773, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17035, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17036, Train Loss:0.01497, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17037, Train Loss:0.01903, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17038, Train Loss:0.00212, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17039, Train Loss:0.06749, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17040, Train Loss:0.46182, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17041, Train Loss:0.00127, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17042, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17043, Train Loss:0.00115, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17044, Train Loss:0.08883, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17045, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17046, Train Loss:0.01678, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17047, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17048, Train Loss:0.05359, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17049, Train Loss:0.12617, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17050, Train Loss:0.00004, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17051, Train Loss:0.04528, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17052, Train Loss:0.01663, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17053, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17054, Train Loss:0.00096, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17055, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17056, Train Loss:0.00947, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17057, Train Loss:0.01464, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17058, Train Loss:0.02526, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17059, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17060, Train Loss:0.00032, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17061, Train Loss:0.00005, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17062, Train Loss:0.20301, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17063, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17064, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17065, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17066, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17067, Train Loss:0.30786, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17068, Train Loss:0.00077, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17069, Train Loss:0.00058, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17070, Train Loss:0.00011, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17071, Train Loss:0.00003, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17072, Train Loss:0.02900, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17073, Train Loss:0.00950, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17074, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17075, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17076, Train Loss:0.00004, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17077, Train Loss:0.00008, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17078, Train Loss:0.01985, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17079, Train Loss:0.00015, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17080, Train Loss:0.14714, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17081, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17082, Train Loss:0.00091, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17083, Train Loss:0.00593, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17084, Train Loss:0.00202, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17085, Train Loss:0.31576, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17086, Train Loss:0.35680, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17087, Train Loss:0.01959, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17088, Train Loss:0.04138, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17089, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17090, Train Loss:0.00127, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17091, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17092, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17093, Train Loss:0.30989, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17094, Train Loss:0.34270, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17095, Train Loss:0.04532, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17096, Train Loss:0.15903, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17097, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17098, Train Loss:0.03292, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17099, Train Loss:0.01556, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17100, Train Loss:0.01177, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17101, Train Loss:0.05230, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17102, Train Loss:0.00014, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17103, Train Loss:0.14281, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17104, Train Loss:0.00074, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17105, Train Loss:0.71384, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17106, Train Loss:0.29623, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17107, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17108, Train Loss:0.10695, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17109, Train Loss:0.68660, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17110, Train Loss:0.00918, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17111, Train Loss:0.00011, Dev Loss:0.14659\n",
      "Epoch:[61/100], step:17112, Train Loss:0.05006, Dev Loss:0.14659\n",
      "Start Epoch: 62, Steps: 17\n",
      "Epoch:[62/100], step:17113, Train Loss:0.11068, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17114, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17115, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17116, Train Loss:0.01948, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17117, Train Loss:0.31328, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17118, Train Loss:0.00765, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17119, Train Loss:0.00125, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17120, Train Loss:0.00031, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17121, Train Loss:0.00209, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17122, Train Loss:0.23220, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17123, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17124, Train Loss:0.00205, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17125, Train Loss:0.00149, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17126, Train Loss:0.12126, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17127, Train Loss:0.26683, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17128, Train Loss:0.00276, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17129, Train Loss:0.00089, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17130, Train Loss:0.03379, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17131, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17132, Train Loss:0.20386, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17133, Train Loss:0.00012, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17134, Train Loss:0.00012, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17135, Train Loss:0.03161, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17136, Train Loss:0.00053, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17137, Train Loss:0.03839, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17138, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17139, Train Loss:0.09190, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17140, Train Loss:0.00211, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17141, Train Loss:0.02915, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17142, Train Loss:0.00836, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17143, Train Loss:0.00015, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17144, Train Loss:0.09701, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17145, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17146, Train Loss:0.25079, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17147, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17148, Train Loss:0.82703, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17149, Train Loss:0.00024, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17150, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17151, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17152, Train Loss:0.00249, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17153, Train Loss:0.11135, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17154, Train Loss:0.14181, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17155, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17156, Train Loss:0.65044, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17157, Train Loss:0.00040, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17158, Train Loss:0.77223, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17159, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17160, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17161, Train Loss:0.02234, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17162, Train Loss:0.26215, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17163, Train Loss:0.08481, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17164, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17165, Train Loss:0.42640, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17166, Train Loss:0.20513, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17167, Train Loss:0.00022, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17168, Train Loss:0.27236, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17169, Train Loss:0.06249, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17170, Train Loss:0.00019, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17171, Train Loss:0.00510, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17172, Train Loss:0.00070, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17173, Train Loss:0.18242, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17174, Train Loss:0.00199, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17175, Train Loss:0.05385, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17176, Train Loss:0.00626, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17177, Train Loss:0.00101, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17178, Train Loss:0.24313, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17179, Train Loss:0.00448, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17180, Train Loss:0.18951, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17181, Train Loss:0.02146, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17182, Train Loss:0.05688, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17183, Train Loss:0.00132, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17184, Train Loss:0.00138, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17185, Train Loss:0.07563, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17186, Train Loss:0.00014, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17187, Train Loss:0.11554, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17188, Train Loss:0.00133, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17189, Train Loss:0.23136, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17190, Train Loss:0.00013, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17191, Train Loss:0.00485, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17192, Train Loss:0.09725, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17193, Train Loss:0.00010, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17194, Train Loss:0.07493, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17195, Train Loss:0.15092, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17196, Train Loss:0.00041, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17197, Train Loss:0.70228, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17198, Train Loss:0.00200, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17199, Train Loss:0.00017, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17200, Train Loss:0.06975, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17201, Train Loss:0.00004, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17202, Train Loss:0.00313, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17203, Train Loss:0.07132, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17204, Train Loss:0.01885, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17205, Train Loss:0.00032, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17206, Train Loss:0.07740, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17207, Train Loss:0.02220, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17208, Train Loss:0.07529, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17209, Train Loss:0.13542, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17210, Train Loss:0.05651, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17211, Train Loss:0.00074, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17212, Train Loss:0.07782, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17213, Train Loss:0.00088, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17214, Train Loss:0.10963, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17215, Train Loss:0.00230, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17216, Train Loss:0.00311, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17217, Train Loss:0.02748, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17218, Train Loss:0.10027, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17219, Train Loss:0.02110, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17220, Train Loss:0.31444, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17221, Train Loss:0.00044, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17222, Train Loss:0.07237, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17223, Train Loss:0.00786, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17224, Train Loss:0.13825, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17225, Train Loss:0.00004, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17226, Train Loss:0.05263, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17227, Train Loss:0.04394, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17228, Train Loss:0.04180, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17229, Train Loss:0.10741, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17230, Train Loss:0.18068, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17231, Train Loss:0.22450, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17232, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17233, Train Loss:0.00142, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17234, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17235, Train Loss:0.00793, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17236, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17237, Train Loss:0.00065, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17238, Train Loss:0.15071, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17239, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17240, Train Loss:0.00736, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17241, Train Loss:0.00401, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17242, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17243, Train Loss:0.02376, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17244, Train Loss:0.18956, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17245, Train Loss:0.07777, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17246, Train Loss:0.01856, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17247, Train Loss:0.00002, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17248, Train Loss:0.00001, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17249, Train Loss:0.00000, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17250, Train Loss:0.41934, Dev Loss:0.14659\n",
      "Epoch:[62/100], step:17251, Train Loss:0.00002, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17252, Train Loss:0.54931, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17253, Train Loss:0.09102, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17254, Train Loss:0.07852, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17255, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17256, Train Loss:0.00566, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17257, Train Loss:0.00525, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17258, Train Loss:0.00025, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17259, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17260, Train Loss:0.00007, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17261, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17262, Train Loss:0.00096, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17263, Train Loss:0.00153, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17264, Train Loss:0.00026, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17265, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17266, Train Loss:1.59901, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17267, Train Loss:0.41789, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17268, Train Loss:0.00013, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17269, Train Loss:0.16686, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17270, Train Loss:0.35303, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17271, Train Loss:0.05693, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17272, Train Loss:0.12189, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17273, Train Loss:0.32414, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17274, Train Loss:0.21241, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17275, Train Loss:0.00659, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17276, Train Loss:2.86269, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17277, Train Loss:0.28327, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17278, Train Loss:0.60454, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17279, Train Loss:0.26814, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17280, Train Loss:0.16320, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17281, Train Loss:0.20533, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17282, Train Loss:0.33618, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17283, Train Loss:0.03652, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17284, Train Loss:0.24938, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17285, Train Loss:0.16215, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17286, Train Loss:0.28916, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17287, Train Loss:0.20589, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17288, Train Loss:0.12995, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17289, Train Loss:0.09555, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17290, Train Loss:0.62907, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17291, Train Loss:0.20882, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17292, Train Loss:0.56793, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17293, Train Loss:0.53707, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17294, Train Loss:0.01794, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17295, Train Loss:0.13903, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17296, Train Loss:0.06862, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17297, Train Loss:0.07379, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17298, Train Loss:0.04074, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17299, Train Loss:0.62172, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17300, Train Loss:0.23004, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17301, Train Loss:0.00025, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17302, Train Loss:0.14688, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17303, Train Loss:0.01387, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17304, Train Loss:0.30100, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17305, Train Loss:0.09676, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17306, Train Loss:0.21821, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17307, Train Loss:0.06546, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17308, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17309, Train Loss:0.05446, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17310, Train Loss:0.04398, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17311, Train Loss:0.00392, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17312, Train Loss:0.34999, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17313, Train Loss:0.00809, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17314, Train Loss:0.12394, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17315, Train Loss:0.06899, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17316, Train Loss:0.07777, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17317, Train Loss:0.05193, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17318, Train Loss:0.01535, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17319, Train Loss:0.16501, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17320, Train Loss:0.00201, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17321, Train Loss:0.01256, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17322, Train Loss:0.13640, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17323, Train Loss:0.09742, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17324, Train Loss:0.24708, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17325, Train Loss:0.08752, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17326, Train Loss:0.11749, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17327, Train Loss:0.18212, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17328, Train Loss:0.10623, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17329, Train Loss:0.01286, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17330, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17331, Train Loss:0.00028, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17332, Train Loss:0.00206, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17333, Train Loss:0.00008, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17334, Train Loss:0.23603, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17335, Train Loss:0.00305, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17336, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17337, Train Loss:0.10504, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17338, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17339, Train Loss:0.00069, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17340, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17341, Train Loss:0.07164, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17342, Train Loss:0.20917, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17343, Train Loss:0.08859, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17344, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17345, Train Loss:0.09074, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17346, Train Loss:0.16436, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17347, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17348, Train Loss:0.00774, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17349, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17350, Train Loss:0.00002, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17351, Train Loss:0.00246, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17352, Train Loss:0.03598, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17353, Train Loss:0.27428, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17354, Train Loss:0.16840, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17355, Train Loss:0.15808, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17356, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17357, Train Loss:0.00003, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17358, Train Loss:0.06823, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17359, Train Loss:0.00120, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17360, Train Loss:0.03819, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17361, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17362, Train Loss:0.10388, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17363, Train Loss:0.11087, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17364, Train Loss:0.00021, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17365, Train Loss:0.00012, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17366, Train Loss:0.00009, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17367, Train Loss:0.00157, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17368, Train Loss:0.58415, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17369, Train Loss:0.00096, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17370, Train Loss:0.09549, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17371, Train Loss:0.01356, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17372, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17373, Train Loss:0.00055, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17374, Train Loss:0.11616, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17375, Train Loss:0.00216, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17376, Train Loss:0.20084, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17377, Train Loss:0.03954, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17378, Train Loss:0.49424, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17379, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17380, Train Loss:0.00086, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17381, Train Loss:0.06900, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17382, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17383, Train Loss:0.21719, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17384, Train Loss:0.03248, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17385, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17386, Train Loss:0.56313, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17387, Train Loss:0.00210, Dev Loss:0.10188\n",
      "Epoch:[62/100], step:17388, Train Loss:0.03490, Dev Loss:0.10188\n",
      "Start Epoch: 63, Steps: 17\n",
      "Epoch:[63/100], step:17389, Train Loss:0.05751, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17390, Train Loss:0.01569, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17391, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17392, Train Loss:0.00132, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17393, Train Loss:0.00108, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17394, Train Loss:0.02516, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17395, Train Loss:0.11192, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17396, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17397, Train Loss:0.00030, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17398, Train Loss:0.05086, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17399, Train Loss:0.07187, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17400, Train Loss:0.30838, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17401, Train Loss:0.00005, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17402, Train Loss:0.00014, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17403, Train Loss:0.04008, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17404, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17405, Train Loss:0.19693, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17406, Train Loss:0.00210, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17407, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17408, Train Loss:0.00004, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17409, Train Loss:0.27632, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17410, Train Loss:0.04737, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17411, Train Loss:0.04824, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17412, Train Loss:0.00162, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17413, Train Loss:0.04012, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17414, Train Loss:0.00018, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17415, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17416, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17417, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17418, Train Loss:0.00004, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17419, Train Loss:0.00127, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17420, Train Loss:0.10818, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17421, Train Loss:0.03437, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17422, Train Loss:0.00093, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17423, Train Loss:0.17297, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17424, Train Loss:0.00036, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17425, Train Loss:0.00409, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17426, Train Loss:0.02597, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17427, Train Loss:0.00081, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17428, Train Loss:1.33181, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17429, Train Loss:0.51678, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17430, Train Loss:0.03254, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17431, Train Loss:0.47004, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17432, Train Loss:0.00266, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17433, Train Loss:0.00024, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17434, Train Loss:0.35408, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17435, Train Loss:0.00026, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17436, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17437, Train Loss:0.39049, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17438, Train Loss:0.49858, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17439, Train Loss:0.20180, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17440, Train Loss:0.12604, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17441, Train Loss:0.17788, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17442, Train Loss:0.03133, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17443, Train Loss:0.18888, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17444, Train Loss:0.23805, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17445, Train Loss:0.15098, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17446, Train Loss:0.03008, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17447, Train Loss:0.00184, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17448, Train Loss:0.01365, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17449, Train Loss:0.00131, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17450, Train Loss:0.08875, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17451, Train Loss:0.01585, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17452, Train Loss:0.07716, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17453, Train Loss:0.00003, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17454, Train Loss:0.00002, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17455, Train Loss:0.00001, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17456, Train Loss:0.01186, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17457, Train Loss:0.04295, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17458, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17459, Train Loss:0.39624, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17460, Train Loss:0.00000, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17461, Train Loss:0.22777, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17462, Train Loss:0.00831, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17463, Train Loss:1.20705, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17464, Train Loss:0.13846, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17465, Train Loss:0.26053, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17466, Train Loss:0.03089, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17467, Train Loss:0.04709, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17468, Train Loss:0.14660, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17469, Train Loss:0.02169, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17470, Train Loss:0.20072, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17471, Train Loss:0.02374, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17472, Train Loss:0.08123, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17473, Train Loss:0.00038, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17474, Train Loss:0.31408, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17475, Train Loss:0.00074, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17476, Train Loss:0.06323, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17477, Train Loss:0.01327, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17478, Train Loss:0.03522, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17479, Train Loss:0.00011, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17480, Train Loss:0.11963, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17481, Train Loss:1.11965, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17482, Train Loss:0.12513, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17483, Train Loss:0.14526, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17484, Train Loss:0.02362, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17485, Train Loss:0.12647, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17486, Train Loss:0.26780, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17487, Train Loss:0.00559, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17488, Train Loss:0.14661, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17489, Train Loss:0.00699, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17490, Train Loss:0.12232, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17491, Train Loss:0.00098, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17492, Train Loss:0.08200, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17493, Train Loss:0.00187, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17494, Train Loss:0.17088, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17495, Train Loss:0.00989, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17496, Train Loss:0.00002, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17497, Train Loss:0.13435, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17498, Train Loss:0.02405, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17499, Train Loss:0.10171, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17500, Train Loss:0.00004, Dev Loss:0.10188\n",
      "Epoch:[63/100], step:17501, Train Loss:0.00056, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17502, Train Loss:0.37115, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17503, Train Loss:0.09907, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17504, Train Loss:0.00181, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17505, Train Loss:0.09507, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17506, Train Loss:0.12579, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17507, Train Loss:0.00576, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17508, Train Loss:0.03625, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17509, Train Loss:0.02225, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17510, Train Loss:0.09988, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17511, Train Loss:0.01440, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17512, Train Loss:0.24308, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17513, Train Loss:0.00365, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17514, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17515, Train Loss:0.00620, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17516, Train Loss:0.00002, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17517, Train Loss:0.00009, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17518, Train Loss:0.12635, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17519, Train Loss:0.00008, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17520, Train Loss:0.02791, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17521, Train Loss:0.00328, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17522, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17523, Train Loss:0.00017, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17524, Train Loss:0.00145, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17525, Train Loss:0.00019, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17526, Train Loss:0.24033, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17527, Train Loss:0.24326, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17528, Train Loss:0.09213, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17529, Train Loss:0.10091, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17530, Train Loss:0.04386, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17531, Train Loss:0.13115, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17532, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17533, Train Loss:0.00023, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17534, Train Loss:0.08441, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17535, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17536, Train Loss:0.69062, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17537, Train Loss:0.01435, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17538, Train Loss:0.71228, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17539, Train Loss:0.08531, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17540, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17541, Train Loss:0.01755, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17542, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17543, Train Loss:0.16744, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17544, Train Loss:0.07020, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17545, Train Loss:0.00018, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17546, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17547, Train Loss:0.01460, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17548, Train Loss:0.00285, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17549, Train Loss:0.01090, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17550, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17551, Train Loss:0.24834, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17552, Train Loss:0.00015, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17553, Train Loss:0.00269, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17554, Train Loss:0.42413, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17555, Train Loss:0.01907, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17556, Train Loss:0.15158, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17557, Train Loss:0.06702, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17558, Train Loss:0.18400, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17559, Train Loss:0.13584, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17560, Train Loss:0.02030, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17561, Train Loss:0.09436, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17562, Train Loss:0.07428, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17563, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17564, Train Loss:0.00467, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17565, Train Loss:0.19114, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17566, Train Loss:0.02223, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17567, Train Loss:0.12052, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17568, Train Loss:0.01094, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17569, Train Loss:0.06374, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17570, Train Loss:0.00022, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17571, Train Loss:0.05652, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17572, Train Loss:0.00299, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17573, Train Loss:0.09120, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17574, Train Loss:0.09520, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17575, Train Loss:0.29597, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17576, Train Loss:0.05785, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17577, Train Loss:0.03266, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17578, Train Loss:0.02841, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17579, Train Loss:0.00903, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17580, Train Loss:0.00457, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17581, Train Loss:0.18023, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17582, Train Loss:0.25557, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17583, Train Loss:0.01995, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17584, Train Loss:0.00020, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17585, Train Loss:0.05977, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17586, Train Loss:0.08765, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17587, Train Loss:0.00003, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17588, Train Loss:0.00018, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17589, Train Loss:0.01678, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17590, Train Loss:0.00010, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17591, Train Loss:0.00005, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17592, Train Loss:0.00188, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17593, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17594, Train Loss:0.10455, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17595, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17596, Train Loss:0.10407, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17597, Train Loss:0.01515, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17598, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17599, Train Loss:0.13331, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17600, Train Loss:0.00073, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17601, Train Loss:0.00802, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17602, Train Loss:0.30006, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17603, Train Loss:0.00603, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17604, Train Loss:0.00007, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17605, Train Loss:0.00044, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17606, Train Loss:0.00014, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17607, Train Loss:0.00082, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17608, Train Loss:0.13785, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17609, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17610, Train Loss:0.10433, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17611, Train Loss:0.00654, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17612, Train Loss:0.00007, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17613, Train Loss:0.00716, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17614, Train Loss:0.04441, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17615, Train Loss:0.00739, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17616, Train Loss:0.00004, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17617, Train Loss:0.12097, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17618, Train Loss:0.00372, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17619, Train Loss:0.00072, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17620, Train Loss:0.05581, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17621, Train Loss:0.00019, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17622, Train Loss:0.00055, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17623, Train Loss:0.00258, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17624, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17625, Train Loss:0.42616, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17626, Train Loss:0.00142, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17627, Train Loss:0.00002, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17628, Train Loss:0.05162, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17629, Train Loss:0.08570, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17630, Train Loss:0.06637, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17631, Train Loss:0.03081, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17632, Train Loss:0.00017, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17633, Train Loss:0.02978, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17634, Train Loss:0.00021, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17635, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17636, Train Loss:0.00051, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17637, Train Loss:0.01451, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17638, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17639, Train Loss:0.00005, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17640, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17641, Train Loss:0.32944, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17642, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17643, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17644, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17645, Train Loss:0.31919, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17646, Train Loss:0.00965, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17647, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17648, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17649, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17650, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17651, Train Loss:0.00002, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17652, Train Loss:0.00826, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17653, Train Loss:0.06473, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17654, Train Loss:0.02681, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17655, Train Loss:0.03573, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17656, Train Loss:0.00088, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17657, Train Loss:0.10209, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17658, Train Loss:0.00005, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17659, Train Loss:0.00019, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17660, Train Loss:0.21142, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17661, Train Loss:0.02055, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17662, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17663, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[63/100], step:17664, Train Loss:0.00481, Dev Loss:0.10514\n",
      "Start Epoch: 64, Steps: 17\n",
      "Epoch:[64/100], step:17665, Train Loss:0.22181, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17666, Train Loss:0.42034, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17667, Train Loss:0.01847, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17668, Train Loss:0.02527, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17669, Train Loss:0.00016, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17670, Train Loss:0.00617, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17671, Train Loss:0.13180, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17672, Train Loss:0.08337, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17673, Train Loss:0.00037, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17674, Train Loss:0.00093, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17675, Train Loss:0.00002, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17676, Train Loss:0.00153, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17677, Train Loss:0.20889, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17678, Train Loss:0.00619, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17679, Train Loss:0.00048, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17680, Train Loss:0.00059, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17681, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17682, Train Loss:0.00136, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17683, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17684, Train Loss:0.00215, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17685, Train Loss:0.08321, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17686, Train Loss:0.00009, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17687, Train Loss:0.00156, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17688, Train Loss:0.21274, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17689, Train Loss:0.03963, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17690, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17691, Train Loss:0.16554, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17692, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17693, Train Loss:0.00088, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17694, Train Loss:0.06877, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17695, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17696, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17697, Train Loss:0.75607, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17698, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17699, Train Loss:0.00970, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17700, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17701, Train Loss:0.02794, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17702, Train Loss:0.24554, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17703, Train Loss:0.00461, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17704, Train Loss:0.01971, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17705, Train Loss:0.00034, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17706, Train Loss:0.00076, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17707, Train Loss:0.09758, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17708, Train Loss:0.05799, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17709, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17710, Train Loss:0.00006, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17711, Train Loss:0.06420, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17712, Train Loss:0.06942, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17713, Train Loss:0.00003, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17714, Train Loss:0.09676, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17715, Train Loss:0.01660, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17716, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17717, Train Loss:0.10831, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17718, Train Loss:0.00047, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17719, Train Loss:0.26815, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17720, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17721, Train Loss:0.11770, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17722, Train Loss:0.11505, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17723, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17724, Train Loss:0.01926, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17725, Train Loss:0.00004, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17726, Train Loss:0.13429, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17727, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17728, Train Loss:0.06195, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17729, Train Loss:0.00438, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17730, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17731, Train Loss:0.01228, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17732, Train Loss:0.00020, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17733, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17734, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17735, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17736, Train Loss:0.02338, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17737, Train Loss:0.00134, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17738, Train Loss:0.00000, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17739, Train Loss:0.20733, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17740, Train Loss:0.52513, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17741, Train Loss:0.03003, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17742, Train Loss:0.12827, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17743, Train Loss:0.00015, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17744, Train Loss:0.05327, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17745, Train Loss:0.00028, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17746, Train Loss:0.00001, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17747, Train Loss:0.00243, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17748, Train Loss:0.14062, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17749, Train Loss:0.57136, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17750, Train Loss:0.17409, Dev Loss:0.10514\n",
      "Epoch:[64/100], step:17751, Train Loss:0.37105, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17752, Train Loss:0.01838, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17753, Train Loss:0.07658, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17754, Train Loss:0.05657, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17755, Train Loss:0.00238, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17756, Train Loss:0.02254, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17757, Train Loss:0.00417, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17758, Train Loss:0.02588, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17759, Train Loss:0.01433, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17760, Train Loss:0.08196, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17761, Train Loss:1.08652, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17762, Train Loss:0.13396, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17763, Train Loss:0.10893, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17764, Train Loss:0.04431, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17765, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17766, Train Loss:0.07902, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17767, Train Loss:0.04429, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17768, Train Loss:0.00167, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17769, Train Loss:0.00404, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17770, Train Loss:0.14361, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17771, Train Loss:0.18100, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17772, Train Loss:0.00044, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17773, Train Loss:0.07440, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17774, Train Loss:0.17889, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17775, Train Loss:0.00303, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17776, Train Loss:0.01413, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17777, Train Loss:0.00492, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17778, Train Loss:0.65589, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17779, Train Loss:0.00004, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17780, Train Loss:0.24503, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17781, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17782, Train Loss:0.55822, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17783, Train Loss:0.09333, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17784, Train Loss:0.00024, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17785, Train Loss:0.14509, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17786, Train Loss:0.01243, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17787, Train Loss:0.38906, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17788, Train Loss:0.10785, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17789, Train Loss:0.00089, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17790, Train Loss:0.00845, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17791, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17792, Train Loss:0.63839, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17793, Train Loss:0.07380, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17794, Train Loss:0.44644, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17795, Train Loss:0.00032, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17796, Train Loss:0.00627, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17797, Train Loss:0.10033, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17798, Train Loss:0.11452, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17799, Train Loss:0.05400, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17800, Train Loss:0.13824, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17801, Train Loss:0.28253, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17802, Train Loss:0.09772, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17803, Train Loss:0.00071, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17804, Train Loss:0.16437, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17805, Train Loss:0.21653, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17806, Train Loss:0.00168, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17807, Train Loss:0.14691, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17808, Train Loss:0.00664, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17809, Train Loss:0.02224, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17810, Train Loss:0.05190, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17811, Train Loss:0.00007, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17812, Train Loss:0.05415, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17813, Train Loss:0.00006, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17814, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17815, Train Loss:0.00004, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17816, Train Loss:0.00004, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17817, Train Loss:0.00003, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17818, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17819, Train Loss:0.41551, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17820, Train Loss:0.10859, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17821, Train Loss:0.00576, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17822, Train Loss:0.00088, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17823, Train Loss:0.08307, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17824, Train Loss:0.06332, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17825, Train Loss:0.00516, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17826, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17827, Train Loss:0.52888, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17828, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17829, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17830, Train Loss:0.00050, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17831, Train Loss:0.01951, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17832, Train Loss:0.10871, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17833, Train Loss:0.00901, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17834, Train Loss:0.00950, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17835, Train Loss:0.00008, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17836, Train Loss:0.00018, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17837, Train Loss:0.22378, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17838, Train Loss:0.09736, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17839, Train Loss:0.15425, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17840, Train Loss:0.00019, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17841, Train Loss:0.19598, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17842, Train Loss:0.04574, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17843, Train Loss:0.00023, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17844, Train Loss:0.00048, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17845, Train Loss:0.00028, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17846, Train Loss:0.06471, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17847, Train Loss:0.00605, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17848, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17849, Train Loss:0.34636, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17850, Train Loss:0.26341, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17851, Train Loss:0.00201, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17852, Train Loss:0.10881, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17853, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17854, Train Loss:0.82785, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17855, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17856, Train Loss:0.00051, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17857, Train Loss:0.00018, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17858, Train Loss:0.04149, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17859, Train Loss:0.11155, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17860, Train Loss:0.10976, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17861, Train Loss:0.04678, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17862, Train Loss:0.00018, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17863, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17864, Train Loss:0.12343, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17865, Train Loss:0.06436, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17866, Train Loss:0.04025, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17867, Train Loss:0.06121, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17868, Train Loss:0.04193, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17869, Train Loss:0.10631, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17870, Train Loss:0.00163, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17871, Train Loss:0.02623, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17872, Train Loss:0.04353, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17873, Train Loss:0.00739, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17874, Train Loss:0.19036, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17875, Train Loss:0.02812, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17876, Train Loss:0.45486, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17877, Train Loss:0.06392, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17878, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17879, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17880, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17881, Train Loss:0.11256, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17882, Train Loss:0.03899, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17883, Train Loss:0.03135, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17884, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17885, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17886, Train Loss:0.05581, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17887, Train Loss:0.04282, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17888, Train Loss:0.31747, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17889, Train Loss:0.10971, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17890, Train Loss:0.00020, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17891, Train Loss:0.62121, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17892, Train Loss:0.40598, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17893, Train Loss:0.13696, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17894, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17895, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17896, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17897, Train Loss:0.00419, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17898, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17899, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17900, Train Loss:0.00007, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17901, Train Loss:0.06045, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17902, Train Loss:0.02046, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17903, Train Loss:0.00063, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17904, Train Loss:0.03219, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17905, Train Loss:0.00075, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17906, Train Loss:0.00012, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17907, Train Loss:0.00021, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17908, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17909, Train Loss:0.02222, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17910, Train Loss:0.00478, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17911, Train Loss:0.00049, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17912, Train Loss:0.00348, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17913, Train Loss:0.02520, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17914, Train Loss:0.03129, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17915, Train Loss:0.00012, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17916, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17917, Train Loss:0.08485, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17918, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17919, Train Loss:0.08218, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17920, Train Loss:0.15729, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17921, Train Loss:0.14253, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17922, Train Loss:0.00019, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17923, Train Loss:0.21012, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17924, Train Loss:0.00072, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17925, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17926, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17927, Train Loss:0.00084, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17928, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17929, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17930, Train Loss:0.00254, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17931, Train Loss:1.05403, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17932, Train Loss:0.00361, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17933, Train Loss:0.00000, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17934, Train Loss:0.07033, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17935, Train Loss:0.18361, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17936, Train Loss:0.08383, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17937, Train Loss:0.05552, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17938, Train Loss:0.19385, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17939, Train Loss:0.11161, Dev Loss:0.46963\n",
      "Epoch:[64/100], step:17940, Train Loss:0.21407, Dev Loss:0.46963\n",
      "Start Epoch: 65, Steps: 17\n",
      "Epoch:[65/100], step:17941, Train Loss:0.00122, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17942, Train Loss:0.22272, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17943, Train Loss:0.42310, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17944, Train Loss:0.03529, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17945, Train Loss:0.16982, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17946, Train Loss:0.00132, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17947, Train Loss:0.01042, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17948, Train Loss:0.12690, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17949, Train Loss:0.33201, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17950, Train Loss:0.01003, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17951, Train Loss:0.00075, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17952, Train Loss:0.00120, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17953, Train Loss:0.30915, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17954, Train Loss:0.39010, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17955, Train Loss:0.00300, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17956, Train Loss:0.68708, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17957, Train Loss:0.06133, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17958, Train Loss:0.00014, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17959, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17960, Train Loss:0.38292, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17961, Train Loss:0.00112, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17962, Train Loss:0.05202, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17963, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17964, Train Loss:0.02885, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17965, Train Loss:0.09781, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17966, Train Loss:0.01473, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17967, Train Loss:0.46457, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17968, Train Loss:0.24980, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17969, Train Loss:0.01352, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17970, Train Loss:0.13862, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17971, Train Loss:0.00631, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17972, Train Loss:0.34812, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17973, Train Loss:0.00844, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17974, Train Loss:0.04404, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17975, Train Loss:0.15686, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17976, Train Loss:0.00002, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17977, Train Loss:0.33441, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17978, Train Loss:0.01068, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17979, Train Loss:2.76649, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17980, Train Loss:0.00003, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17981, Train Loss:0.53906, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17982, Train Loss:0.35547, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17983, Train Loss:0.00004, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17984, Train Loss:0.00001, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17985, Train Loss:0.01478, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17986, Train Loss:0.00031, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17987, Train Loss:0.34606, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17988, Train Loss:0.00013, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17989, Train Loss:0.00483, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17990, Train Loss:0.06409, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17991, Train Loss:0.20864, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17992, Train Loss:0.15529, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17993, Train Loss:0.00082, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17994, Train Loss:0.00657, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17995, Train Loss:0.00050, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17996, Train Loss:0.00089, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17997, Train Loss:0.32234, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17998, Train Loss:0.20414, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:17999, Train Loss:0.13127, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:18000, Train Loss:0.18785, Dev Loss:0.46963\n",
      "Epoch:[65/100], step:18001, Train Loss:0.10444, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18002, Train Loss:0.01867, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18003, Train Loss:0.45497, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18004, Train Loss:0.02609, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18005, Train Loss:0.16812, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18006, Train Loss:0.07493, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18007, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18008, Train Loss:0.02977, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18009, Train Loss:0.00896, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18010, Train Loss:0.00032, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18011, Train Loss:0.05611, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18012, Train Loss:0.05478, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18013, Train Loss:0.11415, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18014, Train Loss:0.00451, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18015, Train Loss:0.08987, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18016, Train Loss:0.48539, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18017, Train Loss:0.14423, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18018, Train Loss:0.00025, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18019, Train Loss:0.00079, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18020, Train Loss:0.07937, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18021, Train Loss:0.19695, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18022, Train Loss:0.03586, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18023, Train Loss:0.24684, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18024, Train Loss:0.09820, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18025, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18026, Train Loss:0.06743, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18027, Train Loss:0.03747, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18028, Train Loss:0.05992, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18029, Train Loss:0.03540, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18030, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18031, Train Loss:0.00002, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18032, Train Loss:0.05529, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18033, Train Loss:0.05222, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18034, Train Loss:0.19619, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18035, Train Loss:0.14381, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18036, Train Loss:0.00681, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18037, Train Loss:3.51528, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18038, Train Loss:0.02039, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18039, Train Loss:0.03022, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18040, Train Loss:0.10651, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18041, Train Loss:0.00773, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18042, Train Loss:0.03512, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18043, Train Loss:0.12832, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18044, Train Loss:0.05358, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18045, Train Loss:0.35714, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18046, Train Loss:0.00051, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18047, Train Loss:0.14692, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18048, Train Loss:0.01814, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18049, Train Loss:0.00877, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18050, Train Loss:0.00064, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18051, Train Loss:0.14455, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18052, Train Loss:0.00711, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18053, Train Loss:0.00206, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18054, Train Loss:0.07452, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18055, Train Loss:0.06456, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18056, Train Loss:0.08686, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18057, Train Loss:0.07375, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18058, Train Loss:0.02253, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18059, Train Loss:0.18032, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18060, Train Loss:0.00088, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18061, Train Loss:0.00145, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18062, Train Loss:0.07469, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18063, Train Loss:0.37284, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18064, Train Loss:0.00106, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18065, Train Loss:0.19684, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18066, Train Loss:0.05680, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18067, Train Loss:0.16931, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18068, Train Loss:0.17312, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18069, Train Loss:1.22482, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18070, Train Loss:0.13237, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18071, Train Loss:0.24697, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18072, Train Loss:0.00153, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18073, Train Loss:0.00233, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18074, Train Loss:0.00017, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18075, Train Loss:0.00241, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18076, Train Loss:0.12249, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18077, Train Loss:0.04414, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18078, Train Loss:0.06050, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18079, Train Loss:0.00203, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18080, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18081, Train Loss:0.00186, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18082, Train Loss:0.23788, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18083, Train Loss:0.34415, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18084, Train Loss:0.01514, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18085, Train Loss:0.01540, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18086, Train Loss:0.04009, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18087, Train Loss:0.00714, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18088, Train Loss:0.01742, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18089, Train Loss:0.01660, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18090, Train Loss:0.00028, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18091, Train Loss:0.00190, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18092, Train Loss:0.08559, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18093, Train Loss:0.02282, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18094, Train Loss:0.00675, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18095, Train Loss:0.00074, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18096, Train Loss:0.00054, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18097, Train Loss:0.00800, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18098, Train Loss:0.00461, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18099, Train Loss:0.00274, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18100, Train Loss:0.27675, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18101, Train Loss:0.00208, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18102, Train Loss:0.02755, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18103, Train Loss:0.01285, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18104, Train Loss:0.01265, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18105, Train Loss:0.15052, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18106, Train Loss:0.00004, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18107, Train Loss:0.18696, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18108, Train Loss:0.12603, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18109, Train Loss:0.12669, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18110, Train Loss:0.00005, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18111, Train Loss:0.29705, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18112, Train Loss:0.09349, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18113, Train Loss:0.04539, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18114, Train Loss:0.04624, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18115, Train Loss:0.01270, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18116, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18117, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18118, Train Loss:0.01191, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18119, Train Loss:0.00631, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18120, Train Loss:0.00702, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18121, Train Loss:0.22790, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18122, Train Loss:0.03520, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18123, Train Loss:0.01249, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18124, Train Loss:0.00068, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18125, Train Loss:0.15710, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18126, Train Loss:0.00822, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18127, Train Loss:0.00011, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18128, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18129, Train Loss:0.00195, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18130, Train Loss:0.00821, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18131, Train Loss:0.00013, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18132, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18133, Train Loss:0.01694, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18134, Train Loss:0.01015, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18135, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18136, Train Loss:0.00016, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18137, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18138, Train Loss:0.06967, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18139, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18140, Train Loss:0.17125, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18141, Train Loss:0.01146, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18142, Train Loss:0.00005, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18143, Train Loss:0.34496, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18144, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18145, Train Loss:0.00014, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18146, Train Loss:0.00484, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18147, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18148, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18149, Train Loss:0.06918, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18150, Train Loss:0.12846, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18151, Train Loss:0.13413, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18152, Train Loss:0.26192, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18153, Train Loss:0.18204, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18154, Train Loss:0.00035, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18155, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18156, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18157, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18158, Train Loss:0.03032, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18159, Train Loss:0.32348, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18160, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18161, Train Loss:0.00247, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18162, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18163, Train Loss:0.20526, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18164, Train Loss:0.01107, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18165, Train Loss:0.00007, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18166, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18167, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18168, Train Loss:0.00132, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18169, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18170, Train Loss:0.00225, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18171, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18172, Train Loss:0.00010, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18173, Train Loss:0.01725, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18174, Train Loss:0.00004, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18175, Train Loss:0.06407, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18176, Train Loss:0.01092, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18177, Train Loss:0.11668, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18178, Train Loss:0.01324, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18179, Train Loss:0.19657, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18180, Train Loss:0.03667, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18181, Train Loss:0.00069, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18182, Train Loss:0.00194, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18183, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18184, Train Loss:0.00020, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18185, Train Loss:0.23465, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18186, Train Loss:0.23285, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18187, Train Loss:0.10486, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18188, Train Loss:0.00029, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18189, Train Loss:0.00936, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18190, Train Loss:0.00401, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18191, Train Loss:0.00002, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18192, Train Loss:0.00249, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18193, Train Loss:0.00322, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18194, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18195, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18196, Train Loss:0.09081, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18197, Train Loss:0.00009, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18198, Train Loss:0.00980, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18199, Train Loss:0.13159, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18200, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18201, Train Loss:0.07144, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18202, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18203, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18204, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18205, Train Loss:0.00006, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18206, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18207, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18208, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18209, Train Loss:0.09990, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18210, Train Loss:0.25200, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18211, Train Loss:0.00033, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18212, Train Loss:0.03547, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18213, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18214, Train Loss:0.05293, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18215, Train Loss:0.00699, Dev Loss:0.10016\n",
      "Epoch:[65/100], step:18216, Train Loss:0.00244, Dev Loss:0.10016\n",
      "Start Epoch: 66, Steps: 17\n",
      "Epoch:[66/100], step:18217, Train Loss:0.00533, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18218, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18219, Train Loss:0.04904, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18220, Train Loss:0.00016, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18221, Train Loss:0.03833, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18222, Train Loss:0.00009, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18223, Train Loss:0.00009, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18224, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18225, Train Loss:0.00044, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18226, Train Loss:0.00435, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18227, Train Loss:0.44169, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18228, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18229, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18230, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18231, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18232, Train Loss:0.15307, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18233, Train Loss:0.12058, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18234, Train Loss:0.00001, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18235, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18236, Train Loss:0.27825, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18237, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18238, Train Loss:0.16021, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18239, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18240, Train Loss:0.04193, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18241, Train Loss:0.00006, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18242, Train Loss:0.00006, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18243, Train Loss:0.05682, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18244, Train Loss:0.14384, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18245, Train Loss:0.36455, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18246, Train Loss:0.00184, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18247, Train Loss:0.00000, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18248, Train Loss:0.00518, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18249, Train Loss:0.00003, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18250, Train Loss:0.54154, Dev Loss:0.10016\n",
      "Epoch:[66/100], step:18251, Train Loss:0.03861, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18252, Train Loss:0.00037, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18253, Train Loss:0.35252, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18254, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18255, Train Loss:0.04404, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18256, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18257, Train Loss:0.08133, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18258, Train Loss:0.00551, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18259, Train Loss:0.00503, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18260, Train Loss:0.42165, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18261, Train Loss:0.00091, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18262, Train Loss:0.22667, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18263, Train Loss:0.01141, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18264, Train Loss:0.01219, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18265, Train Loss:0.87664, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18266, Train Loss:0.00032, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18267, Train Loss:0.00008, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18268, Train Loss:0.00003, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18269, Train Loss:0.05733, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18270, Train Loss:0.00022, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18271, Train Loss:0.04737, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18272, Train Loss:0.00793, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18273, Train Loss:0.00515, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18274, Train Loss:0.07992, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18275, Train Loss:0.00369, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18276, Train Loss:0.02539, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18277, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18278, Train Loss:0.49390, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18279, Train Loss:0.00021, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18280, Train Loss:0.01916, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18281, Train Loss:0.55612, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18282, Train Loss:0.00506, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18283, Train Loss:0.00142, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18284, Train Loss:0.41116, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18285, Train Loss:0.73309, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18286, Train Loss:0.30513, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18287, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18288, Train Loss:0.00115, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18289, Train Loss:0.03842, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18290, Train Loss:0.09345, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18291, Train Loss:0.23333, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18292, Train Loss:0.02124, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18293, Train Loss:0.09583, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18294, Train Loss:0.01638, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18295, Train Loss:1.22330, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18296, Train Loss:0.08150, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18297, Train Loss:0.01573, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18298, Train Loss:0.31124, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18299, Train Loss:0.06357, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18300, Train Loss:0.08995, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18301, Train Loss:0.04686, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18302, Train Loss:0.35535, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18303, Train Loss:0.00016, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18304, Train Loss:0.00282, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18305, Train Loss:0.14415, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18306, Train Loss:0.11855, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18307, Train Loss:0.00276, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18308, Train Loss:0.27371, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18309, Train Loss:0.45017, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18310, Train Loss:0.36100, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18311, Train Loss:0.23778, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18312, Train Loss:0.06556, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18313, Train Loss:0.58006, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18314, Train Loss:0.25156, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18315, Train Loss:0.43551, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18316, Train Loss:0.16414, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18317, Train Loss:0.36305, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18318, Train Loss:0.15828, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18319, Train Loss:0.07635, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18320, Train Loss:0.04697, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18321, Train Loss:0.00024, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18322, Train Loss:0.05309, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18323, Train Loss:0.00021, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18324, Train Loss:0.00061, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18325, Train Loss:0.00141, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18326, Train Loss:0.04226, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18327, Train Loss:0.02933, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18328, Train Loss:0.01543, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18329, Train Loss:0.00193, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18330, Train Loss:0.21523, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18331, Train Loss:0.02619, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18332, Train Loss:0.00095, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18333, Train Loss:0.65749, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18334, Train Loss:0.18083, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18335, Train Loss:0.02180, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18336, Train Loss:0.03172, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18337, Train Loss:0.00288, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18338, Train Loss:0.14872, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18339, Train Loss:0.39978, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18340, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18341, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18342, Train Loss:0.00003, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18343, Train Loss:0.00024, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18344, Train Loss:0.80287, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18345, Train Loss:0.05953, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18346, Train Loss:0.19502, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18347, Train Loss:0.00260, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18348, Train Loss:0.08212, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18349, Train Loss:0.17249, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18350, Train Loss:0.04444, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18351, Train Loss:0.00032, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18352, Train Loss:0.01758, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18353, Train Loss:0.31306, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18354, Train Loss:0.11643, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18355, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18356, Train Loss:0.02773, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18357, Train Loss:0.01832, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18358, Train Loss:0.01094, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18359, Train Loss:0.00002, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18360, Train Loss:0.00046, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18361, Train Loss:0.23460, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18362, Train Loss:0.19474, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18363, Train Loss:0.00787, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18364, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18365, Train Loss:0.00210, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18366, Train Loss:0.00150, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18367, Train Loss:0.00298, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18368, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18369, Train Loss:0.14183, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18370, Train Loss:0.43368, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18371, Train Loss:0.03343, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18372, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18373, Train Loss:0.00347, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18374, Train Loss:0.00052, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18375, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18376, Train Loss:0.01267, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18377, Train Loss:0.03866, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18378, Train Loss:0.00078, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18379, Train Loss:0.09035, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18380, Train Loss:0.01573, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18381, Train Loss:0.06335, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18382, Train Loss:0.00789, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18383, Train Loss:0.12235, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18384, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18385, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18386, Train Loss:0.08075, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18387, Train Loss:0.00144, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18388, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18389, Train Loss:0.31645, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18390, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18391, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18392, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18393, Train Loss:0.00058, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18394, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18395, Train Loss:0.00931, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18396, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18397, Train Loss:0.29810, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18398, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18399, Train Loss:0.04485, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18400, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18401, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18402, Train Loss:0.00011, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18403, Train Loss:0.13171, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18404, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18405, Train Loss:0.00007, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18406, Train Loss:0.00972, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18407, Train Loss:0.04256, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18408, Train Loss:0.00180, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18409, Train Loss:0.00002, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18410, Train Loss:0.31620, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18411, Train Loss:0.43040, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18412, Train Loss:0.00010, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18413, Train Loss:0.00045, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18414, Train Loss:0.17663, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18415, Train Loss:0.34349, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18416, Train Loss:0.00018, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18417, Train Loss:0.00801, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18418, Train Loss:0.00607, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18419, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18420, Train Loss:0.14016, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18421, Train Loss:0.02093, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18422, Train Loss:0.03987, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18423, Train Loss:0.07044, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18424, Train Loss:0.00068, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18425, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18426, Train Loss:0.00015, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18427, Train Loss:0.33630, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18428, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18429, Train Loss:0.06260, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18430, Train Loss:0.50792, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18431, Train Loss:0.00061, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18432, Train Loss:0.03258, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18433, Train Loss:0.01084, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18434, Train Loss:0.02395, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18435, Train Loss:0.00070, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18436, Train Loss:0.05549, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18437, Train Loss:0.30716, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18438, Train Loss:0.00239, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18439, Train Loss:0.02171, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18440, Train Loss:0.04063, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18441, Train Loss:0.10635, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18442, Train Loss:0.08437, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18443, Train Loss:0.00103, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18444, Train Loss:0.00004, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18445, Train Loss:0.01457, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18446, Train Loss:0.31015, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18447, Train Loss:0.62863, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18448, Train Loss:0.32142, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18449, Train Loss:0.17144, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18450, Train Loss:0.59620, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18451, Train Loss:0.01482, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18452, Train Loss:0.03381, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18453, Train Loss:0.00019, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18454, Train Loss:0.19681, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18455, Train Loss:0.11415, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18456, Train Loss:0.00701, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18457, Train Loss:0.06984, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18458, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18459, Train Loss:0.23475, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18460, Train Loss:0.00773, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18461, Train Loss:0.01789, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18462, Train Loss:0.01438, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18463, Train Loss:0.00006, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18464, Train Loss:0.00019, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18465, Train Loss:0.00054, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18466, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18467, Train Loss:0.00003, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18468, Train Loss:0.03338, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18469, Train Loss:0.12091, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18470, Train Loss:0.00583, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18471, Train Loss:0.00003, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18472, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18473, Train Loss:0.30621, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18474, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18475, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18476, Train Loss:0.10597, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18477, Train Loss:0.36349, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18478, Train Loss:0.00001, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18479, Train Loss:0.00814, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18480, Train Loss:0.00013, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18481, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18482, Train Loss:0.13206, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18483, Train Loss:0.00236, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18484, Train Loss:0.19737, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18485, Train Loss:0.00006, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18486, Train Loss:0.00100, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18487, Train Loss:0.00839, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18488, Train Loss:0.21992, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18489, Train Loss:0.06832, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18490, Train Loss:0.06412, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18491, Train Loss:0.02431, Dev Loss:0.18692\n",
      "Epoch:[66/100], step:18492, Train Loss:0.00128, Dev Loss:0.18692\n",
      "Start Epoch: 67, Steps: 17\n",
      "Epoch:[67/100], step:18493, Train Loss:0.00089, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18494, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18495, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18496, Train Loss:0.10766, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18497, Train Loss:0.00035, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18498, Train Loss:0.11704, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18499, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18500, Train Loss:0.00000, Dev Loss:0.18692\n",
      "Epoch:[67/100], step:18501, Train Loss:0.07959, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18502, Train Loss:0.00537, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18503, Train Loss:0.21109, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18504, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18505, Train Loss:0.03626, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18506, Train Loss:0.12336, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18507, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18508, Train Loss:0.00005, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18509, Train Loss:0.31802, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18510, Train Loss:0.23852, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18511, Train Loss:0.97694, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18512, Train Loss:0.00042, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18513, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18514, Train Loss:0.00004, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18515, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18516, Train Loss:0.00007, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18517, Train Loss:0.00225, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18518, Train Loss:0.04610, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18519, Train Loss:0.03246, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18520, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18521, Train Loss:0.00170, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18522, Train Loss:0.04671, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18523, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18524, Train Loss:0.42333, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18525, Train Loss:0.00114, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18526, Train Loss:0.05173, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18527, Train Loss:0.00002, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18528, Train Loss:0.00046, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18529, Train Loss:0.74402, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18530, Train Loss:0.00324, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18531, Train Loss:1.01073, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18532, Train Loss:0.10918, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18533, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18534, Train Loss:0.11437, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18535, Train Loss:0.05187, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18536, Train Loss:0.00640, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18537, Train Loss:0.05832, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18538, Train Loss:0.06262, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18539, Train Loss:0.02519, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18540, Train Loss:0.17868, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18541, Train Loss:0.10663, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18542, Train Loss:0.00302, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18543, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18544, Train Loss:0.70099, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18545, Train Loss:0.13698, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18546, Train Loss:0.00171, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18547, Train Loss:0.00117, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18548, Train Loss:0.04777, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18549, Train Loss:0.00935, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18550, Train Loss:0.00120, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18551, Train Loss:0.17755, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18552, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18553, Train Loss:0.00210, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18554, Train Loss:0.08295, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18555, Train Loss:0.12214, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18556, Train Loss:0.47295, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18557, Train Loss:0.37001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18558, Train Loss:0.00101, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18559, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18560, Train Loss:0.01985, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18561, Train Loss:0.00003, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18562, Train Loss:0.06643, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18563, Train Loss:0.60089, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18564, Train Loss:0.05049, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18565, Train Loss:0.00762, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18566, Train Loss:0.59964, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18567, Train Loss:0.00007, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18568, Train Loss:0.00002, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18569, Train Loss:0.00008, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18570, Train Loss:1.33763, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18571, Train Loss:0.10977, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18572, Train Loss:0.22028, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18573, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18574, Train Loss:0.67185, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18575, Train Loss:0.10973, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18576, Train Loss:0.09419, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18577, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18578, Train Loss:0.28899, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18579, Train Loss:0.02274, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18580, Train Loss:0.01765, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18581, Train Loss:0.00003, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18582, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18583, Train Loss:0.00055, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18584, Train Loss:0.47388, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18585, Train Loss:0.81012, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18586, Train Loss:0.00909, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18587, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18588, Train Loss:0.28460, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18589, Train Loss:0.10966, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18590, Train Loss:0.93085, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18591, Train Loss:0.12985, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18592, Train Loss:0.00298, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18593, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18594, Train Loss:0.00002, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18595, Train Loss:0.79887, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18596, Train Loss:0.00145, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18597, Train Loss:0.16616, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18598, Train Loss:0.00424, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18599, Train Loss:0.21737, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18600, Train Loss:0.08311, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18601, Train Loss:0.27455, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18602, Train Loss:0.00085, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18603, Train Loss:0.11550, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18604, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18605, Train Loss:0.46925, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18606, Train Loss:0.13230, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18607, Train Loss:0.14318, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18608, Train Loss:0.43452, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18609, Train Loss:0.00132, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18610, Train Loss:0.06469, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18611, Train Loss:0.00122, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18612, Train Loss:0.00435, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18613, Train Loss:0.02282, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18614, Train Loss:0.40627, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18615, Train Loss:0.11326, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18616, Train Loss:0.00002, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18617, Train Loss:0.25638, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18618, Train Loss:0.00063, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18619, Train Loss:0.13419, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18620, Train Loss:0.00066, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18621, Train Loss:0.68882, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18622, Train Loss:0.09754, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18623, Train Loss:0.00006, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18624, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18625, Train Loss:0.07499, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18626, Train Loss:0.09190, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18627, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18628, Train Loss:0.42673, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18629, Train Loss:0.04088, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18630, Train Loss:0.00123, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18631, Train Loss:0.02749, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18632, Train Loss:0.00009, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18633, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18634, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18635, Train Loss:0.15969, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18636, Train Loss:0.00003, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18637, Train Loss:0.09554, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18638, Train Loss:0.47583, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18639, Train Loss:0.12665, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18640, Train Loss:0.11354, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18641, Train Loss:0.08929, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18642, Train Loss:0.06688, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18643, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18644, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18645, Train Loss:0.02270, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18646, Train Loss:0.01348, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18647, Train Loss:0.12052, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18648, Train Loss:0.09492, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18649, Train Loss:0.15262, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18650, Train Loss:0.00279, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18651, Train Loss:0.00079, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18652, Train Loss:0.16879, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18653, Train Loss:0.12660, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18654, Train Loss:0.00129, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18655, Train Loss:0.14839, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18656, Train Loss:0.17697, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18657, Train Loss:0.73634, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18658, Train Loss:0.00186, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18659, Train Loss:0.06637, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18660, Train Loss:0.00785, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18661, Train Loss:0.05449, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18662, Train Loss:0.00002, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18663, Train Loss:0.42755, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18664, Train Loss:0.00966, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18665, Train Loss:0.14882, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18666, Train Loss:0.00009, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18667, Train Loss:0.00588, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18668, Train Loss:0.12649, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18669, Train Loss:0.19468, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18670, Train Loss:0.06011, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18671, Train Loss:0.02959, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18672, Train Loss:0.03447, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18673, Train Loss:0.35128, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18674, Train Loss:0.10801, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18675, Train Loss:0.77777, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18676, Train Loss:0.21755, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18677, Train Loss:1.42440, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18678, Train Loss:0.09347, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18679, Train Loss:0.00131, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18680, Train Loss:0.00094, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18681, Train Loss:0.00012, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18682, Train Loss:0.10390, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18683, Train Loss:0.18501, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18684, Train Loss:0.07824, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18685, Train Loss:0.01967, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18686, Train Loss:0.00009, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18687, Train Loss:0.14665, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18688, Train Loss:0.03632, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18689, Train Loss:0.23315, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18690, Train Loss:0.01248, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18691, Train Loss:0.01865, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18692, Train Loss:0.25819, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18693, Train Loss:0.14230, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18694, Train Loss:0.12014, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18695, Train Loss:0.04222, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18696, Train Loss:0.00142, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18697, Train Loss:0.09357, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18698, Train Loss:0.00938, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18699, Train Loss:0.09050, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18700, Train Loss:0.12064, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18701, Train Loss:0.03916, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18702, Train Loss:0.09476, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18703, Train Loss:0.00140, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18704, Train Loss:0.00021, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18705, Train Loss:0.00001, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18706, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18707, Train Loss:0.06737, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18708, Train Loss:0.00020, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18709, Train Loss:0.06333, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18710, Train Loss:0.00060, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18711, Train Loss:0.02989, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18712, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18713, Train Loss:0.13437, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18714, Train Loss:0.11884, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18715, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18716, Train Loss:0.00875, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18717, Train Loss:0.21418, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18718, Train Loss:0.00601, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18719, Train Loss:0.18791, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18720, Train Loss:0.25858, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18721, Train Loss:0.27402, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18722, Train Loss:0.02493, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18723, Train Loss:0.02175, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18724, Train Loss:0.00359, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18725, Train Loss:0.07448, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18726, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18727, Train Loss:0.23874, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18728, Train Loss:0.00494, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18729, Train Loss:0.10125, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18730, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18731, Train Loss:0.00005, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18732, Train Loss:0.78687, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18733, Train Loss:0.00050, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18734, Train Loss:0.02727, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18735, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18736, Train Loss:0.00506, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18737, Train Loss:0.05277, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18738, Train Loss:0.01251, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18739, Train Loss:0.02464, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18740, Train Loss:0.12276, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18741, Train Loss:0.00203, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18742, Train Loss:0.00616, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18743, Train Loss:0.00010, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18744, Train Loss:0.16446, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18745, Train Loss:0.00187, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18746, Train Loss:0.52935, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18747, Train Loss:0.19687, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18748, Train Loss:0.03036, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18749, Train Loss:0.00019, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18750, Train Loss:0.00000, Dev Loss:0.17191\n",
      "Epoch:[67/100], step:18751, Train Loss:0.15654, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18752, Train Loss:0.00393, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18753, Train Loss:0.00089, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18754, Train Loss:0.33631, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18755, Train Loss:0.02547, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18756, Train Loss:0.09442, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18757, Train Loss:0.01845, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18758, Train Loss:0.00122, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18759, Train Loss:0.00613, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18760, Train Loss:0.01460, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18761, Train Loss:0.22045, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18762, Train Loss:0.00003, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18763, Train Loss:0.05674, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18764, Train Loss:0.13843, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18765, Train Loss:0.00005, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18766, Train Loss:0.00028, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18767, Train Loss:0.04562, Dev Loss:0.17105\n",
      "Epoch:[67/100], step:18768, Train Loss:0.05616, Dev Loss:0.17105\n",
      "Start Epoch: 68, Steps: 17\n",
      "Epoch:[68/100], step:18769, Train Loss:0.67697, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18770, Train Loss:0.00488, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18771, Train Loss:0.48562, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18772, Train Loss:0.23341, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18773, Train Loss:0.00008, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18774, Train Loss:0.22002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18775, Train Loss:0.00088, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18776, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18777, Train Loss:0.00846, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18778, Train Loss:0.00004, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18779, Train Loss:0.19741, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18780, Train Loss:0.04904, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18781, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18782, Train Loss:0.00165, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18783, Train Loss:0.08525, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18784, Train Loss:0.19949, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18785, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18786, Train Loss:0.00152, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18787, Train Loss:0.17512, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18788, Train Loss:0.50212, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18789, Train Loss:0.00136, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18790, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18791, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18792, Train Loss:0.14943, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18793, Train Loss:0.05188, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18794, Train Loss:0.00164, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18795, Train Loss:0.13210, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18796, Train Loss:0.09163, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18797, Train Loss:0.06156, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18798, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18799, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18800, Train Loss:0.03663, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18801, Train Loss:0.00013, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18802, Train Loss:0.26402, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18803, Train Loss:0.06298, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18804, Train Loss:0.04310, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18805, Train Loss:0.00539, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18806, Train Loss:0.00023, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18807, Train Loss:0.00062, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18808, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18809, Train Loss:0.00005, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18810, Train Loss:0.15853, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18811, Train Loss:0.13997, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18812, Train Loss:0.00668, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18813, Train Loss:0.00006, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18814, Train Loss:0.00719, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18815, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18816, Train Loss:0.00032, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18817, Train Loss:0.00114, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18818, Train Loss:0.03604, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18819, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18820, Train Loss:0.75121, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18821, Train Loss:0.12324, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18822, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18823, Train Loss:0.00068, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18824, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18825, Train Loss:0.05964, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18826, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18827, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18828, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18829, Train Loss:0.09515, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18830, Train Loss:0.11786, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18831, Train Loss:0.20217, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18832, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18833, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18834, Train Loss:0.00012, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18835, Train Loss:0.04921, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18836, Train Loss:0.10707, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18837, Train Loss:0.00003, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18838, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18839, Train Loss:1.56466, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18840, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18841, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18842, Train Loss:0.09951, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18843, Train Loss:0.83684, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18844, Train Loss:0.00881, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18845, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18846, Train Loss:0.00087, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18847, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18848, Train Loss:0.39351, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18849, Train Loss:0.01604, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18850, Train Loss:0.00896, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18851, Train Loss:0.00439, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18852, Train Loss:0.09355, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18853, Train Loss:0.00007, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18854, Train Loss:0.00230, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18855, Train Loss:0.13673, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18856, Train Loss:0.06587, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18857, Train Loss:0.11013, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18858, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18859, Train Loss:0.26380, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18860, Train Loss:0.43489, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18861, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18862, Train Loss:0.00027, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18863, Train Loss:0.29824, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18864, Train Loss:0.03398, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18865, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18866, Train Loss:0.07330, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18867, Train Loss:0.43703, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18868, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18869, Train Loss:0.17611, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18870, Train Loss:0.01836, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18871, Train Loss:0.00006, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18872, Train Loss:0.00371, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18873, Train Loss:0.08101, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18874, Train Loss:0.00003, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18875, Train Loss:0.00019, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18876, Train Loss:0.00231, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18877, Train Loss:0.43189, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18878, Train Loss:0.00022, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18879, Train Loss:0.00951, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18880, Train Loss:0.25350, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18881, Train Loss:0.34725, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18882, Train Loss:0.05429, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18883, Train Loss:0.10426, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18884, Train Loss:0.01649, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18885, Train Loss:0.24947, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18886, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18887, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18888, Train Loss:0.04368, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18889, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18890, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18891, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18892, Train Loss:0.39740, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18893, Train Loss:0.09880, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18894, Train Loss:0.00071, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18895, Train Loss:0.00008, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18896, Train Loss:0.20272, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18897, Train Loss:0.06517, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18898, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18899, Train Loss:0.00028, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18900, Train Loss:0.50835, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18901, Train Loss:0.11496, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18902, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18903, Train Loss:0.16923, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18904, Train Loss:0.06631, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18905, Train Loss:0.00006, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18906, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18907, Train Loss:0.00020, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18908, Train Loss:0.00227, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18909, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18910, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18911, Train Loss:0.00154, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18912, Train Loss:0.00419, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18913, Train Loss:0.08227, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18914, Train Loss:0.08205, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18915, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18916, Train Loss:0.02816, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18917, Train Loss:0.06249, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18918, Train Loss:0.00466, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18919, Train Loss:0.01933, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18920, Train Loss:0.00068, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18921, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18922, Train Loss:0.00008, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18923, Train Loss:0.00032, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18924, Train Loss:0.11634, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18925, Train Loss:0.01879, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18926, Train Loss:0.08238, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18927, Train Loss:0.01309, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18928, Train Loss:0.07610, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18929, Train Loss:0.02938, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18930, Train Loss:0.00497, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18931, Train Loss:0.00009, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18932, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18933, Train Loss:0.03961, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18934, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18935, Train Loss:0.00017, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18936, Train Loss:0.09921, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18937, Train Loss:0.09769, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18938, Train Loss:0.01453, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18939, Train Loss:0.37873, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18940, Train Loss:0.00961, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18941, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18942, Train Loss:0.00352, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18943, Train Loss:0.03610, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18944, Train Loss:0.00013, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18945, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18946, Train Loss:0.00006, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18947, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18948, Train Loss:0.00017, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18949, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18950, Train Loss:0.01537, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18951, Train Loss:0.09212, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18952, Train Loss:0.01718, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18953, Train Loss:0.07032, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18954, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18955, Train Loss:0.03884, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18956, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18957, Train Loss:0.00586, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18958, Train Loss:0.03839, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18959, Train Loss:0.07527, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18960, Train Loss:0.00027, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18961, Train Loss:0.04561, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18962, Train Loss:0.01515, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18963, Train Loss:0.00202, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18964, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18965, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18966, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18967, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18968, Train Loss:0.22019, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18969, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18970, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18971, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18972, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18973, Train Loss:0.53185, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18974, Train Loss:0.10857, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18975, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18976, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18977, Train Loss:0.09586, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18978, Train Loss:0.00179, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18979, Train Loss:0.09259, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18980, Train Loss:0.02556, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18981, Train Loss:0.24638, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18982, Train Loss:0.00058, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18983, Train Loss:0.37782, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18984, Train Loss:0.09349, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18985, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18986, Train Loss:0.00062, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18987, Train Loss:0.03207, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18988, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18989, Train Loss:0.10727, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18990, Train Loss:0.20929, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18991, Train Loss:0.00000, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18992, Train Loss:0.03557, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18993, Train Loss:0.00002, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18994, Train Loss:0.13124, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18995, Train Loss:0.07200, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18996, Train Loss:0.00320, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18997, Train Loss:0.01101, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18998, Train Loss:0.00106, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:18999, Train Loss:0.64432, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:19000, Train Loss:0.00001, Dev Loss:0.17105\n",
      "Epoch:[68/100], step:19001, Train Loss:0.00178, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19002, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19003, Train Loss:0.08832, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19004, Train Loss:0.10949, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19005, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19006, Train Loss:0.00584, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19007, Train Loss:0.01096, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19008, Train Loss:0.01900, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19009, Train Loss:0.13172, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19010, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19011, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19012, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19013, Train Loss:0.00006, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19014, Train Loss:2.06278, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19015, Train Loss:0.11730, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19016, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19017, Train Loss:0.00367, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19018, Train Loss:0.01332, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19019, Train Loss:0.17929, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19020, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19021, Train Loss:0.96986, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19022, Train Loss:0.10224, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19023, Train Loss:0.00799, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19024, Train Loss:0.25374, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19025, Train Loss:0.10394, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19026, Train Loss:0.74188, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19027, Train Loss:0.36006, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19028, Train Loss:0.03429, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19029, Train Loss:0.14162, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19030, Train Loss:0.19122, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19031, Train Loss:0.17327, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19032, Train Loss:0.08654, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19033, Train Loss:0.00122, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19034, Train Loss:0.12088, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19035, Train Loss:0.11144, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19036, Train Loss:0.11357, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19037, Train Loss:0.26138, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19038, Train Loss:0.00934, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19039, Train Loss:0.10504, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19040, Train Loss:0.26212, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19041, Train Loss:0.00504, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19042, Train Loss:0.01242, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19043, Train Loss:0.00007, Dev Loss:0.08746\n",
      "Epoch:[68/100], step:19044, Train Loss:0.04813, Dev Loss:0.08746\n",
      "Start Epoch: 69, Steps: 17\n",
      "Epoch:[69/100], step:19045, Train Loss:0.01151, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19046, Train Loss:0.00096, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19047, Train Loss:0.13257, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19048, Train Loss:0.04889, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19049, Train Loss:0.08106, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19050, Train Loss:0.23093, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19051, Train Loss:0.21472, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19052, Train Loss:0.08269, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19053, Train Loss:0.27531, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19054, Train Loss:0.01916, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19055, Train Loss:0.00034, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19056, Train Loss:0.15840, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19057, Train Loss:0.08609, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19058, Train Loss:0.02036, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19059, Train Loss:0.04201, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19060, Train Loss:0.00014, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19061, Train Loss:0.00009, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19062, Train Loss:0.12636, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19063, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19064, Train Loss:0.02635, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19065, Train Loss:0.00160, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19066, Train Loss:0.00026, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19067, Train Loss:0.02025, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19068, Train Loss:0.01973, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19069, Train Loss:0.00008, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19070, Train Loss:0.01153, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19071, Train Loss:0.02553, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19072, Train Loss:0.09850, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19073, Train Loss:0.04148, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19074, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19075, Train Loss:0.10556, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19076, Train Loss:0.00015, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19077, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19078, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19079, Train Loss:0.20841, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19080, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19081, Train Loss:0.05657, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19082, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19083, Train Loss:0.06358, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19084, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19085, Train Loss:0.00012, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19086, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19087, Train Loss:0.00022, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19088, Train Loss:0.00025, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19089, Train Loss:0.03327, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19090, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19091, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19092, Train Loss:0.58808, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19093, Train Loss:0.49514, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19094, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19095, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19096, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19097, Train Loss:0.01785, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19098, Train Loss:0.00295, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19099, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19100, Train Loss:0.00178, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19101, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19102, Train Loss:0.00115, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19103, Train Loss:0.00667, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19104, Train Loss:0.15794, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19105, Train Loss:0.05381, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19106, Train Loss:0.22821, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19107, Train Loss:0.05721, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19108, Train Loss:0.00115, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19109, Train Loss:0.08387, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19110, Train Loss:0.04016, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19111, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19112, Train Loss:0.00281, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19113, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19114, Train Loss:0.00006, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19115, Train Loss:0.11682, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19116, Train Loss:0.05950, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19117, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19118, Train Loss:0.19714, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19119, Train Loss:0.00115, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19120, Train Loss:0.08130, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19121, Train Loss:0.00274, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19122, Train Loss:0.04173, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19123, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19124, Train Loss:0.16164, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19125, Train Loss:0.00269, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19126, Train Loss:0.00016, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19127, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19128, Train Loss:0.00082, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19129, Train Loss:0.00002, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19130, Train Loss:0.01719, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19131, Train Loss:0.00012, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19132, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19133, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19134, Train Loss:0.08850, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19135, Train Loss:0.02099, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19136, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19137, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19138, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19139, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19140, Train Loss:0.15868, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19141, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19142, Train Loss:0.01689, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19143, Train Loss:0.18437, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19144, Train Loss:0.18572, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19145, Train Loss:0.00070, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19146, Train Loss:0.02195, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19147, Train Loss:0.00166, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19148, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19149, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19150, Train Loss:0.17193, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19151, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19152, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19153, Train Loss:0.02149, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19154, Train Loss:0.31581, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19155, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19156, Train Loss:0.02132, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19157, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19158, Train Loss:0.00120, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19159, Train Loss:0.20790, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19160, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19161, Train Loss:0.00020, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19162, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19163, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19164, Train Loss:0.09193, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19165, Train Loss:0.13741, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19166, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19167, Train Loss:0.03312, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19168, Train Loss:0.00011, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19169, Train Loss:0.04828, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19170, Train Loss:0.02116, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19171, Train Loss:0.08994, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19172, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19173, Train Loss:0.14180, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19174, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19175, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19176, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19177, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19178, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19179, Train Loss:0.00006, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19180, Train Loss:0.09910, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19181, Train Loss:0.00030, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19182, Train Loss:0.00327, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19183, Train Loss:0.34588, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19184, Train Loss:0.02194, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19185, Train Loss:0.07903, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19186, Train Loss:0.03643, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19187, Train Loss:0.13170, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19188, Train Loss:0.00006, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19189, Train Loss:0.00071, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19190, Train Loss:0.19909, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19191, Train Loss:0.16054, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19192, Train Loss:0.03303, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19193, Train Loss:0.21459, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19194, Train Loss:0.69566, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19195, Train Loss:0.01343, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19196, Train Loss:0.00039, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19197, Train Loss:0.00068, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19198, Train Loss:0.00056, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19199, Train Loss:0.05717, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19200, Train Loss:0.00527, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19201, Train Loss:0.00166, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19202, Train Loss:0.52413, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19203, Train Loss:0.58291, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19204, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19205, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19206, Train Loss:0.00734, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19207, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19208, Train Loss:0.00006, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19209, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19210, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19211, Train Loss:0.00119, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19212, Train Loss:0.35613, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19213, Train Loss:0.01185, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19214, Train Loss:0.02339, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19215, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19216, Train Loss:0.16694, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19217, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19218, Train Loss:0.01612, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19219, Train Loss:0.00096, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19220, Train Loss:0.15188, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19221, Train Loss:0.00010, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19222, Train Loss:0.00392, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19223, Train Loss:0.00333, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19224, Train Loss:0.00004, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19225, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19226, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19227, Train Loss:0.02135, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19228, Train Loss:0.01041, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19229, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19230, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19231, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19232, Train Loss:0.00003, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19233, Train Loss:0.00001, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19234, Train Loss:0.12744, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19235, Train Loss:0.08897, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19236, Train Loss:0.27794, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19237, Train Loss:0.00005, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19238, Train Loss:0.14600, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19239, Train Loss:0.38558, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19240, Train Loss:0.02612, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19241, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19242, Train Loss:0.00504, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19243, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19244, Train Loss:0.10098, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19245, Train Loss:0.20670, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19246, Train Loss:0.00321, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19247, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19248, Train Loss:0.00004, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19249, Train Loss:0.00002, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19250, Train Loss:0.00000, Dev Loss:0.08746\n",
      "Epoch:[69/100], step:19251, Train Loss:0.00014, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19252, Train Loss:0.06412, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19253, Train Loss:0.09112, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19254, Train Loss:0.02252, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19255, Train Loss:0.05663, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19256, Train Loss:0.09476, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19257, Train Loss:0.00567, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19258, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19259, Train Loss:0.19718, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19260, Train Loss:0.16234, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19261, Train Loss:0.00080, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19262, Train Loss:0.00007, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19263, Train Loss:0.24138, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19264, Train Loss:3.82562, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19265, Train Loss:0.00037, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19266, Train Loss:0.00002, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19267, Train Loss:0.04197, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19268, Train Loss:0.02311, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19269, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19270, Train Loss:0.12349, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19271, Train Loss:0.01814, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19272, Train Loss:0.02761, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19273, Train Loss:0.00042, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19274, Train Loss:0.12381, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19275, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19276, Train Loss:0.29367, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19277, Train Loss:0.08077, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19278, Train Loss:0.02631, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19279, Train Loss:0.16976, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19280, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19281, Train Loss:0.49497, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19282, Train Loss:0.18558, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19283, Train Loss:0.15110, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19284, Train Loss:0.49679, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19285, Train Loss:0.05511, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19286, Train Loss:0.12975, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19287, Train Loss:0.10469, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19288, Train Loss:0.44948, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19289, Train Loss:0.02841, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19290, Train Loss:0.10171, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19291, Train Loss:0.39933, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19292, Train Loss:0.00011, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19293, Train Loss:0.04105, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19294, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19295, Train Loss:0.01934, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19296, Train Loss:0.00105, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19297, Train Loss:0.00956, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19298, Train Loss:0.01015, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19299, Train Loss:0.00022, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19300, Train Loss:0.00200, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19301, Train Loss:0.62485, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19302, Train Loss:0.23899, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19303, Train Loss:0.01832, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19304, Train Loss:0.00009, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19305, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19306, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19307, Train Loss:0.44668, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19308, Train Loss:0.26587, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19309, Train Loss:0.03018, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19310, Train Loss:0.39021, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19311, Train Loss:0.34777, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19312, Train Loss:0.13773, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19313, Train Loss:0.00008, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19314, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19315, Train Loss:1.30168, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19316, Train Loss:0.00002, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19317, Train Loss:1.68908, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19318, Train Loss:0.47692, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19319, Train Loss:0.00015, Dev Loss:0.15964\n",
      "Epoch:[69/100], step:19320, Train Loss:0.10507, Dev Loss:0.15964\n",
      "Start Epoch: 70, Steps: 17\n",
      "Epoch:[70/100], step:19321, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19322, Train Loss:0.30549, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19323, Train Loss:0.00081, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19324, Train Loss:0.28864, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19325, Train Loss:0.18659, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19326, Train Loss:0.24666, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19327, Train Loss:3.81905, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19328, Train Loss:0.02410, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19329, Train Loss:0.07852, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19330, Train Loss:0.20842, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19331, Train Loss:0.03593, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19332, Train Loss:0.01741, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19333, Train Loss:0.33445, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19334, Train Loss:0.01840, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19335, Train Loss:0.00096, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19336, Train Loss:0.03656, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19337, Train Loss:0.01597, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19338, Train Loss:0.00020, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19339, Train Loss:0.00068, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19340, Train Loss:0.76456, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19341, Train Loss:0.58714, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19342, Train Loss:0.05750, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19343, Train Loss:0.00508, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19344, Train Loss:0.07912, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19345, Train Loss:0.01955, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19346, Train Loss:0.03632, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19347, Train Loss:0.14857, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19348, Train Loss:0.23890, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19349, Train Loss:0.02417, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19350, Train Loss:0.03888, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19351, Train Loss:0.10383, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19352, Train Loss:0.24256, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19353, Train Loss:0.30190, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19354, Train Loss:0.03657, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19355, Train Loss:0.05477, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19356, Train Loss:0.00745, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19357, Train Loss:0.31006, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19358, Train Loss:0.46933, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19359, Train Loss:0.10580, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19360, Train Loss:0.10615, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19361, Train Loss:0.03396, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19362, Train Loss:0.00012, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19363, Train Loss:0.14461, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19364, Train Loss:0.01892, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19365, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19366, Train Loss:0.10711, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19367, Train Loss:0.05624, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19368, Train Loss:0.04889, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19369, Train Loss:0.16080, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19370, Train Loss:0.01384, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19371, Train Loss:0.02172, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19372, Train Loss:0.00801, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19373, Train Loss:0.08240, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19374, Train Loss:0.00013, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19375, Train Loss:0.00616, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19376, Train Loss:0.22261, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19377, Train Loss:0.21803, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19378, Train Loss:0.00069, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19379, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19380, Train Loss:0.00693, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19381, Train Loss:0.13904, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19382, Train Loss:0.07329, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19383, Train Loss:0.29026, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19384, Train Loss:0.07745, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19385, Train Loss:0.14789, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19386, Train Loss:0.15390, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19387, Train Loss:0.00098, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19388, Train Loss:0.04999, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19389, Train Loss:0.00709, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19390, Train Loss:0.00004, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19391, Train Loss:0.00028, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19392, Train Loss:0.00038, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19393, Train Loss:0.07128, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19394, Train Loss:0.00012, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19395, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19396, Train Loss:0.00006, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19397, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19398, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19399, Train Loss:0.00003, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19400, Train Loss:0.00025, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19401, Train Loss:0.00029, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19402, Train Loss:0.00003, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19403, Train Loss:0.00002, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19404, Train Loss:0.02070, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19405, Train Loss:0.14346, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19406, Train Loss:0.26003, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19407, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19408, Train Loss:0.36889, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19409, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19410, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19411, Train Loss:0.00027, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19412, Train Loss:0.00485, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19413, Train Loss:0.00016, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19414, Train Loss:0.01216, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19415, Train Loss:0.02102, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19416, Train Loss:0.00003, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19417, Train Loss:0.03472, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19418, Train Loss:0.00788, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19419, Train Loss:0.37448, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19420, Train Loss:0.00012, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19421, Train Loss:0.01493, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19422, Train Loss:0.00618, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19423, Train Loss:0.28841, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19424, Train Loss:0.35019, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19425, Train Loss:0.00108, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19426, Train Loss:0.00059, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19427, Train Loss:0.06176, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19428, Train Loss:0.13706, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19429, Train Loss:0.33273, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19430, Train Loss:0.03087, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19431, Train Loss:0.23790, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19432, Train Loss:3.08252, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19433, Train Loss:0.14963, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19434, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19435, Train Loss:0.91369, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19436, Train Loss:0.00423, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19437, Train Loss:0.00204, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19438, Train Loss:0.16405, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19439, Train Loss:0.07993, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19440, Train Loss:0.21048, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19441, Train Loss:0.00508, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19442, Train Loss:0.44162, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19443, Train Loss:0.18932, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19444, Train Loss:0.46421, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19445, Train Loss:0.48154, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19446, Train Loss:0.53583, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19447, Train Loss:0.11838, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19448, Train Loss:0.17530, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19449, Train Loss:0.02360, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19450, Train Loss:0.33040, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19451, Train Loss:0.39346, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19452, Train Loss:0.05167, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19453, Train Loss:0.22215, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19454, Train Loss:0.15612, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19455, Train Loss:0.62259, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19456, Train Loss:0.10807, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19457, Train Loss:0.02753, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19458, Train Loss:0.36233, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19459, Train Loss:0.16381, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19460, Train Loss:0.00404, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19461, Train Loss:0.00687, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19462, Train Loss:0.11018, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19463, Train Loss:0.18204, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19464, Train Loss:0.16204, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19465, Train Loss:0.05923, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19466, Train Loss:0.33855, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19467, Train Loss:0.00007, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19468, Train Loss:0.02287, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19469, Train Loss:0.05545, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19470, Train Loss:0.00634, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19471, Train Loss:0.08045, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19472, Train Loss:0.18416, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19473, Train Loss:0.36092, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19474, Train Loss:0.03489, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19475, Train Loss:0.11113, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19476, Train Loss:0.02845, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19477, Train Loss:0.00161, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19478, Train Loss:0.00145, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19479, Train Loss:0.19054, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19480, Train Loss:0.00009, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19481, Train Loss:0.44659, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19482, Train Loss:0.00085, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19483, Train Loss:0.25571, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19484, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19485, Train Loss:0.00011, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19486, Train Loss:0.00107, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19487, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19488, Train Loss:0.19098, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19489, Train Loss:0.00003, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19490, Train Loss:0.50886, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19491, Train Loss:0.04404, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19492, Train Loss:0.07130, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19493, Train Loss:0.05188, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19494, Train Loss:0.29796, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19495, Train Loss:0.02029, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19496, Train Loss:0.00001, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19497, Train Loss:0.00000, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19498, Train Loss:0.00133, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19499, Train Loss:0.00013, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19500, Train Loss:0.00034, Dev Loss:0.15964\n",
      "Epoch:[70/100], step:19501, Train Loss:0.22772, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19502, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19503, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19504, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19505, Train Loss:0.00017, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19506, Train Loss:0.48429, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19507, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19508, Train Loss:0.00003, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19509, Train Loss:0.00012, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19510, Train Loss:0.01802, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19511, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19512, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19513, Train Loss:0.00992, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19514, Train Loss:0.00003, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19515, Train Loss:0.11426, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19516, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19517, Train Loss:0.09156, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19518, Train Loss:0.02849, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19519, Train Loss:0.00201, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19520, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19521, Train Loss:0.14792, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19522, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19523, Train Loss:0.01092, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19524, Train Loss:0.24289, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19525, Train Loss:0.00012, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19526, Train Loss:0.59271, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19527, Train Loss:0.02711, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19528, Train Loss:0.00422, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19529, Train Loss:0.03713, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19530, Train Loss:0.21078, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19531, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19532, Train Loss:0.15859, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19533, Train Loss:0.00500, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19534, Train Loss:0.40408, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19535, Train Loss:0.01989, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19536, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19537, Train Loss:0.18560, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19538, Train Loss:0.00964, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19539, Train Loss:0.07778, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19540, Train Loss:0.63545, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19541, Train Loss:0.14626, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19542, Train Loss:0.11276, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19543, Train Loss:0.24032, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19544, Train Loss:0.00033, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19545, Train Loss:0.12293, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19546, Train Loss:0.07201, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19547, Train Loss:0.02947, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19548, Train Loss:0.10924, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19549, Train Loss:0.04370, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19550, Train Loss:0.00158, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19551, Train Loss:0.09125, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19552, Train Loss:0.00755, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19553, Train Loss:0.00024, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19554, Train Loss:0.00389, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19555, Train Loss:0.00318, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19556, Train Loss:0.14875, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19557, Train Loss:0.10272, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19558, Train Loss:0.00638, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19559, Train Loss:0.09622, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19560, Train Loss:0.13922, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19561, Train Loss:0.00316, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19562, Train Loss:0.02426, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19563, Train Loss:0.00783, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19564, Train Loss:0.00011, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19565, Train Loss:0.00236, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19566, Train Loss:0.11036, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19567, Train Loss:0.00011, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19568, Train Loss:0.13847, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19569, Train Loss:0.01582, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19570, Train Loss:0.20517, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19571, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19572, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19573, Train Loss:0.00008, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19574, Train Loss:0.20762, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19575, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19576, Train Loss:0.70720, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19577, Train Loss:0.05803, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19578, Train Loss:0.32041, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19579, Train Loss:0.12229, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19580, Train Loss:0.01889, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19581, Train Loss:0.28899, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19582, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19583, Train Loss:0.00220, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19584, Train Loss:0.00507, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19585, Train Loss:0.04724, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19586, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19587, Train Loss:0.00076, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19588, Train Loss:0.00014, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19589, Train Loss:0.38959, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19590, Train Loss:0.00003, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19591, Train Loss:0.00140, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19592, Train Loss:0.06515, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19593, Train Loss:0.01545, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19594, Train Loss:0.00922, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19595, Train Loss:0.21371, Dev Loss:0.06672\n",
      "Epoch:[70/100], step:19596, Train Loss:0.00033, Dev Loss:0.06672\n",
      "Start Epoch: 71, Steps: 17\n",
      "Epoch:[71/100], step:19597, Train Loss:0.20962, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19598, Train Loss:0.00107, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19599, Train Loss:0.00138, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19600, Train Loss:0.12699, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19601, Train Loss:0.14813, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19602, Train Loss:0.00028, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19603, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19604, Train Loss:0.00470, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19605, Train Loss:0.00211, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19606, Train Loss:0.00155, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19607, Train Loss:0.00743, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19608, Train Loss:0.00047, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19609, Train Loss:0.03836, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19610, Train Loss:0.00475, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19611, Train Loss:0.00787, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19612, Train Loss:0.00133, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19613, Train Loss:0.00013, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19614, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19615, Train Loss:0.17153, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19616, Train Loss:0.05610, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19617, Train Loss:0.00013, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19618, Train Loss:0.00358, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19619, Train Loss:0.00004, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19620, Train Loss:0.00108, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19621, Train Loss:0.00341, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19622, Train Loss:0.53848, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19623, Train Loss:0.00887, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19624, Train Loss:0.17373, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19625, Train Loss:0.09289, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19626, Train Loss:0.00780, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19627, Train Loss:0.17563, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19628, Train Loss:0.04836, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19629, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19630, Train Loss:0.06636, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19631, Train Loss:0.01759, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19632, Train Loss:0.01211, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19633, Train Loss:0.01481, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19634, Train Loss:0.00137, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19635, Train Loss:0.07749, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19636, Train Loss:0.00043, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19637, Train Loss:0.00754, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19638, Train Loss:0.00120, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19639, Train Loss:0.00130, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19640, Train Loss:0.00259, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19641, Train Loss:0.00889, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19642, Train Loss:0.00003, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19643, Train Loss:0.07640, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19644, Train Loss:0.00021, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19645, Train Loss:0.00535, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19646, Train Loss:0.17163, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19647, Train Loss:0.36688, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19648, Train Loss:0.03744, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19649, Train Loss:0.00015, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19650, Train Loss:0.00534, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19651, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19652, Train Loss:0.00004, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19653, Train Loss:0.00005, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19654, Train Loss:0.00163, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19655, Train Loss:0.15952, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19656, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19657, Train Loss:0.01720, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19658, Train Loss:0.12889, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19659, Train Loss:0.01903, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19660, Train Loss:0.12358, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19661, Train Loss:0.20334, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19662, Train Loss:0.07193, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19663, Train Loss:0.00816, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19664, Train Loss:0.00920, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19665, Train Loss:0.23837, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19666, Train Loss:0.00186, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19667, Train Loss:0.14524, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19668, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19669, Train Loss:0.00969, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19670, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19671, Train Loss:0.12875, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19672, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19673, Train Loss:1.35641, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19674, Train Loss:0.00419, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19675, Train Loss:0.00106, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19676, Train Loss:0.05390, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19677, Train Loss:0.18880, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19678, Train Loss:0.00062, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19679, Train Loss:0.00196, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19680, Train Loss:0.06917, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19681, Train Loss:0.00005, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19682, Train Loss:0.03809, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19683, Train Loss:0.22010, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19684, Train Loss:0.53473, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19685, Train Loss:0.00052, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19686, Train Loss:0.02526, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19687, Train Loss:0.11144, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19688, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19689, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19690, Train Loss:0.00630, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19691, Train Loss:0.03318, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19692, Train Loss:0.16434, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19693, Train Loss:0.00012, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19694, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19695, Train Loss:0.25928, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19696, Train Loss:0.00394, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19697, Train Loss:0.03410, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19698, Train Loss:0.00007, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19699, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19700, Train Loss:0.07637, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19701, Train Loss:0.00049, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19702, Train Loss:0.00025, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19703, Train Loss:0.37995, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19704, Train Loss:0.01017, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19705, Train Loss:0.13306, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19706, Train Loss:0.00004, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19707, Train Loss:0.00002, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19708, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19709, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19710, Train Loss:0.00005, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19711, Train Loss:0.11530, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19712, Train Loss:0.02300, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19713, Train Loss:0.00013, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19714, Train Loss:0.00022, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19715, Train Loss:0.00023, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19716, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19717, Train Loss:0.00009, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19718, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19719, Train Loss:0.27731, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19720, Train Loss:0.01444, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19721, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19722, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19723, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19724, Train Loss:0.00007, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19725, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19726, Train Loss:0.00024, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19727, Train Loss:0.01890, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19728, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19729, Train Loss:0.01025, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19730, Train Loss:0.00043, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19731, Train Loss:0.00006, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19732, Train Loss:0.00028, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19733, Train Loss:0.00015, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19734, Train Loss:0.80645, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19735, Train Loss:0.00642, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19736, Train Loss:0.22793, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19737, Train Loss:0.00000, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19738, Train Loss:0.12834, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19739, Train Loss:0.17477, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19740, Train Loss:0.00014, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19741, Train Loss:0.08847, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19742, Train Loss:0.02122, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19743, Train Loss:0.00001, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19744, Train Loss:0.00033, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19745, Train Loss:0.00269, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19746, Train Loss:0.00002, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19747, Train Loss:0.26754, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19748, Train Loss:0.04395, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19749, Train Loss:0.46873, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19750, Train Loss:0.02433, Dev Loss:0.06672\n",
      "Epoch:[71/100], step:19751, Train Loss:0.00058, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19752, Train Loss:0.23613, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19753, Train Loss:0.08667, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19754, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19755, Train Loss:0.13836, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19756, Train Loss:0.05027, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19757, Train Loss:0.00080, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19758, Train Loss:0.05797, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19759, Train Loss:0.00074, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19760, Train Loss:0.39575, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19761, Train Loss:0.06199, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19762, Train Loss:0.00835, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19763, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19764, Train Loss:0.04671, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19765, Train Loss:0.00227, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19766, Train Loss:0.00178, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19767, Train Loss:0.00400, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19768, Train Loss:0.00032, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19769, Train Loss:0.00092, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19770, Train Loss:0.01741, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19771, Train Loss:0.02110, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19772, Train Loss:0.02220, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19773, Train Loss:0.00045, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19774, Train Loss:0.00227, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19775, Train Loss:0.32310, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19776, Train Loss:0.00024, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19777, Train Loss:0.00331, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19778, Train Loss:0.00025, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19779, Train Loss:0.02694, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19780, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19781, Train Loss:0.00054, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19782, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19783, Train Loss:0.06415, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19784, Train Loss:0.01132, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19785, Train Loss:0.00878, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19786, Train Loss:0.09887, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19787, Train Loss:0.00053, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19788, Train Loss:0.04828, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19789, Train Loss:0.00032, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19790, Train Loss:0.03953, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19791, Train Loss:0.07106, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19792, Train Loss:0.00026, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19793, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19794, Train Loss:0.00085, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19795, Train Loss:0.08528, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19796, Train Loss:0.07365, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19797, Train Loss:0.20914, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19798, Train Loss:0.00004, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19799, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19800, Train Loss:0.00052, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19801, Train Loss:0.00832, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19802, Train Loss:0.00007, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19803, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19804, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19805, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19806, Train Loss:0.09023, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19807, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19808, Train Loss:0.09056, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19809, Train Loss:0.01749, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19810, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19811, Train Loss:0.00210, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19812, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19813, Train Loss:0.00038, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19814, Train Loss:0.00300, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19815, Train Loss:0.00368, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19816, Train Loss:0.48183, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19817, Train Loss:0.00485, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19818, Train Loss:0.00002, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19819, Train Loss:0.00743, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19820, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19821, Train Loss:0.00002, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19822, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19823, Train Loss:0.02342, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19824, Train Loss:0.00074, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19825, Train Loss:0.00005, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19826, Train Loss:0.12170, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19827, Train Loss:0.04062, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19828, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19829, Train Loss:0.01638, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19830, Train Loss:0.02812, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19831, Train Loss:0.00004, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19832, Train Loss:0.00012, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19833, Train Loss:0.04609, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19834, Train Loss:0.01478, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19835, Train Loss:0.00010, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19836, Train Loss:0.00008, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19837, Train Loss:0.05609, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19838, Train Loss:0.00105, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19839, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19840, Train Loss:0.04554, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19841, Train Loss:0.00454, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19842, Train Loss:0.13349, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19843, Train Loss:0.07099, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19844, Train Loss:0.00704, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19845, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19846, Train Loss:0.00003, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19847, Train Loss:0.00059, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19848, Train Loss:0.00010, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19849, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19850, Train Loss:0.02938, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19851, Train Loss:0.00017, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19852, Train Loss:0.23502, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19853, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19854, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19855, Train Loss:0.00025, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19856, Train Loss:0.06219, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19857, Train Loss:0.00023, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19858, Train Loss:0.13445, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19859, Train Loss:0.61254, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19860, Train Loss:0.00664, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19861, Train Loss:0.06870, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19862, Train Loss:0.50584, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19863, Train Loss:0.03360, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19864, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19865, Train Loss:0.00011, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19866, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19867, Train Loss:0.26484, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19868, Train Loss:0.10256, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19869, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19870, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19871, Train Loss:0.01931, Dev Loss:0.07481\n",
      "Epoch:[71/100], step:19872, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Start Epoch: 72, Steps: 17\n",
      "Epoch:[72/100], step:19873, Train Loss:0.00003, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19874, Train Loss:0.27165, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19875, Train Loss:0.00171, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19876, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19877, Train Loss:0.00211, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19878, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19879, Train Loss:0.00030, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19880, Train Loss:0.04886, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19881, Train Loss:0.10455, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19882, Train Loss:0.76823, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19883, Train Loss:0.00174, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19884, Train Loss:0.51440, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19885, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19886, Train Loss:0.00056, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19887, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19888, Train Loss:0.00199, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19889, Train Loss:0.00169, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19890, Train Loss:0.00809, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19891, Train Loss:0.15378, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19892, Train Loss:0.05912, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19893, Train Loss:0.00139, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19894, Train Loss:0.00024, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19895, Train Loss:0.00049, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19896, Train Loss:0.00813, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19897, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19898, Train Loss:0.00339, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19899, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19900, Train Loss:0.00447, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19901, Train Loss:0.00017, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19902, Train Loss:0.00189, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19903, Train Loss:0.00505, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19904, Train Loss:0.03506, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19905, Train Loss:0.00006, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19906, Train Loss:0.00570, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19907, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19908, Train Loss:0.08091, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19909, Train Loss:0.00178, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19910, Train Loss:0.21411, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19911, Train Loss:0.25802, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19912, Train Loss:0.04071, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19913, Train Loss:0.00012, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19914, Train Loss:0.00021, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19915, Train Loss:0.32995, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19916, Train Loss:0.21442, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19917, Train Loss:0.09976, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19918, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19919, Train Loss:0.00961, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19920, Train Loss:0.00028, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19921, Train Loss:0.05954, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19922, Train Loss:0.00016, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19923, Train Loss:0.01387, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19924, Train Loss:0.02989, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19925, Train Loss:0.00332, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19926, Train Loss:0.00016, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19927, Train Loss:0.19313, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19928, Train Loss:0.00008, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19929, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19930, Train Loss:0.46265, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19931, Train Loss:0.00253, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19932, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19933, Train Loss:0.16211, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19934, Train Loss:0.08160, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19935, Train Loss:0.00030, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19936, Train Loss:0.03066, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19937, Train Loss:0.29834, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19938, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19939, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19940, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19941, Train Loss:0.10618, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19942, Train Loss:0.00587, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19943, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19944, Train Loss:0.02904, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19945, Train Loss:0.10181, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19946, Train Loss:0.08494, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19947, Train Loss:0.00013, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19948, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19949, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19950, Train Loss:0.06325, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19951, Train Loss:0.09935, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19952, Train Loss:0.00095, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19953, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19954, Train Loss:0.00024, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19955, Train Loss:0.06379, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19956, Train Loss:0.00003, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19957, Train Loss:0.10887, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19958, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19959, Train Loss:0.02865, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19960, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19961, Train Loss:0.00016, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19962, Train Loss:0.00015, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19963, Train Loss:0.00009, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19964, Train Loss:0.00187, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19965, Train Loss:0.00060, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19966, Train Loss:0.01043, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19967, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19968, Train Loss:0.00013, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19969, Train Loss:0.00368, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19970, Train Loss:0.00015, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19971, Train Loss:0.00001, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19972, Train Loss:0.20247, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19973, Train Loss:0.00918, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19974, Train Loss:0.13515, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19975, Train Loss:0.24845, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19976, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19977, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19978, Train Loss:0.43359, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19979, Train Loss:0.00058, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19980, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19981, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19982, Train Loss:0.00740, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19983, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19984, Train Loss:0.13537, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19985, Train Loss:0.00011, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19986, Train Loss:0.14224, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19987, Train Loss:0.00002, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19988, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19989, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19990, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19991, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19992, Train Loss:0.13056, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19993, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19994, Train Loss:0.13824, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19995, Train Loss:0.03971, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19996, Train Loss:0.66953, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19997, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19998, Train Loss:0.00000, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:19999, Train Loss:0.04818, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:20000, Train Loss:0.01170, Dev Loss:0.07481\n",
      "Epoch:[72/100], step:20001, Train Loss:0.00913, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20002, Train Loss:0.00004, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20003, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20004, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20005, Train Loss:0.00006, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20006, Train Loss:0.00063, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20007, Train Loss:0.05049, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20008, Train Loss:0.36385, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20009, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20010, Train Loss:0.00023, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20011, Train Loss:0.24705, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20012, Train Loss:0.16020, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20013, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20014, Train Loss:0.00138, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20015, Train Loss:0.59619, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20016, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20017, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20018, Train Loss:0.01230, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20019, Train Loss:0.05421, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20020, Train Loss:0.08758, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20021, Train Loss:0.74439, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20022, Train Loss:0.37816, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20023, Train Loss:0.00037, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20024, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20025, Train Loss:0.08536, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20026, Train Loss:0.04042, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20027, Train Loss:0.52417, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20028, Train Loss:0.65734, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20029, Train Loss:0.00607, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20030, Train Loss:0.18999, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20031, Train Loss:0.00014, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20032, Train Loss:0.00234, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20033, Train Loss:0.01074, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20034, Train Loss:0.00093, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20035, Train Loss:0.01620, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20036, Train Loss:0.01647, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20037, Train Loss:0.00067, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20038, Train Loss:0.01023, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20039, Train Loss:0.06502, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20040, Train Loss:0.14315, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20041, Train Loss:0.10229, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20042, Train Loss:0.00019, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20043, Train Loss:0.15454, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20044, Train Loss:0.04677, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20045, Train Loss:0.23986, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20046, Train Loss:0.00657, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20047, Train Loss:0.01618, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20048, Train Loss:0.12478, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20049, Train Loss:0.00747, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20050, Train Loss:0.03411, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20051, Train Loss:0.01308, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20052, Train Loss:0.02133, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20053, Train Loss:0.15152, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20054, Train Loss:0.00041, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20055, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20056, Train Loss:0.01826, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20057, Train Loss:0.14202, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20058, Train Loss:0.00395, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20059, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20060, Train Loss:0.00007, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20061, Train Loss:0.00014, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20062, Train Loss:0.11055, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20063, Train Loss:0.54690, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20064, Train Loss:0.21202, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20065, Train Loss:0.10256, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20066, Train Loss:0.02566, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20067, Train Loss:0.00635, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20068, Train Loss:0.00002, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20069, Train Loss:0.00003, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20070, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20071, Train Loss:0.00072, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20072, Train Loss:0.00027, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20073, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20074, Train Loss:0.01439, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20075, Train Loss:0.00735, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20076, Train Loss:0.02137, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20077, Train Loss:0.09311, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20078, Train Loss:0.58793, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20079, Train Loss:0.14183, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20080, Train Loss:0.00055, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20081, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20082, Train Loss:0.09700, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20083, Train Loss:0.92992, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20084, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20085, Train Loss:0.00019, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20086, Train Loss:0.02870, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20087, Train Loss:0.00033, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20088, Train Loss:0.34291, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20089, Train Loss:0.01691, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20090, Train Loss:0.06757, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20091, Train Loss:0.04859, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20092, Train Loss:0.00299, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20093, Train Loss:0.00043, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20094, Train Loss:0.00096, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20095, Train Loss:0.00071, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20096, Train Loss:0.00621, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20097, Train Loss:0.09116, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20098, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20099, Train Loss:0.00010, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20100, Train Loss:0.01396, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20101, Train Loss:0.11673, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20102, Train Loss:0.16776, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20103, Train Loss:0.29638, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20104, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20105, Train Loss:0.37375, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20106, Train Loss:0.05876, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20107, Train Loss:0.20733, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20108, Train Loss:0.06647, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20109, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20110, Train Loss:0.12552, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20111, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20112, Train Loss:0.20031, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20113, Train Loss:0.09148, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20114, Train Loss:0.04143, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20115, Train Loss:0.00003, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20116, Train Loss:0.41730, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20117, Train Loss:0.19253, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20118, Train Loss:0.01499, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20119, Train Loss:0.03197, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20120, Train Loss:0.10326, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20121, Train Loss:0.09393, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20122, Train Loss:0.23151, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20123, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20124, Train Loss:0.61213, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20125, Train Loss:0.03340, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20126, Train Loss:0.00591, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20127, Train Loss:0.00479, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20128, Train Loss:0.00915, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20129, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20130, Train Loss:0.07465, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20131, Train Loss:0.08330, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20132, Train Loss:0.00847, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20133, Train Loss:0.05899, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20134, Train Loss:0.67847, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20135, Train Loss:0.00811, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20136, Train Loss:0.08528, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20137, Train Loss:0.12206, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20138, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20139, Train Loss:0.00034, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20140, Train Loss:0.00017, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20141, Train Loss:0.07586, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20142, Train Loss:0.00065, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20143, Train Loss:0.02012, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20144, Train Loss:0.00065, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20145, Train Loss:0.01057, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20146, Train Loss:0.00686, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20147, Train Loss:0.00597, Dev Loss:0.21180\n",
      "Epoch:[72/100], step:20148, Train Loss:0.01070, Dev Loss:0.21180\n",
      "Start Epoch: 73, Steps: 17\n",
      "Epoch:[73/100], step:20149, Train Loss:0.02991, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20150, Train Loss:0.07974, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20151, Train Loss:0.23888, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20152, Train Loss:0.00071, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20153, Train Loss:0.09803, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20154, Train Loss:0.00528, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20155, Train Loss:0.05660, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20156, Train Loss:0.15652, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20157, Train Loss:0.09040, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20158, Train Loss:0.00200, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20159, Train Loss:0.00562, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20160, Train Loss:0.00514, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20161, Train Loss:0.01421, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20162, Train Loss:0.10045, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20163, Train Loss:0.00057, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20164, Train Loss:0.02695, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20165, Train Loss:0.18874, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20166, Train Loss:0.00003, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20167, Train Loss:0.00095, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20168, Train Loss:0.00047, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20169, Train Loss:0.11106, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20170, Train Loss:0.02759, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20171, Train Loss:0.23716, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20172, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20173, Train Loss:0.39777, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20174, Train Loss:0.01513, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20175, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20176, Train Loss:0.00021, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20177, Train Loss:0.01607, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20178, Train Loss:0.00023, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20179, Train Loss:0.33508, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20180, Train Loss:0.00018, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20181, Train Loss:0.05830, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20182, Train Loss:0.00002, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20183, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20184, Train Loss:0.00224, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20185, Train Loss:0.00005, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20186, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20187, Train Loss:0.11305, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20188, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20189, Train Loss:0.00019, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20190, Train Loss:0.00002, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20191, Train Loss:0.05078, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20192, Train Loss:0.13692, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20193, Train Loss:0.10562, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20194, Train Loss:0.35213, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20195, Train Loss:0.08227, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20196, Train Loss:0.02213, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20197, Train Loss:0.49274, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20198, Train Loss:0.12580, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20199, Train Loss:1.13907, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20200, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20201, Train Loss:0.00004, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20202, Train Loss:0.26269, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20203, Train Loss:0.00188, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20204, Train Loss:0.01365, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20205, Train Loss:0.42457, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20206, Train Loss:1.39070, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20207, Train Loss:0.05116, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20208, Train Loss:0.01895, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20209, Train Loss:0.11704, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20210, Train Loss:0.00459, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20211, Train Loss:0.11292, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20212, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20213, Train Loss:0.00025, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20214, Train Loss:0.02470, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20215, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20216, Train Loss:0.02841, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20217, Train Loss:0.38078, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20218, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20219, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20220, Train Loss:0.05774, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20221, Train Loss:0.03497, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20222, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20223, Train Loss:1.57051, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20224, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20225, Train Loss:0.01440, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20226, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20227, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20228, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20229, Train Loss:0.00001, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20230, Train Loss:0.00015, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20231, Train Loss:0.00019, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20232, Train Loss:0.00103, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20233, Train Loss:0.00126, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20234, Train Loss:0.36013, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20235, Train Loss:0.02024, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20236, Train Loss:0.03945, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20237, Train Loss:0.04738, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20238, Train Loss:0.04609, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20239, Train Loss:0.01308, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20240, Train Loss:0.00000, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20241, Train Loss:0.00693, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20242, Train Loss:0.00027, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20243, Train Loss:0.15378, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20244, Train Loss:0.00019, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20245, Train Loss:0.40146, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20246, Train Loss:0.17419, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20247, Train Loss:0.12527, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20248, Train Loss:0.06145, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20249, Train Loss:0.00314, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20250, Train Loss:0.06083, Dev Loss:0.21180\n",
      "Epoch:[73/100], step:20251, Train Loss:0.17025, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20252, Train Loss:0.37443, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20253, Train Loss:0.00120, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20254, Train Loss:0.00031, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20255, Train Loss:0.05529, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20256, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20257, Train Loss:0.00096, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20258, Train Loss:0.04663, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20259, Train Loss:0.00007, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20260, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20261, Train Loss:0.00138, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20262, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20263, Train Loss:0.13410, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20264, Train Loss:0.00463, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20265, Train Loss:0.39785, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20266, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20267, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20268, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20269, Train Loss:0.04783, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20270, Train Loss:0.08252, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20271, Train Loss:0.00013, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20272, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20273, Train Loss:0.27192, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20274, Train Loss:0.00123, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20275, Train Loss:0.05121, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20276, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20277, Train Loss:0.01088, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20278, Train Loss:0.02883, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20279, Train Loss:0.00036, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20280, Train Loss:0.00026, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20281, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20282, Train Loss:0.00002, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20283, Train Loss:0.00540, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20284, Train Loss:0.01295, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20285, Train Loss:0.11592, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20286, Train Loss:0.00043, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20287, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20288, Train Loss:0.12673, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20289, Train Loss:0.22974, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20290, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20291, Train Loss:0.00009, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20292, Train Loss:0.01067, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20293, Train Loss:0.09812, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20294, Train Loss:0.01899, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20295, Train Loss:0.01258, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20296, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20297, Train Loss:0.11744, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20298, Train Loss:0.04514, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20299, Train Loss:0.00993, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20300, Train Loss:0.00177, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20301, Train Loss:0.08048, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20302, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20303, Train Loss:0.15777, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20304, Train Loss:0.00027, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20305, Train Loss:0.00010, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20306, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20307, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20308, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20309, Train Loss:0.07010, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20310, Train Loss:0.00009, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20311, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20312, Train Loss:0.09792, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20313, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20314, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20315, Train Loss:0.60424, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20316, Train Loss:0.00295, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20317, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20318, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20319, Train Loss:0.00020, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20320, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20321, Train Loss:0.06695, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20322, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20323, Train Loss:0.06009, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20324, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20325, Train Loss:0.11327, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20326, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20327, Train Loss:0.03199, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20328, Train Loss:0.14429, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20329, Train Loss:0.10812, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20330, Train Loss:0.00977, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20331, Train Loss:0.04054, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20332, Train Loss:0.02499, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20333, Train Loss:0.00175, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20334, Train Loss:0.00009, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20335, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20336, Train Loss:0.10254, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20337, Train Loss:0.19011, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20338, Train Loss:0.00421, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20339, Train Loss:0.00343, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20340, Train Loss:0.04165, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20341, Train Loss:0.13295, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20342, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20343, Train Loss:0.08951, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20344, Train Loss:0.03111, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20345, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20346, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20347, Train Loss:0.11305, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20348, Train Loss:0.21676, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20349, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20350, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20351, Train Loss:0.00003, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20352, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20353, Train Loss:1.13468, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20354, Train Loss:0.00092, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20355, Train Loss:0.05464, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20356, Train Loss:0.05792, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20357, Train Loss:0.00231, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20358, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20359, Train Loss:0.14284, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20360, Train Loss:0.03872, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20361, Train Loss:0.00436, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20362, Train Loss:0.06612, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20363, Train Loss:0.00010, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20364, Train Loss:0.00970, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20365, Train Loss:0.00166, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20366, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20367, Train Loss:0.00003, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20368, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20369, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20370, Train Loss:0.00063, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20371, Train Loss:0.01187, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20372, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20373, Train Loss:0.00106, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20374, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20375, Train Loss:0.30179, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20376, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20377, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20378, Train Loss:0.13313, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20379, Train Loss:0.20606, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20380, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20381, Train Loss:0.08492, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20382, Train Loss:0.18808, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20383, Train Loss:0.01779, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20384, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20385, Train Loss:0.00022, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20386, Train Loss:0.07305, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20387, Train Loss:0.13649, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20388, Train Loss:0.00111, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20389, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20390, Train Loss:1.13018, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20391, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20392, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20393, Train Loss:0.22518, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20394, Train Loss:0.14561, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20395, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20396, Train Loss:0.00130, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20397, Train Loss:0.00208, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20398, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20399, Train Loss:0.47822, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20400, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20401, Train Loss:0.00002, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20402, Train Loss:0.45009, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20403, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20404, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20405, Train Loss:0.22628, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20406, Train Loss:0.39726, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20407, Train Loss:0.66098, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20408, Train Loss:0.02496, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20409, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20410, Train Loss:0.01398, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20411, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20412, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20413, Train Loss:0.08594, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20414, Train Loss:0.92229, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20415, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20416, Train Loss:0.11885, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20417, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20418, Train Loss:0.21328, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20419, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20420, Train Loss:0.15876, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20421, Train Loss:0.00046, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20422, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20423, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[73/100], step:20424, Train Loss:0.48336, Dev Loss:0.11703\n",
      "Start Epoch: 74, Steps: 17\n",
      "Epoch:[74/100], step:20425, Train Loss:0.17925, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20426, Train Loss:0.03822, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20427, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20428, Train Loss:0.00002, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20429, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20430, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20431, Train Loss:0.00003, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20432, Train Loss:0.27781, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20433, Train Loss:0.00019, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20434, Train Loss:0.00003, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20435, Train Loss:0.02301, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20436, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20437, Train Loss:0.00079, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20438, Train Loss:0.02691, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20439, Train Loss:0.29389, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20440, Train Loss:0.08985, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20441, Train Loss:0.09937, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20442, Train Loss:0.09804, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20443, Train Loss:0.08339, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20444, Train Loss:0.00130, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20445, Train Loss:0.13810, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20446, Train Loss:0.07143, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20447, Train Loss:0.00233, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20448, Train Loss:0.01812, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20449, Train Loss:0.00056, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20450, Train Loss:0.00242, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20451, Train Loss:0.03173, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20452, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20453, Train Loss:0.00894, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20454, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20455, Train Loss:0.00001, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20456, Train Loss:0.27591, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20457, Train Loss:0.10679, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20458, Train Loss:0.00190, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20459, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20460, Train Loss:0.08485, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20461, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20462, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20463, Train Loss:0.01513, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20464, Train Loss:0.17009, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20465, Train Loss:0.04050, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20466, Train Loss:0.09221, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20467, Train Loss:0.00019, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20468, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20469, Train Loss:0.07254, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20470, Train Loss:0.00261, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20471, Train Loss:0.00247, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20472, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20473, Train Loss:0.02178, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20474, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20475, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20476, Train Loss:0.02319, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20477, Train Loss:0.02545, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20478, Train Loss:0.00069, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20479, Train Loss:0.02363, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20480, Train Loss:0.03766, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20481, Train Loss:0.00009, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20482, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20483, Train Loss:0.00004, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20484, Train Loss:0.45633, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20485, Train Loss:0.26483, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20486, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20487, Train Loss:0.13178, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20488, Train Loss:0.23644, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20489, Train Loss:0.00014, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20490, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20491, Train Loss:0.07149, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20492, Train Loss:0.07994, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20493, Train Loss:0.03569, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20494, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20495, Train Loss:0.00006, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20496, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20497, Train Loss:0.00034, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20498, Train Loss:0.00000, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20499, Train Loss:0.14995, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20500, Train Loss:0.00402, Dev Loss:0.11703\n",
      "Epoch:[74/100], step:20501, Train Loss:0.26374, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20502, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20503, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20504, Train Loss:0.12710, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20505, Train Loss:0.00011, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20506, Train Loss:0.00003, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20507, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20508, Train Loss:0.02570, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20509, Train Loss:0.71632, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20510, Train Loss:0.22801, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20511, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20512, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20513, Train Loss:0.35284, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20514, Train Loss:0.00009, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20515, Train Loss:0.00170, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20516, Train Loss:0.00883, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20517, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20518, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20519, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20520, Train Loss:0.00939, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20521, Train Loss:0.04338, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20522, Train Loss:0.01888, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20523, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20524, Train Loss:0.02119, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20525, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20526, Train Loss:0.58811, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20527, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20528, Train Loss:0.00008, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20529, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20530, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20531, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20532, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20533, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20534, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20535, Train Loss:0.10900, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20536, Train Loss:0.07306, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20537, Train Loss:0.09757, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20538, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20539, Train Loss:0.00331, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20540, Train Loss:0.09219, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20541, Train Loss:0.05194, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20542, Train Loss:0.09635, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20543, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20544, Train Loss:0.23955, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20545, Train Loss:0.31764, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20546, Train Loss:0.94637, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20547, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20548, Train Loss:0.23356, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20549, Train Loss:0.00005, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20550, Train Loss:0.00001, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20551, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20552, Train Loss:0.00003, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20553, Train Loss:0.10941, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20554, Train Loss:1.60232, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20555, Train Loss:0.00424, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20556, Train Loss:0.00125, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20557, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20558, Train Loss:0.01332, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20559, Train Loss:0.00027, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20560, Train Loss:0.00521, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20561, Train Loss:0.23207, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20562, Train Loss:0.00045, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20563, Train Loss:0.14101, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20564, Train Loss:0.24230, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20565, Train Loss:0.01578, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20566, Train Loss:0.00060, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20567, Train Loss:0.82529, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20568, Train Loss:0.04549, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20569, Train Loss:0.17940, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20570, Train Loss:0.29646, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20571, Train Loss:0.51132, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20572, Train Loss:0.30652, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20573, Train Loss:0.18900, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20574, Train Loss:0.02907, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20575, Train Loss:0.36398, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20576, Train Loss:0.00028, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20577, Train Loss:0.07945, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20578, Train Loss:0.02088, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20579, Train Loss:0.20961, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20580, Train Loss:0.21421, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20581, Train Loss:0.00277, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20582, Train Loss:0.00001, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20583, Train Loss:0.26224, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20584, Train Loss:0.22695, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20585, Train Loss:0.19259, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20586, Train Loss:0.11837, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20587, Train Loss:0.29486, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20588, Train Loss:0.19443, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20589, Train Loss:0.13479, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20590, Train Loss:0.00876, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20591, Train Loss:0.19531, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20592, Train Loss:0.00234, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20593, Train Loss:0.10350, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20594, Train Loss:0.21693, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20595, Train Loss:0.26780, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20596, Train Loss:0.01708, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20597, Train Loss:0.04115, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20598, Train Loss:0.19013, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20599, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20600, Train Loss:0.00096, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20601, Train Loss:0.00286, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20602, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20603, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20604, Train Loss:0.00427, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20605, Train Loss:0.09597, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20606, Train Loss:0.29774, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20607, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20608, Train Loss:0.29039, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20609, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20610, Train Loss:0.03907, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20611, Train Loss:0.00001, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20612, Train Loss:0.01856, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20613, Train Loss:0.00007, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20614, Train Loss:0.00008, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20615, Train Loss:0.10015, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20616, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20617, Train Loss:0.00001, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20618, Train Loss:0.00010, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20619, Train Loss:0.00512, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20620, Train Loss:0.00033, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20621, Train Loss:0.38235, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20622, Train Loss:0.00156, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20623, Train Loss:0.04127, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20624, Train Loss:0.00047, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20625, Train Loss:0.00007, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20626, Train Loss:0.04558, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20627, Train Loss:0.00007, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20628, Train Loss:0.05227, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20629, Train Loss:0.00042, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20630, Train Loss:0.00481, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20631, Train Loss:0.41362, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20632, Train Loss:0.00615, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20633, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20634, Train Loss:0.57228, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20635, Train Loss:0.00039, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20636, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20637, Train Loss:0.02315, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20638, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20639, Train Loss:0.00004, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20640, Train Loss:0.00026, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20641, Train Loss:0.06051, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20642, Train Loss:0.03736, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20643, Train Loss:0.12081, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20644, Train Loss:0.13611, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20645, Train Loss:0.00237, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20646, Train Loss:0.06723, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20647, Train Loss:0.00550, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20648, Train Loss:0.11880, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20649, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20650, Train Loss:0.00774, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20651, Train Loss:2.68490, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20652, Train Loss:0.00009, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20653, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20654, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20655, Train Loss:0.65645, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20656, Train Loss:0.00027, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20657, Train Loss:0.03635, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20658, Train Loss:0.09451, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20659, Train Loss:0.00841, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20660, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20661, Train Loss:0.01424, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20662, Train Loss:0.14742, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20663, Train Loss:0.00116, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20664, Train Loss:0.00106, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20665, Train Loss:0.02620, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20666, Train Loss:0.57993, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20667, Train Loss:0.09053, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20668, Train Loss:0.77812, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20669, Train Loss:0.16521, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20670, Train Loss:0.01948, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20671, Train Loss:0.05544, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20672, Train Loss:0.00002, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20673, Train Loss:0.13561, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20674, Train Loss:0.01066, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20675, Train Loss:0.30100, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20676, Train Loss:0.00018, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20677, Train Loss:0.63772, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20678, Train Loss:0.14138, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20679, Train Loss:0.00083, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20680, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20681, Train Loss:0.30533, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20682, Train Loss:0.19783, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20683, Train Loss:0.75633, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20684, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20685, Train Loss:0.11689, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20686, Train Loss:0.09525, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20687, Train Loss:0.71002, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20688, Train Loss:0.17437, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20689, Train Loss:0.06485, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20690, Train Loss:1.38999, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20691, Train Loss:0.05671, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20692, Train Loss:0.07649, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20693, Train Loss:0.00006, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20694, Train Loss:0.07421, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20695, Train Loss:0.25809, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20696, Train Loss:0.03881, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20697, Train Loss:0.02290, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20698, Train Loss:0.02212, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20699, Train Loss:0.05022, Dev Loss:0.12099\n",
      "Epoch:[74/100], step:20700, Train Loss:0.29046, Dev Loss:0.12099\n",
      "Start Epoch: 75, Steps: 17\n",
      "Epoch:[75/100], step:20701, Train Loss:0.25523, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20702, Train Loss:0.07904, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20703, Train Loss:0.07185, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20704, Train Loss:0.01297, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20705, Train Loss:0.49382, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20706, Train Loss:0.00503, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20707, Train Loss:0.27861, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20708, Train Loss:0.05347, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20709, Train Loss:0.16268, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20710, Train Loss:0.00371, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20711, Train Loss:0.28630, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20712, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20713, Train Loss:0.09779, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20714, Train Loss:0.04822, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20715, Train Loss:6.47113, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20716, Train Loss:0.04384, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20717, Train Loss:0.00065, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20718, Train Loss:0.06347, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20719, Train Loss:0.00133, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20720, Train Loss:0.44706, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20721, Train Loss:0.23314, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20722, Train Loss:0.47174, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20723, Train Loss:0.01696, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20724, Train Loss:0.19282, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20725, Train Loss:0.13696, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20726, Train Loss:0.17250, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20727, Train Loss:0.02098, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20728, Train Loss:0.21846, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20729, Train Loss:0.02445, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20730, Train Loss:0.33558, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20731, Train Loss:0.01214, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20732, Train Loss:0.05465, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20733, Train Loss:0.00284, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20734, Train Loss:0.00000, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20735, Train Loss:0.03679, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20736, Train Loss:0.00023, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20737, Train Loss:0.13099, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20738, Train Loss:0.00116, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20739, Train Loss:0.13093, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20740, Train Loss:0.00163, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20741, Train Loss:0.23315, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20742, Train Loss:0.14996, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20743, Train Loss:0.20172, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20744, Train Loss:0.00167, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20745, Train Loss:0.05771, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20746, Train Loss:0.00022, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20747, Train Loss:0.00178, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20748, Train Loss:0.44697, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20749, Train Loss:0.10274, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20750, Train Loss:0.04086, Dev Loss:0.12099\n",
      "Epoch:[75/100], step:20751, Train Loss:0.00691, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20752, Train Loss:0.04841, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20753, Train Loss:0.02562, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20754, Train Loss:0.00002, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20755, Train Loss:0.03396, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20756, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20757, Train Loss:0.00017, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20758, Train Loss:1.06802, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20759, Train Loss:0.12991, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20760, Train Loss:0.52923, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20761, Train Loss:0.00005, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20762, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20763, Train Loss:0.06535, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20764, Train Loss:0.13818, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20765, Train Loss:0.01322, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20766, Train Loss:0.00098, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20767, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20768, Train Loss:0.00209, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20769, Train Loss:0.03109, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20770, Train Loss:0.01723, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20771, Train Loss:0.03801, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20772, Train Loss:0.00055, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20773, Train Loss:0.06612, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20774, Train Loss:0.02396, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20775, Train Loss:0.03398, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20776, Train Loss:0.06256, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20777, Train Loss:0.55884, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20778, Train Loss:0.28565, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20779, Train Loss:0.17480, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20780, Train Loss:0.00062, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20781, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20782, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20783, Train Loss:0.00329, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20784, Train Loss:0.85008, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20785, Train Loss:0.07614, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20786, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20787, Train Loss:0.19566, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20788, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20789, Train Loss:0.37710, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20790, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20791, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20792, Train Loss:0.00032, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20793, Train Loss:0.08775, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20794, Train Loss:0.14877, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20795, Train Loss:0.06518, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20796, Train Loss:0.11608, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20797, Train Loss:0.00008, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20798, Train Loss:0.26126, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20799, Train Loss:0.18282, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20800, Train Loss:0.02972, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20801, Train Loss:0.01637, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20802, Train Loss:1.10375, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20803, Train Loss:0.00574, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20804, Train Loss:0.06757, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20805, Train Loss:0.00172, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20806, Train Loss:0.00028, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20807, Train Loss:0.00735, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20808, Train Loss:0.12960, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20809, Train Loss:0.00208, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20810, Train Loss:0.47209, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20811, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20812, Train Loss:0.25197, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20813, Train Loss:0.00441, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20814, Train Loss:0.02142, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20815, Train Loss:0.26526, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20816, Train Loss:0.00368, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20817, Train Loss:0.14806, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20818, Train Loss:0.03567, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20819, Train Loss:0.00300, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20820, Train Loss:0.37407, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20821, Train Loss:0.06997, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20822, Train Loss:0.11309, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20823, Train Loss:0.08934, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20824, Train Loss:0.66568, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20825, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20826, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20827, Train Loss:0.01457, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20828, Train Loss:1.13780, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20829, Train Loss:0.24863, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20830, Train Loss:0.00361, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20831, Train Loss:0.09636, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20832, Train Loss:0.14805, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20833, Train Loss:0.07240, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20834, Train Loss:0.34138, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20835, Train Loss:0.12205, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20836, Train Loss:0.00045, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20837, Train Loss:0.31736, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20838, Train Loss:0.16796, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20839, Train Loss:0.08005, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20840, Train Loss:0.05217, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20841, Train Loss:0.05644, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20842, Train Loss:0.00028, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20843, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20844, Train Loss:0.09725, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20845, Train Loss:0.04925, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20846, Train Loss:0.15566, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20847, Train Loss:0.21659, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20848, Train Loss:0.00292, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20849, Train Loss:0.25626, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20850, Train Loss:0.12389, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20851, Train Loss:0.01912, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20852, Train Loss:0.00003, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20853, Train Loss:0.09296, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20854, Train Loss:0.52756, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20855, Train Loss:0.92848, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20856, Train Loss:0.02497, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20857, Train Loss:0.06569, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20858, Train Loss:0.00076, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20859, Train Loss:0.01030, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20860, Train Loss:0.01226, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20861, Train Loss:0.11023, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20862, Train Loss:0.02944, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20863, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20864, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20865, Train Loss:0.00005, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20866, Train Loss:0.66014, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20867, Train Loss:0.04109, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20868, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20869, Train Loss:0.00109, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20870, Train Loss:0.24308, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20871, Train Loss:0.10852, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20872, Train Loss:0.00551, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20873, Train Loss:0.32441, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20874, Train Loss:0.00646, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20875, Train Loss:0.01895, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20876, Train Loss:0.13322, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20877, Train Loss:0.06416, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20878, Train Loss:0.00023, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20879, Train Loss:0.07553, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20880, Train Loss:0.00024, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20881, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20882, Train Loss:0.00006, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20883, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20884, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20885, Train Loss:0.56564, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20886, Train Loss:0.01554, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20887, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20888, Train Loss:0.12083, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20889, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20890, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20891, Train Loss:0.01770, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20892, Train Loss:0.00002, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20893, Train Loss:0.00375, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20894, Train Loss:0.01099, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20895, Train Loss:0.01541, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20896, Train Loss:0.00006, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20897, Train Loss:0.02887, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20898, Train Loss:0.13513, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20899, Train Loss:0.00002, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20900, Train Loss:0.17544, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20901, Train Loss:0.71709, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20902, Train Loss:0.03400, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20903, Train Loss:0.00303, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20904, Train Loss:0.11223, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20905, Train Loss:0.00006, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20906, Train Loss:0.08219, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20907, Train Loss:0.11466, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20908, Train Loss:0.28398, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20909, Train Loss:0.00048, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20910, Train Loss:0.00703, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20911, Train Loss:0.00093, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20912, Train Loss:0.05077, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20913, Train Loss:0.00055, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20914, Train Loss:0.64120, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20915, Train Loss:0.00038, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20916, Train Loss:0.25007, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20917, Train Loss:0.00012, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20918, Train Loss:0.01207, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20919, Train Loss:0.00027, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20920, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20921, Train Loss:0.25937, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20922, Train Loss:0.02663, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20923, Train Loss:0.00335, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20924, Train Loss:0.07130, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20925, Train Loss:0.00017, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20926, Train Loss:0.00002, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20927, Train Loss:0.44912, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20928, Train Loss:0.02529, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20929, Train Loss:0.40181, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20930, Train Loss:0.02643, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20931, Train Loss:0.04887, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20932, Train Loss:0.00047, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20933, Train Loss:0.08246, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20934, Train Loss:0.01827, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20935, Train Loss:0.00841, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20936, Train Loss:0.06326, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20937, Train Loss:0.12167, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20938, Train Loss:0.23643, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20939, Train Loss:0.17291, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20940, Train Loss:0.97827, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20941, Train Loss:0.18176, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20942, Train Loss:1.10374, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20943, Train Loss:0.08569, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20944, Train Loss:0.06123, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20945, Train Loss:0.07411, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20946, Train Loss:0.07035, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20947, Train Loss:0.00019, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20948, Train Loss:1.17699, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20949, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20950, Train Loss:0.00037, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20951, Train Loss:0.00020, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20952, Train Loss:0.02584, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20953, Train Loss:0.01519, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20954, Train Loss:0.05193, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20955, Train Loss:0.01758, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20956, Train Loss:0.04349, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20957, Train Loss:0.02453, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20958, Train Loss:0.09688, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20959, Train Loss:0.05386, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20960, Train Loss:0.24807, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20961, Train Loss:0.10212, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20962, Train Loss:0.04719, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20963, Train Loss:0.00002, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20964, Train Loss:0.00004, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20965, Train Loss:0.08736, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20966, Train Loss:0.00984, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20967, Train Loss:0.00665, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20968, Train Loss:0.00083, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20969, Train Loss:0.00010, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20970, Train Loss:0.00004, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20971, Train Loss:0.00115, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20972, Train Loss:0.00122, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20973, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20974, Train Loss:0.07583, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20975, Train Loss:0.01665, Dev Loss:0.17855\n",
      "Epoch:[75/100], step:20976, Train Loss:0.15732, Dev Loss:0.17855\n",
      "Start Epoch: 76, Steps: 17\n",
      "Epoch:[76/100], step:20977, Train Loss:0.24981, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20978, Train Loss:0.01280, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20979, Train Loss:0.81829, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20980, Train Loss:0.00020, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20981, Train Loss:0.00271, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20982, Train Loss:0.22246, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20983, Train Loss:0.08170, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20984, Train Loss:0.00000, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20985, Train Loss:0.32299, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20986, Train Loss:0.00001, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20987, Train Loss:0.17443, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20988, Train Loss:0.02857, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20989, Train Loss:0.00887, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20990, Train Loss:0.31117, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20991, Train Loss:0.14855, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20992, Train Loss:0.24836, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20993, Train Loss:0.00010, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20994, Train Loss:0.07128, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20995, Train Loss:0.00014, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20996, Train Loss:0.33833, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20997, Train Loss:0.09436, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20998, Train Loss:0.06500, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:20999, Train Loss:0.47663, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:21000, Train Loss:0.03869, Dev Loss:0.17855\n",
      "Epoch:[76/100], step:21001, Train Loss:0.05358, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21002, Train Loss:0.07630, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21003, Train Loss:0.03770, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21004, Train Loss:0.01205, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21005, Train Loss:0.10984, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21006, Train Loss:0.11542, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21007, Train Loss:0.14725, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21008, Train Loss:0.00041, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21009, Train Loss:0.00001, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21010, Train Loss:0.09380, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21011, Train Loss:0.02166, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21012, Train Loss:0.00192, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21013, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21014, Train Loss:0.00663, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21015, Train Loss:0.32966, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21016, Train Loss:0.08704, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21017, Train Loss:0.34797, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21018, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21019, Train Loss:0.07782, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21020, Train Loss:0.07426, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21021, Train Loss:0.01090, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21022, Train Loss:0.00471, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21023, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21024, Train Loss:0.00767, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21025, Train Loss:0.23274, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21026, Train Loss:0.00103, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21027, Train Loss:0.10456, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21028, Train Loss:0.20577, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21029, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21030, Train Loss:0.07044, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21031, Train Loss:0.32886, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21032, Train Loss:0.16912, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21033, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21034, Train Loss:0.01519, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21035, Train Loss:0.00030, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21036, Train Loss:0.06235, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21037, Train Loss:0.00484, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21038, Train Loss:0.00111, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21039, Train Loss:0.08226, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21040, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21041, Train Loss:0.00150, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21042, Train Loss:0.03866, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21043, Train Loss:0.32840, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21044, Train Loss:0.02730, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21045, Train Loss:0.03852, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21046, Train Loss:0.01435, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21047, Train Loss:0.00361, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21048, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21049, Train Loss:0.30962, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21050, Train Loss:0.04446, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21051, Train Loss:0.00005, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21052, Train Loss:0.39264, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21053, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21054, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21055, Train Loss:0.02955, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21056, Train Loss:0.42762, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21057, Train Loss:0.00008, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21058, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21059, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21060, Train Loss:0.00154, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21061, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21062, Train Loss:0.03362, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21063, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21064, Train Loss:0.00847, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21065, Train Loss:0.00004, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21066, Train Loss:0.37499, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21067, Train Loss:0.09379, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21068, Train Loss:0.00028, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21069, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21070, Train Loss:1.48478, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21071, Train Loss:0.04124, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21072, Train Loss:0.10702, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21073, Train Loss:0.11482, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21074, Train Loss:0.06017, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21075, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21076, Train Loss:0.37232, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21077, Train Loss:0.00014, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21078, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21079, Train Loss:0.25156, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21080, Train Loss:0.04271, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21081, Train Loss:0.00207, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21082, Train Loss:0.13220, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21083, Train Loss:0.21459, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21084, Train Loss:0.07070, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21085, Train Loss:0.10772, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21086, Train Loss:0.12299, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21087, Train Loss:0.36515, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21088, Train Loss:0.00859, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21089, Train Loss:0.00968, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21090, Train Loss:0.20281, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21091, Train Loss:0.32059, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21092, Train Loss:0.11251, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21093, Train Loss:0.00097, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21094, Train Loss:0.27076, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21095, Train Loss:0.15800, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21096, Train Loss:0.17019, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21097, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21098, Train Loss:0.04691, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21099, Train Loss:0.01147, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21100, Train Loss:0.93103, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21101, Train Loss:0.56213, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21102, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21103, Train Loss:0.29599, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21104, Train Loss:0.00114, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21105, Train Loss:0.02053, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21106, Train Loss:0.04612, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21107, Train Loss:0.00004, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21108, Train Loss:0.04911, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21109, Train Loss:0.12553, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21110, Train Loss:0.09200, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21111, Train Loss:0.29038, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21112, Train Loss:0.03078, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21113, Train Loss:0.00806, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21114, Train Loss:0.48307, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21115, Train Loss:0.01174, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21116, Train Loss:0.11091, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21117, Train Loss:0.00695, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21118, Train Loss:0.10431, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21119, Train Loss:0.00459, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21120, Train Loss:0.03043, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21121, Train Loss:0.01501, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21122, Train Loss:0.00075, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21123, Train Loss:0.17026, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21124, Train Loss:0.00024, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21125, Train Loss:0.04099, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21126, Train Loss:0.12273, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21127, Train Loss:0.00205, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21128, Train Loss:0.00001, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21129, Train Loss:0.00007, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21130, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21131, Train Loss:0.00027, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21132, Train Loss:0.06004, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21133, Train Loss:0.00142, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21134, Train Loss:0.00003, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21135, Train Loss:0.05536, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21136, Train Loss:0.24076, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21137, Train Loss:0.07947, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21138, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21139, Train Loss:0.04659, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21140, Train Loss:0.00239, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21141, Train Loss:0.02558, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21142, Train Loss:0.00001, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21143, Train Loss:0.00260, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21144, Train Loss:0.05138, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21145, Train Loss:0.22383, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21146, Train Loss:0.10709, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21147, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21148, Train Loss:0.03764, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21149, Train Loss:0.18403, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21150, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21151, Train Loss:0.00169, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21152, Train Loss:0.10179, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21153, Train Loss:0.05698, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21154, Train Loss:0.07075, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21155, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21156, Train Loss:1.05981, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21157, Train Loss:0.00001, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21158, Train Loss:0.12930, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21159, Train Loss:0.08215, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21160, Train Loss:0.15856, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21161, Train Loss:0.01522, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21162, Train Loss:0.00016, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21163, Train Loss:0.00005, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21164, Train Loss:0.38846, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21165, Train Loss:0.13284, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21166, Train Loss:0.12059, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21167, Train Loss:0.00499, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21168, Train Loss:0.00011, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21169, Train Loss:0.00165, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21170, Train Loss:0.00741, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21171, Train Loss:0.59094, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21172, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21173, Train Loss:0.04409, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21174, Train Loss:0.00140, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21175, Train Loss:0.16323, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21176, Train Loss:0.11325, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21177, Train Loss:0.07732, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21178, Train Loss:0.03912, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21179, Train Loss:0.05043, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21180, Train Loss:0.11655, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21181, Train Loss:0.05705, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21182, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21183, Train Loss:0.30634, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21184, Train Loss:0.00003, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21185, Train Loss:0.00560, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21186, Train Loss:0.09247, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21187, Train Loss:0.50622, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21188, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21189, Train Loss:0.10540, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21190, Train Loss:0.00006, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21191, Train Loss:0.00101, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21192, Train Loss:0.08074, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21193, Train Loss:0.16488, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21194, Train Loss:0.10947, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21195, Train Loss:0.01541, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21196, Train Loss:0.28940, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21197, Train Loss:0.17999, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21198, Train Loss:0.10965, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21199, Train Loss:0.03435, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21200, Train Loss:0.02959, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21201, Train Loss:0.00002, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21202, Train Loss:0.09880, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21203, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21204, Train Loss:0.00005, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21205, Train Loss:0.01510, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21206, Train Loss:0.02112, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21207, Train Loss:0.06161, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21208, Train Loss:0.00887, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21209, Train Loss:0.00010, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21210, Train Loss:0.00005, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21211, Train Loss:0.00056, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21212, Train Loss:0.00033, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21213, Train Loss:0.07232, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21214, Train Loss:0.05703, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21215, Train Loss:0.00009, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21216, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21217, Train Loss:0.00006, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21218, Train Loss:0.00007, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21219, Train Loss:0.00008, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21220, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21221, Train Loss:0.00001, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21222, Train Loss:2.36979, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21223, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21224, Train Loss:0.32664, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21225, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21226, Train Loss:0.02704, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21227, Train Loss:0.59198, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21228, Train Loss:0.03520, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21229, Train Loss:0.05525, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21230, Train Loss:0.00389, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21231, Train Loss:0.00003, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21232, Train Loss:0.06666, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21233, Train Loss:1.20439, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21234, Train Loss:0.22424, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21235, Train Loss:0.02593, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21236, Train Loss:0.00024, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21237, Train Loss:0.05015, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21238, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21239, Train Loss:0.02382, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21240, Train Loss:0.00101, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21241, Train Loss:0.04176, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21242, Train Loss:0.14309, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21243, Train Loss:0.00003, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21244, Train Loss:0.00510, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21245, Train Loss:0.00046, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21246, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21247, Train Loss:0.00278, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21248, Train Loss:0.00000, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21249, Train Loss:0.00011, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21250, Train Loss:0.00045, Dev Loss:0.12552\n",
      "Epoch:[76/100], step:21251, Train Loss:0.00368, Dev Loss:0.11881\n",
      "Epoch:[76/100], step:21252, Train Loss:0.03965, Dev Loss:0.11881\n",
      "Start Epoch: 77, Steps: 17\n",
      "Epoch:[77/100], step:21253, Train Loss:0.07735, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21254, Train Loss:0.00041, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21255, Train Loss:0.08531, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21256, Train Loss:0.01089, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21257, Train Loss:0.73856, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21258, Train Loss:0.03148, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21259, Train Loss:0.01743, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21260, Train Loss:0.00004, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21261, Train Loss:0.00015, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21262, Train Loss:0.15718, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21263, Train Loss:0.29493, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21264, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21265, Train Loss:0.13909, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21266, Train Loss:0.00012, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21267, Train Loss:0.06684, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21268, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21269, Train Loss:0.02279, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21270, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21271, Train Loss:0.66567, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21272, Train Loss:0.10989, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21273, Train Loss:0.04290, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21274, Train Loss:0.12392, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21275, Train Loss:0.00010, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21276, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21277, Train Loss:0.00002, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21278, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21279, Train Loss:0.00013, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21280, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21281, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21282, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21283, Train Loss:0.19484, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21284, Train Loss:0.16212, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21285, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21286, Train Loss:0.00867, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21287, Train Loss:0.19084, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21288, Train Loss:0.12065, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21289, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21290, Train Loss:0.00052, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21291, Train Loss:0.00002, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21292, Train Loss:0.05285, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21293, Train Loss:0.10120, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21294, Train Loss:0.24454, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21295, Train Loss:0.14946, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21296, Train Loss:0.01129, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21297, Train Loss:0.00112, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21298, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21299, Train Loss:0.09807, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21300, Train Loss:0.18985, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21301, Train Loss:0.06231, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21302, Train Loss:0.00055, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21303, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21304, Train Loss:0.00005, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21305, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21306, Train Loss:0.00083, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21307, Train Loss:0.42501, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21308, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21309, Train Loss:0.00210, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21310, Train Loss:0.00037, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21311, Train Loss:0.06897, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21312, Train Loss:0.01277, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21313, Train Loss:0.00066, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21314, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21315, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21316, Train Loss:0.00019, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21317, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21318, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21319, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21320, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21321, Train Loss:0.02312, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21322, Train Loss:0.01380, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21323, Train Loss:0.00573, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21324, Train Loss:0.03232, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21325, Train Loss:0.00014, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21326, Train Loss:0.08958, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21327, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21328, Train Loss:0.00007, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21329, Train Loss:0.00003, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21330, Train Loss:0.02275, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21331, Train Loss:0.00010, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21332, Train Loss:0.02625, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21333, Train Loss:0.37766, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21334, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21335, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21336, Train Loss:0.03361, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21337, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21338, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21339, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21340, Train Loss:0.15262, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21341, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21342, Train Loss:0.10998, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21343, Train Loss:0.01721, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21344, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21345, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21346, Train Loss:0.00064, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21347, Train Loss:0.01546, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21348, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21349, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21350, Train Loss:0.04478, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21351, Train Loss:0.00129, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21352, Train Loss:0.00002, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21353, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21354, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21355, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21356, Train Loss:0.10062, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21357, Train Loss:0.00016, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21358, Train Loss:0.16092, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21359, Train Loss:0.02338, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21360, Train Loss:0.00031, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21361, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21362, Train Loss:0.00006, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21363, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21364, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21365, Train Loss:0.53218, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21366, Train Loss:0.00004, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21367, Train Loss:0.26108, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21368, Train Loss:0.00136, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21369, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21370, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21371, Train Loss:0.03387, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21372, Train Loss:0.15686, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21373, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21374, Train Loss:0.00002, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21375, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21376, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21377, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21378, Train Loss:0.04235, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21379, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21380, Train Loss:0.00625, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21381, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21382, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21383, Train Loss:0.00003, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21384, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21385, Train Loss:0.01413, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21386, Train Loss:0.23761, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21387, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21388, Train Loss:0.22434, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21389, Train Loss:0.19408, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21390, Train Loss:0.03923, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21391, Train Loss:0.00070, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21392, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21393, Train Loss:0.19849, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21394, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21395, Train Loss:0.02309, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21396, Train Loss:0.00027, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21397, Train Loss:0.00003, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21398, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21399, Train Loss:0.16110, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21400, Train Loss:0.30492, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21401, Train Loss:0.93738, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21402, Train Loss:0.00042, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21403, Train Loss:0.00002, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21404, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21405, Train Loss:0.08098, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21406, Train Loss:0.04247, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21407, Train Loss:0.37959, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21408, Train Loss:0.23163, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21409, Train Loss:0.78679, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21410, Train Loss:0.13463, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21411, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21412, Train Loss:0.79272, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21413, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21414, Train Loss:0.00116, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21415, Train Loss:0.01962, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21416, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21417, Train Loss:0.00009, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21418, Train Loss:0.00106, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21419, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21420, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21421, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21422, Train Loss:0.95617, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21423, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21424, Train Loss:0.30731, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21425, Train Loss:0.00003, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21426, Train Loss:0.79199, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21427, Train Loss:0.01339, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21428, Train Loss:0.00149, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21429, Train Loss:1.05122, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21430, Train Loss:0.68834, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21431, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21432, Train Loss:0.08583, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21433, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21434, Train Loss:0.47027, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21435, Train Loss:0.01209, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21436, Train Loss:0.01376, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21437, Train Loss:0.00049, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21438, Train Loss:0.29528, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21439, Train Loss:0.08820, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21440, Train Loss:0.85646, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21441, Train Loss:0.00022, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21442, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21443, Train Loss:0.00015, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21444, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21445, Train Loss:0.03166, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21446, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21447, Train Loss:1.35156, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21448, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21449, Train Loss:0.03174, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21450, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21451, Train Loss:0.07354, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21452, Train Loss:0.02455, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21453, Train Loss:0.03582, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21454, Train Loss:0.08396, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21455, Train Loss:0.16589, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21456, Train Loss:0.15077, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21457, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21458, Train Loss:0.05764, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21459, Train Loss:0.19857, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21460, Train Loss:0.02337, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21461, Train Loss:0.01534, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21462, Train Loss:0.00148, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21463, Train Loss:0.19790, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21464, Train Loss:0.11446, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21465, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21466, Train Loss:0.00016, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21467, Train Loss:0.04219, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21468, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21469, Train Loss:0.08940, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21470, Train Loss:0.10369, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21471, Train Loss:0.23531, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21472, Train Loss:0.01330, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21473, Train Loss:0.15324, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21474, Train Loss:0.31527, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21475, Train Loss:0.00190, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21476, Train Loss:0.00039, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21477, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21478, Train Loss:0.22675, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21479, Train Loss:0.00137, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21480, Train Loss:0.00001, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21481, Train Loss:0.13504, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21482, Train Loss:0.00123, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21483, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21484, Train Loss:0.00018, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21485, Train Loss:0.00589, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21486, Train Loss:0.44344, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21487, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21488, Train Loss:0.57235, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21489, Train Loss:0.00016, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21490, Train Loss:0.00011, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21491, Train Loss:0.06500, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21492, Train Loss:0.00065, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21493, Train Loss:0.01922, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21494, Train Loss:0.78544, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21495, Train Loss:0.00096, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21496, Train Loss:0.00195, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21497, Train Loss:0.50014, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21498, Train Loss:0.00000, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21499, Train Loss:0.00003, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21500, Train Loss:0.00006, Dev Loss:0.11881\n",
      "Epoch:[77/100], step:21501, Train Loss:0.11141, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21502, Train Loss:0.36061, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21503, Train Loss:0.00035, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21504, Train Loss:0.09521, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21505, Train Loss:0.09946, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21506, Train Loss:0.00025, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21507, Train Loss:0.00169, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21508, Train Loss:0.03773, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21509, Train Loss:0.09354, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21510, Train Loss:0.00003, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21511, Train Loss:0.11251, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21512, Train Loss:0.38762, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21513, Train Loss:0.00413, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21514, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21515, Train Loss:0.09972, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21516, Train Loss:0.10103, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21517, Train Loss:0.05739, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21518, Train Loss:0.17983, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21519, Train Loss:0.02575, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21520, Train Loss:0.07101, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21521, Train Loss:0.01716, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21522, Train Loss:0.00524, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21523, Train Loss:1.15116, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21524, Train Loss:0.07824, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21525, Train Loss:0.00111, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21526, Train Loss:0.04218, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21527, Train Loss:0.02428, Dev Loss:0.12111\n",
      "Epoch:[77/100], step:21528, Train Loss:0.01042, Dev Loss:0.12111\n",
      "Start Epoch: 78, Steps: 17\n",
      "Epoch:[78/100], step:21529, Train Loss:0.00074, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21530, Train Loss:0.12357, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21531, Train Loss:0.00071, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21532, Train Loss:0.37139, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21533, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21534, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21535, Train Loss:0.00173, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21536, Train Loss:0.12667, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21537, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21538, Train Loss:0.24247, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21539, Train Loss:0.02636, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21540, Train Loss:0.00020, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21541, Train Loss:0.10278, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21542, Train Loss:0.24264, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21543, Train Loss:0.00047, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21544, Train Loss:0.19946, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21545, Train Loss:0.09489, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21546, Train Loss:0.00007, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21547, Train Loss:0.00318, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21548, Train Loss:0.00362, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21549, Train Loss:0.37182, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21550, Train Loss:0.08411, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21551, Train Loss:0.00019, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21552, Train Loss:0.01430, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21553, Train Loss:0.15588, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21554, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21555, Train Loss:0.85889, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21556, Train Loss:0.00023, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21557, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21558, Train Loss:0.02822, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21559, Train Loss:0.00273, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21560, Train Loss:0.09324, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21561, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21562, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21563, Train Loss:0.08864, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21564, Train Loss:0.00015, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21565, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21566, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21567, Train Loss:0.05999, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21568, Train Loss:0.00007, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21569, Train Loss:0.05117, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21570, Train Loss:0.00028, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21571, Train Loss:0.00089, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21572, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21573, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21574, Train Loss:0.00025, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21575, Train Loss:0.05349, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21576, Train Loss:0.00027, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21577, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21578, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21579, Train Loss:0.03482, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21580, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21581, Train Loss:0.01528, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21582, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21583, Train Loss:0.57712, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21584, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21585, Train Loss:0.00003, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21586, Train Loss:0.00383, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21587, Train Loss:0.00652, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21588, Train Loss:0.00085, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21589, Train Loss:0.01464, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21590, Train Loss:0.02489, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21591, Train Loss:0.00046, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21592, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21593, Train Loss:0.22718, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21594, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21595, Train Loss:0.00139, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21596, Train Loss:0.00554, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21597, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21598, Train Loss:0.23552, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21599, Train Loss:0.14363, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21600, Train Loss:0.11936, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21601, Train Loss:0.00016, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21602, Train Loss:0.03714, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21603, Train Loss:0.00008, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21604, Train Loss:0.00476, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21605, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21606, Train Loss:0.00043, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21607, Train Loss:0.00669, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21608, Train Loss:0.03432, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21609, Train Loss:0.06688, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21610, Train Loss:0.06783, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21611, Train Loss:0.01068, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21612, Train Loss:0.02945, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21613, Train Loss:0.00023, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21614, Train Loss:0.07298, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21615, Train Loss:0.05937, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21616, Train Loss:0.02903, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21617, Train Loss:0.00008, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21618, Train Loss:0.08678, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21619, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21620, Train Loss:0.02672, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21621, Train Loss:0.04143, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21622, Train Loss:0.01561, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21623, Train Loss:0.25634, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21624, Train Loss:0.00075, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21625, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21626, Train Loss:0.14291, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21627, Train Loss:0.20804, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21628, Train Loss:0.26253, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21629, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21630, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21631, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21632, Train Loss:0.33587, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21633, Train Loss:0.09623, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21634, Train Loss:0.14506, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21635, Train Loss:0.00177, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21636, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21637, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21638, Train Loss:0.00004, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21639, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21640, Train Loss:0.00356, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21641, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21642, Train Loss:0.01157, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21643, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21644, Train Loss:0.02250, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21645, Train Loss:0.01925, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21646, Train Loss:0.00297, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21647, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21648, Train Loss:0.00190, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21649, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21650, Train Loss:0.13663, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21651, Train Loss:0.08558, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21652, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21653, Train Loss:0.05624, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21654, Train Loss:0.00066, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21655, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21656, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21657, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21658, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21659, Train Loss:0.49540, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21660, Train Loss:0.00005, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21661, Train Loss:0.06564, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21662, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21663, Train Loss:0.00004, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21664, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21665, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21666, Train Loss:0.07207, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21667, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21668, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21669, Train Loss:0.00006, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21670, Train Loss:0.00012, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21671, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21672, Train Loss:0.05156, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21673, Train Loss:0.00003, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21674, Train Loss:0.00002, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21675, Train Loss:0.61726, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21676, Train Loss:0.05799, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21677, Train Loss:0.67248, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21678, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21679, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21680, Train Loss:0.24807, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21681, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21682, Train Loss:0.00615, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21683, Train Loss:0.00013, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21684, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21685, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21686, Train Loss:0.02480, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21687, Train Loss:0.00065, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21688, Train Loss:0.20520, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21689, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21690, Train Loss:0.00010, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21691, Train Loss:0.16022, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21692, Train Loss:0.01442, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21693, Train Loss:0.00239, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21694, Train Loss:0.00021, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21695, Train Loss:0.01420, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21696, Train Loss:0.00066, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21697, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21698, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21699, Train Loss:0.07131, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21700, Train Loss:0.01170, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21701, Train Loss:0.14636, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21702, Train Loss:0.00007, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21703, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21704, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21705, Train Loss:0.15902, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21706, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21707, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21708, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21709, Train Loss:0.01685, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21710, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21711, Train Loss:0.07746, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21712, Train Loss:0.02757, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21713, Train Loss:0.00032, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21714, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21715, Train Loss:0.15025, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21716, Train Loss:0.00039, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21717, Train Loss:0.00017, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21718, Train Loss:0.01986, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21719, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21720, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21721, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21722, Train Loss:0.27306, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21723, Train Loss:0.00218, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21724, Train Loss:0.09387, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21725, Train Loss:0.50771, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21726, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21727, Train Loss:0.00005, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21728, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21729, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21730, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21731, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21732, Train Loss:0.00001, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21733, Train Loss:0.06309, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21734, Train Loss:0.17995, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21735, Train Loss:0.72562, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21736, Train Loss:0.34200, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21737, Train Loss:1.20686, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21738, Train Loss:0.00000, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21739, Train Loss:0.06346, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21740, Train Loss:0.00005, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21741, Train Loss:0.00396, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21742, Train Loss:0.00118, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21743, Train Loss:0.00229, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21744, Train Loss:0.11010, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21745, Train Loss:0.00192, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21746, Train Loss:0.00010, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21747, Train Loss:0.41426, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21748, Train Loss:0.08025, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21749, Train Loss:0.24373, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21750, Train Loss:0.00117, Dev Loss:0.12111\n",
      "Epoch:[78/100], step:21751, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21752, Train Loss:0.01813, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21753, Train Loss:0.32825, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21754, Train Loss:0.38448, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21755, Train Loss:0.01737, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21756, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21757, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21758, Train Loss:0.00005, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21759, Train Loss:0.00018, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21760, Train Loss:0.00011, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21761, Train Loss:0.25889, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21762, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21763, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21764, Train Loss:0.00785, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21765, Train Loss:0.00008, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21766, Train Loss:0.00138, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21767, Train Loss:0.02090, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21768, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21769, Train Loss:0.00131, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21770, Train Loss:0.24229, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21771, Train Loss:0.03532, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21772, Train Loss:0.01878, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21773, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21774, Train Loss:0.00011, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21775, Train Loss:0.00003, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21776, Train Loss:0.77213, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21777, Train Loss:0.11700, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21778, Train Loss:0.01739, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21779, Train Loss:0.47392, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21780, Train Loss:0.06386, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21781, Train Loss:0.27402, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21782, Train Loss:0.22619, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21783, Train Loss:0.00022, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21784, Train Loss:0.10406, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21785, Train Loss:0.25279, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21786, Train Loss:0.00026, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21787, Train Loss:0.03026, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21788, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21789, Train Loss:0.00020, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21790, Train Loss:0.02180, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21791, Train Loss:0.00005, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21792, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21793, Train Loss:0.01180, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21794, Train Loss:0.11155, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21795, Train Loss:0.12587, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21796, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21797, Train Loss:0.00101, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21798, Train Loss:0.01305, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21799, Train Loss:0.00009, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21800, Train Loss:0.23824, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21801, Train Loss:0.03862, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21802, Train Loss:0.02315, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21803, Train Loss:0.00574, Dev Loss:0.11038\n",
      "Epoch:[78/100], step:21804, Train Loss:0.07867, Dev Loss:0.11038\n",
      "Start Epoch: 79, Steps: 17\n",
      "Epoch:[79/100], step:21805, Train Loss:0.04232, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21806, Train Loss:0.00010, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21807, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21808, Train Loss:0.10182, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21809, Train Loss:0.18039, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21810, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21811, Train Loss:0.07807, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21812, Train Loss:0.00040, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21813, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21814, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21815, Train Loss:0.00558, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21816, Train Loss:0.00449, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21817, Train Loss:0.00002, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21818, Train Loss:0.00105, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21819, Train Loss:1.81723, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21820, Train Loss:0.01919, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21821, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21822, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21823, Train Loss:0.00045, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21824, Train Loss:0.17175, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21825, Train Loss:0.26801, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21826, Train Loss:0.00061, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21827, Train Loss:0.01928, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21828, Train Loss:0.01163, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21829, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21830, Train Loss:0.05793, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21831, Train Loss:0.09985, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21832, Train Loss:0.10308, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21833, Train Loss:0.07491, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21834, Train Loss:0.01108, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21835, Train Loss:0.69148, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21836, Train Loss:1.12196, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21837, Train Loss:0.00172, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21838, Train Loss:0.00002, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21839, Train Loss:0.39083, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21840, Train Loss:0.21304, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21841, Train Loss:0.00002, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21842, Train Loss:0.00003, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21843, Train Loss:0.00005, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21844, Train Loss:0.42405, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21845, Train Loss:0.33935, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21846, Train Loss:0.02037, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21847, Train Loss:0.03829, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21848, Train Loss:0.02433, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21849, Train Loss:0.25491, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21850, Train Loss:0.15628, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21851, Train Loss:0.11554, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21852, Train Loss:0.00003, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21853, Train Loss:0.35083, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21854, Train Loss:0.12937, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21855, Train Loss:0.03820, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21856, Train Loss:0.01304, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21857, Train Loss:0.02478, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21858, Train Loss:0.00060, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21859, Train Loss:0.13345, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21860, Train Loss:0.16892, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21861, Train Loss:0.03322, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21862, Train Loss:0.17515, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21863, Train Loss:0.00793, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21864, Train Loss:0.08563, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21865, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21866, Train Loss:0.00054, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21867, Train Loss:0.00068, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21868, Train Loss:0.23080, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21869, Train Loss:0.02568, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21870, Train Loss:0.00003, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21871, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21872, Train Loss:0.07836, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21873, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21874, Train Loss:0.18353, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21875, Train Loss:0.00006, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21876, Train Loss:0.00061, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21877, Train Loss:0.12146, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21878, Train Loss:0.00215, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21879, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21880, Train Loss:0.00727, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21881, Train Loss:0.03274, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21882, Train Loss:0.09945, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21883, Train Loss:0.26542, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21884, Train Loss:0.00017, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21885, Train Loss:0.09559, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21886, Train Loss:0.08902, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21887, Train Loss:0.01044, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21888, Train Loss:0.00106, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21889, Train Loss:0.00972, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21890, Train Loss:0.35529, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21891, Train Loss:0.00041, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21892, Train Loss:0.78489, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21893, Train Loss:0.00033, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21894, Train Loss:0.00047, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21895, Train Loss:0.00386, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21896, Train Loss:0.01902, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21897, Train Loss:0.03002, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21898, Train Loss:0.02490, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21899, Train Loss:0.01554, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21900, Train Loss:0.00019, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21901, Train Loss:0.24423, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21902, Train Loss:0.13748, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21903, Train Loss:0.11132, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21904, Train Loss:0.23613, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21905, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21906, Train Loss:0.05259, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21907, Train Loss:0.10420, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21908, Train Loss:0.00007, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21909, Train Loss:0.00011, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21910, Train Loss:0.03858, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21911, Train Loss:0.29821, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21912, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21913, Train Loss:0.06158, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21914, Train Loss:0.00024, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21915, Train Loss:0.00046, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21916, Train Loss:0.06743, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21917, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21918, Train Loss:0.00040, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21919, Train Loss:0.00004, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21920, Train Loss:0.17443, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21921, Train Loss:0.05210, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21922, Train Loss:0.10270, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21923, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21924, Train Loss:0.00055, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21925, Train Loss:0.00035, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21926, Train Loss:0.00005, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21927, Train Loss:0.04702, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21928, Train Loss:0.02695, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21929, Train Loss:0.21092, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21930, Train Loss:0.09792, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21931, Train Loss:0.19958, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21932, Train Loss:0.00352, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21933, Train Loss:0.19798, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21934, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21935, Train Loss:0.02869, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21936, Train Loss:0.02656, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21937, Train Loss:0.00129, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21938, Train Loss:0.00253, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21939, Train Loss:0.42419, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21940, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21941, Train Loss:0.18068, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21942, Train Loss:0.06227, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21943, Train Loss:0.15685, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21944, Train Loss:0.00101, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21945, Train Loss:0.00727, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21946, Train Loss:0.00033, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21947, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21948, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21949, Train Loss:0.03884, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21950, Train Loss:0.20321, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21951, Train Loss:0.19226, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21952, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21953, Train Loss:0.00111, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21954, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21955, Train Loss:0.01704, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21956, Train Loss:0.02675, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21957, Train Loss:0.00024, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21958, Train Loss:0.13382, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21959, Train Loss:0.00006, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21960, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21961, Train Loss:0.05070, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21962, Train Loss:0.15014, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21963, Train Loss:0.38161, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21964, Train Loss:0.08088, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21965, Train Loss:0.00050, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21966, Train Loss:0.09469, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21967, Train Loss:0.26322, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21968, Train Loss:1.04885, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21969, Train Loss:0.17556, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21970, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21971, Train Loss:0.00006, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21972, Train Loss:0.00015, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21973, Train Loss:0.04640, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21974, Train Loss:0.11213, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21975, Train Loss:0.10955, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21976, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21977, Train Loss:0.02492, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21978, Train Loss:0.15783, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21979, Train Loss:0.01462, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21980, Train Loss:0.00627, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21981, Train Loss:0.00025, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21982, Train Loss:0.00034, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21983, Train Loss:0.00022, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21984, Train Loss:0.08577, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21985, Train Loss:0.00505, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21986, Train Loss:0.06975, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21987, Train Loss:0.28026, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21988, Train Loss:0.07371, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21989, Train Loss:0.19004, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21990, Train Loss:0.30069, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21991, Train Loss:0.00001, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21992, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21993, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21994, Train Loss:0.14669, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21995, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21996, Train Loss:0.10540, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21997, Train Loss:0.00000, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21998, Train Loss:0.78973, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:21999, Train Loss:0.00505, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:22000, Train Loss:0.00296, Dev Loss:0.11038\n",
      "Epoch:[79/100], step:22001, Train Loss:0.98202, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22002, Train Loss:0.11983, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22003, Train Loss:0.15520, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22004, Train Loss:0.00230, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22005, Train Loss:0.01956, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22006, Train Loss:0.00023, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22007, Train Loss:0.00121, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22008, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22009, Train Loss:0.00109, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22010, Train Loss:0.00003, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22011, Train Loss:1.53539, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22012, Train Loss:0.00013, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22013, Train Loss:0.00133, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22014, Train Loss:0.00613, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22015, Train Loss:0.29778, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22016, Train Loss:0.05693, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22017, Train Loss:0.03069, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22018, Train Loss:0.00151, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22019, Train Loss:0.00498, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22020, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22021, Train Loss:0.24311, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22022, Train Loss:0.00434, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22023, Train Loss:0.62613, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22024, Train Loss:0.04324, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22025, Train Loss:0.04680, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22026, Train Loss:0.00465, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22027, Train Loss:0.11468, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22028, Train Loss:0.04333, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22029, Train Loss:0.06261, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22030, Train Loss:0.04105, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22031, Train Loss:0.17660, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22032, Train Loss:0.00013, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22033, Train Loss:0.02448, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22034, Train Loss:0.03458, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22035, Train Loss:0.00376, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22036, Train Loss:0.03300, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22037, Train Loss:0.00741, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22038, Train Loss:0.09251, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22039, Train Loss:0.06134, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22040, Train Loss:0.05469, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22041, Train Loss:1.09103, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22042, Train Loss:0.00110, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22043, Train Loss:0.01864, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22044, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22045, Train Loss:0.00711, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22046, Train Loss:0.00011, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22047, Train Loss:0.14503, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22048, Train Loss:0.05628, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22049, Train Loss:0.00639, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22050, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22051, Train Loss:0.36419, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22052, Train Loss:0.02297, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22053, Train Loss:0.00018, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22054, Train Loss:0.00003, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22055, Train Loss:0.04470, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22056, Train Loss:0.00687, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22057, Train Loss:0.00126, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22058, Train Loss:0.15382, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22059, Train Loss:0.35486, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22060, Train Loss:0.26597, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22061, Train Loss:0.02915, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22062, Train Loss:0.00006, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22063, Train Loss:0.14516, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22064, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22065, Train Loss:0.36733, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22066, Train Loss:0.00240, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22067, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22068, Train Loss:0.22273, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22069, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22070, Train Loss:0.06338, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22071, Train Loss:0.01176, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22072, Train Loss:0.15482, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22073, Train Loss:0.01057, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22074, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22075, Train Loss:0.11222, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22076, Train Loss:0.00044, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22077, Train Loss:0.00081, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22078, Train Loss:0.00007, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22079, Train Loss:0.15852, Dev Loss:0.08358\n",
      "Epoch:[79/100], step:22080, Train Loss:0.03860, Dev Loss:0.08358\n",
      "Start Epoch: 80, Steps: 17\n",
      "Epoch:[80/100], step:22081, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22082, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22083, Train Loss:0.33947, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22084, Train Loss:0.00017, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22085, Train Loss:0.06963, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22086, Train Loss:0.25209, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22087, Train Loss:0.00202, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22088, Train Loss:0.30171, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22089, Train Loss:0.06419, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22090, Train Loss:0.00027, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22091, Train Loss:0.00017, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22092, Train Loss:0.28346, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22093, Train Loss:0.00006, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22094, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22095, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22096, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22097, Train Loss:0.08520, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22098, Train Loss:0.14140, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22099, Train Loss:0.03192, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22100, Train Loss:0.22417, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22101, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22102, Train Loss:0.08524, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22103, Train Loss:0.01884, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22104, Train Loss:0.45119, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22105, Train Loss:0.39702, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22106, Train Loss:0.06800, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22107, Train Loss:0.00751, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22108, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22109, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22110, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22111, Train Loss:0.00041, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22112, Train Loss:0.09952, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22113, Train Loss:0.09858, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22114, Train Loss:0.20920, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22115, Train Loss:0.00752, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22116, Train Loss:0.00114, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22117, Train Loss:0.05296, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22118, Train Loss:0.05276, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22119, Train Loss:0.00004, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22120, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22121, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22122, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22123, Train Loss:0.00091, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22124, Train Loss:0.05732, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22125, Train Loss:0.00767, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22126, Train Loss:0.00298, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22127, Train Loss:0.00005, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22128, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22129, Train Loss:0.00602, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22130, Train Loss:0.04614, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22131, Train Loss:0.00008, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22132, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22133, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22134, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22135, Train Loss:0.00698, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22136, Train Loss:0.00060, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22137, Train Loss:0.01108, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22138, Train Loss:0.08522, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22139, Train Loss:0.00784, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22140, Train Loss:0.44519, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22141, Train Loss:0.00534, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22142, Train Loss:0.00017, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22143, Train Loss:0.00153, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22144, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22145, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22146, Train Loss:0.00359, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22147, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22148, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22149, Train Loss:0.01315, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22150, Train Loss:0.02344, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22151, Train Loss:0.00002, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22152, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22153, Train Loss:0.04026, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22154, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22155, Train Loss:0.01512, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22156, Train Loss:0.00551, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22157, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22158, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22159, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22160, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22161, Train Loss:0.00227, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22162, Train Loss:0.00256, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22163, Train Loss:0.08734, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22164, Train Loss:0.00036, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22165, Train Loss:0.00931, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22166, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22167, Train Loss:0.15235, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22168, Train Loss:0.05938, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22169, Train Loss:0.00606, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22170, Train Loss:0.00436, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22171, Train Loss:0.00182, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22172, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22173, Train Loss:0.00970, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22174, Train Loss:0.37393, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22175, Train Loss:0.11123, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22176, Train Loss:0.00703, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22177, Train Loss:0.00030, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22178, Train Loss:0.03986, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22179, Train Loss:0.00004, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22180, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22181, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22182, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22183, Train Loss:0.07357, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22184, Train Loss:1.20996, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22185, Train Loss:0.01038, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22186, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22187, Train Loss:0.05331, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22188, Train Loss:0.01402, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22189, Train Loss:0.00091, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22190, Train Loss:0.16829, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22191, Train Loss:0.00004, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22192, Train Loss:0.02845, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22193, Train Loss:0.00496, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22194, Train Loss:0.00067, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22195, Train Loss:0.61003, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22196, Train Loss:0.24609, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22197, Train Loss:0.00316, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22198, Train Loss:0.16985, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22199, Train Loss:0.02555, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22200, Train Loss:0.01736, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22201, Train Loss:0.32686, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22202, Train Loss:0.02278, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22203, Train Loss:0.00091, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22204, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22205, Train Loss:0.00026, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22206, Train Loss:0.04903, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22207, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22208, Train Loss:0.05426, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22209, Train Loss:0.02549, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22210, Train Loss:0.00037, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22211, Train Loss:0.07030, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22212, Train Loss:0.18166, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22213, Train Loss:0.11019, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22214, Train Loss:0.29746, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22215, Train Loss:0.01256, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22216, Train Loss:0.14172, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22217, Train Loss:0.00040, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22218, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22219, Train Loss:0.00082, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22220, Train Loss:0.09055, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22221, Train Loss:0.20988, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22222, Train Loss:0.43380, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22223, Train Loss:0.22893, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22224, Train Loss:0.00207, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22225, Train Loss:0.00455, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22226, Train Loss:0.04019, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22227, Train Loss:0.11741, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22228, Train Loss:0.01334, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22229, Train Loss:0.05576, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22230, Train Loss:0.00381, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22231, Train Loss:0.02883, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22232, Train Loss:0.05222, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22233, Train Loss:0.00007, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22234, Train Loss:0.21768, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22235, Train Loss:0.10785, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22236, Train Loss:0.00161, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22237, Train Loss:0.15494, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22238, Train Loss:0.19975, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22239, Train Loss:0.00370, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22240, Train Loss:0.23021, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22241, Train Loss:0.00381, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22242, Train Loss:0.53592, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22243, Train Loss:0.00002, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22244, Train Loss:0.00000, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22245, Train Loss:0.00015, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22246, Train Loss:0.00003, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22247, Train Loss:0.05239, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22248, Train Loss:0.00001, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22249, Train Loss:0.00046, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22250, Train Loss:0.14336, Dev Loss:0.08358\n",
      "Epoch:[80/100], step:22251, Train Loss:0.05351, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22252, Train Loss:0.00022, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22253, Train Loss:0.20514, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22254, Train Loss:0.52194, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22255, Train Loss:0.11713, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22256, Train Loss:0.10100, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22257, Train Loss:0.00379, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22258, Train Loss:0.00002, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22259, Train Loss:0.05557, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22260, Train Loss:0.11392, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22261, Train Loss:0.03707, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22262, Train Loss:0.12580, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22263, Train Loss:0.08113, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22264, Train Loss:0.00016, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22265, Train Loss:0.18070, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22266, Train Loss:0.09925, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22267, Train Loss:0.00188, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22268, Train Loss:0.00003, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22269, Train Loss:0.48489, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22270, Train Loss:0.02498, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22271, Train Loss:0.00455, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22272, Train Loss:0.00668, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22273, Train Loss:0.00846, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22274, Train Loss:0.00015, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22275, Train Loss:0.01054, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22276, Train Loss:0.18723, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22277, Train Loss:0.02879, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22278, Train Loss:0.17832, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22279, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22280, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22281, Train Loss:0.00208, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22282, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22283, Train Loss:0.07440, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22284, Train Loss:0.13538, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22285, Train Loss:2.54264, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22286, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22287, Train Loss:0.02144, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22288, Train Loss:0.00457, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22289, Train Loss:0.91529, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22290, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22291, Train Loss:0.38263, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22292, Train Loss:0.02858, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22293, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22294, Train Loss:0.00796, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22295, Train Loss:0.29068, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22296, Train Loss:0.25097, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22297, Train Loss:0.20653, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22298, Train Loss:0.82052, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22299, Train Loss:1.25480, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22300, Train Loss:0.30631, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22301, Train Loss:0.00020, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22302, Train Loss:0.00311, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22303, Train Loss:0.03279, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22304, Train Loss:0.05626, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22305, Train Loss:0.12927, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22306, Train Loss:0.03008, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22307, Train Loss:0.12362, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22308, Train Loss:0.09436, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22309, Train Loss:0.28694, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22310, Train Loss:0.00453, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22311, Train Loss:0.22651, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22312, Train Loss:0.00081, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22313, Train Loss:0.00432, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22314, Train Loss:0.11079, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22315, Train Loss:0.06893, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22316, Train Loss:0.55294, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22317, Train Loss:0.00625, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22318, Train Loss:0.00002, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22319, Train Loss:0.00012, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22320, Train Loss:0.00361, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22321, Train Loss:0.00015, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22322, Train Loss:0.00381, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22323, Train Loss:0.06807, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22324, Train Loss:0.00004, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22325, Train Loss:0.02614, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22326, Train Loss:0.06198, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22327, Train Loss:0.10691, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22328, Train Loss:0.00848, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22329, Train Loss:0.15120, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22330, Train Loss:0.14061, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22331, Train Loss:0.00972, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22332, Train Loss:0.00008, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22333, Train Loss:0.17212, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22334, Train Loss:0.00590, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22335, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22336, Train Loss:0.00019, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22337, Train Loss:0.14041, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22338, Train Loss:0.54449, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22339, Train Loss:0.19202, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22340, Train Loss:0.01795, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22341, Train Loss:0.00068, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22342, Train Loss:0.02449, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22343, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22344, Train Loss:0.07523, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22345, Train Loss:0.00034, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22346, Train Loss:0.00008, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22347, Train Loss:0.00024, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22348, Train Loss:0.00086, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22349, Train Loss:0.01758, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22350, Train Loss:0.00018, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22351, Train Loss:0.10781, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22352, Train Loss:0.07316, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22353, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22354, Train Loss:1.18367, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22355, Train Loss:0.33258, Dev Loss:0.08991\n",
      "Epoch:[80/100], step:22356, Train Loss:0.30895, Dev Loss:0.08991\n",
      "Start Epoch: 81, Steps: 17\n",
      "Epoch:[81/100], step:22357, Train Loss:3.66579, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22358, Train Loss:0.00051, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22359, Train Loss:0.16597, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22360, Train Loss:1.11363, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22361, Train Loss:0.40854, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22362, Train Loss:1.99214, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22363, Train Loss:0.00165, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22364, Train Loss:0.59518, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22365, Train Loss:0.07037, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22366, Train Loss:0.05838, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22367, Train Loss:0.05514, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22368, Train Loss:0.01121, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22369, Train Loss:0.01127, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22370, Train Loss:0.11374, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22371, Train Loss:1.12509, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22372, Train Loss:0.31355, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22373, Train Loss:1.09292, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22374, Train Loss:1.08650, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22375, Train Loss:0.60802, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22376, Train Loss:0.34716, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22377, Train Loss:0.24082, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22378, Train Loss:0.42177, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22379, Train Loss:0.14581, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22380, Train Loss:0.34393, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22381, Train Loss:0.07192, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22382, Train Loss:0.01929, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22383, Train Loss:0.14595, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22384, Train Loss:0.22159, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22385, Train Loss:0.49178, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22386, Train Loss:1.43213, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22387, Train Loss:0.12242, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22388, Train Loss:0.08731, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22389, Train Loss:0.32964, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22390, Train Loss:0.20318, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22391, Train Loss:0.16754, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22392, Train Loss:0.57552, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22393, Train Loss:0.15765, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22394, Train Loss:0.15961, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22395, Train Loss:0.06905, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22396, Train Loss:0.17816, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22397, Train Loss:0.04049, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22398, Train Loss:0.00103, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22399, Train Loss:0.12075, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22400, Train Loss:0.72891, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22401, Train Loss:0.38401, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22402, Train Loss:0.19887, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22403, Train Loss:0.11862, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22404, Train Loss:0.00162, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22405, Train Loss:0.00327, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22406, Train Loss:0.62610, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22407, Train Loss:0.02833, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22408, Train Loss:0.14787, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22409, Train Loss:0.03790, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22410, Train Loss:0.11162, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22411, Train Loss:0.50210, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22412, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22413, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22414, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22415, Train Loss:0.10573, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22416, Train Loss:0.13704, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22417, Train Loss:1.11718, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22418, Train Loss:0.34867, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22419, Train Loss:0.00856, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22420, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22421, Train Loss:0.15814, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22422, Train Loss:0.10644, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22423, Train Loss:0.00133, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22424, Train Loss:0.01468, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22425, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22426, Train Loss:0.44347, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22427, Train Loss:0.00194, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22428, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22429, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22430, Train Loss:0.37391, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22431, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22432, Train Loss:0.00213, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22433, Train Loss:0.10744, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22434, Train Loss:0.02631, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22435, Train Loss:0.07413, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22436, Train Loss:0.05951, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22437, Train Loss:0.08397, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22438, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22439, Train Loss:0.00005, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22440, Train Loss:0.53394, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22441, Train Loss:0.00002, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22442, Train Loss:0.17864, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22443, Train Loss:0.00053, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22444, Train Loss:0.09525, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22445, Train Loss:0.00584, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22446, Train Loss:0.23001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22447, Train Loss:0.07605, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22448, Train Loss:0.68677, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22449, Train Loss:0.01665, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22450, Train Loss:0.04145, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22451, Train Loss:0.00009, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22452, Train Loss:0.00001, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22453, Train Loss:0.17410, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22454, Train Loss:0.00586, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22455, Train Loss:0.02498, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22456, Train Loss:0.09925, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22457, Train Loss:0.00011, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22458, Train Loss:0.13147, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22459, Train Loss:0.00399, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22460, Train Loss:0.13407, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22461, Train Loss:0.00710, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22462, Train Loss:0.24179, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22463, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22464, Train Loss:0.27798, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22465, Train Loss:0.11506, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22466, Train Loss:0.09561, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22467, Train Loss:0.00020, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22468, Train Loss:0.00108, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22469, Train Loss:0.00002, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22470, Train Loss:0.00003, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22471, Train Loss:0.00286, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22472, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22473, Train Loss:0.10449, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22474, Train Loss:0.02254, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22475, Train Loss:0.11347, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22476, Train Loss:0.00004, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22477, Train Loss:0.12508, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22478, Train Loss:0.00060, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22479, Train Loss:0.01175, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22480, Train Loss:0.26977, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22481, Train Loss:0.04356, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22482, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22483, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22484, Train Loss:0.19470, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22485, Train Loss:0.11635, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22486, Train Loss:0.09558, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22487, Train Loss:0.00021, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22488, Train Loss:0.02880, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22489, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22490, Train Loss:0.00404, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22491, Train Loss:0.00011, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22492, Train Loss:0.00832, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22493, Train Loss:0.13118, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22494, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22495, Train Loss:0.00000, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22496, Train Loss:0.01013, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22497, Train Loss:0.00358, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22498, Train Loss:0.11274, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22499, Train Loss:0.00011, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22500, Train Loss:0.00199, Dev Loss:0.08991\n",
      "Epoch:[81/100], step:22501, Train Loss:0.01203, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22502, Train Loss:0.00891, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22503, Train Loss:0.04561, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22504, Train Loss:0.00070, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22505, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22506, Train Loss:0.10535, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22507, Train Loss:0.00006, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22508, Train Loss:0.08368, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22509, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22510, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22511, Train Loss:0.05634, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22512, Train Loss:0.08469, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22513, Train Loss:0.28248, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22514, Train Loss:0.12829, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22515, Train Loss:0.00138, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22516, Train Loss:0.38472, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22517, Train Loss:0.01222, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22518, Train Loss:0.82661, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22519, Train Loss:0.00036, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22520, Train Loss:0.05653, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22521, Train Loss:0.30919, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22522, Train Loss:0.00872, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22523, Train Loss:0.08127, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22524, Train Loss:0.12803, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22525, Train Loss:0.00033, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22526, Train Loss:0.16206, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22527, Train Loss:0.09269, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22528, Train Loss:0.03551, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22529, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22530, Train Loss:0.13152, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22531, Train Loss:0.07529, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22532, Train Loss:0.13510, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22533, Train Loss:0.00109, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22534, Train Loss:0.04149, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22535, Train Loss:0.00022, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22536, Train Loss:0.00210, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22537, Train Loss:0.02563, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22538, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22539, Train Loss:0.01383, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22540, Train Loss:0.00234, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22541, Train Loss:0.00007, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22542, Train Loss:0.20866, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22543, Train Loss:0.21996, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22544, Train Loss:0.00110, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22545, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22546, Train Loss:0.11929, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22547, Train Loss:0.52710, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22548, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22549, Train Loss:0.00187, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22550, Train Loss:0.00031, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22551, Train Loss:0.10110, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22552, Train Loss:0.06803, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22553, Train Loss:0.00519, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22554, Train Loss:0.00826, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22555, Train Loss:0.00020, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22556, Train Loss:0.42194, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22557, Train Loss:0.00051, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22558, Train Loss:0.00018, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22559, Train Loss:0.00017, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22560, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22561, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22562, Train Loss:0.06492, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22563, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22564, Train Loss:0.23102, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22565, Train Loss:0.36160, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22566, Train Loss:0.00683, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22567, Train Loss:0.10555, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22568, Train Loss:0.00054, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22569, Train Loss:0.01095, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22570, Train Loss:0.00040, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22571, Train Loss:0.00676, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22572, Train Loss:0.03022, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22573, Train Loss:0.29768, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22574, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22575, Train Loss:0.04393, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22576, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22577, Train Loss:0.00793, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22578, Train Loss:0.01665, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22579, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22580, Train Loss:0.09554, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22581, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22582, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22583, Train Loss:0.32613, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22584, Train Loss:0.10105, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22585, Train Loss:0.15312, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22586, Train Loss:0.00044, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22587, Train Loss:0.10082, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22588, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22589, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22590, Train Loss:0.10152, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22591, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22592, Train Loss:0.00767, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22593, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22594, Train Loss:0.05156, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22595, Train Loss:0.22722, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22596, Train Loss:0.04131, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22597, Train Loss:0.04569, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22598, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22599, Train Loss:0.04352, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22600, Train Loss:0.49988, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22601, Train Loss:0.03521, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22602, Train Loss:0.10688, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22603, Train Loss:0.00004, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22604, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22605, Train Loss:0.13904, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22606, Train Loss:0.02513, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22607, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22608, Train Loss:0.08441, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22609, Train Loss:0.10915, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22610, Train Loss:0.21771, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22611, Train Loss:0.41281, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22612, Train Loss:0.07236, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22613, Train Loss:0.00200, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22614, Train Loss:0.17120, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22615, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22616, Train Loss:0.01958, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22617, Train Loss:0.03958, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22618, Train Loss:0.00192, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22619, Train Loss:0.01950, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22620, Train Loss:0.11961, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22621, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22622, Train Loss:0.00014, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22623, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22624, Train Loss:0.10527, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22625, Train Loss:0.14766, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22626, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22627, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22628, Train Loss:0.06525, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22629, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22630, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22631, Train Loss:0.00007, Dev Loss:0.09837\n",
      "Epoch:[81/100], step:22632, Train Loss:0.01493, Dev Loss:0.09837\n",
      "Start Epoch: 82, Steps: 17\n",
      "Epoch:[82/100], step:22633, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22634, Train Loss:0.00006, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22635, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22636, Train Loss:0.12205, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22637, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22638, Train Loss:0.01568, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22639, Train Loss:0.00036, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22640, Train Loss:0.01610, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22641, Train Loss:0.00096, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22642, Train Loss:0.03287, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22643, Train Loss:0.00004, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22644, Train Loss:0.78558, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22645, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22646, Train Loss:0.00857, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22647, Train Loss:0.00036, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22648, Train Loss:0.00443, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22649, Train Loss:0.01335, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22650, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22651, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22652, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22653, Train Loss:0.07086, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22654, Train Loss:0.12426, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22655, Train Loss:0.15949, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22656, Train Loss:0.35520, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22657, Train Loss:0.01221, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22658, Train Loss:0.10812, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22659, Train Loss:0.00003, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22660, Train Loss:0.00189, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22661, Train Loss:0.09118, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22662, Train Loss:0.00656, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22663, Train Loss:0.00446, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22664, Train Loss:0.06534, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22665, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22666, Train Loss:0.00022, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22667, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22668, Train Loss:0.00046, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22669, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22670, Train Loss:0.00002, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22671, Train Loss:0.11730, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22672, Train Loss:0.06759, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22673, Train Loss:0.20529, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22674, Train Loss:0.00587, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22675, Train Loss:1.78463, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22676, Train Loss:0.17696, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22677, Train Loss:0.00035, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22678, Train Loss:0.07818, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22679, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22680, Train Loss:0.07814, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22681, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22682, Train Loss:0.00106, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22683, Train Loss:0.00228, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22684, Train Loss:0.00029, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22685, Train Loss:0.39714, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22686, Train Loss:0.02815, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22687, Train Loss:0.16813, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22688, Train Loss:0.08229, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22689, Train Loss:0.00093, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22690, Train Loss:0.14002, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22691, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22692, Train Loss:0.00343, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22693, Train Loss:0.00087, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22694, Train Loss:0.12776, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22695, Train Loss:0.01521, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22696, Train Loss:0.00037, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22697, Train Loss:0.00858, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22698, Train Loss:0.01523, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22699, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22700, Train Loss:0.00637, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22701, Train Loss:0.00734, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22702, Train Loss:0.02610, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22703, Train Loss:0.08705, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22704, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22705, Train Loss:0.00688, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22706, Train Loss:0.23341, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22707, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22708, Train Loss:0.06083, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22709, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22710, Train Loss:0.00049, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22711, Train Loss:0.00731, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22712, Train Loss:0.29737, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22713, Train Loss:0.08222, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22714, Train Loss:0.00679, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22715, Train Loss:0.05413, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22716, Train Loss:0.00009, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22717, Train Loss:0.00571, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22718, Train Loss:0.00080, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22719, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22720, Train Loss:0.00056, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22721, Train Loss:0.00017, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22722, Train Loss:0.00086, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22723, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22724, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22725, Train Loss:0.10191, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22726, Train Loss:0.00609, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22727, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22728, Train Loss:0.00011, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22729, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22730, Train Loss:0.08451, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22731, Train Loss:0.15308, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22732, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22733, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22734, Train Loss:0.01870, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22735, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22736, Train Loss:0.01197, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22737, Train Loss:0.00349, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22738, Train Loss:0.20671, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22739, Train Loss:0.00502, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22740, Train Loss:0.00012, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22741, Train Loss:0.00250, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22742, Train Loss:0.00000, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22743, Train Loss:0.00027, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22744, Train Loss:0.05993, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22745, Train Loss:0.08701, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22746, Train Loss:0.17356, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22747, Train Loss:0.00011, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22748, Train Loss:0.01665, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22749, Train Loss:0.00001, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22750, Train Loss:0.00157, Dev Loss:0.09837\n",
      "Epoch:[82/100], step:22751, Train Loss:0.00090, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22752, Train Loss:0.00010, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22753, Train Loss:0.78636, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22754, Train Loss:0.08283, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22755, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22756, Train Loss:0.01452, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22757, Train Loss:0.00786, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22758, Train Loss:0.00006, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22759, Train Loss:0.01250, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22760, Train Loss:0.00592, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22761, Train Loss:0.00377, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22762, Train Loss:0.48331, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22763, Train Loss:0.00002, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22764, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22765, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22766, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22767, Train Loss:0.05305, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22768, Train Loss:0.00011, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22769, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22770, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22771, Train Loss:0.00021, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22772, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22773, Train Loss:0.10321, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22774, Train Loss:0.00002, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22775, Train Loss:0.05435, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22776, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22777, Train Loss:0.00679, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22778, Train Loss:0.26836, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22779, Train Loss:0.01788, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22780, Train Loss:0.06705, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22781, Train Loss:0.00074, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22782, Train Loss:0.00580, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22783, Train Loss:0.00481, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22784, Train Loss:0.25538, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22785, Train Loss:0.16280, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22786, Train Loss:0.20699, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22787, Train Loss:0.20551, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22788, Train Loss:0.05240, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22789, Train Loss:0.00045, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22790, Train Loss:0.08925, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22791, Train Loss:0.18407, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22792, Train Loss:0.00481, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22793, Train Loss:0.44509, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22794, Train Loss:0.00016, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22795, Train Loss:0.02003, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22796, Train Loss:0.09266, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22797, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22798, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22799, Train Loss:0.06071, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22800, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22801, Train Loss:0.00015, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22802, Train Loss:0.05668, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22803, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22804, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22805, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22806, Train Loss:0.00013, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22807, Train Loss:0.00034, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22808, Train Loss:0.19314, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22809, Train Loss:0.18741, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22810, Train Loss:0.00727, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22811, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22812, Train Loss:0.00032, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22813, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22814, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22815, Train Loss:0.01630, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22816, Train Loss:0.01500, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22817, Train Loss:0.00243, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22818, Train Loss:0.09158, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22819, Train Loss:0.03520, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22820, Train Loss:0.00341, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22821, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22822, Train Loss:0.11089, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22823, Train Loss:0.16000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22824, Train Loss:0.22768, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22825, Train Loss:0.01991, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22826, Train Loss:0.21522, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22827, Train Loss:0.22069, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22828, Train Loss:0.00980, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22829, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22830, Train Loss:0.05675, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22831, Train Loss:0.30763, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22832, Train Loss:0.00013, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22833, Train Loss:0.05489, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22834, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22835, Train Loss:0.06785, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22836, Train Loss:0.10992, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22837, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22838, Train Loss:0.01626, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22839, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22840, Train Loss:0.00488, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22841, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22842, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22843, Train Loss:0.00140, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22844, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22845, Train Loss:0.12191, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22846, Train Loss:0.01737, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22847, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22848, Train Loss:0.07786, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22849, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22850, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22851, Train Loss:0.00397, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22852, Train Loss:2.09321, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22853, Train Loss:0.00001, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22854, Train Loss:0.03624, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22855, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22856, Train Loss:0.08749, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22857, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22858, Train Loss:0.00232, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22859, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22860, Train Loss:0.00056, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22861, Train Loss:0.11949, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22862, Train Loss:0.05160, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22863, Train Loss:0.01019, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22864, Train Loss:0.00064, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22865, Train Loss:0.00277, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22866, Train Loss:0.06195, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22867, Train Loss:0.10466, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22868, Train Loss:0.15161, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22869, Train Loss:0.00004, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22870, Train Loss:0.19491, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22871, Train Loss:0.00620, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22872, Train Loss:0.20651, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22873, Train Loss:0.08256, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22874, Train Loss:0.24205, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22875, Train Loss:2.52870, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22876, Train Loss:0.00217, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22877, Train Loss:0.00079, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22878, Train Loss:0.00038, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22879, Train Loss:0.05282, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22880, Train Loss:0.03263, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22881, Train Loss:0.00249, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22882, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22883, Train Loss:0.00640, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22884, Train Loss:0.01510, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22885, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22886, Train Loss:0.03811, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22887, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22888, Train Loss:0.19033, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22889, Train Loss:0.18273, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22890, Train Loss:0.86132, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22891, Train Loss:0.15904, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22892, Train Loss:0.00061, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22893, Train Loss:0.39392, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22894, Train Loss:0.01845, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22895, Train Loss:0.40206, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22896, Train Loss:0.14057, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22897, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22898, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22899, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22900, Train Loss:0.08306, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22901, Train Loss:0.00040, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22902, Train Loss:0.11198, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22903, Train Loss:0.01673, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22904, Train Loss:0.06243, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22905, Train Loss:0.04491, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22906, Train Loss:0.00046, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22907, Train Loss:0.15938, Dev Loss:0.12788\n",
      "Epoch:[82/100], step:22908, Train Loss:0.29365, Dev Loss:0.12788\n",
      "Start Epoch: 83, Steps: 17\n",
      "Epoch:[83/100], step:22909, Train Loss:0.00204, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22910, Train Loss:0.01301, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22911, Train Loss:0.05569, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22912, Train Loss:0.03852, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22913, Train Loss:0.10512, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22914, Train Loss:0.24741, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22915, Train Loss:0.08860, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22916, Train Loss:0.00105, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22917, Train Loss:0.32301, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22918, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22919, Train Loss:0.00002, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22920, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22921, Train Loss:0.02339, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22922, Train Loss:0.00062, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22923, Train Loss:0.03367, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22924, Train Loss:0.13077, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22925, Train Loss:0.09611, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22926, Train Loss:0.17014, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22927, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22928, Train Loss:0.06022, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22929, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22930, Train Loss:0.00040, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22931, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22932, Train Loss:0.08335, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22933, Train Loss:0.04648, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22934, Train Loss:0.06037, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22935, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22936, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22937, Train Loss:0.07731, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22938, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22939, Train Loss:0.00050, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22940, Train Loss:0.00001, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22941, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22942, Train Loss:0.10101, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22943, Train Loss:0.01635, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22944, Train Loss:0.21378, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22945, Train Loss:0.00416, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22946, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22947, Train Loss:0.00001, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22948, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22949, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22950, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22951, Train Loss:0.00858, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22952, Train Loss:0.01450, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22953, Train Loss:0.00009, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22954, Train Loss:0.00084, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22955, Train Loss:0.00031, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22956, Train Loss:0.05880, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22957, Train Loss:0.06515, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22958, Train Loss:0.20491, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22959, Train Loss:0.11424, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22960, Train Loss:0.25498, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22961, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22962, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22963, Train Loss:0.27639, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22964, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22965, Train Loss:0.00018, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22966, Train Loss:0.00012, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22967, Train Loss:0.00263, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22968, Train Loss:0.21966, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22969, Train Loss:0.32716, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22970, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22971, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22972, Train Loss:0.00169, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22973, Train Loss:0.00015, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22974, Train Loss:0.04973, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22975, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22976, Train Loss:0.00046, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22977, Train Loss:0.00004, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22978, Train Loss:0.00001, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22979, Train Loss:0.08408, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22980, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22981, Train Loss:0.00323, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22982, Train Loss:0.03779, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22983, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22984, Train Loss:0.29717, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22985, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22986, Train Loss:0.00577, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22987, Train Loss:0.01366, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22988, Train Loss:0.00020, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22989, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22990, Train Loss:0.12693, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22991, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22992, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22993, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22994, Train Loss:0.00000, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22995, Train Loss:0.14558, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22996, Train Loss:0.10383, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22997, Train Loss:0.00128, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22998, Train Loss:0.00824, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:22999, Train Loss:0.00005, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:23000, Train Loss:0.00746, Dev Loss:0.12788\n",
      "Epoch:[83/100], step:23001, Train Loss:0.30251, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23002, Train Loss:0.00003, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23003, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23004, Train Loss:0.09534, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23005, Train Loss:0.00877, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23006, Train Loss:0.00002, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23007, Train Loss:0.00012, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23008, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23009, Train Loss:0.06340, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23010, Train Loss:0.10430, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23011, Train Loss:0.08917, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23012, Train Loss:0.12445, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23013, Train Loss:0.00093, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23014, Train Loss:0.00005, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23015, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23016, Train Loss:0.19485, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23017, Train Loss:0.11357, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23018, Train Loss:0.00107, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23019, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23020, Train Loss:0.05169, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23021, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23022, Train Loss:0.22557, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23023, Train Loss:0.04834, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23024, Train Loss:0.00011, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23025, Train Loss:0.09028, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23026, Train Loss:0.07874, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23027, Train Loss:0.00009, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23028, Train Loss:0.00088, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23029, Train Loss:0.04793, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23030, Train Loss:0.05239, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23031, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23032, Train Loss:0.13376, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23033, Train Loss:0.32791, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23034, Train Loss:0.00003, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23035, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23036, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23037, Train Loss:0.00169, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23038, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23039, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23040, Train Loss:0.00938, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23041, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23042, Train Loss:0.01655, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23043, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23044, Train Loss:0.00008, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23045, Train Loss:0.30073, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23046, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23047, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23048, Train Loss:0.17129, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23049, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23050, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23051, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23052, Train Loss:0.09376, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23053, Train Loss:0.35329, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23054, Train Loss:0.01094, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23055, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23056, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23057, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23058, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23059, Train Loss:0.00035, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23060, Train Loss:0.00019, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23061, Train Loss:0.24162, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23062, Train Loss:0.00009, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23063, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23064, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23065, Train Loss:0.00003, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23066, Train Loss:0.65774, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23067, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23068, Train Loss:0.03367, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23069, Train Loss:0.00557, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23070, Train Loss:0.00155, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23071, Train Loss:0.14487, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23072, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23073, Train Loss:0.02702, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23074, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23075, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23076, Train Loss:0.00023, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23077, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23078, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23079, Train Loss:0.09686, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23080, Train Loss:0.00004, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23081, Train Loss:0.16701, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23082, Train Loss:0.13624, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23083, Train Loss:0.07980, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23084, Train Loss:0.00008, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23085, Train Loss:0.00024, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23086, Train Loss:0.00356, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23087, Train Loss:0.00466, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23088, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23089, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23090, Train Loss:0.04426, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23091, Train Loss:0.00004, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23092, Train Loss:0.01232, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23093, Train Loss:0.08699, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23094, Train Loss:0.00008, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23095, Train Loss:0.08596, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23096, Train Loss:0.08109, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23097, Train Loss:0.58158, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23098, Train Loss:0.05726, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23099, Train Loss:0.18163, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23100, Train Loss:0.03139, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23101, Train Loss:0.00004, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23102, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23103, Train Loss:0.08089, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23104, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23105, Train Loss:0.00642, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23106, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23107, Train Loss:0.10555, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23108, Train Loss:0.07559, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23109, Train Loss:0.00290, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23110, Train Loss:0.46142, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23111, Train Loss:0.00122, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23112, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23113, Train Loss:0.08304, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23114, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23115, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23116, Train Loss:0.04322, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23117, Train Loss:0.00669, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23118, Train Loss:0.12411, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23119, Train Loss:0.00066, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23120, Train Loss:0.27975, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23121, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23122, Train Loss:0.00222, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23123, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23124, Train Loss:0.01512, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23125, Train Loss:0.00020, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23126, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23127, Train Loss:0.01323, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23128, Train Loss:0.00120, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23129, Train Loss:0.28462, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23130, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23131, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23132, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23133, Train Loss:0.00035, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23134, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23135, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23136, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23137, Train Loss:0.00011, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23138, Train Loss:0.02046, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23139, Train Loss:0.00007, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23140, Train Loss:0.00106, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23141, Train Loss:0.16135, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23142, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23143, Train Loss:0.04304, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23144, Train Loss:0.01154, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23145, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23146, Train Loss:0.13323, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23147, Train Loss:0.21497, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23148, Train Loss:0.17797, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23149, Train Loss:0.01308, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23150, Train Loss:0.00518, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23151, Train Loss:0.04202, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23152, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23153, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23154, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23155, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23156, Train Loss:0.78080, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23157, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23158, Train Loss:0.00009, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23159, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23160, Train Loss:0.00051, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23161, Train Loss:0.00046, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23162, Train Loss:0.39899, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23163, Train Loss:0.15500, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23164, Train Loss:0.88987, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23165, Train Loss:0.23295, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23166, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23167, Train Loss:0.00007, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23168, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23169, Train Loss:0.24837, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23170, Train Loss:0.00008, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23171, Train Loss:0.00062, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23172, Train Loss:0.00059, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23173, Train Loss:0.00005, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23174, Train Loss:0.08441, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23175, Train Loss:0.64274, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23176, Train Loss:0.19592, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23177, Train Loss:0.06139, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23178, Train Loss:0.04085, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23179, Train Loss:0.03507, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23180, Train Loss:0.00014, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23181, Train Loss:0.07541, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23182, Train Loss:0.03510, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23183, Train Loss:0.02500, Dev Loss:0.12608\n",
      "Epoch:[83/100], step:23184, Train Loss:0.97794, Dev Loss:0.12608\n",
      "Start Epoch: 84, Steps: 17\n",
      "Epoch:[84/100], step:23185, Train Loss:0.07552, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23186, Train Loss:0.74785, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23187, Train Loss:0.16358, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23188, Train Loss:0.02087, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23189, Train Loss:0.12304, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23190, Train Loss:0.00026, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23191, Train Loss:1.34919, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23192, Train Loss:0.00872, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23193, Train Loss:0.05680, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23194, Train Loss:0.03642, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23195, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23196, Train Loss:0.08704, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23197, Train Loss:0.03345, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23198, Train Loss:0.12450, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23199, Train Loss:0.32643, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23200, Train Loss:0.01240, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23201, Train Loss:0.03896, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23202, Train Loss:0.13645, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23203, Train Loss:0.00185, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23204, Train Loss:0.00122, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23205, Train Loss:1.08808, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23206, Train Loss:0.00761, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23207, Train Loss:0.32621, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23208, Train Loss:0.01657, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23209, Train Loss:0.14010, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23210, Train Loss:0.77851, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23211, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23212, Train Loss:0.05990, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23213, Train Loss:0.87985, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23214, Train Loss:0.00184, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23215, Train Loss:0.00002, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23216, Train Loss:0.03208, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23217, Train Loss:0.00044, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23218, Train Loss:0.00311, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23219, Train Loss:0.00034, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23220, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23221, Train Loss:0.00616, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23222, Train Loss:0.00001, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23223, Train Loss:0.00034, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23224, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23225, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23226, Train Loss:0.01107, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23227, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23228, Train Loss:0.00004, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23229, Train Loss:0.04929, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23230, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23231, Train Loss:0.00949, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23232, Train Loss:0.03011, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23233, Train Loss:0.08686, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23234, Train Loss:0.09595, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23235, Train Loss:0.00132, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23236, Train Loss:0.01086, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23237, Train Loss:0.18525, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23238, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23239, Train Loss:0.07858, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23240, Train Loss:0.00657, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23241, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23242, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23243, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23244, Train Loss:0.14878, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23245, Train Loss:0.02031, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23246, Train Loss:0.02281, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23247, Train Loss:0.12166, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23248, Train Loss:0.17731, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23249, Train Loss:0.03161, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23250, Train Loss:0.00000, Dev Loss:0.12608\n",
      "Epoch:[84/100], step:23251, Train Loss:0.37710, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23252, Train Loss:0.01997, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23253, Train Loss:0.16584, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23254, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23255, Train Loss:0.08509, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23256, Train Loss:0.00290, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23257, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23258, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23259, Train Loss:0.00925, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23260, Train Loss:0.09392, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23261, Train Loss:0.23659, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23262, Train Loss:0.00004, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23263, Train Loss:0.06739, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23264, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23265, Train Loss:0.00027, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23266, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23267, Train Loss:0.11447, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23268, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23269, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23270, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23271, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23272, Train Loss:0.00046, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23273, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23274, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23275, Train Loss:0.14975, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23276, Train Loss:0.00021, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23277, Train Loss:0.00091, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23278, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23279, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23280, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23281, Train Loss:0.00014, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23282, Train Loss:0.00025, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23283, Train Loss:0.62335, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23284, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23285, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23286, Train Loss:0.18789, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23287, Train Loss:0.00325, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23288, Train Loss:0.18412, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23289, Train Loss:0.00991, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23290, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23291, Train Loss:0.00004, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23292, Train Loss:0.02184, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23293, Train Loss:0.10440, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23294, Train Loss:0.00051, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23295, Train Loss:0.23692, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23296, Train Loss:0.09908, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23297, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23298, Train Loss:1.63279, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23299, Train Loss:0.19416, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23300, Train Loss:0.12607, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23301, Train Loss:0.00013, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23302, Train Loss:0.28054, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23303, Train Loss:0.05869, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23304, Train Loss:0.00058, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23305, Train Loss:0.00791, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23306, Train Loss:0.02097, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23307, Train Loss:0.42597, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23308, Train Loss:0.12603, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23309, Train Loss:0.00032, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23310, Train Loss:0.12018, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23311, Train Loss:0.08808, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23312, Train Loss:0.02988, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23313, Train Loss:0.03159, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23314, Train Loss:0.00087, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23315, Train Loss:0.00039, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23316, Train Loss:0.31112, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23317, Train Loss:0.05871, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23318, Train Loss:0.01237, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23319, Train Loss:0.06416, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23320, Train Loss:0.23415, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23321, Train Loss:0.00007, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23322, Train Loss:0.01195, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23323, Train Loss:0.00036, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23324, Train Loss:0.13094, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23325, Train Loss:0.00016, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23326, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23327, Train Loss:0.00006, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23328, Train Loss:0.00110, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23329, Train Loss:0.02640, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23330, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23331, Train Loss:0.00645, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23332, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23333, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23334, Train Loss:0.02064, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23335, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23336, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23337, Train Loss:0.15237, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23338, Train Loss:0.00056, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23339, Train Loss:0.00329, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23340, Train Loss:0.30429, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23341, Train Loss:0.36423, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23342, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23343, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23344, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23345, Train Loss:0.19376, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23346, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23347, Train Loss:0.00457, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23348, Train Loss:0.08178, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23349, Train Loss:0.03039, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23350, Train Loss:0.00034, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23351, Train Loss:0.13724, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23352, Train Loss:0.35336, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23353, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23354, Train Loss:0.05177, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23355, Train Loss:0.00054, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23356, Train Loss:0.11924, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23357, Train Loss:0.14298, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23358, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23359, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23360, Train Loss:0.00002, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23361, Train Loss:0.00783, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23362, Train Loss:0.00419, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23363, Train Loss:0.31160, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23364, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23365, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23366, Train Loss:0.00050, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23367, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23368, Train Loss:0.45671, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23369, Train Loss:0.00034, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23370, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23371, Train Loss:0.00002, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23372, Train Loss:0.02979, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23373, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23374, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23375, Train Loss:0.12332, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23376, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23377, Train Loss:0.00015, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23378, Train Loss:0.28513, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23379, Train Loss:0.04210, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23380, Train Loss:0.00219, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23381, Train Loss:0.00268, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23382, Train Loss:0.21763, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23383, Train Loss:0.00014, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23384, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23385, Train Loss:0.00012, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23386, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23387, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23388, Train Loss:0.00070, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23389, Train Loss:0.12530, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23390, Train Loss:0.04341, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23391, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23392, Train Loss:0.00849, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23393, Train Loss:0.00003, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23394, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23395, Train Loss:0.38334, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23396, Train Loss:0.01390, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23397, Train Loss:0.03313, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23398, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23399, Train Loss:0.16344, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23400, Train Loss:0.00102, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23401, Train Loss:0.00128, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23402, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23403, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23404, Train Loss:0.07485, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23405, Train Loss:0.33615, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23406, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23407, Train Loss:0.00079, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23408, Train Loss:0.03044, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23409, Train Loss:0.00005, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23410, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23411, Train Loss:0.00036, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23412, Train Loss:0.08222, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23413, Train Loss:0.15810, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23414, Train Loss:0.00002, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23415, Train Loss:0.00122, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23416, Train Loss:0.00266, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23417, Train Loss:0.00004, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23418, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23419, Train Loss:0.00206, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23420, Train Loss:0.00092, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23421, Train Loss:0.00031, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23422, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23423, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23424, Train Loss:0.03610, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23425, Train Loss:0.06347, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23426, Train Loss:0.00013, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23427, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23428, Train Loss:0.00006, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23429, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23430, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23431, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23432, Train Loss:0.00108, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23433, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23434, Train Loss:0.00360, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23435, Train Loss:0.00031, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23436, Train Loss:0.00012, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23437, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23438, Train Loss:0.00002, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23439, Train Loss:0.00369, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23440, Train Loss:0.07768, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23441, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23442, Train Loss:0.18377, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23443, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23444, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23445, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23446, Train Loss:0.02942, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23447, Train Loss:0.00435, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23448, Train Loss:0.10783, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23449, Train Loss:0.04490, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23450, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23451, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23452, Train Loss:0.00214, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23453, Train Loss:0.03026, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23454, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23455, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23456, Train Loss:1.32060, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23457, Train Loss:0.39074, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23458, Train Loss:0.00042, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23459, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[84/100], step:23460, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Start Epoch: 85, Steps: 17\n",
      "Epoch:[85/100], step:23461, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23462, Train Loss:0.00002, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23463, Train Loss:0.01223, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23464, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23465, Train Loss:0.00012, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23466, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23467, Train Loss:0.00705, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23468, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23469, Train Loss:0.00004, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23470, Train Loss:0.15372, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23471, Train Loss:0.12861, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23472, Train Loss:1.77052, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23473, Train Loss:0.00001, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23474, Train Loss:0.00043, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23475, Train Loss:0.00062, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23476, Train Loss:0.78036, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23477, Train Loss:0.20707, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23478, Train Loss:0.08288, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23479, Train Loss:0.00000, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23480, Train Loss:0.00016, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23481, Train Loss:0.14904, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23482, Train Loss:0.03471, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23483, Train Loss:0.29124, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23484, Train Loss:0.10571, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23485, Train Loss:0.05347, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23486, Train Loss:0.85488, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23487, Train Loss:0.00008, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23488, Train Loss:0.00007, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23489, Train Loss:0.08058, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23490, Train Loss:0.09553, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23491, Train Loss:0.21020, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23492, Train Loss:5.49304, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23493, Train Loss:0.17008, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23494, Train Loss:0.01776, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23495, Train Loss:0.12638, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23496, Train Loss:0.30851, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23497, Train Loss:0.01282, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23498, Train Loss:0.41436, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23499, Train Loss:0.03151, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23500, Train Loss:0.33095, Dev Loss:0.14072\n",
      "Epoch:[85/100], step:23501, Train Loss:0.25467, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23502, Train Loss:0.14966, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23503, Train Loss:0.05096, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23504, Train Loss:0.08241, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23505, Train Loss:0.07432, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23506, Train Loss:0.04593, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23507, Train Loss:0.17723, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23508, Train Loss:0.40413, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23509, Train Loss:0.57873, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23510, Train Loss:0.08550, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23511, Train Loss:0.35346, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23512, Train Loss:0.04791, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23513, Train Loss:0.15695, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23514, Train Loss:0.38129, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23515, Train Loss:0.11175, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23516, Train Loss:0.00580, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23517, Train Loss:0.02370, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23518, Train Loss:0.00072, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23519, Train Loss:1.20404, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23520, Train Loss:0.22248, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23521, Train Loss:0.10702, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23522, Train Loss:0.01012, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23523, Train Loss:0.00062, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23524, Train Loss:0.01276, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23525, Train Loss:0.31072, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23526, Train Loss:0.10222, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23527, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23528, Train Loss:0.45208, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23529, Train Loss:0.00787, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23530, Train Loss:0.00147, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23531, Train Loss:0.06808, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23532, Train Loss:0.00005, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23533, Train Loss:0.02048, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23534, Train Loss:0.00002, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23535, Train Loss:0.03952, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23536, Train Loss:0.09191, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23537, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23538, Train Loss:0.04877, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23539, Train Loss:0.03327, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23540, Train Loss:0.49343, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23541, Train Loss:0.04850, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23542, Train Loss:0.00138, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23543, Train Loss:0.28174, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23544, Train Loss:0.06144, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23545, Train Loss:0.02831, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23546, Train Loss:0.15214, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23547, Train Loss:0.08665, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23548, Train Loss:0.00036, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23549, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23550, Train Loss:0.14558, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23551, Train Loss:0.00218, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23552, Train Loss:0.00471, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23553, Train Loss:0.11444, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23554, Train Loss:0.42352, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23555, Train Loss:0.08420, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23556, Train Loss:0.04874, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23557, Train Loss:0.08536, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23558, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23559, Train Loss:0.00208, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23560, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23561, Train Loss:0.00129, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23562, Train Loss:0.00010, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23563, Train Loss:0.00113, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23564, Train Loss:0.00469, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23565, Train Loss:0.33815, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23566, Train Loss:0.24328, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23567, Train Loss:0.11585, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23568, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23569, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23570, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23571, Train Loss:0.00005, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23572, Train Loss:0.00042, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23573, Train Loss:0.00698, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23574, Train Loss:0.07197, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23575, Train Loss:0.11096, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23576, Train Loss:0.04383, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23577, Train Loss:0.12220, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23578, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23579, Train Loss:0.00025, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23580, Train Loss:0.03329, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23581, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23582, Train Loss:0.01505, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23583, Train Loss:0.00417, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23584, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23585, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23586, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23587, Train Loss:0.04698, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23588, Train Loss:0.21275, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23589, Train Loss:0.00032, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23590, Train Loss:0.04504, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23591, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23592, Train Loss:0.00752, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23593, Train Loss:0.00950, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23594, Train Loss:0.03231, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23595, Train Loss:0.00092, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23596, Train Loss:0.00003, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23597, Train Loss:0.00675, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23598, Train Loss:0.00035, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23599, Train Loss:0.07367, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23600, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23601, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23602, Train Loss:0.00014, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23603, Train Loss:0.11475, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23604, Train Loss:0.00746, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23605, Train Loss:0.00367, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23606, Train Loss:0.01239, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23607, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23608, Train Loss:0.08694, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23609, Train Loss:0.00082, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23610, Train Loss:0.13120, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23611, Train Loss:0.03042, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23612, Train Loss:0.03894, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23613, Train Loss:0.00465, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23614, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23615, Train Loss:0.21530, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23616, Train Loss:0.00002, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23617, Train Loss:0.00004, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23618, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23619, Train Loss:0.01296, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23620, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23621, Train Loss:0.00163, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23622, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23623, Train Loss:0.02367, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23624, Train Loss:0.10819, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23625, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23626, Train Loss:0.00345, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23627, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23628, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23629, Train Loss:1.69320, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23630, Train Loss:0.01341, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23631, Train Loss:0.10305, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23632, Train Loss:0.12508, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23633, Train Loss:0.01445, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23634, Train Loss:0.11045, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23635, Train Loss:0.11075, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23636, Train Loss:0.17645, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23637, Train Loss:0.00016, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23638, Train Loss:0.00016, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23639, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23640, Train Loss:0.08413, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23641, Train Loss:0.01951, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23642, Train Loss:0.08728, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23643, Train Loss:0.00036, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23644, Train Loss:0.04951, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23645, Train Loss:0.02578, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23646, Train Loss:0.40233, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23647, Train Loss:0.06237, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23648, Train Loss:0.00039, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23649, Train Loss:0.11830, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23650, Train Loss:0.00144, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23651, Train Loss:0.01265, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23652, Train Loss:0.00030, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23653, Train Loss:0.02349, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23654, Train Loss:0.01048, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23655, Train Loss:0.02292, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23656, Train Loss:0.08391, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23657, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23658, Train Loss:0.04839, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23659, Train Loss:0.00102, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23660, Train Loss:0.22152, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23661, Train Loss:0.00121, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23662, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23663, Train Loss:0.02864, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23664, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23665, Train Loss:0.07177, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23666, Train Loss:0.00070, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23667, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23668, Train Loss:0.08861, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23669, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23670, Train Loss:0.00308, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23671, Train Loss:0.00071, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23672, Train Loss:0.00023, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23673, Train Loss:0.03613, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23674, Train Loss:0.01345, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23675, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23676, Train Loss:0.00017, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23677, Train Loss:0.06403, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23678, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23679, Train Loss:0.00563, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23680, Train Loss:0.38913, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23681, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23682, Train Loss:0.15472, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23683, Train Loss:0.00005, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23684, Train Loss:0.17770, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23685, Train Loss:0.00160, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23686, Train Loss:0.00675, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23687, Train Loss:0.12453, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23688, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23689, Train Loss:0.00070, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23690, Train Loss:0.00004, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23691, Train Loss:0.00003, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23692, Train Loss:0.55442, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23693, Train Loss:0.02827, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23694, Train Loss:0.11659, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23695, Train Loss:0.08124, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23696, Train Loss:0.00858, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23697, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23698, Train Loss:0.05581, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23699, Train Loss:0.03181, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23700, Train Loss:0.00029, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23701, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23702, Train Loss:0.00002, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23703, Train Loss:0.00030, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23704, Train Loss:0.00003, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23705, Train Loss:0.00088, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23706, Train Loss:0.10966, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23707, Train Loss:0.03869, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23708, Train Loss:0.00105, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23709, Train Loss:0.11823, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23710, Train Loss:0.00905, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23711, Train Loss:0.00031, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23712, Train Loss:0.00097, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23713, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23714, Train Loss:0.00005, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23715, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23716, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23717, Train Loss:0.01015, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23718, Train Loss:0.20338, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23719, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23720, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23721, Train Loss:0.00011, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23722, Train Loss:0.03011, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23723, Train Loss:0.14264, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23724, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23725, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23726, Train Loss:0.20366, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23727, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23728, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23729, Train Loss:0.07563, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23730, Train Loss:0.17271, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23731, Train Loss:0.11516, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23732, Train Loss:0.00076, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23733, Train Loss:0.08061, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23734, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23735, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[85/100], step:23736, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Start Epoch: 86, Steps: 17\n",
      "Epoch:[86/100], step:23737, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23738, Train Loss:0.00005, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23739, Train Loss:0.04145, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23740, Train Loss:0.00007, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23741, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23742, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23743, Train Loss:0.00001, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23744, Train Loss:0.09635, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23745, Train Loss:0.00000, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23746, Train Loss:0.00438, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23747, Train Loss:0.00016, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23748, Train Loss:0.00534, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23749, Train Loss:0.00109, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23750, Train Loss:0.03674, Dev Loss:0.27009\n",
      "Epoch:[86/100], step:23751, Train Loss:0.23111, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23752, Train Loss:0.00350, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23753, Train Loss:0.00001, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23754, Train Loss:0.00185, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23755, Train Loss:0.00002, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23756, Train Loss:0.09621, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23757, Train Loss:0.10523, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23758, Train Loss:0.00001, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23759, Train Loss:0.05966, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23760, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23761, Train Loss:0.16726, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23762, Train Loss:0.00778, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23763, Train Loss:0.02575, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23764, Train Loss:0.01417, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23765, Train Loss:0.00037, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23766, Train Loss:0.35011, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23767, Train Loss:0.24690, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23768, Train Loss:0.27990, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23769, Train Loss:0.00003, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23770, Train Loss:0.00001, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23771, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23772, Train Loss:0.02432, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23773, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23774, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23775, Train Loss:0.00191, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23776, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23777, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23778, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23779, Train Loss:0.37490, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23780, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23781, Train Loss:0.07078, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23782, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23783, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23784, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23785, Train Loss:0.00001, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23786, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23787, Train Loss:0.29195, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23788, Train Loss:0.08502, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23789, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23790, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23791, Train Loss:0.57913, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23792, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23793, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23794, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23795, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23796, Train Loss:0.08141, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23797, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23798, Train Loss:0.22729, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23799, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23800, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23801, Train Loss:0.10938, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23802, Train Loss:0.00003, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23803, Train Loss:0.14225, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23804, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23805, Train Loss:0.13237, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23806, Train Loss:0.00002, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23807, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23808, Train Loss:0.10031, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23809, Train Loss:0.00044, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23810, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23811, Train Loss:0.00422, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23812, Train Loss:0.13100, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23813, Train Loss:0.00047, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23814, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23815, Train Loss:0.28579, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23816, Train Loss:0.00256, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23817, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23818, Train Loss:0.03422, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23819, Train Loss:0.09706, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23820, Train Loss:0.00048, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23821, Train Loss:0.00130, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23822, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23823, Train Loss:0.00049, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23824, Train Loss:0.08002, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23825, Train Loss:0.00736, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23826, Train Loss:0.86229, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23827, Train Loss:0.19080, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23828, Train Loss:0.00082, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23829, Train Loss:0.00003, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23830, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23831, Train Loss:0.04373, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23832, Train Loss:0.02932, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23833, Train Loss:0.11379, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23834, Train Loss:0.03942, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23835, Train Loss:0.01787, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23836, Train Loss:0.00002, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23837, Train Loss:0.00056, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23838, Train Loss:0.17098, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23839, Train Loss:0.00313, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23840, Train Loss:0.00030, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23841, Train Loss:0.00491, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23842, Train Loss:0.10346, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23843, Train Loss:0.00189, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23844, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23845, Train Loss:0.06944, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23846, Train Loss:0.02907, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23847, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23848, Train Loss:0.00039, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23849, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23850, Train Loss:0.06267, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23851, Train Loss:0.37739, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23852, Train Loss:0.30069, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23853, Train Loss:0.01104, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23854, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23855, Train Loss:0.00285, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23856, Train Loss:0.00235, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23857, Train Loss:0.08626, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23858, Train Loss:0.15954, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23859, Train Loss:0.03433, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23860, Train Loss:0.00539, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23861, Train Loss:0.02243, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23862, Train Loss:0.00364, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23863, Train Loss:0.03488, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23864, Train Loss:0.11658, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23865, Train Loss:0.05662, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23866, Train Loss:0.04941, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23867, Train Loss:0.08741, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23868, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23869, Train Loss:0.06036, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23870, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23871, Train Loss:0.00117, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23872, Train Loss:0.08077, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23873, Train Loss:0.04666, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23874, Train Loss:0.00007, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23875, Train Loss:0.04325, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23876, Train Loss:0.05978, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23877, Train Loss:0.12585, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23878, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23879, Train Loss:0.02144, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23880, Train Loss:0.79072, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23881, Train Loss:0.05504, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23882, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23883, Train Loss:0.05774, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23884, Train Loss:0.01558, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23885, Train Loss:0.00074, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23886, Train Loss:0.12210, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23887, Train Loss:0.00679, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23888, Train Loss:0.06073, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23889, Train Loss:0.01887, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23890, Train Loss:0.29255, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23891, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23892, Train Loss:0.25754, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23893, Train Loss:0.00003, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23894, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23895, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23896, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23897, Train Loss:0.04095, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23898, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23899, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23900, Train Loss:0.00030, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23901, Train Loss:1.09368, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23902, Train Loss:0.02699, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23903, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23904, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23905, Train Loss:0.02925, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23906, Train Loss:0.02504, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23907, Train Loss:0.11309, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23908, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23909, Train Loss:0.05651, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23910, Train Loss:0.00547, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23911, Train Loss:0.20668, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23912, Train Loss:0.11727, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23913, Train Loss:0.03572, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23914, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23915, Train Loss:0.00052, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23916, Train Loss:0.00014, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23917, Train Loss:0.04627, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23918, Train Loss:0.00039, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23919, Train Loss:0.07562, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23920, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23921, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23922, Train Loss:3.16921, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23923, Train Loss:0.20710, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23924, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23925, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23926, Train Loss:0.00907, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23927, Train Loss:0.00205, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23928, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23929, Train Loss:0.20612, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23930, Train Loss:0.03327, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23931, Train Loss:0.98079, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23932, Train Loss:0.01422, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23933, Train Loss:0.47399, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23934, Train Loss:0.34782, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23935, Train Loss:0.21431, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23936, Train Loss:0.11016, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23937, Train Loss:3.96909, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23938, Train Loss:0.00352, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23939, Train Loss:0.00414, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23940, Train Loss:1.83011, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23941, Train Loss:0.00108, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23942, Train Loss:0.13524, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23943, Train Loss:0.37475, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23944, Train Loss:0.07009, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23945, Train Loss:0.37203, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23946, Train Loss:0.15696, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23947, Train Loss:0.00527, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23948, Train Loss:0.16077, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23949, Train Loss:0.00329, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23950, Train Loss:0.05242, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23951, Train Loss:0.05328, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23952, Train Loss:0.22759, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23953, Train Loss:0.22515, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23954, Train Loss:0.19104, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23955, Train Loss:0.29683, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23956, Train Loss:0.39598, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23957, Train Loss:0.06434, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23958, Train Loss:0.41176, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23959, Train Loss:0.28734, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23960, Train Loss:0.00678, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23961, Train Loss:0.10475, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23962, Train Loss:0.26289, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23963, Train Loss:0.00558, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23964, Train Loss:0.04298, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23965, Train Loss:0.04021, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23966, Train Loss:0.08076, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23967, Train Loss:0.00001, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23968, Train Loss:0.00004, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23969, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23970, Train Loss:0.13827, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23971, Train Loss:0.00014, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23972, Train Loss:0.01315, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23973, Train Loss:0.21618, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23974, Train Loss:0.51067, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23975, Train Loss:0.29256, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23976, Train Loss:0.48096, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23977, Train Loss:0.34829, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23978, Train Loss:1.06266, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23979, Train Loss:0.00083, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23980, Train Loss:0.08370, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23981, Train Loss:0.00292, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23982, Train Loss:0.26238, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23983, Train Loss:0.19919, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23984, Train Loss:0.05742, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23985, Train Loss:0.16211, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23986, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23987, Train Loss:0.04351, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23988, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23989, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23990, Train Loss:0.00015, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23991, Train Loss:0.00000, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23992, Train Loss:0.39471, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23993, Train Loss:0.00005, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23994, Train Loss:0.02757, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23995, Train Loss:1.28438, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23996, Train Loss:0.09051, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23997, Train Loss:0.04111, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23998, Train Loss:2.02837, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:23999, Train Loss:0.87336, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:24000, Train Loss:0.86773, Dev Loss:0.13575\n",
      "Epoch:[86/100], step:24001, Train Loss:0.05808, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24002, Train Loss:0.13316, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24003, Train Loss:0.07925, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24004, Train Loss:0.60523, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24005, Train Loss:0.23488, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24006, Train Loss:0.01181, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24007, Train Loss:0.12860, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24008, Train Loss:0.50295, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24009, Train Loss:0.50055, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24010, Train Loss:0.83910, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24011, Train Loss:0.27079, Dev Loss:0.23815\n",
      "Epoch:[86/100], step:24012, Train Loss:0.26411, Dev Loss:0.23815\n",
      "Start Epoch: 87, Steps: 17\n",
      "Epoch:[87/100], step:24013, Train Loss:0.20776, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24014, Train Loss:0.14371, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24015, Train Loss:0.62576, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24016, Train Loss:0.37041, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24017, Train Loss:0.15942, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24018, Train Loss:0.03702, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24019, Train Loss:0.10583, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24020, Train Loss:0.04167, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24021, Train Loss:0.15143, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24022, Train Loss:0.38484, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24023, Train Loss:0.45830, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24024, Train Loss:0.01434, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24025, Train Loss:0.40639, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24026, Train Loss:0.14984, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24027, Train Loss:0.05931, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24028, Train Loss:0.28833, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24029, Train Loss:0.25528, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24030, Train Loss:0.37151, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24031, Train Loss:0.00028, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24032, Train Loss:0.01369, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24033, Train Loss:0.16154, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24034, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24035, Train Loss:0.70486, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24036, Train Loss:0.04821, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24037, Train Loss:0.04218, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24038, Train Loss:0.00055, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24039, Train Loss:0.00033, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24040, Train Loss:0.00334, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24041, Train Loss:0.00002, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24042, Train Loss:0.01359, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24043, Train Loss:0.13144, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24044, Train Loss:0.30916, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24045, Train Loss:0.13391, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24046, Train Loss:0.14489, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24047, Train Loss:0.47307, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24048, Train Loss:0.11736, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24049, Train Loss:0.05108, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24050, Train Loss:0.28071, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24051, Train Loss:0.00031, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24052, Train Loss:0.00283, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24053, Train Loss:0.01863, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24054, Train Loss:0.08019, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24055, Train Loss:0.05801, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24056, Train Loss:0.95926, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24057, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24058, Train Loss:0.01566, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24059, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24060, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24061, Train Loss:0.17242, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24062, Train Loss:0.13208, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24063, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24064, Train Loss:0.00105, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24065, Train Loss:0.00002, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24066, Train Loss:0.00082, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24067, Train Loss:0.04431, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24068, Train Loss:0.69809, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24069, Train Loss:0.00015, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24070, Train Loss:0.01113, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24071, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24072, Train Loss:0.17789, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24073, Train Loss:0.22740, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24074, Train Loss:0.13349, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24075, Train Loss:0.03778, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24076, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24077, Train Loss:0.19212, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24078, Train Loss:0.00458, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24079, Train Loss:0.06699, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24080, Train Loss:0.16779, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24081, Train Loss:0.00286, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24082, Train Loss:0.00054, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24083, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24084, Train Loss:0.06934, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24085, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24086, Train Loss:0.00792, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24087, Train Loss:0.03117, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24088, Train Loss:0.01216, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24089, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24090, Train Loss:0.06358, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24091, Train Loss:0.00977, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24092, Train Loss:0.04728, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24093, Train Loss:0.00062, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24094, Train Loss:0.02197, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24095, Train Loss:0.00658, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24096, Train Loss:0.00296, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24097, Train Loss:0.42996, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24098, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24099, Train Loss:0.00294, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24100, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24101, Train Loss:0.02666, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24102, Train Loss:0.03043, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24103, Train Loss:0.09006, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24104, Train Loss:0.10842, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24105, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24106, Train Loss:0.00199, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24107, Train Loss:0.18398, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24108, Train Loss:0.00173, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24109, Train Loss:0.27183, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24110, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24111, Train Loss:0.10056, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24112, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24113, Train Loss:0.15204, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24114, Train Loss:0.03492, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24115, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24116, Train Loss:0.00006, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24117, Train Loss:0.00010, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24118, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24119, Train Loss:0.10674, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24120, Train Loss:0.00011, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24121, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24122, Train Loss:0.00878, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24123, Train Loss:0.09056, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24124, Train Loss:0.12766, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24125, Train Loss:0.06093, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24126, Train Loss:0.01410, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24127, Train Loss:0.03185, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24128, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24129, Train Loss:0.01700, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24130, Train Loss:0.04388, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24131, Train Loss:0.00511, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24132, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24133, Train Loss:0.11147, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24134, Train Loss:0.22342, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24135, Train Loss:0.00468, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24136, Train Loss:0.00053, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24137, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24138, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24139, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24140, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24141, Train Loss:0.04270, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24142, Train Loss:0.03781, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24143, Train Loss:0.00938, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24144, Train Loss:0.00006, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24145, Train Loss:0.00018, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24146, Train Loss:0.07363, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24147, Train Loss:0.16928, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24148, Train Loss:0.04309, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24149, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24150, Train Loss:0.08297, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24151, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24152, Train Loss:0.15670, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24153, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24154, Train Loss:0.00656, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24155, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24156, Train Loss:0.15239, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24157, Train Loss:0.08742, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24158, Train Loss:0.13255, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24159, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24160, Train Loss:0.00056, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24161, Train Loss:0.18171, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24162, Train Loss:0.02890, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24163, Train Loss:0.12604, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24164, Train Loss:0.09813, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24165, Train Loss:0.07450, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24166, Train Loss:0.00083, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24167, Train Loss:0.04059, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24168, Train Loss:0.10231, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24169, Train Loss:0.05517, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24170, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24171, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24172, Train Loss:0.01561, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24173, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24174, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24175, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24176, Train Loss:0.00159, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24177, Train Loss:0.00010, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24178, Train Loss:0.00005, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24179, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24180, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24181, Train Loss:0.06261, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24182, Train Loss:0.22714, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24183, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24184, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24185, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24186, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24187, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24188, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24189, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24190, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24191, Train Loss:0.00002, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24192, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24193, Train Loss:0.16585, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24194, Train Loss:0.68992, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24195, Train Loss:0.18838, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24196, Train Loss:0.28275, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24197, Train Loss:0.00105, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24198, Train Loss:0.00002, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24199, Train Loss:0.17369, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24200, Train Loss:0.00016, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24201, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24202, Train Loss:0.00026, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24203, Train Loss:0.00019, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24204, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24205, Train Loss:0.01167, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24206, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24207, Train Loss:0.12881, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24208, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24209, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24210, Train Loss:0.00744, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24211, Train Loss:0.00473, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24212, Train Loss:0.84090, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24213, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24214, Train Loss:0.00023, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24215, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24216, Train Loss:0.11099, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24217, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24218, Train Loss:0.11911, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24219, Train Loss:0.00008, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24220, Train Loss:0.00005, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24221, Train Loss:0.02226, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24222, Train Loss:0.00572, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24223, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24224, Train Loss:0.00008, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24225, Train Loss:0.24604, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24226, Train Loss:0.11166, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24227, Train Loss:0.00124, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24228, Train Loss:0.81414, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24229, Train Loss:0.00094, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24230, Train Loss:0.03794, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24231, Train Loss:0.05451, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24232, Train Loss:0.32251, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24233, Train Loss:0.43524, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24234, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24235, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24236, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24237, Train Loss:0.00004, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24238, Train Loss:0.20385, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24239, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24240, Train Loss:0.00001, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24241, Train Loss:0.19695, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24242, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24243, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24244, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24245, Train Loss:0.46053, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24246, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24247, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24248, Train Loss:0.12639, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24249, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24250, Train Loss:0.00000, Dev Loss:0.23815\n",
      "Epoch:[87/100], step:24251, Train Loss:1.68932, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24252, Train Loss:0.06664, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24253, Train Loss:0.08912, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24254, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24255, Train Loss:0.05356, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24256, Train Loss:0.00150, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24257, Train Loss:0.03288, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24258, Train Loss:0.00474, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24259, Train Loss:0.00003, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24260, Train Loss:0.00002, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24261, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24262, Train Loss:0.00215, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24263, Train Loss:0.00179, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24264, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24265, Train Loss:0.00272, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24266, Train Loss:0.65997, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24267, Train Loss:0.29007, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24268, Train Loss:0.14543, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24269, Train Loss:0.48195, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24270, Train Loss:0.12944, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24271, Train Loss:0.41613, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24272, Train Loss:0.03039, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24273, Train Loss:0.00881, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24274, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24275, Train Loss:0.00194, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24276, Train Loss:0.15015, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24277, Train Loss:0.00201, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24278, Train Loss:0.29250, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24279, Train Loss:0.04021, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24280, Train Loss:0.28957, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24281, Train Loss:0.17581, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24282, Train Loss:0.17582, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24283, Train Loss:0.17366, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24284, Train Loss:0.03937, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24285, Train Loss:0.00784, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24286, Train Loss:0.00047, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24287, Train Loss:0.01305, Dev Loss:0.19542\n",
      "Epoch:[87/100], step:24288, Train Loss:0.05586, Dev Loss:0.19542\n",
      "Start Epoch: 88, Steps: 17\n",
      "Epoch:[88/100], step:24289, Train Loss:0.02760, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24290, Train Loss:0.06240, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24291, Train Loss:0.46285, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24292, Train Loss:0.19388, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24293, Train Loss:0.09134, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24294, Train Loss:0.16646, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24295, Train Loss:0.03083, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24296, Train Loss:0.33739, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24297, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24298, Train Loss:0.09476, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24299, Train Loss:0.11750, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24300, Train Loss:0.23680, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24301, Train Loss:0.13039, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24302, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24303, Train Loss:0.02192, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24304, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24305, Train Loss:0.00002, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24306, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24307, Train Loss:0.00480, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24308, Train Loss:0.92056, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24309, Train Loss:0.00746, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24310, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24311, Train Loss:0.03550, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24312, Train Loss:0.12980, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24313, Train Loss:0.74997, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24314, Train Loss:0.03425, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24315, Train Loss:0.22501, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24316, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24317, Train Loss:0.00730, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24318, Train Loss:0.40106, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24319, Train Loss:0.13521, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24320, Train Loss:0.15945, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24321, Train Loss:0.00005, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24322, Train Loss:0.63645, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24323, Train Loss:0.28205, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24324, Train Loss:0.44790, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24325, Train Loss:0.72216, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24326, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24327, Train Loss:0.00205, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24328, Train Loss:0.34647, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24329, Train Loss:0.14839, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24330, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24331, Train Loss:0.24418, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24332, Train Loss:0.10787, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24333, Train Loss:0.21957, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24334, Train Loss:0.01166, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24335, Train Loss:0.04837, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24336, Train Loss:0.00065, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24337, Train Loss:0.00609, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24338, Train Loss:0.77670, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24339, Train Loss:0.19590, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24340, Train Loss:0.17661, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24341, Train Loss:0.10346, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24342, Train Loss:0.15076, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24343, Train Loss:0.03278, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24344, Train Loss:0.00133, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24345, Train Loss:0.00713, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24346, Train Loss:0.09201, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24347, Train Loss:0.00009, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24348, Train Loss:0.00866, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24349, Train Loss:0.00376, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24350, Train Loss:0.07898, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24351, Train Loss:0.14123, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24352, Train Loss:0.23584, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24353, Train Loss:0.01169, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24354, Train Loss:0.00407, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24355, Train Loss:0.01495, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24356, Train Loss:0.01032, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24357, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24358, Train Loss:0.00037, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24359, Train Loss:0.16097, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24360, Train Loss:0.00303, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24361, Train Loss:0.00018, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24362, Train Loss:0.08283, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24363, Train Loss:0.00031, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24364, Train Loss:0.14233, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24365, Train Loss:0.00008, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24366, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24367, Train Loss:0.05885, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24368, Train Loss:0.28515, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24369, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24370, Train Loss:0.17973, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24371, Train Loss:0.02459, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24372, Train Loss:0.10750, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24373, Train Loss:0.07582, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24374, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24375, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24376, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24377, Train Loss:0.00479, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24378, Train Loss:0.02452, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24379, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24380, Train Loss:0.42412, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24381, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24382, Train Loss:0.14590, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24383, Train Loss:0.20348, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24384, Train Loss:0.07197, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24385, Train Loss:0.02624, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24386, Train Loss:0.08036, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24387, Train Loss:0.09593, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24388, Train Loss:0.05062, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24389, Train Loss:0.10338, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24390, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24391, Train Loss:0.22573, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24392, Train Loss:0.50650, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24393, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24394, Train Loss:0.06899, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24395, Train Loss:0.65735, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24396, Train Loss:0.02928, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24397, Train Loss:0.49866, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24398, Train Loss:0.15336, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24399, Train Loss:0.05935, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24400, Train Loss:0.01985, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24401, Train Loss:0.05206, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24402, Train Loss:0.09098, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24403, Train Loss:0.03465, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24404, Train Loss:0.00330, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24405, Train Loss:0.00005, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24406, Train Loss:0.17784, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24407, Train Loss:0.94066, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24408, Train Loss:0.00202, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24409, Train Loss:0.00070, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24410, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24411, Train Loss:0.12805, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24412, Train Loss:0.00134, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24413, Train Loss:0.15782, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24414, Train Loss:0.08779, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24415, Train Loss:0.01988, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24416, Train Loss:0.02419, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24417, Train Loss:0.13250, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24418, Train Loss:0.10293, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24419, Train Loss:3.75707, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24420, Train Loss:0.21377, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24421, Train Loss:0.12721, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24422, Train Loss:0.19384, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24423, Train Loss:0.36231, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24424, Train Loss:0.17036, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24425, Train Loss:0.31445, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24426, Train Loss:0.07230, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24427, Train Loss:0.03498, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24428, Train Loss:0.02981, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24429, Train Loss:0.28022, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24430, Train Loss:0.56084, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24431, Train Loss:0.10194, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24432, Train Loss:0.01858, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24433, Train Loss:0.26907, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24434, Train Loss:0.04379, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24435, Train Loss:0.08041, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24436, Train Loss:0.03667, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24437, Train Loss:0.25157, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24438, Train Loss:0.02306, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24439, Train Loss:0.05679, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24440, Train Loss:0.06954, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24441, Train Loss:0.02016, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24442, Train Loss:0.03964, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24443, Train Loss:0.02174, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24444, Train Loss:0.04854, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24445, Train Loss:0.03381, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24446, Train Loss:0.01645, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24447, Train Loss:0.00073, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24448, Train Loss:0.00715, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24449, Train Loss:0.00415, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24450, Train Loss:0.00050, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24451, Train Loss:0.14786, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24452, Train Loss:0.58563, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24453, Train Loss:0.01543, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24454, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24455, Train Loss:0.18314, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24456, Train Loss:0.02707, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24457, Train Loss:0.26847, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24458, Train Loss:0.05679, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24459, Train Loss:0.00113, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24460, Train Loss:0.00917, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24461, Train Loss:0.08410, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24462, Train Loss:0.00181, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24463, Train Loss:0.24596, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24464, Train Loss:0.21542, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24465, Train Loss:0.16732, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24466, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24467, Train Loss:0.01955, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24468, Train Loss:0.00004, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24469, Train Loss:0.12084, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24470, Train Loss:0.07807, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24471, Train Loss:0.31161, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24472, Train Loss:0.05130, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24473, Train Loss:0.18844, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24474, Train Loss:0.10006, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24475, Train Loss:0.37259, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24476, Train Loss:0.15526, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24477, Train Loss:0.09368, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24478, Train Loss:0.00514, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24479, Train Loss:0.06988, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24480, Train Loss:0.00633, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24481, Train Loss:0.01446, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24482, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24483, Train Loss:0.07240, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24484, Train Loss:0.02621, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24485, Train Loss:0.01489, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24486, Train Loss:0.23195, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24487, Train Loss:0.64197, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24488, Train Loss:0.05900, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24489, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24490, Train Loss:0.05111, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24491, Train Loss:0.00753, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24492, Train Loss:0.00000, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24493, Train Loss:0.29575, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24494, Train Loss:0.25268, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24495, Train Loss:0.00014, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24496, Train Loss:0.08929, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24497, Train Loss:0.00082, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24498, Train Loss:0.05583, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24499, Train Loss:0.00001, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24500, Train Loss:0.24742, Dev Loss:0.19542\n",
      "Epoch:[88/100], step:24501, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24502, Train Loss:0.00004, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24503, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24504, Train Loss:0.00315, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24505, Train Loss:0.01261, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24506, Train Loss:2.53329, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24507, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24508, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24509, Train Loss:0.03022, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24510, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24511, Train Loss:0.00923, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24512, Train Loss:0.01215, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24513, Train Loss:0.01037, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24514, Train Loss:0.00870, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24515, Train Loss:0.00009, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24516, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24517, Train Loss:0.10422, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24518, Train Loss:0.23986, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24519, Train Loss:0.10564, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24520, Train Loss:0.00070, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24521, Train Loss:0.03612, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24522, Train Loss:0.39602, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24523, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24524, Train Loss:0.03762, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24525, Train Loss:0.09924, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24526, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24527, Train Loss:0.00015, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24528, Train Loss:0.26639, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24529, Train Loss:0.11476, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24530, Train Loss:0.02815, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24531, Train Loss:0.20571, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24532, Train Loss:0.00146, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24533, Train Loss:0.00528, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24534, Train Loss:0.03246, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24535, Train Loss:0.00072, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24536, Train Loss:0.06741, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24537, Train Loss:0.13691, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24538, Train Loss:0.16253, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24539, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24540, Train Loss:0.00009, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24541, Train Loss:0.00045, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24542, Train Loss:0.32378, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24543, Train Loss:0.02910, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24544, Train Loss:0.06061, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24545, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24546, Train Loss:0.00030, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24547, Train Loss:0.00648, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24548, Train Loss:0.00572, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24549, Train Loss:0.15479, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24550, Train Loss:0.04144, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24551, Train Loss:0.16566, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24552, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24553, Train Loss:0.55581, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24554, Train Loss:0.31527, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24555, Train Loss:0.22212, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24556, Train Loss:0.00372, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24557, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24558, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24559, Train Loss:0.13403, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24560, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24561, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24562, Train Loss:0.00009, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24563, Train Loss:0.34708, Dev Loss:0.07621\n",
      "Epoch:[88/100], step:24564, Train Loss:0.00005, Dev Loss:0.07621\n",
      "Start Epoch: 89, Steps: 17\n",
      "Epoch:[89/100], step:24565, Train Loss:0.06170, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24566, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24567, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24568, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24569, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24570, Train Loss:0.22674, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24571, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24572, Train Loss:0.00024, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24573, Train Loss:0.16300, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24574, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24575, Train Loss:0.29759, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24576, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24577, Train Loss:0.00053, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24578, Train Loss:0.00345, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24579, Train Loss:0.04362, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24580, Train Loss:0.01623, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24581, Train Loss:0.00237, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24582, Train Loss:0.32325, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24583, Train Loss:0.00354, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24584, Train Loss:0.01690, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24585, Train Loss:0.01731, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24586, Train Loss:0.11032, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24587, Train Loss:0.02459, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24588, Train Loss:0.03603, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24589, Train Loss:0.09613, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24590, Train Loss:0.01462, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24591, Train Loss:0.05180, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24592, Train Loss:0.27404, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24593, Train Loss:0.14447, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24594, Train Loss:0.16279, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24595, Train Loss:0.00772, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24596, Train Loss:0.00036, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24597, Train Loss:0.06260, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24598, Train Loss:0.00174, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24599, Train Loss:0.00823, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24600, Train Loss:0.07263, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24601, Train Loss:0.00178, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24602, Train Loss:0.02182, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24603, Train Loss:0.00057, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24604, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24605, Train Loss:0.09172, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24606, Train Loss:0.04207, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24607, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24608, Train Loss:0.02176, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24609, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24610, Train Loss:0.67610, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24611, Train Loss:0.09642, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24612, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24613, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24614, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24615, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24616, Train Loss:0.02516, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24617, Train Loss:0.00061, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24618, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24619, Train Loss:0.28912, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24620, Train Loss:0.00008, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24621, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24622, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24623, Train Loss:0.08512, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24624, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24625, Train Loss:0.00005, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24626, Train Loss:0.01447, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24627, Train Loss:0.05452, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24628, Train Loss:0.01072, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24629, Train Loss:0.00022, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24630, Train Loss:0.00007, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24631, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24632, Train Loss:0.12051, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24633, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24634, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24635, Train Loss:0.01323, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24636, Train Loss:0.43095, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24637, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24638, Train Loss:0.03175, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24639, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24640, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24641, Train Loss:0.02144, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24642, Train Loss:0.01721, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24643, Train Loss:0.00152, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24644, Train Loss:0.03126, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24645, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24646, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24647, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24648, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24649, Train Loss:0.18764, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24650, Train Loss:0.00009, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24651, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24652, Train Loss:0.31218, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24653, Train Loss:0.10517, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24654, Train Loss:0.18501, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24655, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24656, Train Loss:0.00002, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24657, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24658, Train Loss:0.07946, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24659, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24660, Train Loss:0.00443, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24661, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24662, Train Loss:0.02877, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24663, Train Loss:0.48820, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24664, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24665, Train Loss:0.00905, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24666, Train Loss:1.01537, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24667, Train Loss:0.07309, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24668, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24669, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24670, Train Loss:0.07643, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24671, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24672, Train Loss:0.01333, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24673, Train Loss:0.30369, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24674, Train Loss:0.25494, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24675, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24676, Train Loss:0.00001, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24677, Train Loss:0.00010, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24678, Train Loss:0.03123, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24679, Train Loss:0.00101, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24680, Train Loss:0.00612, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24681, Train Loss:0.00127, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24682, Train Loss:0.31308, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24683, Train Loss:3.74546, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24684, Train Loss:0.58159, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24685, Train Loss:0.00170, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24686, Train Loss:0.00045, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24687, Train Loss:0.01445, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24688, Train Loss:0.03883, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24689, Train Loss:0.03177, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24690, Train Loss:0.00000, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24691, Train Loss:0.00003, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24692, Train Loss:0.00117, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24693, Train Loss:0.08424, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24694, Train Loss:0.00196, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24695, Train Loss:0.00360, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24696, Train Loss:1.96652, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24697, Train Loss:0.00798, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24698, Train Loss:0.25253, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24699, Train Loss:0.01662, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24700, Train Loss:0.57133, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24701, Train Loss:0.17408, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24702, Train Loss:0.00445, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24703, Train Loss:0.00229, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24704, Train Loss:0.20715, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24705, Train Loss:0.00404, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24706, Train Loss:0.14029, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24707, Train Loss:0.15567, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24708, Train Loss:0.44646, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24709, Train Loss:0.00176, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24710, Train Loss:0.11834, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24711, Train Loss:0.00366, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24712, Train Loss:0.14128, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24713, Train Loss:0.30909, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24714, Train Loss:0.00016, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24715, Train Loss:0.00053, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24716, Train Loss:0.03200, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24717, Train Loss:0.01955, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24718, Train Loss:0.54573, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24719, Train Loss:0.00059, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24720, Train Loss:0.00595, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24721, Train Loss:0.23340, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24722, Train Loss:0.16376, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24723, Train Loss:0.06212, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24724, Train Loss:0.10195, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24725, Train Loss:0.38928, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24726, Train Loss:0.06058, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24727, Train Loss:0.13240, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24728, Train Loss:0.27229, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24729, Train Loss:0.03015, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24730, Train Loss:0.64244, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24731, Train Loss:0.14131, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24732, Train Loss:0.07478, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24733, Train Loss:0.62509, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24734, Train Loss:0.30154, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24735, Train Loss:0.00739, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24736, Train Loss:0.09641, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24737, Train Loss:0.18128, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24738, Train Loss:0.00049, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24739, Train Loss:0.09671, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24740, Train Loss:0.25256, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24741, Train Loss:0.16577, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24742, Train Loss:0.02053, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24743, Train Loss:0.55154, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24744, Train Loss:0.30064, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24745, Train Loss:0.30088, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24746, Train Loss:0.48811, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24747, Train Loss:0.00931, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24748, Train Loss:0.05659, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24749, Train Loss:0.00004, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24750, Train Loss:0.00624, Dev Loss:0.07621\n",
      "Epoch:[89/100], step:24751, Train Loss:0.04286, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24752, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24753, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24754, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24755, Train Loss:0.00151, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24756, Train Loss:0.10223, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24757, Train Loss:0.12453, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24758, Train Loss:0.11911, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24759, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24760, Train Loss:0.20611, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24761, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24762, Train Loss:0.06239, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24763, Train Loss:0.11277, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24764, Train Loss:0.07641, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24765, Train Loss:0.09908, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24766, Train Loss:0.07813, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24767, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24768, Train Loss:0.00011, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24769, Train Loss:0.01068, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24770, Train Loss:0.26484, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24771, Train Loss:0.03203, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24772, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24773, Train Loss:0.09897, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24774, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24775, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24776, Train Loss:1.06297, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24777, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24778, Train Loss:0.12119, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24779, Train Loss:0.00240, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24780, Train Loss:0.00169, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24781, Train Loss:0.12501, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24782, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24783, Train Loss:0.11221, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24784, Train Loss:0.00004, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24785, Train Loss:0.13860, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24786, Train Loss:0.18248, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24787, Train Loss:0.02539, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24788, Train Loss:0.00043, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24789, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24790, Train Loss:0.00492, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24791, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24792, Train Loss:0.39140, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24793, Train Loss:0.09306, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24794, Train Loss:0.01261, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24795, Train Loss:0.23699, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24796, Train Loss:0.00009, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24797, Train Loss:0.09632, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24798, Train Loss:0.00205, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24799, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24800, Train Loss:0.05823, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24801, Train Loss:0.26369, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24802, Train Loss:0.00017, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24803, Train Loss:0.02485, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24804, Train Loss:0.50548, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24805, Train Loss:0.00066, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24806, Train Loss:0.00077, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24807, Train Loss:0.03265, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24808, Train Loss:0.00035, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24809, Train Loss:1.24051, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24810, Train Loss:0.32070, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24811, Train Loss:0.00010, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24812, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24813, Train Loss:0.08444, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24814, Train Loss:0.10537, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24815, Train Loss:0.01450, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24816, Train Loss:0.00012, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24817, Train Loss:0.00026, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24818, Train Loss:0.06804, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24819, Train Loss:0.00118, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24820, Train Loss:0.00062, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24821, Train Loss:0.02376, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24822, Train Loss:0.11196, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24823, Train Loss:0.00231, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24824, Train Loss:0.00026, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24825, Train Loss:0.00047, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24826, Train Loss:0.26189, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24827, Train Loss:0.19215, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24828, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24829, Train Loss:0.51552, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24830, Train Loss:0.11930, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24831, Train Loss:0.16617, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24832, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24833, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24834, Train Loss:0.18315, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24835, Train Loss:0.10779, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24836, Train Loss:0.05822, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24837, Train Loss:0.03934, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24838, Train Loss:0.09955, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24839, Train Loss:0.00203, Dev Loss:0.09456\n",
      "Epoch:[89/100], step:24840, Train Loss:0.21360, Dev Loss:0.09456\n",
      "Start Epoch: 90, Steps: 17\n",
      "Epoch:[90/100], step:24841, Train Loss:0.04815, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24842, Train Loss:0.00231, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24843, Train Loss:0.01173, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24844, Train Loss:0.04739, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24845, Train Loss:0.14603, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24846, Train Loss:0.08641, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24847, Train Loss:0.00109, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24848, Train Loss:1.84458, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24849, Train Loss:0.00006, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24850, Train Loss:0.00447, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24851, Train Loss:0.14108, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24852, Train Loss:0.10123, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24853, Train Loss:0.13794, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24854, Train Loss:0.04713, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24855, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24856, Train Loss:0.14543, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24857, Train Loss:0.02472, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24858, Train Loss:0.03585, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24859, Train Loss:0.00006, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24860, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24861, Train Loss:0.12282, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24862, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24863, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24864, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24865, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24866, Train Loss:0.25855, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24867, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24868, Train Loss:0.10421, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24869, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24870, Train Loss:0.03210, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24871, Train Loss:0.00379, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24872, Train Loss:0.02521, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24873, Train Loss:0.02563, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24874, Train Loss:0.28589, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24875, Train Loss:0.00127, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24876, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24877, Train Loss:0.09890, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24878, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24879, Train Loss:0.00016, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24880, Train Loss:0.12807, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24881, Train Loss:0.16921, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24882, Train Loss:0.03928, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24883, Train Loss:0.21502, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24884, Train Loss:0.01204, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24885, Train Loss:0.00293, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24886, Train Loss:0.08880, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24887, Train Loss:0.03167, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24888, Train Loss:0.04806, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24889, Train Loss:0.01081, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24890, Train Loss:0.01494, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24891, Train Loss:0.00524, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24892, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24893, Train Loss:0.06343, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24894, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24895, Train Loss:0.04426, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24896, Train Loss:0.00017, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24897, Train Loss:0.02168, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24898, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24899, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24900, Train Loss:0.00977, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24901, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24902, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24903, Train Loss:0.00012, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24904, Train Loss:0.00020, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24905, Train Loss:0.08485, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24906, Train Loss:0.07573, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24907, Train Loss:0.23992, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24908, Train Loss:0.30487, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24909, Train Loss:0.00319, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24910, Train Loss:0.10529, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24911, Train Loss:0.11279, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24912, Train Loss:0.07859, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24913, Train Loss:0.00008, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24914, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24915, Train Loss:0.18330, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24916, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24917, Train Loss:0.03145, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24918, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24919, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24920, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24921, Train Loss:0.03203, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24922, Train Loss:0.00022, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24923, Train Loss:0.04387, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24924, Train Loss:0.31496, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24925, Train Loss:0.00205, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24926, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24927, Train Loss:0.00013, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24928, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24929, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24930, Train Loss:0.00039, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24931, Train Loss:0.00010, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24932, Train Loss:0.00014, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24933, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24934, Train Loss:0.00005, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24935, Train Loss:0.12709, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24936, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24937, Train Loss:0.16904, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24938, Train Loss:0.00724, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24939, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24940, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24941, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24942, Train Loss:0.00026, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24943, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24944, Train Loss:0.00003, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24945, Train Loss:0.00008, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24946, Train Loss:0.08126, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24947, Train Loss:0.12097, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24948, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24949, Train Loss:0.09248, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24950, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24951, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24952, Train Loss:0.00012, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24953, Train Loss:0.00546, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24954, Train Loss:0.44653, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24955, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24956, Train Loss:0.09189, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24957, Train Loss:0.00004, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24958, Train Loss:0.09099, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24959, Train Loss:0.00034, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24960, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24961, Train Loss:0.00009, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24962, Train Loss:0.02945, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24963, Train Loss:0.00093, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24964, Train Loss:0.09684, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24965, Train Loss:0.11626, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24966, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24967, Train Loss:0.01502, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24968, Train Loss:0.00455, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24969, Train Loss:0.14779, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24970, Train Loss:0.00020, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24971, Train Loss:0.00010, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24972, Train Loss:0.02908, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24973, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24974, Train Loss:0.00003, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24975, Train Loss:0.00002, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24976, Train Loss:0.00009, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24977, Train Loss:0.03142, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24978, Train Loss:0.15681, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24979, Train Loss:0.19737, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24980, Train Loss:0.00006, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24981, Train Loss:0.03161, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24982, Train Loss:0.00076, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24983, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24984, Train Loss:0.00003, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24985, Train Loss:0.31872, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24986, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24987, Train Loss:0.00134, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24988, Train Loss:0.00016, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24989, Train Loss:0.10227, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24990, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24991, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24992, Train Loss:0.00554, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24993, Train Loss:0.22728, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24994, Train Loss:0.00001, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24995, Train Loss:0.05424, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24996, Train Loss:0.04327, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24997, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24998, Train Loss:0.00870, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:24999, Train Loss:0.00006, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:25000, Train Loss:0.00000, Dev Loss:0.09456\n",
      "Epoch:[90/100], step:25001, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25002, Train Loss:0.00002, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25003, Train Loss:0.03977, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25004, Train Loss:0.00541, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25005, Train Loss:0.07739, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25006, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25007, Train Loss:0.00071, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25008, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25009, Train Loss:0.10683, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25010, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25011, Train Loss:1.10316, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25012, Train Loss:0.01598, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25013, Train Loss:0.00017, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25014, Train Loss:0.24857, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25015, Train Loss:0.00214, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25016, Train Loss:0.00004, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25017, Train Loss:0.21708, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25018, Train Loss:0.02854, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25019, Train Loss:0.00076, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25020, Train Loss:0.06541, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25021, Train Loss:0.01892, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25022, Train Loss:0.11590, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25023, Train Loss:0.01074, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25024, Train Loss:0.62740, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25025, Train Loss:0.05911, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25026, Train Loss:0.52285, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25027, Train Loss:0.09421, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25028, Train Loss:0.14599, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25029, Train Loss:0.09779, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25030, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25031, Train Loss:0.08907, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25032, Train Loss:0.10739, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25033, Train Loss:0.13534, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25034, Train Loss:0.01957, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25035, Train Loss:0.09973, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25036, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25037, Train Loss:0.00151, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25038, Train Loss:0.00114, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25039, Train Loss:0.23110, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25040, Train Loss:0.10542, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25041, Train Loss:0.00122, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25042, Train Loss:0.19220, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25043, Train Loss:0.15629, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25044, Train Loss:0.06350, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25045, Train Loss:0.10196, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25046, Train Loss:0.00731, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25047, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25048, Train Loss:0.00626, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25049, Train Loss:0.00056, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25050, Train Loss:0.00189, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25051, Train Loss:0.07250, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25052, Train Loss:0.02352, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25053, Train Loss:0.00030, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25054, Train Loss:0.44707, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25055, Train Loss:0.19562, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25056, Train Loss:0.00012, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25057, Train Loss:0.00261, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25058, Train Loss:0.00020, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25059, Train Loss:0.27653, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25060, Train Loss:0.00003, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25061, Train Loss:0.05667, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25062, Train Loss:0.38791, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25063, Train Loss:0.00165, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25064, Train Loss:0.09788, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25065, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25066, Train Loss:0.00008, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25067, Train Loss:0.03962, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25068, Train Loss:0.00072, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25069, Train Loss:0.09595, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25070, Train Loss:0.08854, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25071, Train Loss:0.10343, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25072, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25073, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25074, Train Loss:0.00019, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25075, Train Loss:0.91422, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25076, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25077, Train Loss:0.05281, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25078, Train Loss:0.00006, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25079, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25080, Train Loss:0.02917, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25081, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25082, Train Loss:0.02128, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25083, Train Loss:0.00055, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25084, Train Loss:0.01256, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25085, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25086, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25087, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25088, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25089, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25090, Train Loss:0.00952, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25091, Train Loss:0.06106, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25092, Train Loss:0.03202, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25093, Train Loss:0.00015, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25094, Train Loss:0.00930, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25095, Train Loss:0.00012, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25096, Train Loss:0.03248, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25097, Train Loss:0.44133, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25098, Train Loss:0.03757, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25099, Train Loss:0.17440, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25100, Train Loss:0.00050, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25101, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25102, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25103, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25104, Train Loss:0.00370, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25105, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25106, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25107, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25108, Train Loss:0.01439, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25109, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25110, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25111, Train Loss:0.38515, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25112, Train Loss:0.00017, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25113, Train Loss:0.05615, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25114, Train Loss:0.05048, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25115, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[90/100], step:25116, Train Loss:0.00043, Dev Loss:0.08517\n",
      "Start Epoch: 91, Steps: 17\n",
      "Epoch:[91/100], step:25117, Train Loss:0.01238, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25118, Train Loss:0.01822, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25119, Train Loss:0.13863, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25120, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25121, Train Loss:0.01027, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25122, Train Loss:0.10235, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25123, Train Loss:0.00418, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25124, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25125, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25126, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25127, Train Loss:0.16158, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25128, Train Loss:0.11001, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25129, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25130, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25131, Train Loss:0.02283, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25132, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25133, Train Loss:0.00006, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25134, Train Loss:0.05112, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25135, Train Loss:0.00009, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25136, Train Loss:0.09242, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25137, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25138, Train Loss:0.01329, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25139, Train Loss:0.09416, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25140, Train Loss:0.00011, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25141, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25142, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25143, Train Loss:0.00005, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25144, Train Loss:0.00009, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25145, Train Loss:0.11826, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25146, Train Loss:0.00022, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25147, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25148, Train Loss:0.05033, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25149, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25150, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25151, Train Loss:0.15927, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25152, Train Loss:0.03268, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25153, Train Loss:0.01638, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25154, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25155, Train Loss:0.02144, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25156, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25157, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25158, Train Loss:0.00599, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25159, Train Loss:0.02943, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25160, Train Loss:0.00006, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25161, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25162, Train Loss:0.02493, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25163, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25164, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25165, Train Loss:0.06300, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25166, Train Loss:0.00073, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25167, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25168, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25169, Train Loss:0.00393, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25170, Train Loss:0.00008, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25171, Train Loss:0.01998, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25172, Train Loss:0.03139, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25173, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25174, Train Loss:0.10444, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25175, Train Loss:0.01968, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25176, Train Loss:0.00052, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25177, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25178, Train Loss:0.00098, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25179, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25180, Train Loss:0.00027, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25181, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25182, Train Loss:0.00459, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25183, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25184, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25185, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25186, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25187, Train Loss:0.03845, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25188, Train Loss:0.07112, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25189, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25190, Train Loss:0.01155, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25191, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25192, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25193, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25194, Train Loss:0.00357, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25195, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25196, Train Loss:0.02122, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25197, Train Loss:0.00039, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25198, Train Loss:0.00023, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25199, Train Loss:0.00916, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25200, Train Loss:0.02281, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25201, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25202, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25203, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25204, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25205, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25206, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25207, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25208, Train Loss:0.24908, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25209, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25210, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25211, Train Loss:0.00002, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25212, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25213, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25214, Train Loss:0.12792, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25215, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25216, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25217, Train Loss:0.00500, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25218, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25219, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25220, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25221, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25222, Train Loss:0.18613, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25223, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25224, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25225, Train Loss:0.00008, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25226, Train Loss:0.00060, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25227, Train Loss:0.07799, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25228, Train Loss:0.00013, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25229, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25230, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25231, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25232, Train Loss:0.03990, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25233, Train Loss:0.04458, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25234, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25235, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25236, Train Loss:0.06751, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25237, Train Loss:0.00574, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25238, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25239, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25240, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25241, Train Loss:0.00006, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25242, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25243, Train Loss:0.00005, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25244, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25245, Train Loss:0.00160, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25246, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25247, Train Loss:0.00001, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25248, Train Loss:0.00000, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25249, Train Loss:0.09608, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25250, Train Loss:0.17076, Dev Loss:0.08517\n",
      "Epoch:[91/100], step:25251, Train Loss:0.00378, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25252, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25253, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25254, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25255, Train Loss:0.01348, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25256, Train Loss:0.00004, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25257, Train Loss:0.08508, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25258, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25259, Train Loss:0.00004, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25260, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25261, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25262, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25263, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25264, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25265, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25266, Train Loss:0.04885, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25267, Train Loss:0.11356, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25268, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25269, Train Loss:0.00024, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25270, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25271, Train Loss:0.00067, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25272, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25273, Train Loss:0.08616, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25274, Train Loss:0.13497, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25275, Train Loss:0.00707, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25276, Train Loss:1.43582, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25277, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25278, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25279, Train Loss:0.06855, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25280, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25281, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25282, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25283, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25284, Train Loss:0.00042, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25285, Train Loss:0.28813, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25286, Train Loss:0.09358, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25287, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25288, Train Loss:0.00017, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25289, Train Loss:0.13441, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25290, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25291, Train Loss:0.00002, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25292, Train Loss:0.00234, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25293, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25294, Train Loss:0.01001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25295, Train Loss:0.00310, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25296, Train Loss:0.08137, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25297, Train Loss:0.00009, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25298, Train Loss:0.00029, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25299, Train Loss:0.00281, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25300, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25301, Train Loss:0.00463, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25302, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25303, Train Loss:0.11892, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25304, Train Loss:0.01013, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25305, Train Loss:0.15662, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25306, Train Loss:0.14499, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25307, Train Loss:0.00005, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25308, Train Loss:0.02569, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25309, Train Loss:0.16192, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25310, Train Loss:0.01908, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25311, Train Loss:0.04887, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25312, Train Loss:0.38669, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25313, Train Loss:0.19236, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25314, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25315, Train Loss:0.00344, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25316, Train Loss:0.00012, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25317, Train Loss:0.00007, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25318, Train Loss:0.00008, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25319, Train Loss:0.07568, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25320, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25321, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25322, Train Loss:0.00043, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25323, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25324, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25325, Train Loss:0.12294, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25326, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25327, Train Loss:0.00579, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25328, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25329, Train Loss:0.26033, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25330, Train Loss:0.00002, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25331, Train Loss:0.02784, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25332, Train Loss:0.02405, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25333, Train Loss:0.10667, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25334, Train Loss:0.00003, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25335, Train Loss:0.12843, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25336, Train Loss:0.00074, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25337, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25338, Train Loss:0.05543, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25339, Train Loss:0.00263, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25340, Train Loss:0.00097, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25341, Train Loss:0.09483, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25342, Train Loss:0.00025, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25343, Train Loss:0.00785, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25344, Train Loss:0.03102, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25345, Train Loss:0.00919, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25346, Train Loss:0.37445, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25347, Train Loss:0.06139, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25348, Train Loss:0.00003, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25349, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25350, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25351, Train Loss:1.04071, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25352, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25353, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25354, Train Loss:0.04913, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25355, Train Loss:0.00355, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25356, Train Loss:0.00757, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25357, Train Loss:0.09375, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25358, Train Loss:0.03570, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25359, Train Loss:0.02795, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25360, Train Loss:0.00279, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25361, Train Loss:0.16945, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25362, Train Loss:0.00556, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25363, Train Loss:0.00014, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25364, Train Loss:0.01452, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25365, Train Loss:0.03825, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25366, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25367, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25368, Train Loss:0.11944, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25369, Train Loss:0.02145, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25370, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25371, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25372, Train Loss:0.00201, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25373, Train Loss:0.01245, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25374, Train Loss:0.00042, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25375, Train Loss:0.00002, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25376, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25377, Train Loss:0.48591, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25378, Train Loss:0.05917, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25379, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25380, Train Loss:0.00138, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25381, Train Loss:0.00124, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25382, Train Loss:0.00686, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25383, Train Loss:0.00016, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25384, Train Loss:0.00167, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25385, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25386, Train Loss:0.01326, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25387, Train Loss:0.02724, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25388, Train Loss:0.11072, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25389, Train Loss:0.00191, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25390, Train Loss:0.01406, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25391, Train Loss:0.73393, Dev Loss:0.09909\n",
      "Epoch:[91/100], step:25392, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Start Epoch: 92, Steps: 17\n",
      "Epoch:[92/100], step:25393, Train Loss:0.38379, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25394, Train Loss:0.13484, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25395, Train Loss:0.07387, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25396, Train Loss:0.00003, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25397, Train Loss:0.20181, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25398, Train Loss:0.07913, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25399, Train Loss:0.01285, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25400, Train Loss:0.05499, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25401, Train Loss:0.17293, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25402, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25403, Train Loss:0.15638, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25404, Train Loss:0.02167, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25405, Train Loss:0.00027, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25406, Train Loss:0.00040, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25407, Train Loss:0.00009, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25408, Train Loss:0.00191, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25409, Train Loss:0.00086, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25410, Train Loss:0.01475, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25411, Train Loss:0.00144, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25412, Train Loss:0.00039, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25413, Train Loss:0.00008, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25414, Train Loss:0.11785, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25415, Train Loss:0.06781, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25416, Train Loss:0.00167, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25417, Train Loss:0.00285, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25418, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25419, Train Loss:0.18854, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25420, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25421, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25422, Train Loss:0.01477, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25423, Train Loss:0.05445, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25424, Train Loss:0.01272, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25425, Train Loss:0.01449, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25426, Train Loss:0.11820, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25427, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25428, Train Loss:0.06494, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25429, Train Loss:0.06763, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25430, Train Loss:0.08062, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25431, Train Loss:0.00336, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25432, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25433, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25434, Train Loss:0.00014, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25435, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25436, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25437, Train Loss:0.01841, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25438, Train Loss:0.00012, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25439, Train Loss:0.00069, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25440, Train Loss:0.15342, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25441, Train Loss:0.00007, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25442, Train Loss:0.00007, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25443, Train Loss:0.15223, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25444, Train Loss:0.07499, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25445, Train Loss:0.00088, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25446, Train Loss:0.14275, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25447, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25448, Train Loss:0.00012, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25449, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25450, Train Loss:0.00218, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25451, Train Loss:0.00003, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25452, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25453, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25454, Train Loss:0.03733, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25455, Train Loss:0.19620, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25456, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25457, Train Loss:0.00029, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25458, Train Loss:0.00089, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25459, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25460, Train Loss:0.02431, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25461, Train Loss:0.06673, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25462, Train Loss:0.20826, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25463, Train Loss:0.00496, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25464, Train Loss:0.00014, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25465, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25466, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25467, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25468, Train Loss:0.14139, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25469, Train Loss:0.21789, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25470, Train Loss:0.00074, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25471, Train Loss:0.10031, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25472, Train Loss:0.00491, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25473, Train Loss:0.00475, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25474, Train Loss:0.08284, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25475, Train Loss:0.37065, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25476, Train Loss:0.04950, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25477, Train Loss:0.00033, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25478, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25479, Train Loss:0.04284, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25480, Train Loss:0.17503, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25481, Train Loss:0.00070, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25482, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25483, Train Loss:0.12738, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25484, Train Loss:0.07398, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25485, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25486, Train Loss:0.12141, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25487, Train Loss:0.05657, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25488, Train Loss:0.06823, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25489, Train Loss:0.00044, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25490, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25491, Train Loss:0.00002, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25492, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25493, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25494, Train Loss:0.00002, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25495, Train Loss:0.00000, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25496, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25497, Train Loss:0.07619, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25498, Train Loss:0.00001, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25499, Train Loss:0.11585, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25500, Train Loss:0.00012, Dev Loss:0.09909\n",
      "Epoch:[92/100], step:25501, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25502, Train Loss:0.00002, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25503, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25504, Train Loss:0.02651, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25505, Train Loss:0.05434, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25506, Train Loss:0.00088, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25507, Train Loss:0.11968, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25508, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25509, Train Loss:0.00256, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25510, Train Loss:0.04275, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25511, Train Loss:0.03913, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25512, Train Loss:0.04832, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25513, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25514, Train Loss:0.02655, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25515, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25516, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25517, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25518, Train Loss:0.00003, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25519, Train Loss:0.00140, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25520, Train Loss:0.00182, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25521, Train Loss:0.01260, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25522, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25523, Train Loss:0.08340, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25524, Train Loss:0.03992, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25525, Train Loss:0.03038, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25526, Train Loss:0.00014, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25527, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25528, Train Loss:0.03961, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25529, Train Loss:0.15186, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25530, Train Loss:0.04843, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25531, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25532, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25533, Train Loss:0.01336, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25534, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25535, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25536, Train Loss:0.00005, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25537, Train Loss:0.01074, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25538, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25539, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25540, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25541, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25542, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25543, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25544, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25545, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25546, Train Loss:0.21409, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25547, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25548, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25549, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25550, Train Loss:0.00004, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25551, Train Loss:0.07947, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25552, Train Loss:0.00004, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25553, Train Loss:0.08614, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25554, Train Loss:0.97971, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25555, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25556, Train Loss:0.00016, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25557, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25558, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25559, Train Loss:0.00345, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25560, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25561, Train Loss:0.00148, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25562, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25563, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25564, Train Loss:0.43394, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25565, Train Loss:0.00229, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25566, Train Loss:0.16762, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25567, Train Loss:0.00104, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25568, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25569, Train Loss:0.00006, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25570, Train Loss:0.10693, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25571, Train Loss:0.08705, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25572, Train Loss:0.04933, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25573, Train Loss:0.10207, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25574, Train Loss:0.00031, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25575, Train Loss:0.07761, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25576, Train Loss:0.02767, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25577, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25578, Train Loss:0.00116, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25579, Train Loss:0.00660, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25580, Train Loss:0.03717, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25581, Train Loss:0.12578, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25582, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25583, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25584, Train Loss:0.86169, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25585, Train Loss:0.00642, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25586, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25587, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25588, Train Loss:0.01194, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25589, Train Loss:0.09790, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25590, Train Loss:0.10505, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25591, Train Loss:0.16656, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25592, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25593, Train Loss:0.20188, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25594, Train Loss:0.00002, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25595, Train Loss:0.31439, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25596, Train Loss:0.00022, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25597, Train Loss:0.00884, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25598, Train Loss:0.00531, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25599, Train Loss:0.00544, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25600, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25601, Train Loss:0.20424, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25602, Train Loss:0.00063, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25603, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25604, Train Loss:0.06567, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25605, Train Loss:0.00045, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25606, Train Loss:0.12284, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25607, Train Loss:0.13341, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25608, Train Loss:0.00044, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25609, Train Loss:0.06194, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25610, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25611, Train Loss:0.00032, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25612, Train Loss:0.06432, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25613, Train Loss:0.08442, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25614, Train Loss:0.02585, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25615, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25616, Train Loss:0.08230, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25617, Train Loss:0.02526, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25618, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25619, Train Loss:0.00626, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25620, Train Loss:0.12083, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25621, Train Loss:0.00060, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25622, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25623, Train Loss:0.06247, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25624, Train Loss:0.05201, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25625, Train Loss:0.00158, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25626, Train Loss:0.05953, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25627, Train Loss:0.79480, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25628, Train Loss:0.00026, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25629, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25630, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25631, Train Loss:0.00761, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25632, Train Loss:0.16324, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25633, Train Loss:0.00285, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25634, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25635, Train Loss:0.01830, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25636, Train Loss:0.00606, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25637, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25638, Train Loss:0.12738, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25639, Train Loss:0.03764, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25640, Train Loss:0.00098, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25641, Train Loss:0.04036, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25642, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25643, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25644, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25645, Train Loss:0.01400, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25646, Train Loss:0.26628, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25647, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25648, Train Loss:0.00003, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25649, Train Loss:0.02796, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25650, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25651, Train Loss:0.00507, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25652, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25653, Train Loss:0.00002, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25654, Train Loss:0.31479, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25655, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25656, Train Loss:0.00031, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25657, Train Loss:0.03476, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25658, Train Loss:0.17074, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25659, Train Loss:0.17854, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25660, Train Loss:0.00007, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25661, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25662, Train Loss:0.00036, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25663, Train Loss:0.02233, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25664, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25665, Train Loss:0.00020, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25666, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25667, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[92/100], step:25668, Train Loss:0.00045, Dev Loss:0.06123\n",
      "Start Epoch: 93, Steps: 17\n",
      "Epoch:[93/100], step:25669, Train Loss:0.00255, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25670, Train Loss:0.00099, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25671, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25672, Train Loss:0.04565, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25673, Train Loss:0.00414, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25674, Train Loss:0.00012, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25675, Train Loss:0.18060, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25676, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25677, Train Loss:0.16612, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25678, Train Loss:0.00112, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25679, Train Loss:0.00339, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25680, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25681, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25682, Train Loss:0.00004, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25683, Train Loss:0.02059, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25684, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25685, Train Loss:0.14754, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25686, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25687, Train Loss:0.53800, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25688, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25689, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25690, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25691, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25692, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25693, Train Loss:0.08372, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25694, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25695, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25696, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25697, Train Loss:0.01230, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25698, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25699, Train Loss:0.24651, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25700, Train Loss:0.00161, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25701, Train Loss:0.06166, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25702, Train Loss:0.00071, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25703, Train Loss:0.15785, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25704, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25705, Train Loss:0.00457, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25706, Train Loss:0.02109, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25707, Train Loss:0.00266, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25708, Train Loss:0.06745, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25709, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25710, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25711, Train Loss:0.00055, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25712, Train Loss:0.00671, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25713, Train Loss:0.01945, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25714, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25715, Train Loss:0.02190, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25716, Train Loss:0.13383, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25717, Train Loss:0.00007, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25718, Train Loss:0.00006, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25719, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25720, Train Loss:0.00016, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25721, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25722, Train Loss:0.07676, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25723, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25724, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25725, Train Loss:0.00217, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25726, Train Loss:0.01328, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25727, Train Loss:0.02647, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25728, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25729, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25730, Train Loss:0.18577, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25731, Train Loss:0.05662, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25732, Train Loss:0.00006, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25733, Train Loss:0.32765, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25734, Train Loss:0.00001, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25735, Train Loss:0.00058, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25736, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25737, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25738, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25739, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25740, Train Loss:0.00014, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25741, Train Loss:0.07210, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25742, Train Loss:0.00003, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25743, Train Loss:0.00179, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25744, Train Loss:0.00238, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25745, Train Loss:0.08488, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25746, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25747, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25748, Train Loss:0.35568, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25749, Train Loss:0.01933, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25750, Train Loss:0.00000, Dev Loss:0.06123\n",
      "Epoch:[93/100], step:25751, Train Loss:0.14509, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25752, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25753, Train Loss:0.14833, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25754, Train Loss:0.00258, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25755, Train Loss:0.08387, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25756, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25757, Train Loss:0.08279, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25758, Train Loss:0.05535, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25759, Train Loss:0.05286, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25760, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25761, Train Loss:0.00002, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25762, Train Loss:0.01466, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25763, Train Loss:0.00469, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25764, Train Loss:0.02720, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25765, Train Loss:0.00009, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25766, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25767, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25768, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25769, Train Loss:0.00023, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25770, Train Loss:0.00521, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25771, Train Loss:0.08033, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25772, Train Loss:0.04194, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25773, Train Loss:0.01931, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25774, Train Loss:0.01355, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25775, Train Loss:0.37236, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25776, Train Loss:0.03727, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25777, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25778, Train Loss:0.04317, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25779, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25780, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25781, Train Loss:0.18426, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25782, Train Loss:0.00012, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25783, Train Loss:0.03601, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25784, Train Loss:0.03942, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25785, Train Loss:0.24837, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25786, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25787, Train Loss:0.00007, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25788, Train Loss:0.01453, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25789, Train Loss:0.00006, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25790, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25791, Train Loss:0.02527, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25792, Train Loss:0.11202, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25793, Train Loss:0.18159, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25794, Train Loss:0.03886, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25795, Train Loss:0.13906, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25796, Train Loss:0.00059, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25797, Train Loss:0.15561, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25798, Train Loss:0.06441, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25799, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25800, Train Loss:0.00003, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25801, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25802, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25803, Train Loss:0.02767, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25804, Train Loss:0.00563, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25805, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25806, Train Loss:0.01454, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25807, Train Loss:2.30472, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25808, Train Loss:0.18027, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25809, Train Loss:0.13766, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25810, Train Loss:0.00071, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25811, Train Loss:0.03656, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25812, Train Loss:0.03078, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25813, Train Loss:0.25898, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25814, Train Loss:0.00013, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25815, Train Loss:0.04748, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25816, Train Loss:0.13126, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25817, Train Loss:0.14309, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25818, Train Loss:0.15253, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25819, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25820, Train Loss:0.00101, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25821, Train Loss:0.05280, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25822, Train Loss:0.30051, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25823, Train Loss:0.01509, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25824, Train Loss:0.12225, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25825, Train Loss:0.00196, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25826, Train Loss:0.04145, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25827, Train Loss:0.00001, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25828, Train Loss:0.03949, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25829, Train Loss:0.00001, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25830, Train Loss:0.09040, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25831, Train Loss:0.12738, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25832, Train Loss:0.00004, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25833, Train Loss:0.02025, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25834, Train Loss:0.00152, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25835, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25836, Train Loss:0.00441, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25837, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25838, Train Loss:0.21272, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25839, Train Loss:0.31113, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25840, Train Loss:0.01368, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25841, Train Loss:0.01325, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25842, Train Loss:0.01884, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25843, Train Loss:0.00947, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25844, Train Loss:0.00001, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25845, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25846, Train Loss:0.17342, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25847, Train Loss:0.08802, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25848, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25849, Train Loss:0.07303, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25850, Train Loss:0.17557, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25851, Train Loss:0.00046, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25852, Train Loss:0.00075, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25853, Train Loss:0.00007, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25854, Train Loss:0.02940, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25855, Train Loss:0.00021, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25856, Train Loss:0.00005, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25857, Train Loss:0.00007, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25858, Train Loss:0.00015, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25859, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25860, Train Loss:0.30144, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25861, Train Loss:0.00011, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25862, Train Loss:0.06058, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25863, Train Loss:0.02870, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25864, Train Loss:0.00492, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25865, Train Loss:0.03028, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25866, Train Loss:0.12685, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25867, Train Loss:0.09351, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25868, Train Loss:0.33694, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25869, Train Loss:0.04922, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25870, Train Loss:0.01120, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25871, Train Loss:0.00020, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25872, Train Loss:0.00292, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25873, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25874, Train Loss:0.00038, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25875, Train Loss:0.00024, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25876, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25877, Train Loss:0.00001, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25878, Train Loss:0.16654, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25879, Train Loss:0.04633, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25880, Train Loss:0.00137, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25881, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25882, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25883, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25884, Train Loss:0.01927, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25885, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25886, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25887, Train Loss:0.02288, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25888, Train Loss:0.02083, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25889, Train Loss:0.29365, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25890, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25891, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25892, Train Loss:0.57176, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25893, Train Loss:0.00168, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25894, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25895, Train Loss:0.18588, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25896, Train Loss:0.01685, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25897, Train Loss:0.00026, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25898, Train Loss:0.00030, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25899, Train Loss:0.04331, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25900, Train Loss:0.12007, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25901, Train Loss:0.00018, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25902, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25903, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25904, Train Loss:0.00008, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25905, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25906, Train Loss:0.00012, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25907, Train Loss:0.00091, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25908, Train Loss:0.01028, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25909, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25910, Train Loss:0.00003, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25911, Train Loss:0.04479, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25912, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25913, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25914, Train Loss:0.00003, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25915, Train Loss:0.16776, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25916, Train Loss:0.00227, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25917, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25918, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25919, Train Loss:0.01464, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25920, Train Loss:0.03444, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25921, Train Loss:0.00002, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25922, Train Loss:0.00251, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25923, Train Loss:0.03896, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25924, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25925, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25926, Train Loss:0.00501, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25927, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25928, Train Loss:2.08126, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25929, Train Loss:0.42303, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25930, Train Loss:0.00001, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25931, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25932, Train Loss:0.00448, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25933, Train Loss:0.00081, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25934, Train Loss:0.00076, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25935, Train Loss:0.18319, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25936, Train Loss:1.09428, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25937, Train Loss:0.38522, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25938, Train Loss:0.50279, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25939, Train Loss:1.14466, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25940, Train Loss:0.01114, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25941, Train Loss:0.02195, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25942, Train Loss:0.00032, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25943, Train Loss:0.00002, Dev Loss:0.04849\n",
      "Epoch:[93/100], step:25944, Train Loss:0.00016, Dev Loss:0.04849\n",
      "Start Epoch: 94, Steps: 17\n",
      "Epoch:[94/100], step:25945, Train Loss:0.23295, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25946, Train Loss:0.95139, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25947, Train Loss:0.13963, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25948, Train Loss:0.28218, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25949, Train Loss:0.38314, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25950, Train Loss:0.00003, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25951, Train Loss:0.61512, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25952, Train Loss:0.01128, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25953, Train Loss:0.26214, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25954, Train Loss:0.10379, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25955, Train Loss:0.00020, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25956, Train Loss:0.07614, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25957, Train Loss:0.00012, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25958, Train Loss:0.17234, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25959, Train Loss:0.00222, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25960, Train Loss:1.06200, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25961, Train Loss:0.00607, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25962, Train Loss:0.19800, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25963, Train Loss:0.24107, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25964, Train Loss:0.00170, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25965, Train Loss:0.00065, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25966, Train Loss:0.00736, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25967, Train Loss:0.07610, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25968, Train Loss:0.00179, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25969, Train Loss:0.18528, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25970, Train Loss:0.02032, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25971, Train Loss:0.00707, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25972, Train Loss:0.00042, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25973, Train Loss:0.00789, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25974, Train Loss:0.01624, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25975, Train Loss:0.06849, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25976, Train Loss:0.19397, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25977, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25978, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25979, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25980, Train Loss:0.28398, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25981, Train Loss:0.00368, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25982, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25983, Train Loss:0.00003, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25984, Train Loss:0.30103, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25985, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25986, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25987, Train Loss:0.00357, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25988, Train Loss:0.00020, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25989, Train Loss:0.02586, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25990, Train Loss:0.00201, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25991, Train Loss:0.29453, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25992, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25993, Train Loss:0.44954, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25994, Train Loss:0.37540, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25995, Train Loss:0.00007, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25996, Train Loss:0.00071, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25997, Train Loss:0.00005, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25998, Train Loss:0.00060, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:25999, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:26000, Train Loss:0.00000, Dev Loss:0.04849\n",
      "Epoch:[94/100], step:26001, Train Loss:0.00153, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26002, Train Loss:0.00547, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26003, Train Loss:1.50128, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26004, Train Loss:3.22368, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26005, Train Loss:0.00003, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26006, Train Loss:0.22799, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26007, Train Loss:1.09353, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26008, Train Loss:0.00004, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26009, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26010, Train Loss:0.00298, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26011, Train Loss:0.10002, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26012, Train Loss:0.02504, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26013, Train Loss:0.15693, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26014, Train Loss:0.61831, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26015, Train Loss:0.14118, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26016, Train Loss:0.46083, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26017, Train Loss:0.39656, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26018, Train Loss:0.01359, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26019, Train Loss:0.08488, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26020, Train Loss:0.14558, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26021, Train Loss:0.07764, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26022, Train Loss:0.08450, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26023, Train Loss:0.00007, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26024, Train Loss:0.64472, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26025, Train Loss:0.16615, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26026, Train Loss:0.16862, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26027, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26028, Train Loss:0.16109, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26029, Train Loss:0.00481, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26030, Train Loss:0.01727, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26031, Train Loss:0.97678, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26032, Train Loss:0.08913, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26033, Train Loss:0.09070, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26034, Train Loss:0.10514, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26035, Train Loss:0.12312, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26036, Train Loss:0.33412, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26037, Train Loss:0.02580, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26038, Train Loss:0.00010, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26039, Train Loss:0.05213, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26040, Train Loss:0.00004, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26041, Train Loss:0.01925, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26042, Train Loss:0.15098, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26043, Train Loss:0.03023, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26044, Train Loss:0.00007, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26045, Train Loss:0.15984, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26046, Train Loss:0.09783, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26047, Train Loss:0.05032, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26048, Train Loss:0.00030, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26049, Train Loss:0.09332, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26050, Train Loss:0.06157, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26051, Train Loss:0.50666, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26052, Train Loss:0.11641, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26053, Train Loss:0.00001, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26054, Train Loss:0.99363, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26055, Train Loss:0.00011, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26056, Train Loss:0.00010, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26057, Train Loss:0.23066, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26058, Train Loss:0.54262, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26059, Train Loss:0.00018, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26060, Train Loss:0.00221, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26061, Train Loss:0.19243, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26062, Train Loss:0.00102, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26063, Train Loss:0.01089, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26064, Train Loss:0.70942, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26065, Train Loss:0.24808, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26066, Train Loss:0.22552, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26067, Train Loss:0.11956, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26068, Train Loss:0.23897, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26069, Train Loss:0.13008, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26070, Train Loss:0.18812, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26071, Train Loss:0.79116, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26072, Train Loss:0.07009, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26073, Train Loss:0.01878, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26074, Train Loss:0.08130, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26075, Train Loss:0.01421, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26076, Train Loss:0.19301, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26077, Train Loss:0.00001, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26078, Train Loss:0.34405, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26079, Train Loss:0.01960, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26080, Train Loss:0.11702, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26081, Train Loss:0.00002, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26082, Train Loss:1.72772, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26083, Train Loss:0.07692, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26084, Train Loss:0.04469, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26085, Train Loss:0.09089, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26086, Train Loss:0.10634, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26087, Train Loss:0.08977, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26088, Train Loss:0.05497, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26089, Train Loss:0.25206, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26090, Train Loss:0.20823, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26091, Train Loss:0.00831, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26092, Train Loss:0.00201, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26093, Train Loss:0.05076, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26094, Train Loss:0.03835, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26095, Train Loss:0.00036, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26096, Train Loss:0.17897, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26097, Train Loss:0.00303, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26098, Train Loss:0.08051, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26099, Train Loss:1.01062, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26100, Train Loss:0.12134, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26101, Train Loss:0.01182, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26102, Train Loss:0.14522, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26103, Train Loss:0.18933, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26104, Train Loss:0.06980, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26105, Train Loss:0.04762, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26106, Train Loss:0.00079, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26107, Train Loss:0.11360, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26108, Train Loss:0.00580, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26109, Train Loss:0.00069, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26110, Train Loss:0.15325, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26111, Train Loss:0.00398, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26112, Train Loss:0.00537, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26113, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26114, Train Loss:0.00008, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26115, Train Loss:0.00067, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26116, Train Loss:0.00308, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26117, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26118, Train Loss:0.03564, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26119, Train Loss:0.00001, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26120, Train Loss:0.01246, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26121, Train Loss:0.00009, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26122, Train Loss:0.00004, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26123, Train Loss:0.07318, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26124, Train Loss:0.00008, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26125, Train Loss:0.00173, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26126, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26127, Train Loss:0.05195, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26128, Train Loss:0.21008, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26129, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26130, Train Loss:0.09758, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26131, Train Loss:0.00422, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26132, Train Loss:0.13047, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26133, Train Loss:0.08675, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26134, Train Loss:0.01697, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26135, Train Loss:0.01781, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26136, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26137, Train Loss:0.08893, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26138, Train Loss:0.00026, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26139, Train Loss:0.00238, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26140, Train Loss:0.25359, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26141, Train Loss:0.00574, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26142, Train Loss:0.16402, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26143, Train Loss:0.50040, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26144, Train Loss:0.27544, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26145, Train Loss:0.10903, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26146, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26147, Train Loss:0.16906, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26148, Train Loss:0.03834, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26149, Train Loss:0.74499, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26150, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26151, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26152, Train Loss:0.00015, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26153, Train Loss:0.01011, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26154, Train Loss:0.10270, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26155, Train Loss:0.00001, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26156, Train Loss:0.18969, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26157, Train Loss:0.00409, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26158, Train Loss:0.04319, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26159, Train Loss:0.00009, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26160, Train Loss:0.22066, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26161, Train Loss:0.10804, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26162, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26163, Train Loss:0.00221, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26164, Train Loss:0.17043, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26165, Train Loss:0.00862, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26166, Train Loss:0.08034, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26167, Train Loss:0.00003, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26168, Train Loss:0.08107, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26169, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26170, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26171, Train Loss:0.20266, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26172, Train Loss:0.02502, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26173, Train Loss:2.17050, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26174, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26175, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26176, Train Loss:0.09589, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26177, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26178, Train Loss:0.27016, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26179, Train Loss:0.67186, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26180, Train Loss:0.37529, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26181, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26182, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26183, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26184, Train Loss:0.44433, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26185, Train Loss:0.00006, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26186, Train Loss:0.01965, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26187, Train Loss:1.73018, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26188, Train Loss:0.02134, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26189, Train Loss:0.13541, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26190, Train Loss:0.00065, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26191, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26192, Train Loss:0.20244, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26193, Train Loss:0.09257, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26194, Train Loss:0.10238, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26195, Train Loss:0.05218, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26196, Train Loss:0.04822, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26197, Train Loss:0.03149, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26198, Train Loss:1.29769, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26199, Train Loss:0.10639, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26200, Train Loss:0.03737, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26201, Train Loss:0.00649, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26202, Train Loss:0.04619, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26203, Train Loss:0.06308, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26204, Train Loss:0.53788, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26205, Train Loss:0.51158, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26206, Train Loss:0.20026, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26207, Train Loss:0.17260, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26208, Train Loss:0.11887, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26209, Train Loss:0.05570, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26210, Train Loss:0.02448, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26211, Train Loss:0.00000, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26212, Train Loss:0.00262, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26213, Train Loss:0.22541, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26214, Train Loss:0.00920, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26215, Train Loss:0.07950, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26216, Train Loss:0.01214, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26217, Train Loss:0.00171, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26218, Train Loss:0.00029, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26219, Train Loss:0.11146, Dev Loss:0.11880\n",
      "Epoch:[94/100], step:26220, Train Loss:1.09294, Dev Loss:0.11880\n",
      "Start Epoch: 95, Steps: 17\n",
      "Epoch:[95/100], step:26221, Train Loss:0.14240, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26222, Train Loss:0.25415, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26223, Train Loss:0.17175, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26224, Train Loss:0.00006, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26225, Train Loss:0.05969, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26226, Train Loss:0.09581, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26227, Train Loss:0.02229, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26228, Train Loss:0.10966, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26229, Train Loss:0.02584, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26230, Train Loss:0.01769, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26231, Train Loss:0.02465, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26232, Train Loss:0.43039, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26233, Train Loss:0.02402, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26234, Train Loss:0.08540, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26235, Train Loss:0.05089, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26236, Train Loss:0.04591, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26237, Train Loss:0.00032, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26238, Train Loss:0.10515, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26239, Train Loss:0.02154, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26240, Train Loss:0.01278, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26241, Train Loss:0.40033, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26242, Train Loss:0.09954, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26243, Train Loss:0.00134, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26244, Train Loss:0.13661, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26245, Train Loss:0.00033, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26246, Train Loss:0.02204, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26247, Train Loss:0.16213, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26248, Train Loss:0.00006, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26249, Train Loss:0.05247, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26250, Train Loss:0.01956, Dev Loss:0.11880\n",
      "Epoch:[95/100], step:26251, Train Loss:0.02286, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26252, Train Loss:0.00030, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26253, Train Loss:0.02995, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26254, Train Loss:0.00443, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26255, Train Loss:0.90175, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26256, Train Loss:0.06340, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26257, Train Loss:0.41434, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26258, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26259, Train Loss:0.11483, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26260, Train Loss:0.08457, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26261, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26262, Train Loss:0.10386, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26263, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26264, Train Loss:0.00649, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26265, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26266, Train Loss:0.26245, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26267, Train Loss:0.01740, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26268, Train Loss:0.00284, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26269, Train Loss:0.00061, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26270, Train Loss:0.03049, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26271, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26272, Train Loss:0.09420, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26273, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26274, Train Loss:0.00288, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26275, Train Loss:0.01867, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26276, Train Loss:0.13638, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26277, Train Loss:0.19655, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26278, Train Loss:0.00554, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26279, Train Loss:0.37290, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26280, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26281, Train Loss:0.00983, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26282, Train Loss:0.00935, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26283, Train Loss:0.28165, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26284, Train Loss:0.21060, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26285, Train Loss:0.10663, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26286, Train Loss:0.02339, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26287, Train Loss:0.15610, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26288, Train Loss:0.07091, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26289, Train Loss:0.15414, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26290, Train Loss:0.03115, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26291, Train Loss:0.13630, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26292, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26293, Train Loss:0.32479, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26294, Train Loss:0.06131, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26295, Train Loss:0.18491, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26296, Train Loss:0.00069, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26297, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26298, Train Loss:0.73524, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26299, Train Loss:0.46534, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26300, Train Loss:0.02812, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26301, Train Loss:0.00624, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26302, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26303, Train Loss:0.00022, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26304, Train Loss:0.00018, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26305, Train Loss:0.10119, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26306, Train Loss:0.18694, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26307, Train Loss:0.40399, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26308, Train Loss:0.00002, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26309, Train Loss:0.00904, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26310, Train Loss:0.15750, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26311, Train Loss:0.03507, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26312, Train Loss:0.01551, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26313, Train Loss:0.59567, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26314, Train Loss:0.10250, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26315, Train Loss:0.02879, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26316, Train Loss:0.01678, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26317, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26318, Train Loss:0.06781, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26319, Train Loss:0.00143, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26320, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26321, Train Loss:0.12052, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26322, Train Loss:0.01126, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26323, Train Loss:0.08390, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26324, Train Loss:0.09982, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26325, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26326, Train Loss:0.29226, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26327, Train Loss:0.04355, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26328, Train Loss:0.00080, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26329, Train Loss:0.07590, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26330, Train Loss:0.00573, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26331, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26332, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26333, Train Loss:0.03536, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26334, Train Loss:0.01718, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26335, Train Loss:0.33287, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26336, Train Loss:0.08134, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26337, Train Loss:0.00006, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26338, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26339, Train Loss:0.50769, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26340, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26341, Train Loss:0.48710, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26342, Train Loss:0.00381, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26343, Train Loss:0.01204, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26344, Train Loss:0.06655, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26345, Train Loss:0.00011, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26346, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26347, Train Loss:0.00184, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26348, Train Loss:0.00182, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26349, Train Loss:0.00844, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26350, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26351, Train Loss:0.00865, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26352, Train Loss:0.00009, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26353, Train Loss:0.14075, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26354, Train Loss:0.00396, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26355, Train Loss:0.03114, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26356, Train Loss:0.08149, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26357, Train Loss:0.00015, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26358, Train Loss:0.05056, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26359, Train Loss:0.09651, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26360, Train Loss:0.22602, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26361, Train Loss:0.08662, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26362, Train Loss:0.04411, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26363, Train Loss:0.00147, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26364, Train Loss:0.01303, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26365, Train Loss:0.00018, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26366, Train Loss:0.19079, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26367, Train Loss:0.00172, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26368, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26369, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26370, Train Loss:0.03469, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26371, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26372, Train Loss:0.01748, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26373, Train Loss:0.73227, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26374, Train Loss:0.00011, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26375, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26376, Train Loss:0.00118, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26377, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26378, Train Loss:0.10070, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26379, Train Loss:0.03805, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26380, Train Loss:0.00183, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26381, Train Loss:0.05715, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26382, Train Loss:0.05796, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26383, Train Loss:0.00013, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26384, Train Loss:0.18270, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26385, Train Loss:0.00005, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26386, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26387, Train Loss:0.09215, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26388, Train Loss:0.00155, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26389, Train Loss:0.42157, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26390, Train Loss:0.00354, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26391, Train Loss:0.00119, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26392, Train Loss:0.10815, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26393, Train Loss:0.00042, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26394, Train Loss:0.14172, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26395, Train Loss:0.84615, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26396, Train Loss:0.00022, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26397, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26398, Train Loss:0.05299, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26399, Train Loss:0.23205, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26400, Train Loss:0.26173, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26401, Train Loss:0.01719, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26402, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26403, Train Loss:0.29918, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26404, Train Loss:0.27950, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26405, Train Loss:0.13869, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26406, Train Loss:0.05451, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26407, Train Loss:0.00001, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26408, Train Loss:0.09628, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26409, Train Loss:0.09912, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26410, Train Loss:6.08761, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26411, Train Loss:0.13083, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26412, Train Loss:0.49619, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26413, Train Loss:0.00000, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26414, Train Loss:0.57479, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26415, Train Loss:0.00439, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26416, Train Loss:0.40577, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26417, Train Loss:0.59143, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26418, Train Loss:0.00420, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26419, Train Loss:0.14216, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26420, Train Loss:0.09255, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26421, Train Loss:0.91519, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26422, Train Loss:0.20938, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26423, Train Loss:1.15054, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26424, Train Loss:0.24864, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26425, Train Loss:1.03482, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26426, Train Loss:1.35011, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26427, Train Loss:0.67058, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26428, Train Loss:0.66959, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26429, Train Loss:0.63171, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26430, Train Loss:0.17962, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26431, Train Loss:0.17736, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26432, Train Loss:0.36488, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26433, Train Loss:0.28341, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26434, Train Loss:0.26134, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26435, Train Loss:0.55442, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26436, Train Loss:0.18077, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26437, Train Loss:0.04239, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26438, Train Loss:0.28474, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26439, Train Loss:0.00004, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26440, Train Loss:0.44431, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26441, Train Loss:0.15812, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26442, Train Loss:0.40437, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26443, Train Loss:0.10166, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26444, Train Loss:0.32387, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26445, Train Loss:0.31477, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26446, Train Loss:0.34327, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26447, Train Loss:0.56669, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26448, Train Loss:0.38110, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26449, Train Loss:0.04778, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26450, Train Loss:0.21313, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26451, Train Loss:0.23029, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26452, Train Loss:0.46992, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26453, Train Loss:0.17383, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26454, Train Loss:0.20038, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26455, Train Loss:0.93232, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26456, Train Loss:0.17233, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26457, Train Loss:0.51682, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26458, Train Loss:0.16245, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26459, Train Loss:0.16450, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26460, Train Loss:0.65929, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26461, Train Loss:1.05392, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26462, Train Loss:0.05325, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26463, Train Loss:0.10324, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26464, Train Loss:0.16494, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26465, Train Loss:0.17215, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26466, Train Loss:0.01465, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26467, Train Loss:0.30247, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26468, Train Loss:0.00003, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26469, Train Loss:0.16279, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26470, Train Loss:0.20249, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26471, Train Loss:0.36082, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26472, Train Loss:0.04300, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26473, Train Loss:0.89569, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26474, Train Loss:0.33474, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26475, Train Loss:0.00007, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26476, Train Loss:0.00313, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26477, Train Loss:0.10830, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26478, Train Loss:0.54302, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26479, Train Loss:0.10656, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26480, Train Loss:0.00714, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26481, Train Loss:0.29008, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26482, Train Loss:0.01403, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26483, Train Loss:0.26981, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26484, Train Loss:0.00173, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26485, Train Loss:0.04765, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26486, Train Loss:0.05829, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26487, Train Loss:0.39412, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26488, Train Loss:0.03465, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26489, Train Loss:0.17695, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26490, Train Loss:0.47461, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26491, Train Loss:0.34318, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26492, Train Loss:0.04957, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26493, Train Loss:0.02793, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26494, Train Loss:0.10320, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26495, Train Loss:0.62508, Dev Loss:0.18641\n",
      "Epoch:[95/100], step:26496, Train Loss:0.06193, Dev Loss:0.18641\n",
      "Start Epoch: 96, Steps: 17\n",
      "Epoch:[96/100], step:26497, Train Loss:0.03428, Dev Loss:0.18641\n",
      "Epoch:[96/100], step:26498, Train Loss:0.44964, Dev Loss:0.18641\n",
      "Epoch:[96/100], step:26499, Train Loss:0.14914, Dev Loss:0.18641\n",
      "Epoch:[96/100], step:26500, Train Loss:0.01498, Dev Loss:0.18641\n",
      "Epoch:[96/100], step:26501, Train Loss:0.00057, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26502, Train Loss:0.00846, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26503, Train Loss:0.03561, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26504, Train Loss:0.00916, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26505, Train Loss:0.04629, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26506, Train Loss:0.11190, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26507, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26508, Train Loss:0.00024, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26509, Train Loss:0.32708, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26510, Train Loss:0.35313, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26511, Train Loss:0.34408, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26512, Train Loss:0.02126, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26513, Train Loss:0.34093, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26514, Train Loss:0.05281, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26515, Train Loss:0.00017, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26516, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26517, Train Loss:0.29603, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26518, Train Loss:0.04970, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26519, Train Loss:0.19003, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26520, Train Loss:0.09983, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26521, Train Loss:0.09905, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26522, Train Loss:0.20585, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26523, Train Loss:0.13383, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26524, Train Loss:0.03275, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26525, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26526, Train Loss:0.00211, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26527, Train Loss:0.13384, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26528, Train Loss:0.08095, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26529, Train Loss:0.00335, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26530, Train Loss:0.20890, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26531, Train Loss:0.00361, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26532, Train Loss:0.05249, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26533, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26534, Train Loss:0.00003, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26535, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26536, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26537, Train Loss:0.36065, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26538, Train Loss:0.00451, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26539, Train Loss:0.00044, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26540, Train Loss:0.19680, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26541, Train Loss:0.04370, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26542, Train Loss:0.22127, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26543, Train Loss:0.12843, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26544, Train Loss:0.00200, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26545, Train Loss:0.04175, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26546, Train Loss:0.01291, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26547, Train Loss:0.13894, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26548, Train Loss:0.10257, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26549, Train Loss:0.00833, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26550, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26551, Train Loss:0.18408, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26552, Train Loss:0.00007, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26553, Train Loss:0.00151, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26554, Train Loss:0.21004, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26555, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26556, Train Loss:0.12835, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26557, Train Loss:2.02261, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26558, Train Loss:0.08096, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26559, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26560, Train Loss:0.04753, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26561, Train Loss:0.00014, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26562, Train Loss:2.03280, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26563, Train Loss:0.00001, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26564, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26565, Train Loss:0.00687, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26566, Train Loss:0.00001, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26567, Train Loss:0.11378, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26568, Train Loss:0.08221, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26569, Train Loss:0.30108, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26570, Train Loss:1.57389, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26571, Train Loss:0.19131, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26572, Train Loss:0.14299, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26573, Train Loss:0.00006, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26574, Train Loss:0.12124, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26575, Train Loss:0.20872, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26576, Train Loss:0.00011, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26577, Train Loss:0.12589, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26578, Train Loss:0.51890, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26579, Train Loss:0.20541, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26580, Train Loss:0.10699, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26581, Train Loss:0.00211, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26582, Train Loss:0.10244, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26583, Train Loss:0.70312, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26584, Train Loss:0.28354, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26585, Train Loss:0.03173, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26586, Train Loss:0.01241, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26587, Train Loss:0.04922, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26588, Train Loss:0.12661, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26589, Train Loss:0.66481, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26590, Train Loss:0.20970, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26591, Train Loss:0.42438, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26592, Train Loss:1.66603, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26593, Train Loss:0.04193, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26594, Train Loss:0.52914, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26595, Train Loss:0.00174, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26596, Train Loss:0.21248, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26597, Train Loss:0.05464, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26598, Train Loss:0.10022, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26599, Train Loss:0.21729, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26600, Train Loss:2.88965, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26601, Train Loss:0.02435, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26602, Train Loss:0.04714, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26603, Train Loss:0.00955, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26604, Train Loss:0.36883, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26605, Train Loss:0.44491, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26606, Train Loss:0.01874, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26607, Train Loss:0.47082, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26608, Train Loss:0.13320, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26609, Train Loss:0.21645, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26610, Train Loss:0.13965, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26611, Train Loss:0.07948, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26612, Train Loss:0.11475, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26613, Train Loss:0.14615, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26614, Train Loss:0.15858, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26615, Train Loss:0.00674, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26616, Train Loss:0.18309, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26617, Train Loss:0.06876, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26618, Train Loss:0.59768, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26619, Train Loss:0.25847, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26620, Train Loss:0.06917, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26621, Train Loss:0.02972, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26622, Train Loss:0.10479, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26623, Train Loss:0.17861, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26624, Train Loss:0.47460, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26625, Train Loss:0.03871, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26626, Train Loss:0.10762, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26627, Train Loss:0.10615, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26628, Train Loss:0.00084, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26629, Train Loss:0.00118, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26630, Train Loss:0.00189, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26631, Train Loss:0.28451, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26632, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26633, Train Loss:0.11263, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26634, Train Loss:0.19755, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26635, Train Loss:1.44913, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26636, Train Loss:0.14969, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26637, Train Loss:0.04368, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26638, Train Loss:0.40256, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26639, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26640, Train Loss:0.00059, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26641, Train Loss:0.03364, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26642, Train Loss:0.15738, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26643, Train Loss:0.01657, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26644, Train Loss:0.00002, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26645, Train Loss:0.58972, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26646, Train Loss:0.15099, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26647, Train Loss:0.00155, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26648, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26649, Train Loss:0.88258, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26650, Train Loss:0.83075, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26651, Train Loss:0.07559, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26652, Train Loss:0.00940, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26653, Train Loss:0.00108, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26654, Train Loss:0.55470, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26655, Train Loss:0.04829, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26656, Train Loss:0.03354, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26657, Train Loss:0.14617, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26658, Train Loss:0.44987, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26659, Train Loss:0.00011, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26660, Train Loss:0.06692, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26661, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26662, Train Loss:0.01029, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26663, Train Loss:0.00017, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26664, Train Loss:0.00099, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26665, Train Loss:0.00001, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26666, Train Loss:0.03051, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26667, Train Loss:0.00544, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26668, Train Loss:0.00018, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26669, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26670, Train Loss:0.04716, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26671, Train Loss:0.00001, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26672, Train Loss:0.01456, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26673, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26674, Train Loss:0.00431, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26675, Train Loss:0.01917, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26676, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26677, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26678, Train Loss:0.03961, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26679, Train Loss:0.09454, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26680, Train Loss:0.00096, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26681, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26682, Train Loss:0.00001, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26683, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26684, Train Loss:0.15096, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26685, Train Loss:0.17681, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26686, Train Loss:0.00003, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26687, Train Loss:0.12329, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26688, Train Loss:0.00311, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26689, Train Loss:0.00004, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26690, Train Loss:0.20508, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26691, Train Loss:0.32439, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26692, Train Loss:0.00002, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26693, Train Loss:0.00871, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26694, Train Loss:0.00104, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26695, Train Loss:0.00004, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26696, Train Loss:0.00006, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26697, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26698, Train Loss:0.13032, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26699, Train Loss:0.10198, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26700, Train Loss:0.00116, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26701, Train Loss:0.32458, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26702, Train Loss:0.05600, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26703, Train Loss:0.10329, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26704, Train Loss:0.00006, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26705, Train Loss:0.09220, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26706, Train Loss:0.07657, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26707, Train Loss:0.00550, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26708, Train Loss:0.03173, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26709, Train Loss:0.29650, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26710, Train Loss:2.08802, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26711, Train Loss:0.17913, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26712, Train Loss:0.05529, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26713, Train Loss:0.43267, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26714, Train Loss:0.00030, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26715, Train Loss:0.09326, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26716, Train Loss:0.10053, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26717, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26718, Train Loss:0.61281, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26719, Train Loss:0.48894, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26720, Train Loss:0.00650, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26721, Train Loss:0.00867, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26722, Train Loss:0.00248, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26723, Train Loss:0.04677, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26724, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26725, Train Loss:0.00270, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26726, Train Loss:0.14698, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26727, Train Loss:0.41069, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26728, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26729, Train Loss:0.09981, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26730, Train Loss:0.05737, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26731, Train Loss:0.01268, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26732, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26733, Train Loss:0.00107, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26734, Train Loss:0.13857, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26735, Train Loss:0.11025, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26736, Train Loss:0.23697, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26737, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26738, Train Loss:0.00133, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26739, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26740, Train Loss:0.00002, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26741, Train Loss:0.02031, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26742, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26743, Train Loss:0.04548, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26744, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26745, Train Loss:0.17396, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26746, Train Loss:0.15285, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26747, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26748, Train Loss:0.00134, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26749, Train Loss:0.41907, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26750, Train Loss:0.00000, Dev Loss:0.13559\n",
      "Epoch:[96/100], step:26751, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26752, Train Loss:0.00035, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26753, Train Loss:0.31434, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26754, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26755, Train Loss:0.12360, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26756, Train Loss:0.06061, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26757, Train Loss:0.01883, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26758, Train Loss:0.12098, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26759, Train Loss:0.08381, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26760, Train Loss:0.01035, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26761, Train Loss:0.07734, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26762, Train Loss:0.10994, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26763, Train Loss:0.00032, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26764, Train Loss:0.11722, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26765, Train Loss:0.08718, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26766, Train Loss:0.02453, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26767, Train Loss:1.61313, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26768, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26769, Train Loss:0.14597, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26770, Train Loss:0.05781, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26771, Train Loss:0.12702, Dev Loss:0.09819\n",
      "Epoch:[96/100], step:26772, Train Loss:0.09717, Dev Loss:0.09819\n",
      "Start Epoch: 97, Steps: 17\n",
      "Epoch:[97/100], step:26773, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26774, Train Loss:0.01626, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26775, Train Loss:0.13556, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26776, Train Loss:0.07612, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26777, Train Loss:0.60282, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26778, Train Loss:0.00536, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26779, Train Loss:0.00175, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26780, Train Loss:0.00380, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26781, Train Loss:0.00003, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26782, Train Loss:0.00045, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26783, Train Loss:0.00179, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26784, Train Loss:0.02667, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26785, Train Loss:0.00119, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26786, Train Loss:0.06962, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26787, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26788, Train Loss:0.08796, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26789, Train Loss:0.01025, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26790, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26791, Train Loss:0.00324, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26792, Train Loss:0.00004, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26793, Train Loss:0.06327, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26794, Train Loss:0.24757, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26795, Train Loss:0.00947, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26796, Train Loss:0.00130, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26797, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26798, Train Loss:0.00013, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26799, Train Loss:0.00026, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26800, Train Loss:0.00030, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26801, Train Loss:0.14068, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26802, Train Loss:0.00122, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26803, Train Loss:0.10125, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26804, Train Loss:0.07539, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26805, Train Loss:0.05875, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26806, Train Loss:0.00015, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26807, Train Loss:0.00057, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26808, Train Loss:0.00297, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26809, Train Loss:0.01397, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26810, Train Loss:0.05047, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26811, Train Loss:0.06139, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26812, Train Loss:0.00003, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26813, Train Loss:0.00069, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26814, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26815, Train Loss:0.02080, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26816, Train Loss:0.19169, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26817, Train Loss:0.10594, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26818, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26819, Train Loss:0.00036, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26820, Train Loss:0.12712, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26821, Train Loss:0.01044, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26822, Train Loss:0.06897, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26823, Train Loss:0.00046, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26824, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26825, Train Loss:0.02922, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26826, Train Loss:0.00393, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26827, Train Loss:0.15266, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26828, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26829, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26830, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26831, Train Loss:1.02720, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26832, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26833, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26834, Train Loss:0.11238, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26835, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26836, Train Loss:0.05989, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26837, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26838, Train Loss:0.37557, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26839, Train Loss:0.02170, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26840, Train Loss:0.00005, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26841, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26842, Train Loss:0.00565, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26843, Train Loss:0.09328, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26844, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26845, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26846, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26847, Train Loss:0.08816, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26848, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26849, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26850, Train Loss:0.03018, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26851, Train Loss:0.21251, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26852, Train Loss:0.01551, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26853, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26854, Train Loss:0.00076, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26855, Train Loss:0.00003, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26856, Train Loss:0.13140, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26857, Train Loss:0.00033, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26858, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26859, Train Loss:0.16356, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26860, Train Loss:0.02191, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26861, Train Loss:0.00068, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26862, Train Loss:0.01564, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26863, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26864, Train Loss:0.01326, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26865, Train Loss:0.25750, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26866, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26867, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26868, Train Loss:0.36721, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26869, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26870, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26871, Train Loss:0.00007, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26872, Train Loss:0.10615, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26873, Train Loss:0.10442, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26874, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26875, Train Loss:0.00427, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26876, Train Loss:0.02061, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26877, Train Loss:0.00005, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26878, Train Loss:0.07855, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26879, Train Loss:0.44144, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26880, Train Loss:0.05159, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26881, Train Loss:0.00004, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26882, Train Loss:0.03015, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26883, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26884, Train Loss:0.08238, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26885, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26886, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26887, Train Loss:0.04159, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26888, Train Loss:0.24252, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26889, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26890, Train Loss:0.00385, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26891, Train Loss:0.12037, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26892, Train Loss:0.11923, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26893, Train Loss:0.00147, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26894, Train Loss:0.00240, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26895, Train Loss:0.10042, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26896, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26897, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26898, Train Loss:0.06436, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26899, Train Loss:0.11662, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26900, Train Loss:0.00215, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26901, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26902, Train Loss:0.00645, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26903, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26904, Train Loss:0.00062, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26905, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26906, Train Loss:0.14001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26907, Train Loss:0.00416, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26908, Train Loss:0.04147, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26909, Train Loss:0.12530, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26910, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26911, Train Loss:0.06252, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26912, Train Loss:0.00017, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26913, Train Loss:0.00398, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26914, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26915, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26916, Train Loss:0.07772, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26917, Train Loss:0.00466, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26918, Train Loss:0.00003, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26919, Train Loss:0.00005, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26920, Train Loss:0.00010, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26921, Train Loss:0.04244, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26922, Train Loss:0.09754, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26923, Train Loss:0.02974, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26924, Train Loss:0.00298, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26925, Train Loss:0.00014, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26926, Train Loss:0.11071, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26927, Train Loss:0.05181, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26928, Train Loss:0.04492, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26929, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26930, Train Loss:0.00015, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26931, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26932, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26933, Train Loss:0.00697, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26934, Train Loss:0.37448, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26935, Train Loss:0.02180, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26936, Train Loss:0.01159, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26937, Train Loss:0.18291, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26938, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26939, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26940, Train Loss:0.02106, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26941, Train Loss:0.00004, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26942, Train Loss:0.01227, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26943, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26944, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26945, Train Loss:0.00478, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26946, Train Loss:0.00439, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26947, Train Loss:0.17707, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26948, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26949, Train Loss:0.00240, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26950, Train Loss:0.00292, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26951, Train Loss:0.00067, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26952, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26953, Train Loss:0.03898, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26954, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26955, Train Loss:0.01473, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26956, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26957, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26958, Train Loss:0.00043, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26959, Train Loss:0.00023, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26960, Train Loss:0.00009, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26961, Train Loss:0.00547, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26962, Train Loss:0.07816, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26963, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26964, Train Loss:0.01118, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26965, Train Loss:0.00047, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26966, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26967, Train Loss:0.00004, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26968, Train Loss:0.00078, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26969, Train Loss:0.12752, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26970, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26971, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26972, Train Loss:0.02218, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26973, Train Loss:0.00002, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26974, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26975, Train Loss:0.01082, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26976, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26977, Train Loss:0.44184, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26978, Train Loss:0.00105, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26979, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26980, Train Loss:0.00008, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26981, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26982, Train Loss:0.09560, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26983, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26984, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26985, Train Loss:0.23160, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26986, Train Loss:0.74400, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26987, Train Loss:0.03665, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26988, Train Loss:0.00455, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26989, Train Loss:0.01681, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26990, Train Loss:0.03333, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26991, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26992, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26993, Train Loss:0.00057, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26994, Train Loss:0.00062, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26995, Train Loss:0.00150, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26996, Train Loss:0.13277, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26997, Train Loss:0.00000, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26998, Train Loss:0.00398, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:26999, Train Loss:0.00001, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:27000, Train Loss:0.10238, Dev Loss:0.09819\n",
      "Epoch:[97/100], step:27001, Train Loss:0.00013, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27002, Train Loss:0.01161, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27003, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27004, Train Loss:0.02664, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27005, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27006, Train Loss:0.25229, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27007, Train Loss:0.10962, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27008, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27009, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27010, Train Loss:0.21447, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27011, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27012, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27013, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27014, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27015, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27016, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27017, Train Loss:0.00003, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27018, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27019, Train Loss:0.00254, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27020, Train Loss:0.01913, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27021, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27022, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27023, Train Loss:0.07747, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27024, Train Loss:0.10441, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27025, Train Loss:0.15270, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27026, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27027, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27028, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27029, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27030, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27031, Train Loss:0.00958, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27032, Train Loss:0.00004, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27033, Train Loss:0.20876, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27034, Train Loss:0.00222, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27035, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27036, Train Loss:0.03721, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27037, Train Loss:0.01631, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27038, Train Loss:0.00469, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27039, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27040, Train Loss:0.00082, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27041, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27042, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27043, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27044, Train Loss:0.03224, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27045, Train Loss:0.04334, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27046, Train Loss:0.09172, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27047, Train Loss:0.16074, Dev Loss:0.09307\n",
      "Epoch:[97/100], step:27048, Train Loss:0.00033, Dev Loss:0.09307\n",
      "Start Epoch: 98, Steps: 17\n",
      "Epoch:[98/100], step:27049, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27050, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27051, Train Loss:0.03151, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27052, Train Loss:0.07873, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27053, Train Loss:0.36622, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27054, Train Loss:0.09421, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27055, Train Loss:0.00913, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27056, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27057, Train Loss:0.17744, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27058, Train Loss:0.23549, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27059, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27060, Train Loss:0.00024, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27061, Train Loss:0.04969, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27062, Train Loss:0.04754, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27063, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27064, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27065, Train Loss:0.14468, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27066, Train Loss:0.02271, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27067, Train Loss:0.01951, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27068, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27069, Train Loss:0.00004, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27070, Train Loss:0.05015, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27071, Train Loss:0.03030, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27072, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27073, Train Loss:0.01665, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27074, Train Loss:0.43257, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27075, Train Loss:0.00043, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27076, Train Loss:0.00380, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27077, Train Loss:0.06394, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27078, Train Loss:0.02007, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27079, Train Loss:0.09871, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27080, Train Loss:1.25853, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27081, Train Loss:0.00153, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27082, Train Loss:0.04602, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27083, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27084, Train Loss:0.00042, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27085, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27086, Train Loss:0.07522, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27087, Train Loss:0.03531, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27088, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27089, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27090, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27091, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27092, Train Loss:0.04404, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27093, Train Loss:0.00790, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27094, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27095, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27096, Train Loss:0.00008, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27097, Train Loss:0.05715, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27098, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27099, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27100, Train Loss:0.07314, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27101, Train Loss:0.10004, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27102, Train Loss:0.05061, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27103, Train Loss:0.68711, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27104, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27105, Train Loss:0.08487, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27106, Train Loss:0.04974, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27107, Train Loss:0.02987, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27108, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27109, Train Loss:0.00312, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27110, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27111, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27112, Train Loss:0.00052, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27113, Train Loss:0.00338, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27114, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27115, Train Loss:1.20935, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27116, Train Loss:0.00754, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27117, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27118, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27119, Train Loss:0.37578, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27120, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27121, Train Loss:0.25991, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27122, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27123, Train Loss:0.00292, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27124, Train Loss:0.14161, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27125, Train Loss:0.16816, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27126, Train Loss:0.00564, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27127, Train Loss:0.00235, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27128, Train Loss:0.01015, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27129, Train Loss:0.02091, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27130, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27131, Train Loss:0.04191, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27132, Train Loss:0.00025, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27133, Train Loss:0.00015, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27134, Train Loss:0.00058, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27135, Train Loss:0.00352, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27136, Train Loss:0.23961, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27137, Train Loss:0.00006, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27138, Train Loss:0.26533, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27139, Train Loss:0.43156, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27140, Train Loss:0.50402, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27141, Train Loss:0.00449, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27142, Train Loss:0.00016, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27143, Train Loss:0.33115, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27144, Train Loss:0.13976, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27145, Train Loss:0.01579, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27146, Train Loss:0.04352, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27147, Train Loss:0.07179, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27148, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27149, Train Loss:0.03465, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27150, Train Loss:0.09023, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27151, Train Loss:0.00343, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27152, Train Loss:0.02081, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27153, Train Loss:0.02915, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27154, Train Loss:0.00518, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27155, Train Loss:0.00854, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27156, Train Loss:0.24167, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27157, Train Loss:0.04212, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27158, Train Loss:0.00009, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27159, Train Loss:0.51235, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27160, Train Loss:0.00018, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27161, Train Loss:0.01660, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27162, Train Loss:0.01215, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27163, Train Loss:0.00541, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27164, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27165, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27166, Train Loss:0.05137, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27167, Train Loss:0.02835, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27168, Train Loss:0.02616, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27169, Train Loss:0.00450, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27170, Train Loss:0.00604, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27171, Train Loss:0.04699, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27172, Train Loss:0.04753, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27173, Train Loss:0.00027, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27174, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27175, Train Loss:0.08310, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27176, Train Loss:0.10174, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27177, Train Loss:0.00114, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27178, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27179, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27180, Train Loss:0.39178, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27181, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27182, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27183, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27184, Train Loss:0.08988, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27185, Train Loss:0.35147, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27186, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27187, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27188, Train Loss:0.03380, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27189, Train Loss:0.00003, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27190, Train Loss:0.00045, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27191, Train Loss:0.00018, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27192, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27193, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27194, Train Loss:0.41571, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27195, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27196, Train Loss:0.00025, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27197, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27198, Train Loss:0.00927, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27199, Train Loss:0.25641, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27200, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27201, Train Loss:0.37979, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27202, Train Loss:0.01645, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27203, Train Loss:0.08245, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27204, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27205, Train Loss:0.00017, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27206, Train Loss:0.00057, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27207, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27208, Train Loss:0.12391, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27209, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27210, Train Loss:0.00001, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27211, Train Loss:0.14833, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27212, Train Loss:0.00017, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27213, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27214, Train Loss:0.06621, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27215, Train Loss:0.00104, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27216, Train Loss:0.01978, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27217, Train Loss:0.12795, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27218, Train Loss:0.22543, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27219, Train Loss:0.21522, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27220, Train Loss:0.00040, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27221, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27222, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27223, Train Loss:0.23504, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27224, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27225, Train Loss:0.01557, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27226, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27227, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27228, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27229, Train Loss:0.13158, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27230, Train Loss:0.00341, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27231, Train Loss:0.00320, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27232, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27233, Train Loss:0.00004, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27234, Train Loss:0.00056, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27235, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27236, Train Loss:0.21168, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27237, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27238, Train Loss:0.01916, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27239, Train Loss:0.07450, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27240, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27241, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27242, Train Loss:0.00191, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27243, Train Loss:0.00002, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27244, Train Loss:0.00268, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27245, Train Loss:0.51545, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27246, Train Loss:0.00026, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27247, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27248, Train Loss:0.11866, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27249, Train Loss:0.00000, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27250, Train Loss:0.16764, Dev Loss:0.09307\n",
      "Epoch:[98/100], step:27251, Train Loss:0.29102, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27252, Train Loss:0.00020, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27253, Train Loss:0.00010, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27254, Train Loss:0.51038, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27255, Train Loss:0.02979, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27256, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27257, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27258, Train Loss:0.07153, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27259, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27260, Train Loss:0.21220, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27261, Train Loss:0.00793, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27262, Train Loss:0.23034, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27263, Train Loss:0.03822, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27264, Train Loss:0.54792, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27265, Train Loss:0.00022, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27266, Train Loss:0.00017, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27267, Train Loss:0.16087, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27268, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27269, Train Loss:0.20471, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27270, Train Loss:0.00511, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27271, Train Loss:0.00026, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27272, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27273, Train Loss:0.00792, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27274, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27275, Train Loss:0.13930, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27276, Train Loss:0.00005, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27277, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27278, Train Loss:0.01317, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27279, Train Loss:0.15739, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27280, Train Loss:0.11498, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27281, Train Loss:0.09366, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27282, Train Loss:0.10216, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27283, Train Loss:0.64008, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27284, Train Loss:0.00003, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27285, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27286, Train Loss:0.09136, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27287, Train Loss:0.76817, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27288, Train Loss:0.29122, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27289, Train Loss:0.02093, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27290, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27291, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27292, Train Loss:0.11477, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27293, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27294, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27295, Train Loss:0.00660, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27296, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27297, Train Loss:0.00013, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27298, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27299, Train Loss:0.01395, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27300, Train Loss:0.14515, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27301, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27302, Train Loss:0.35034, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27303, Train Loss:0.00036, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27304, Train Loss:0.05411, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27305, Train Loss:0.01703, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27306, Train Loss:0.01026, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27307, Train Loss:0.06227, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27308, Train Loss:0.04504, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27309, Train Loss:0.00007, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27310, Train Loss:0.00010, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27311, Train Loss:0.00012, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27312, Train Loss:0.08040, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27313, Train Loss:0.43558, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27314, Train Loss:0.00005, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27315, Train Loss:0.01626, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27316, Train Loss:0.38134, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27317, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27318, Train Loss:0.00004, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27319, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27320, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27321, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27322, Train Loss:0.01162, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27323, Train Loss:0.00966, Dev Loss:0.12881\n",
      "Epoch:[98/100], step:27324, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Start Epoch: 99, Steps: 17\n",
      "Epoch:[99/100], step:27325, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27326, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27327, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27328, Train Loss:0.00013, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27329, Train Loss:0.13186, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27330, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27331, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27332, Train Loss:0.00003, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27333, Train Loss:0.00015, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27334, Train Loss:0.11666, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27335, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27336, Train Loss:0.07367, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27337, Train Loss:0.00318, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27338, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27339, Train Loss:0.10033, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27340, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27341, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27342, Train Loss:0.00006, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27343, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27344, Train Loss:0.00024, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27345, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27346, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27347, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27348, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27349, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27350, Train Loss:0.02347, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27351, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27352, Train Loss:0.15965, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27353, Train Loss:0.01177, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27354, Train Loss:0.00059, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27355, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27356, Train Loss:0.00050, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27357, Train Loss:0.00030, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27358, Train Loss:0.01146, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27359, Train Loss:0.59160, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27360, Train Loss:0.00154, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27361, Train Loss:0.22580, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27362, Train Loss:0.00002, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27363, Train Loss:0.44056, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27364, Train Loss:0.00006, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27365, Train Loss:0.06964, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27366, Train Loss:0.00052, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27367, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27368, Train Loss:0.14276, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27369, Train Loss:0.00932, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27370, Train Loss:0.00004, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27371, Train Loss:1.81695, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27372, Train Loss:0.35515, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27373, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27374, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27375, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27376, Train Loss:0.21461, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27377, Train Loss:0.00078, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27378, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27379, Train Loss:0.00185, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27380, Train Loss:0.34688, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27381, Train Loss:8.75419, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27382, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27383, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27384, Train Loss:0.00394, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27385, Train Loss:0.03772, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27386, Train Loss:0.00660, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27387, Train Loss:0.09244, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27388, Train Loss:0.16284, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27389, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27390, Train Loss:0.34554, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27391, Train Loss:0.06814, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27392, Train Loss:0.00145, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27393, Train Loss:0.03837, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27394, Train Loss:0.13996, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27395, Train Loss:0.08870, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27396, Train Loss:0.02889, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27397, Train Loss:0.00156, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27398, Train Loss:0.07146, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27399, Train Loss:0.21313, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27400, Train Loss:0.80011, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27401, Train Loss:0.02273, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27402, Train Loss:0.63179, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27403, Train Loss:0.16122, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27404, Train Loss:0.01379, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27405, Train Loss:0.04385, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27406, Train Loss:0.00064, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27407, Train Loss:0.08440, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27408, Train Loss:0.05390, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27409, Train Loss:0.08042, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27410, Train Loss:0.01596, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27411, Train Loss:0.01340, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27412, Train Loss:0.08241, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27413, Train Loss:0.00008, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27414, Train Loss:0.46527, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27415, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27416, Train Loss:0.15549, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27417, Train Loss:0.13705, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27418, Train Loss:0.14943, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27419, Train Loss:0.85709, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27420, Train Loss:0.03831, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27421, Train Loss:1.28275, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27422, Train Loss:0.36990, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27423, Train Loss:0.09328, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27424, Train Loss:0.07375, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27425, Train Loss:0.11051, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27426, Train Loss:0.07524, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27427, Train Loss:0.15698, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27428, Train Loss:0.01714, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27429, Train Loss:0.33388, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27430, Train Loss:0.34102, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27431, Train Loss:0.08711, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27432, Train Loss:0.46042, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27433, Train Loss:0.03540, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27434, Train Loss:0.36227, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27435, Train Loss:0.00010, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27436, Train Loss:0.00004, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27437, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27438, Train Loss:0.00121, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27439, Train Loss:0.08162, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27440, Train Loss:0.00003, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27441, Train Loss:0.09232, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27442, Train Loss:0.61251, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27443, Train Loss:0.04132, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27444, Train Loss:0.05543, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27445, Train Loss:0.13659, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27446, Train Loss:0.30386, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27447, Train Loss:0.00429, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27448, Train Loss:0.00026, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27449, Train Loss:0.00236, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27450, Train Loss:0.23745, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27451, Train Loss:0.23206, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27452, Train Loss:0.00348, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27453, Train Loss:0.13368, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27454, Train Loss:0.00508, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27455, Train Loss:0.00131, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27456, Train Loss:0.04856, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27457, Train Loss:0.01027, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27458, Train Loss:0.02216, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27459, Train Loss:0.00005, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27460, Train Loss:0.12990, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27461, Train Loss:0.00056, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27462, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27463, Train Loss:0.32529, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27464, Train Loss:0.18841, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27465, Train Loss:0.02565, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27466, Train Loss:0.00267, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27467, Train Loss:0.00081, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27468, Train Loss:0.11195, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27469, Train Loss:0.00004, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27470, Train Loss:0.00015, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27471, Train Loss:0.07666, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27472, Train Loss:0.19309, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27473, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27474, Train Loss:0.00470, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27475, Train Loss:0.10713, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27476, Train Loss:0.09513, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27477, Train Loss:0.00026, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27478, Train Loss:0.01383, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27479, Train Loss:0.00884, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27480, Train Loss:0.00124, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27481, Train Loss:0.20806, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27482, Train Loss:0.47048, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27483, Train Loss:0.43849, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27484, Train Loss:0.00020, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27485, Train Loss:0.09419, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27486, Train Loss:0.00001, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27487, Train Loss:0.16433, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27488, Train Loss:0.09108, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27489, Train Loss:0.11625, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27490, Train Loss:0.00145, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27491, Train Loss:0.11907, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27492, Train Loss:0.65109, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27493, Train Loss:0.08070, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27494, Train Loss:0.21110, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27495, Train Loss:0.09856, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27496, Train Loss:0.14859, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27497, Train Loss:0.14279, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27498, Train Loss:0.02210, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27499, Train Loss:0.00000, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27500, Train Loss:0.15697, Dev Loss:0.12881\n",
      "Epoch:[99/100], step:27501, Train Loss:0.36161, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27502, Train Loss:0.94002, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27503, Train Loss:0.01181, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27504, Train Loss:0.07673, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27505, Train Loss:0.00837, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27506, Train Loss:0.13820, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27507, Train Loss:0.04939, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27508, Train Loss:0.16918, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27509, Train Loss:0.06175, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27510, Train Loss:0.09072, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27511, Train Loss:0.15796, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27512, Train Loss:0.05344, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27513, Train Loss:0.03930, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27514, Train Loss:0.08373, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27515, Train Loss:0.03395, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27516, Train Loss:0.00061, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27517, Train Loss:0.00190, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27518, Train Loss:0.01752, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27519, Train Loss:0.08366, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27520, Train Loss:0.00035, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27521, Train Loss:0.06821, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27522, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27523, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27524, Train Loss:0.04313, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27525, Train Loss:0.00002, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27526, Train Loss:0.00603, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27527, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27528, Train Loss:0.00160, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27529, Train Loss:0.00423, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27530, Train Loss:0.25120, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27531, Train Loss:0.00007, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27532, Train Loss:0.00225, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27533, Train Loss:0.64188, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27534, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27535, Train Loss:0.06713, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27536, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27537, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27538, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27539, Train Loss:0.00002, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27540, Train Loss:0.00078, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27541, Train Loss:0.00024, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27542, Train Loss:0.03091, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27543, Train Loss:0.16903, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27544, Train Loss:0.00013, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27545, Train Loss:0.00125, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27546, Train Loss:0.03632, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27547, Train Loss:0.35248, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27548, Train Loss:0.06049, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27549, Train Loss:0.01939, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27550, Train Loss:0.02694, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27551, Train Loss:0.14359, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27552, Train Loss:0.18273, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27553, Train Loss:0.01941, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27554, Train Loss:0.00014, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27555, Train Loss:0.01524, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27556, Train Loss:0.08806, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27557, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27558, Train Loss:0.11518, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27559, Train Loss:0.00038, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27560, Train Loss:0.09405, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27561, Train Loss:0.02508, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27562, Train Loss:0.05609, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27563, Train Loss:0.19590, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27564, Train Loss:0.07993, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27565, Train Loss:0.00116, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27566, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27567, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27568, Train Loss:0.06748, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27569, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27570, Train Loss:0.09296, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27571, Train Loss:0.00005, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27572, Train Loss:0.50651, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27573, Train Loss:0.15548, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27574, Train Loss:0.17536, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27575, Train Loss:0.00234, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27576, Train Loss:0.00004, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27577, Train Loss:0.55821, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27578, Train Loss:0.37647, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27579, Train Loss:0.00963, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27580, Train Loss:0.20911, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27581, Train Loss:0.09094, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27582, Train Loss:0.00710, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27583, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27584, Train Loss:0.42940, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27585, Train Loss:0.77647, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27586, Train Loss:0.17720, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27587, Train Loss:0.12796, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27588, Train Loss:0.00246, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27589, Train Loss:0.00434, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27590, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27591, Train Loss:0.00000, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27592, Train Loss:0.60579, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27593, Train Loss:0.00002, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27594, Train Loss:0.16266, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27595, Train Loss:0.05268, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27596, Train Loss:0.00034, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27597, Train Loss:0.00001, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27598, Train Loss:0.04599, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27599, Train Loss:0.08993, Dev Loss:0.08796\n",
      "Epoch:[99/100], step:27600, Train Loss:0.02126, Dev Loss:0.08796\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10167.977834,
   "end_time": "2022-04-22T12:19:17.092735",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-22T09:29:49.114901",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
