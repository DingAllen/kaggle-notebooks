{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# config","metadata":{}},{"cell_type":"code","source":"# 超参配置\n\nclass Hyperparameter:\n    # ################################################################\n    #                             Data\n    # ################################################################\n    device = 'cuda'\n    data_root = './data/'\n    cifar10_root = '../input/cifar10-python/cifar-10-batches-py'\n    train_image_root = './data/train_images'\n    test_image_root = './data/test_images'\n\n    class_num = 10\n    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n    seed = 1234  # random seed\n\n    # ################################################################\n    #                             Experiment\n    # ################################################################\n    batch_size = 32\n    init_lr = 0.01\n    epochs = 20\n    verbose_step = 20\n    save_step = 10000\n\n\nHP = Hyperparameter()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:02.143424Z","iopub.execute_input":"2022-07-03T07:39:02.144123Z","iopub.status.idle":"2022-07-03T07:39:02.167074Z","shell.execute_reply.started":"2022-07-03T07:39:02.144033Z","shell.execute_reply":"2022-07-03T07:39:02.166091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# preprocess","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport json\n\nrandom.seed(HP.seed)\n\nfor foldername in ['data', 'log', 'model_save', HP.train_image_root, HP.test_image_root]:\n    if not os.path.exists(foldername):\n        os.mkdir(foldername)\n\n\ndef unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\ncls2id = {}\nfor id, cls in enumerate(HP.class_names):\n    cls2id[cls] = id\njson.dump(cls2id, open('./data/cls2id.json', 'w'))\n\nimport glob\nimport numpy as np\nimport cv2\n\nfor batch_name, image_root in [('/data_batch*', HP.train_image_root), ('/test_batch*', HP.test_image_root)]:\n    data_batch_files = HP.cifar10_root + batch_name\n    train_list = glob.glob(data_batch_files)\n\n    for l in train_list:\n        l_dict = unpickle(l)\n\n        for im_idx, im_data in enumerate(l_dict[b'data']):\n            im_label = l_dict[b'labels'][im_idx]\n            im_name = l_dict[b'filenames'][im_idx]\n\n            im_label_name = HP.class_names[im_label]\n            im_data = np.reshape(im_data, [3, 32, 32])\n            im_data = np.transpose(im_data, (1, 2, 0))\n\n            if not os.path.exists('{}/{}'.format(image_root, im_label_name)):\n                os.mkdir('{}/{}'.format(image_root, im_label_name))\n\n            cv2.imwrite('{}/{}/{}'.format(image_root, im_label_name, im_name.decode('utf-8')), im_data)\nprint('图片数据初始化完毕')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:02.170378Z","iopub.execute_input":"2022-07-03T07:39:02.170678Z","iopub.status.idle":"2022-07-03T07:39:14.86571Z","shell.execute_reply.started":"2022-07-03T07:39:02.170651Z","shell.execute_reply":"2022-07-03T07:39:14.864479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset_cifar10","metadata":{}},{"cell_type":"code","source":"import glob\nimport os.path\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom torchvision import transforms as T\nimport json\n\ncls2id = json.load(open('./data/cls2id.json', 'r'))\n\ndefault_transform = T.Compose([\n    T.ToTensor()\n])\n\n\ndef default_loader(path):\n    return Image.open(path)\n\n\nclass CifarDataset(torch.utils.data.Dataset):\n    def __init__(self, im_list, transform=default_transform, loader=default_loader):\n        imgs = []\n\n        for im_item in im_list:\n            im_label_name = im_item.split('/')[-2]\n            imgs.append((im_item, cls2id[im_label_name]))\n\n        self.imgs = imgs\n        self.transform = transform\n        self.loader = loader\n\n    def __getitem__(self, idx):\n        im_path, im_label, = self.imgs[idx]\n        im_data = self.loader(im_path)\n\n        return self.transform(im_data).to(HP.device), im_label\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:14.867433Z","iopub.execute_input":"2022-07-03T07:39:14.868073Z","iopub.status.idle":"2022-07-03T07:39:16.678433Z","shell.execute_reply.started":"2022-07-03T07:39:14.868034Z","shell.execute_reply":"2022-07-03T07:39:16.676507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass ClassiNet(nn.Module):\n\n    def __init__(self):\n        super(ClassiNet, self).__init__()\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        self.max_pooling1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n        self.conv2_1 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        self.conv2_2 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        self.max_pooling2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n        self.conv3_1 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        self.conv3_2 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        self.max_pooling3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=1)\n\n        self.conv4_1 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        self.conv4_2 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        self.max_pooling4 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(in_features=512 * 2 * 2, out_features=HP.class_num)\n        )\n\n    def forward(self, x):\n        batchsize = x.size(0)\n        out = self.conv1(x)\n        out = self.max_pooling1(out)\n\n        out = self.conv2_1(out)\n        out = self.conv2_2(out)\n        out = self.max_pooling2(out)\n\n        out = self.conv3_1(out)\n        out = self.conv3_2(out)\n        out = self.max_pooling3(out)\n\n        out = self.conv4_1(out)\n        out = self.conv4_2(out)\n        out = self.max_pooling4(out)\n\n        out = out.view(batchsize, -1)\n\n        out = self.fc(out)\n        out = F.log_softmax(out, dim=1)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:16.68116Z","iopub.execute_input":"2022-07-03T07:39:16.68178Z","iopub.status.idle":"2022-07-03T07:39:16.718091Z","shell.execute_reply.started":"2022-07-03T07:39:16.681741Z","shell.execute_reply":"2022-07-03T07:39:16.71723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainer","metadata":{}},{"cell_type":"code","source":"import os.path\nimport random\nimport torch\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nfrom argparse import ArgumentParser\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nimport glob\nfrom torchvision import transforms as T\n\nlogger = SummaryWriter('./log')\n\n# seed init: 保证模型的可复现性\ntorch.manual_seed(HP.seed)\nrandom.seed(HP.seed)\nnp.random.seed(HP.seed)\ntorch.cuda.manual_seed(HP.seed)\n\n\ndef evaluate(model, devloader, crit):\n    model.eval()\n    sum_loss = 0.\n    with torch.no_grad():\n        for batch in devloader:\n            x, y = batch\n            pred = model(x)\n            loss = crit(pred, y.to(HP.device))\n            sum_loss += loss.item()\n\n    model.train()\n    return sum_loss / len(devloader)\n\n\ndef save_checkpoint(model, epoch, opt, save_path):\n    save_dict = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': opt.state_dict()\n    }\n    torch.save(save_dict, save_path)\n\ntrain_transform = T.Compose([\n    T.RandomResizedCrop((28, 28)),\n    T.RandomHorizontalFlip(),\n    T.RandomRotation(90),\n    T.RandomGrayscale(0.1),\n    T.ColorJitter(0.3, 0.3, 0.3, 0.3),\n    T.ToTensor()\n])\n\ntest_transform = T.Compose([\n    T.Resize((28, 28)),\n    T.ToTensor()\n])\n\ndef train():\n    model = ClassiNet().to(HP.device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    opt = optim.Adam(model.parameters(), lr=HP.init_lr)\n\n    im_train_list = glob.glob('./data/train_images/*/*.png')\n    im_test_list = glob.glob('./data/test_images/*/*.png')\n\n    trainset = CifarDataset(im_train_list, transform=train_transform)\n    train_loader = DataLoader(trainset, batch_size=HP.batch_size, shuffle=True, drop_last=True)\n\n    devset = CifarDataset(im_test_list, transform=test_transform)\n    dev_loader = DataLoader(devset, batch_size=HP.batch_size, shuffle=True, drop_last=False)\n\n    start_epoch, step = 0, 0\n\n    model.train()\n\n    for epoch in range(start_epoch, HP.epochs):\n        print('Start Epoch: %d, Steps: %d' % (epoch, len(train_loader)))\n        for batch in train_loader:\n            x, y = batch  # 加载数据\n            opt.zero_grad()  # 梯度归零\n            pred = model(x)\n            loss = criterion(pred, y.to(HP.device))\n\n            loss.backward()\n            opt.step()\n\n            logger.add_scalar('Loss/Train', loss, step)\n\n            if not step % HP.verbose_step:\n                eval_loss = evaluate(model, dev_loader, criterion)\n                logger.add_scalar('Loss/Dev', eval_loss, step)\n\n            if not step % HP.save_step:\n                model_path = 'model_%d_%d.model' % (epoch, step)\n                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n\n            step += 1\n            logger.flush()\n            print('Epoch:[%d/%d], step:%d, Train Loss:%.5f, Dev Loss:%.5f' % (\n                epoch, HP.epochs, step, loss.item(), eval_loss))\n\n    logger.close()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:16.719902Z","iopub.execute_input":"2022-07-03T07:39:16.720828Z","iopub.status.idle":"2022-07-03T07:39:16.936457Z","shell.execute_reply.started":"2022-07-03T07:39:16.720775Z","shell.execute_reply":"2022-07-03T07:39:16.935459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练","metadata":{}},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:39:16.938189Z","iopub.execute_input":"2022-07-03T07:39:16.938817Z","iopub.status.idle":"2022-07-03T07:46:56.395511Z","shell.execute_reply.started":"2022-07-03T07:39:16.938775Z","shell.execute_reply":"2022-07-03T07:46:56.394082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf log.tar.gz ./log\n\nfrom IPython.display import FileLink\nFileLink('log.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T07:47:09.963151Z","iopub.execute_input":"2022-07-03T07:47:09.963559Z","iopub.status.idle":"2022-07-03T07:47:10.687467Z","shell.execute_reply.started":"2022-07-03T07:47:09.963524Z","shell.execute_reply":"2022-07-03T07:47:10.686388Z"},"trusted":true},"execution_count":null,"outputs":[]}]}