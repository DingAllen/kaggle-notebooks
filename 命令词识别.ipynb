{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"# banknote classification config\n\n# 超参配置\n# yaml\nclass Hyperparameter:\n    # ################################################################\n    #                             Data\n    # ################################################################\n    device = 'cuda'\n    data_root = './data/'\n    origin_bgn_root = '../input/gru-speech-command-prepare/_background_noise_'\n    bgn_root = './data/bgn'\n    cls_mapper_path = './data/cls_mapper.json'\n\n    metadata_train_path = './data/train_speech_commands.txt'\n    metadata_eval_path = './data/eval_speech_commands.txt'\n    metadata_test_path = './data/test_speech_commands.txt'\n\n    cls_name_list = ['bgn', 'down', 'go', 'left', 'off', 'on', 'right', 'stop']\n    cls_folder_name_list = [\n        './data/bgn',\n        '../input/gru-speech-command-prepare/down',\n        '../input/gru-speech-command-prepare/go',\n        '../input/gru-speech-command-prepare/left',\n        '../input/gru-speech-command-prepare/off',\n        '../input/gru-speech-command-prepare/on',\n        '../input/gru-speech-command-prepare/right',\n        '../input/gru-speech-command-prepare/stop'\n    ]\n\n    class_num = 8\n    mel_size = 40\n    seed = 1234  # random seed\n\n    # ################################################################\n    #                             Model Structure\n    # ################################################################\n    data_point_channel = mel_size\n    rnn_hidden_dim = 256\n    rnn_layer_num = 2\n    is_bidirection = True\n    fc_drop = 0.3\n\n    # ################################################################\n    #                             Experiment\n    # ################################################################\n    batch_size = 8\n    init_lr = 5e-4\n    epochs = 5\n    verbose_step = 50\n    save_step = 500\n\n\nHP = Hyperparameter()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T03:16:28.580566Z","iopub.execute_input":"2022-04-25T03:16:28.580853Z","iopub.status.idle":"2022-04-25T03:16:28.590617Z","shell.execute_reply.started":"2022-04-25T03:16:28.580797Z","shell.execute_reply":"2022-04-25T03:16:28.589719Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## utils","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torchaudio\n\ndef gen_cls_mapper(cls_name_list):\n\n    cls_mapper = {\n        'cls2id': {},\n        'id2cls': {}\n    }\n\n    for i, name in enumerate(cls_name_list):\n        cls_mapper['cls2id'][name] = i\n        cls_mapper['id2cls'][i] = name\n\n    return cls_mapper\n\n# 获取某个文件夹下面所有后缀为suffix的文件，返回path的list\ndef recursive_fetching(root, suffix=['jpg', 'png']):\n    all_file_path = []\n\n    def get_all_files(path):\n        all_file_list = os.listdir(path)\n        # 遍历该文件夹下的所有目录或者文件\n        for file in all_file_list:\n            filepath = os.path.join(path, file)\n            # 如果是文件夹，递归调用函数\n            if os.path.isdir(filepath):\n                get_all_files(filepath)\n            # 如果不是文件夹，保存文件路径及文件名\n            elif os.path.isfile(filepath):\n                all_file_path.append(filepath)\n\n    get_all_files(root)\n\n    file_paths = [it for it in all_file_path if os.path.split(it)[-1].split('.')[-1].lower() in suffix]\n\n    return file_paths\n\n\ndef load_meta(meta_path):\n    with open(meta_path, 'r') as fr:\n        return [line.strip().split('|') for line in fr.readlines()]\n\n\ndef load_mel(audio_path):\n    wave, sampling_rate = torchaudio.load(audio_path)\n    mel = torchaudio.transforms.MelSpectrogram(sample_rate=sampling_rate, n_mels=40)(wave).squeeze(0)\n    return mel\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T03:16:31.540023Z","iopub.execute_input":"2022-04-25T03:16:31.540562Z","iopub.status.idle":"2022-04-25T03:16:31.551286Z","shell.execute_reply.started":"2022-04-25T03:16:31.540525Z","shell.execute_reply":"2022-04-25T03:16:31.550209Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## preprocess","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport json\nfrom scipy.io import wavfile as wf\n\nrandom.seed(HP.seed)\n\nfor foldername in ['data', 'log', 'model_save', 'data/bgn']:\n    if not os.path.exists(foldername):\n        os.mkdir(foldername)\n\ndef chop_bgn():\n    '''\n    将原始的噪声，以200ms为步长剪切为多个长度为1000ms的噪声片段\n    '''\n\n    wav_files = recursive_fetching(HP.origin_bgn_root, suffix=['wav', 'WAV'])\n\n    for wav_file in wav_files:\n        file_name = os.path.split(wav_file)[-1]\n        sampling_rate, data = wf.read(wav_file)\n        data_len = data.shape[0]\n        len_200ms = int(sampling_rate/5) # sampling_rate * 200 / 1000\n        count = round(data_len/len_200ms)\n\n        for i in range(count):\n            segment = data[i*len_200ms:i*len_200ms+sampling_rate]\n            output_file_name = \"seg-%04d-%s\" % (i, file_name)\n            wf.write(os.path.join(HP.bgn_root, output_file_name), sampling_rate, segment)\n\nchop_bgn()\n\n# 构建类别到id的映射\ncls_mapper = gen_cls_mapper(HP.cls_name_list)\njson.dump(cls_mapper, open(HP.cls_mapper_path, 'w'))\n\n# 获取train和test的数据集，并将它们合并\ndataset = []\nfor cls_folder_name in HP.cls_folder_name_list:\n    dataset.extend(recursive_fetching(cls_folder_name, suffix=['wav']))\ndataset_num = len(dataset)\nprint(\"Number of total items is\", dataset_num)\nrandom.shuffle(dataset)\n\ndataset_dict = {}\nfor it in dataset:\n    cls_name = os.path.split(os.path.split(it)[0])[-1]\n    cls_id = cls_mapper['cls2id'][cls_name]\n    if cls_id not in dataset_dict:\n        dataset_dict[cls_id] = [it]\n    else:\n        dataset_dict[cls_id].append(it)\n\n# 自己划分训练集、评价集和测试集\ntrain_ratio, eval_ratio, test_ratio = 0.8, 0.1, 0.1\ntrain_set, eval_set, test_set = [], [], [],\nfor _, set_list in dataset_dict.items():\n    length = len(set_list)\n    train_num, eval_num = int(length * train_ratio), int(length * eval_ratio)\n    test_num = length - train_num - eval_num\n    random.shuffle(set_list)\n    train_set.extend(set_list[:train_num])\n    eval_set.extend(set_list[train_num:train_num + eval_num])\n    test_set.extend(set_list[train_num + eval_num:])\n\n# 再次随机打乱\nrandom.shuffle(train_set)\nrandom.shuffle(eval_set)\nrandom.shuffle(test_set)\n\nprint('num of trainset : %d' % (len(train_set)))\nprint('num of evalset : %d' % (len(eval_set)))\nprint('num of testset : %d' % (len(test_set)))\n\nwith open(HP.metadata_train_path, 'w') as fw:\n    for path in train_set:\n        fn_start = os.path.split(os.path.split(path)[0])[-1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))\n\nwith open(HP.metadata_eval_path, 'w') as fw:\n    for path in eval_set:\n        fn_start = os.path.split(os.path.split(path)[0])[-1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))\n\nwith open(HP.metadata_test_path, 'w') as fw:\n    for path in test_set:\n        fn_start = os.path.split(os.path.split(path)[0])[-1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, path))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:05:24.642972Z","iopub.execute_input":"2022-04-25T02:05:24.643233Z","iopub.status.idle":"2022-04-25T02:06:26.180228Z","shell.execute_reply.started":"2022-04-25T02:05:24.643197Z","shell.execute_reply":"2022-04-25T02:06:26.179489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset_kws","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass KWSDataset(torch.utils.data.Dataset):\n\n    def __init__(self, metadata_path):\n        self.dataset = load_meta(metadata_path)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        cls_id, path = int(item[0]), item[1]\n        mel = load_mel(path) # [data_point_dim, sequence_len] = [40, ?]\n        # [x,x,x,x,x,0,0]\n        # [x,x,x,x,x,x,x]\n        return mel.to(HP.device), cls_id # cls_int\n\n    def __len__(self):\n        return len(self.dataset)\n\n\n# batch : 8\ndef collate_fn(batch):\n    # [(mel cls_id),(mel cls_id),(mel cls_id),(mel cls_id)...]\n    sorted_batch = sorted(batch, key=lambda b: b[0].size(1), reverse=True)\n    # get all mel and pad them: mel defaul dim: [40, ?]=[datapoint_dim, L] -> [L, datapoint_dim]\n    mel_list = [item[0].transpose(0, 1) for item in sorted_batch]\n    # [sequence, batch, datapoint_dim], [batch, sequence, datapoint_dim]\n    mel_padded = pad_sequence(mel_list, batch_first=True)\n    labels = torch.LongTensor([item[1] for item in sorted_batch]) # transfer labels to long tensor\n    mel_lengths = torch.LongTensor([item.size(0) for item in mel_list])\n    return mel_padded, mel_lengths, labels\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T03:16:38.726545Z","iopub.execute_input":"2022-04-25T03:16:38.726801Z","iopub.status.idle":"2022-04-25T03:16:38.735553Z","shell.execute_reply.started":"2022-04-25T03:16:38.726771Z","shell.execute_reply":"2022-04-25T03:16:38.734883Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\n\nclass SpeechCommandModel(nn.Module):\n\n    def __init__(self):\n        super(SpeechCommandModel, self).__init__()\n\n        self.rnn = nn.GRU(\n            input_size=HP.data_point_channel,\n            hidden_size=HP.rnn_hidden_dim,\n            num_layers=HP.rnn_layer_num,\n            bidirectional=HP.is_bidirection\n        )\n\n        fc_in_dim = 2 * HP.rnn_hidden_dim if HP.is_bidirection else HP.rnn_hidden_dim\n\n        self.fc = nn.Sequential(\n            nn.Linear(fc_in_dim, 1024),\n            nn.Mish(),\n            nn.Dropout(HP.fc_drop),\n            nn.Linear(1024, 512),\n            nn.Mish(),\n            nn.Dropout(HP.fc_drop),\n            nn.Linear(512, HP.class_num)\n        )\n\n    def forward(self, mel_input, mel_lengths):\n        mel_input = mel_input.permute(1, 0, 2)\n        mel_packed = pack_padded_sequence(mel_input, mel_lengths)\n        output_packed, hn = self.rnn(mel_packed)\n        output, _ = pad_packed_sequence(output_packed)\n\n        # if语句在模型迁移后使用可能出现bug，此处这么写仅为学习，实际模型搭建过程中应避免\n        if HP.is_bidirection:\n            forward_feature = output[-1, :, :HP.rnn_hidden_dim]\n            backward_feature = output[0, :, HP.rnn_hidden_dim:]\n            fc_in = torch.cat((forward_feature, backward_feature), dim=-1)\n            cls_output = self.fc(fc_in)\n        else:\n            cls_output = self.fc(output[-1])\n        \n        return cls_output\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T03:16:41.649807Z","iopub.execute_input":"2022-04-25T03:16:41.650557Z","iopub.status.idle":"2022-04-25T03:16:41.661071Z","shell.execute_reply.started":"2022-04-25T03:16:41.650517Z","shell.execute_reply":"2022-04-25T03:16:41.660212Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## trainer","metadata":{}},{"cell_type":"code","source":"import os.path\nimport random\nimport torch\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\n\nlogger = SummaryWriter('./log')\n\n# seed init: 保证模型的可复现性\ntorch.manual_seed(HP.seed)\nrandom.seed(HP.seed)\nnp.random.seed(HP.seed)\ntorch.cuda.manual_seed(HP.seed)\n\n\ndef evaluate(model, devloader, crit):\n    model.eval()\n    sum_loss = 0.\n    with torch.no_grad():\n        for batch in devloader:\n            x, x_lens, y = batch\n            pred = model(x, x_lens)\n            loss = crit(pred, y.to(HP.device))\n            sum_loss += loss.item()\n\n    model.train()\n    return sum_loss / len(devloader)\n\n\ndef save_checkpoint(model, epoch, opt, save_path):\n    save_dict = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': opt.state_dict()\n    }\n    torch.save(save_dict, save_path)\n\n\ndef train():\n\n    model = SpeechCommandModel().to(HP.device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    opt = optim.Adam(model.parameters(), lr=HP.init_lr)\n\n    trainset = KWSDataset(HP.metadata_train_path)\n    train_loader = DataLoader(trainset, batch_size=HP.batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn)\n\n    devset = KWSDataset(HP.metadata_eval_path)\n    dev_loader = DataLoader(devset, batch_size=HP.batch_size, shuffle=True, drop_last=False, collate_fn=collate_fn)\n\n    start_epoch, step = 0, 0\n\n    model.train()\n\n    for epoch in range(start_epoch, HP.epochs):\n        print('Start Epoch: %d, Steps: %d' % (epoch, len(train_loader)))\n        for batch in train_loader:\n            x, x_len, y = batch  # 加载数据\n            opt.zero_grad()  # 梯度归零\n            pred = model(x, x_len)\n            loss = criterion(pred, y.to(HP.device))\n\n            loss.backward()\n            opt.step()\n\n            logger.add_scalar('Loss/Train', loss, step)\n\n            if not step % HP.verbose_step:\n                eval_loss = evaluate(model, dev_loader, criterion)\n                logger.add_scalar('Loss/Dev', eval_loss, step)\n\n            if not step % HP.save_step:\n                model_path = 'model_%d_%d.model' % (epoch, step)\n                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n\n            step += 1\n            logger.flush()\n            print('Epoch:[%d/%d], step:%d, Train Loss:%.5f, Dev Loss:%.5f' % (\n                epoch, HP.epochs, step, loss.item(), eval_loss))\n\n    torch.save(model, \"kws_model.dm\")\n\n    logger.close()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:07:14.749794Z","iopub.execute_input":"2022-04-25T02:07:14.750238Z","iopub.status.idle":"2022-04-25T02:07:14.931709Z","shell.execute_reply.started":"2022-04-25T02:07:14.750201Z","shell.execute_reply":"2022-04-25T02:07:14.931005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 训练","metadata":{}},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:07:18.462736Z","iopub.execute_input":"2022-04-25T02:07:18.463326Z","iopub.status.idle":"2022-04-25T02:35:59.924661Z","shell.execute_reply.started":"2022-04-25T02:07:18.463288Z","shell.execute_reply":"2022-04-25T02:35:59.923667Z"},"trusted":true},"execution_count":null,"outputs":[]}]}