{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"# 超参配置\n\nclass Hyperparameter:\n    # ################################################################\n    #                             Data\n    # ################################################################\n    device = 'cuda'\n    data_root = './data/'\n    origin_jpg_root = '../input/resnet-transferlearning-action-prepare/data'\n    cls_mapper_path = '../input/resnet-transferlearning-action-prepare/cls_mapper.json'\n\n    metadata_train_path = './data/meta_train.txt'\n    metadata_dev_path = './data/meta_dev.txt'\n    metadata_test_path = './data/meta_test.txt'\n\n    class_num = 11\n    seed = 1234  # random seed\n\n    # ################################################################\n    #                             Model Structure\n    # ################################################################\n    if_conv_frozen = False\n\n    # ################################################################\n    #                             Experiment\n    # ################################################################\n    batch_size = 128\n    init_lr = 5e-4\n    epochs = 30\n    verbose_step = 20\n    save_step = 100\n\n\nHP = Hyperparameter()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:42.01497Z","iopub.execute_input":"2022-05-03T01:39:42.015308Z","iopub.status.idle":"2022-05-03T01:39:42.045242Z","shell.execute_reply.started":"2022-05-03T01:39:42.015222Z","shell.execute_reply":"2022-05-03T01:39:42.044495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## utils","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\n\n# 获取某个文件夹下面所有后缀为suffix的文件，返回path的list\ndef recursive_fetching(root, suffix=['jpg', 'png']):\n    all_file_path = []\n\n    def get_all_files(path):\n        all_file_list = os.listdir(path)\n        # 遍历该文件夹下的所有目录或者文件\n        for file in all_file_list:\n            filepath = os.path.join(path, file)\n            # 如果是文件夹，递归调用函数\n            if os.path.isdir(filepath):\n                get_all_files(filepath)\n            # 如果不是文件夹，保存文件路径及文件名\n            elif os.path.isfile(filepath):\n                all_file_path.append(filepath)\n\n    get_all_files(root)\n\n    file_paths = [it for it in all_file_path if os.path.split(it)[-1].split('.')[-1].lower() in suffix]\n\n    return file_paths\n\n\ndef load_meta(meta_path):\n    with open(meta_path, 'r') as fr:\n        return [line.strip().split('|') for line in fr.readlines()]\n\n\ndef load_image(image_path):\n    return Image.open(image_path)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:42.046822Z","iopub.execute_input":"2022-05-03T01:39:42.047287Z","iopub.status.idle":"2022-05-03T01:39:42.056233Z","shell.execute_reply.started":"2022-05-03T01:39:42.047249Z","shell.execute_reply":"2022-05-03T01:39:42.055429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preprocess","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport random\n\nrandom.seed(HP.seed)\n\ncls_mapper = json.load(open(HP.cls_mapper_path, 'r'))\n\nfor foldername in ['data', 'log', 'model_save']:\n    if not os.path.exists(foldername):\n        os.mkdir(foldername)\n\ndata_list = os.listdir(HP.origin_jpg_root)\n\nrandom.shuffle(data_list)\n\ntrain_ratio, dev_ratio, test_ratio = 0.8, 0.1, 0.1\navi_list_len = len(data_list)\ntrain_len, dev_len = int(avi_list_len * train_ratio), int(avi_list_len * dev_ratio),\ntrain_set, dev_set, test_set = data_list[:train_len], data_list[train_len:train_len + dev_len], data_list[train_len + dev_len:]\n\nwith open(HP.metadata_train_path, 'w') as fw:\n    for path in train_set:\n        fn_start = os.path.split(path)[-1].split('_')[1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, os.path.join(HP.origin_jpg_root, path)))\n\nwith open(HP.metadata_dev_path, 'w') as fw:\n    for path in dev_set:\n        fn_start = os.path.split(path)[-1].split('_')[1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, os.path.join(HP.origin_jpg_root, path)))\n\nwith open(HP.metadata_test_path, 'w') as fw:\n    for path in test_set:\n        fn_start = os.path.split(path)[-1].split('_')[1]\n        cls_id = cls_mapper['cls2id'][fn_start]\n        fw.write('%d|%s\\n' % (cls_id, os.path.join(HP.origin_jpg_root, path)))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:42.058995Z","iopub.execute_input":"2022-05-03T01:39:42.05925Z","iopub.status.idle":"2022-05-03T01:39:42.620616Z","shell.execute_reply.started":"2022-05-03T01:39:42.059198Z","shell.execute_reply":"2022-05-03T01:39:42.619876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset_action","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\nac_transform = T.Compose([\n    T.Resize((112, 112)),  # 保证同样输入的shape\n    T.RandomRotation(degrees=45),  # 减小倾斜图片影响\n    T.GaussianBlur(kernel_size=(3, 3)),  # 抑制模糊图片的影响\n    T.RandomHorizontalFlip(),  # 左右\n    T.ToTensor(),  # 归一化 & float32 tensor\n    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 标准化\n])\n\n\nclass ActionDataset(torch.utils.data.Dataset):\n    def __init__(self, metadata_path):\n        self.dataset = load_meta(metadata_path)  # [(0, image_path), () ,...]\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        cls_id, path = int(item[0]), item[1]\n        image = load_image(path)\n        return ac_transform(image).to(HP.device), cls_id\n\n    def __len__(self):\n        return len(self.dataset)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:42.62226Z","iopub.execute_input":"2022-05-03T01:39:42.622503Z","iopub.status.idle":"2022-05-03T01:39:44.414616Z","shell.execute_reply.started":"2022-05-03T01:39:42.62247Z","shell.execute_reply":"2022-05-03T01:39:44.413851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torchvision\n\n\nclass TLNet(nn.Module):\n\n    def __init__(self):\n        super(TLNet, self).__init__()\n        self.model = torchvision.models.resnet34(pretrained=True)\n        if HP.if_conv_frozen:\n            for k, v in self.model.named_parameters():\n                v.requires_grad = False\n        resnet_fc_dim = self.model.fc.in_features\n        new_fc_layer = nn.Linear(resnet_fc_dim, HP.class_num)\n        self.model.fc = new_fc_layer\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:44.416764Z","iopub.execute_input":"2022-05-03T01:39:44.417179Z","iopub.status.idle":"2022-05-03T01:39:44.424Z","shell.execute_reply.started":"2022-05-03T01:39:44.417139Z","shell.execute_reply":"2022-05-03T01:39:44.423223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## trainer","metadata":{}},{"cell_type":"code","source":"import os.path\nimport random\nimport torch\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\n\nlogger = SummaryWriter('./log')\n\n# seed init: 保证模型的可复现性\ntorch.manual_seed(HP.seed)\nrandom.seed(HP.seed)\nnp.random.seed(HP.seed)\ntorch.cuda.manual_seed(HP.seed)\n\n\ndef evaluate(model, devloader, crit):\n    model.eval()\n    sum_loss = 0.\n    with torch.no_grad():\n        for batch in devloader:\n            x, y = batch\n            pred = model(x)\n            loss = crit(pred, y.to(HP.device))\n            sum_loss += loss.item()\n\n    model.train()\n    return sum_loss / len(devloader)\n\n\ndef save_checkpoint(model, epoch, opt, save_path):\n    save_dict = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': opt.state_dict()\n    }\n    torch.save(save_dict, save_path)\n\n\ndef train():\n\n    model = TLNet().to(HP.device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    opt = optim.Adam(model.parameters(), lr=HP.init_lr)\n\n    trainset = ActionDataset(HP.metadata_train_path)\n    train_loader = DataLoader(trainset, batch_size=HP.batch_size, shuffle=True, drop_last=True)\n\n    devset = ActionDataset(HP.metadata_dev_path)\n    dev_loader = DataLoader(devset, batch_size=HP.batch_size, shuffle=True, drop_last=False)\n\n    start_epoch, step = 0, 0\n\n    model.train()\n\n    for epoch in range(start_epoch, HP.epochs):\n        print('Start Epoch: %d, Steps: %d' % (epoch, len(train_loader)))\n        for batch in train_loader:\n            x, y = batch  # 加载数据\n            opt.zero_grad()  # 梯度归零\n            pred = model(x)\n            loss = criterion(pred, y.to(HP.device))\n\n            loss.backward()\n            opt.step()\n\n            logger.add_scalar('Loss/Train', loss, step)\n\n            if not step % HP.verbose_step:\n                eval_loss = evaluate(model, dev_loader, criterion)\n                logger.add_scalar('Loss/Dev', eval_loss, step)\n\n            if not step % HP.save_step:\n                model_path = 'model_%d_%d.model' % (epoch, step)\n                save_checkpoint(model, epoch, opt, os.path.join('model_save', model_path))\n\n            step += 1\n            logger.flush()\n            print('Epoch:[%d/%d], step:%d, Train Loss:%.5f, Dev Loss:%.5f' % (\n                epoch, HP.epochs, step, loss.item(), eval_loss))\n\n    logger.close()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:44.427339Z","iopub.execute_input":"2022-05-03T01:39:44.427537Z","iopub.status.idle":"2022-05-03T01:39:44.615732Z","shell.execute_reply.started":"2022-05-03T01:39:44.427513Z","shell.execute_reply":"2022-05-03T01:39:44.615065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 训练","metadata":{}},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T01:39:44.616864Z","iopub.execute_input":"2022-05-03T01:39:44.617117Z","iopub.status.idle":"2022-05-03T01:41:37.792161Z","shell.execute_reply.started":"2022-05-03T01:39:44.617074Z","shell.execute_reply":"2022-05-03T01:41:37.790909Z"},"trusted":true},"execution_count":null,"outputs":[]}]}